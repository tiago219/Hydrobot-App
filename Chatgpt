
Perfeito — o “pisca” acontece porque alguns frames não retornam nada e o app mostra 0 imediatamente. Resolvi isso no servidor, dando um “voto/hold” temporal nos objetos (como você já faz para o fogo): se aparecer pessoa/animal em alguns frames dentro de uma janela, o servidor mantém o estado por um curto período (histerese + cooldown). O app praticamente não precisa mudar.


Abaixo vai o server_heuristic.py completo (idêntico ao anterior para fogo e stream). A única diferença relevante está na classe ObjectsDetector, que agora:




mantém votos (janela deslizante) para pessoa e animais (VOTE_WIN_OBJ, VOTE_NEED_OBJ);


aplica hold de alguns ms após a última detecção (HOLD_MS_OBJ) para não piscar;


publica no JSON campos prontos para UI:



n_person_stable (0/1), n_animals_stable (0/1) — estado suavizado


n_person e n_animals — contagem bruta daquele frame


objects — lista de caixas como antes









1) Substitua hydrobot-server/server_heuristic.py por este (COMPLETO)


# server_heuristic.py
# FOGO (heurístico, inalterado) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny) com votação/hold anti-pisca
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0
JPEG_QUALITY = 85

# ===================== FOGO (seu, inalterado) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

# anti-pisca (votação/hold) — ajuste fino aqui
VOTE_WIN_OBJ   = 10   # últimos N frames considerados
VOTE_NEED_OBJ  = 3    # precisa de pelo menos 3 "acertos" nessa janela
HOLD_MS_OBJ    = 900  # mantém ligado por 0.9s após o último acerto

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}
MNET_IN_SIZE = (300,300); MNET_SCALE = 0.007843; MNET_MEAN = 127.5
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# YOLOv4-tiny (COCO)
YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"
YOLO_IN_SZ = (416,416)

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (AutoBackend, Stable)", version="1.6.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip: self._ip = ip
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200: time.sleep(0.5); continue
                    buf = b""; MAX_BYTES = 4_000_000
                    self._frames = 0; self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VISÃO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area: boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else: self._persist_hits = 1
            else: self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
            elif ema<=HYST_LOW: guess=0
            else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)

            self._det_frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval: time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {"ok":True,"isFire":self._is_fire,"score":round(self._score_ema,3),
                    "score_raw":round(self._score_raw,3),"score_ema":round(self._score_ema,3),
                    "boxes":self._boxes,"ts":self._last_result_ts,"fps_det":round(self._det_fps,2),
                    "vote":{"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                    "persist":{"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                    "hyst":{"hi":HYST_HIGH,"lo":HYST_LOW}}
detector = Detector(grabber); detector.start()

# ===================== OBJETOS (AutoBackend + votos/hold) =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        # estado backend
        self.backend = "mobilenet-ssd"   # ou "yolov4-tiny"
        self.net = None; self.ok = False
        self.proto = None; self.weights = None; self.cfg = None; self.names = None
        self.labels = []
        self.swap_rb = False  # usado só no MNet
        self._nohit = 0
        self._last_conf_max = 0.0

        # votos/hold
        self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
        self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
        self.hold_person_until = 0
        self.hold_animal_until = 0

        # FPS/resultado
        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    # ---------- loaders ----------
    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
        self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok = False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok = False; self.net=None

    def _try_load_yolo(self):
        self.backend = "yolov4-tiny"
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    # ---------- thread ----------
    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,MNET_IN_SIZE),
                                     MNET_SCALE, MNET_IN_SIZE, MNET_MEAN, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in MNET_ANIMALS: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, YOLO_IN_SZ, swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            out=[]; cmax=0.0; backend=self.backend
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        # fallback swapRB se não houver sinais por ~1s
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False
                    with self._lock:
                        self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                                    "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            # fallback para YOLO se MNet estiver “mudo”
            if (backend=="mobilenet-ssd" and cmax<0.05 and
                os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
                self._try_load_yolo()
                backend=self.backend
                if self.ok and self.backend=="yolov4-tiny":
                    out,cmax = self._infer_yolo(frame, max(0.2, OBJ_CONF_THRESH))

            # ---- votos/hold (anti-pisca) ----
            n_person  = sum(1 for o in out if o["label"]=="person")
            n_animals = sum(1 for o in out if o["label"]!="person")
            hit_person  = 1 if n_person  > 0 else 0
            hit_animal  = 1 if n_animals > 0 else 0
            self.votes_person.append(hit_person)
            self.votes_animal.append(hit_animal)
            now_ms = int(time.time()*1000)
            if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
            if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
            stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
            stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "proto":self.proto,"weights":self.weights,"cfg":YOLO_CFG if backend=="yolov4-tiny" else None,
                            "names":COCO_NAMES if backend=="yolov4-tiny" else None,
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                            "n_person":n_person,"n_animals":n_animals,
                            "n_person_stable":1 if stable_person else 0,
                            "n_animals_stable":1 if stable_animal else 0}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status(); s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    # fallback rápido (fogo somente)
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get(); backend = o.get("backend"); det = objects_det
    try:
        if backend=="yolov4-tiny":
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, conf)))
        else:
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, conf)))
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get(); s = grabber.status()
    return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
            "proto":o.get("proto"), "weights":o.get("weights"),
            "cfg":o.get("cfg"), "names":o.get("names"),
            "swap_rb":o.get("swap_rb"), "conf_max":o.get("conf_max"),
            "conf_thresh":OBJ_CONF_THRESH, "fps_obj":o.get("fps_obj"),
            "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
            "n_person":o.get("n_person"), "n_animals":o.get("n_animals"),
            "n_person_stable":o.get("n_person_stable"), "n_animals_stable":o.get("n_animals_stable"),
            "num_objects":len(o.get("objects",[])), "error":o.get("error")}




2) (Opcional) Pequeno ajuste no app para usar os campos “estáveis”


Se sua CameraScreen.tsx hoje faz algo como:


const objs = j.objects?.objects || [];
const people = objs.filter(o => o.label === "person").length;
const animals = objs.filter(o => o.label !== "person").length;



troque por:


const objs = j.objects?.objects || [];
const people = j.objects?.n_person_stable ?? j.objects?.n_person ?? objs.filter(o => o.label === "person").length;
const animals = j.objects?.n_animals_stable ?? j.objects?.n_animals ?? objs.filter(o => o.label !== "person").length;



Assim, a UI já pega o sinal com histerese do servidor (sem piscar).



3) Como testar




Reinicie o servidor:

uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload





Abra http://SEU_PC:8000/objects e depois http://SEU_PC:8000/debug_models.

Veja n_person_stable / n_animals_stable mudando para 1 e ficando por ~1 segundo após sair do quadro.


No app, tocar Detectar e observar que Pessoas / Animais não “piscam” mais.




Se quiser ainda mais “pegajoso”, aumente:




VOTE_WIN_OBJ para 12,


VOTE_NEED_OBJ para 4,


HOLD_MS_OBJ para 1200–1500.
































Aqui está o HydroBotApp2/src/screens/CameraScreen.tsx completo, já lendo os campos estáveis do servidor (n_person_stable, n_animals_stable) e mostrando um preview opcional com caixas usando /objects_frame. Não mexe na detecção — só no visual/comunicação.


// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
  Image,
  Animated,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = {
  bg: "#000000",
  card: "#0d0d0d",
  border: "#1a1a1a",
  red: "#E53B2F",
  white: "#ffffff",
};

const textsByLang = {
  pt: {
    espIp: "ESP IP:",
    test: "Testar",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "BOMBA ON",
    pumpOff: "BOMBA OFF",
    server: "Servidor:",
    detect: "Detectar",
    detecting: "Detectando",
    saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem vídeo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `🔥 FOGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Visão:",
    stream: "STREAM (rápido)",
    snapshot: "SNAPSHOT (fallback)",
    persons: "Pessoas",
    animals: "Animais",
    boxes: "Caixas",
    backend: "Modelo",
  },
  en: {
    espIp: "ESP IP:",
    test: "Test",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "PUMP ON",
    pumpOff: "PUMP OFF",
    server: "Server:",
    detect: "Detect",
    detecting: "Detecting",
    saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `🔥 FIRE • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "View:",
    stream: "STREAM (fast)",
    snapshot: "SNAPSHOT (fallback)",
    persons: "People",
    animals: "Animals",
    boxes: "Boxes",
    backend: "Model",
  },
  es: {
    espIp: "ESP IP:",
    test: "Probar",
    ledOn: "LED ENC.",
    ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.",
    pumpOff: "BOMBA APAG.",
    server: "Servidor:",
    detect: "Detectar",
    detecting: "Detectando",
    saving: "Guardando...",
    statusFail: "Error de conexión. Revisa Wi-Fi/IP.",
    noVideo: "Sin vídeo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `🔥 FUEGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vista:",
    stream: "STREAM (rápido)",
    snapshot: "SNAPSHOT (fallback)",
    persons: "Personas",
    animals: "Animales",
    boxes: "Cajas",
    backend: "Modelo",
  },
};

const DEFAULT_IP = "192.168.4.1";
const DEFAULT_SERVER = "http://192.168.4.2:8000";

/* --------------------------
   STREAM MJPEG (>=20 FPS)
---------------------------*/
function LiveMJPEG({ ip }: { ip: string }) {
  const html = `
    <html><head><meta name="viewport" content="width=device-width, initial-scale=1">
      <style>
        html,body{margin:0;padding:0;background:#000;height:100%;}
        .wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;background:#000;}
        img{max-width:100%;max-height:100%;object-fit:contain;background:#000;}
      </style>
    </head>
    <body>
      <div class="wrap"><img src="http://${ip}:81/stream" /></div>
    </body></html>
  `.trim();

  return (
    <WebView
      originWhitelist={["*"]}
      source={{ html }}
      javaScriptEnabled
      allowsInlineMediaPlayback
      mediaPlaybackRequiresUserAction={false}
      automaticallyAdjustContentInsets={false}
      style={{ flex: 1, backgroundColor: "black" }}
    />
  );
}

/* --------------------------
   SNAPSHOT com crossfade
---------------------------*/
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: () => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}

      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={onNextShown}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown();
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conexões
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState("—");
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detecção
  const [detectOn, setDetectOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);

  // pessoas/animais (usando campos estáveis do servidor)
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("—");
  const [confMax, setConfMax] = useState<number>(0);

  // preview de caixas
  const [showBoxes, setShowBoxes] = useState(false);
  const [boxesUri, setBoxesUri] = useState("");

  // registro automático (aproveita seu fluxo)
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // visão
  const [useStream, setUseStream] = useState(true);
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(`OK • ip:${j.ip} • mode:${j.mode} • led:${j.led ? "on" : "off"} • pump:${j.pump ? "on" : "off"}`);
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() {
    try {
      const t = !ledOn;
      await fetch(ledUrl(t));
      setLedOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  async function togglePump() {
    try {
      const t = !pumpOn;
      await fetch(pumpUrl(t));
      setPumpOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  useEffect(() => {
    pingStatus();
    const id = setInterval(pingStatus, 5000);
    return () => clearInterval(id);
  }, [statusUrl]);

  /* ===== Vídeo SNAPSHOT fallback (25 fps alvo) ===== */
  useEffect(() => {
    if (useStream) return;
    let stop = false;
    const FPS_INTERVAL = 40; // ~25 fps

    setCurrentFrameUri(`${cleanServer(server)}/snapshot?ts=${Date.now()}`);

    const tick = () => {
      if (stop) return;
      if (!loadingNextRef.current) {
        const url = `${cleanServer(server)}/snapshot?ts=${Date.now()}`;
        setNextFrameUri(url);
      }
      setTimeout(tick, FPS_INTERVAL);
    };
    tick();

    return () => {
      stop = true;
    };
  }, [server, useStream]);

  function onNextLoadStart() {
    loadingNextRef.current = true;
  }
  function onNextShown() {
    if (nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== LOOP DE DETECÇÃO ===== */
  useEffect(() => {
    if (!detectOn) return;
    let stop = false;

    const loop = async () => {
      try {
        const r = await fetch(`${cleanServer(server)}/detect`);
        const j = await r.json();

        if (!stop && j && j.ok !== false) {
          // fogo
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          // objetos (usar valores estáveis quando existir)
          const o = j.objects || {};
          const objs = o.objects || [];
          const peopleStable =
            typeof o.n_person_stable === "number"
              ? o.n_person_stable
              : typeof o.n_person === "number"
              ? o.n_person
              : objs.filter((x: any) => x.label === "person").length > 0
              ? 1
              : 0;
          const animalsStable =
            typeof o.n_animals_stable === "number"
              ? o.n_animals_stable
              : typeof o.n_animals === "number"
              ? o.n_animals
              : objs.filter((x: any) => x.label !== "person").length > 0
              ? 1
              : 0;

          setPeople(peopleStable);
          setAnimals(animalsStable);
          setBackend(o.backend || "—");
          setConfMax(Number(o.conf_max || 0));

          // atualiza mini preview de caixas (se ligado)
          if (showBoxes) {
            setBoxesUri(`${cleanServer(server)}/objects_frame?conf=0.25&ts=${Date.now()}`);
          }
        }
      } catch {
        if (!stop) {
          setIsFire(false);
          setFireScore(0);
          setPeople(0);
          setAnimals(0);
        }
      } finally {
        if (!stop) setTimeout(loop, 180); // ~5-6Hz (leve)
      }
    };
    loop();

    return () => {
      stop = true;
    };
  }, [detectOn, server, showBoxes]);

  /* ===== Registro automático (igual ao seu fluxo) ===== */
  useEffect(() => {
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;

    if (detectOn && rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [detectOn, isFire, server, saving, T]);

  /* ===== Joystick ===== */
  const RADIUS = 64,
    KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS,
          ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) {
          nx /= len;
          ny /= len;
        }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
      onPanResponderTerminate: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
    })
  ).current;

  const knobLeft = joy.x * RADIUS,
    knobTop = -joy.y * RADIUS;

  return (
    <View style={styles.container}>
      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor + Detectar + Seletor de visão */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={setServer}
          placeholder={T.placeholderServer}
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Pressable onPress={() => setDetectOn((v) => !v)} style={[styles.btn, detectOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{detectOn ? (saving ? T.saving : T.detecting) : T.detect}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>
          {statusText}
        </Text>
      </View>

      {/* Seletor de visão */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.view}</Text>
        <Pressable onPress={() => setUseStream(true)} style={[styles.btn, useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.stream}</Text>
        </Pressable>
        <Pressable onPress={() => setUseStream(false)} style={[styles.btn, !useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.snapshot}</Text>
        </Pressable>

        {/* toggle boxes */}
        <Pressable
          onPress={() => {
            const val = !showBoxes;
            setShowBoxes(val);
            if (val) setBoxesUri(`${cleanServer(server)}/objects_frame?conf=0.25&ts=${Date.now()}`);
          }}
          style={[styles.btn, showBoxes ? styles.btnOn : styles.btnOff]}
        >
          <Text style={styles.btnText}>{T.boxes}</Text>
        </Pressable>
      </View>

      {/* Banner de fogo */}
      {detectOn && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
        </View>
      )}

      {/* Banner de pessoas/animais + backend */}
      {detectOn && (
        <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
          <Text style={styles.statChip}>
            {T.persons}: <Text style={styles.statNumber}>{people}</Text>
          </Text>
          <Text style={styles.statChip}>
            {T.animals}: <Text style={styles.statNumber}>{animals}</Text>
          </Text>
          <Text style={styles.modelChip}>
            {T.backend}: {backend} • conf_max {confMax.toFixed(2)}
          </Text>
        </View>
      )}

      {/* Vídeo (stream rápido OU snapshot fallback) */}
      <View style={{ flex: 1 }}>
        {useStream ? (
          <LiveMJPEG ip={ip} />
        ) : (
          <CrossfadeImage
            currentUri={currentFrameUri}
            nextUri={nextFrameUri}
            onNextLoadStart={onNextLoadStart}
            onNextShown={onNextShown}
          />
        )}
      </View>

      {/* Mini preview com caixas (opcional) */}
      {detectOn && showBoxes && (
        <View style={{ height: 140, backgroundColor: "#000" }}>
          {!!boxesUri && (
            <Image
              source={{ uri: boxesUri }}
              style={{ flex: 1, width: "100%" }}
              resizeMode="contain"
              onError={() => setBoxesUri(`${cleanServer(server)}/objects_frame?conf=0.25&ts=${Date.now()}`)}
            />
          )}
        </View>
      )}

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: RADIUS * 2 + 24, height: RADIUS * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: RADIUS * 2, height: RADIUS * 2, borderRadius: RADIUS }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: KNOB_R * 2,
                height: KNOB_R * 2,
                borderRadius: KNOB_R,
                transform: [{ translateX: knobLeft }, { translateY: knobTop }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: PALETTE.bg,
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: "#1e2a4d",
    minWidth: 110,
  },
  btn: {
    backgroundColor: "#2b48ff",
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1730",
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" },
  statNumber: { color: "#fff" },
  modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(43,72,255,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});



Como usar




Coloque este arquivo exatamente em HydroBotApp2/src/screens/CameraScreen.tsx (substituindo o atual).


Abra o app, configure Servidor para http://SEU_PC:8000.


Toque Detectar. O banner de fogo continua igual; a linha “Pessoas / Animais” usa os sinais estáveis do servidor (não fica piscando).


Se quiser ver as caixas, toque o botão Caixas — aparece um mini-preview carregado de /objects_frame.






















































































Valeu pela print. Mesmo com os caminhos dos arquivos corretos, o conf_max continua ~0.0 — então o MobileNet-SSD que usamos não está “pegando” na sua cena/dispositivo. Em vez de ficar brigando com isso, vou te dar uma solução mais robusta:




O servidor passa a tentar MobileNet-SSD e, se não vier nada por alguns frames, ele troca automaticamente para YOLOv4-tiny (COCO), que costuma detectar pessoa/cão/gato/etc com bem mais confiança.


Você já tem o yolov4-tiny.cfg na pasta; só faltam os weights e o coco.names.




Abaixo estão:




server_heuristic.py completo (substitui o seu).


Passo a passo rápido para baixar os arquivos e testar.





1) Substitua o hydrobot-server/server_heuristic.py por este (COMPLETO)




Não mexi em nada da sua lógica de fogo. Só troquei a parte de objetos para “duplo backend”: tenta MobileNet-SSD; se o conf_max ficar baixo, ativa YOLOv4-tiny (se os arquivos existirem). Também mantive /objects, /objects_frame e /debug_models.




# server_heuristic.py
# FOGO (heurístico, inalterado) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny)
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0
JPEG_QUALITY = 85

# ===================== FOGO (seu) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}  # classes que nos interessam

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}
MNET_IN_SIZE = (300,300); MNET_SCALE = 0.007843; MNET_MEAN = 127.5

MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# YOLOv4-tiny (COCO)
YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"
YOLO_IN_SZ = (416,416)

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (AutoBackend)", version="1.5.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip: self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200:
                        time.sleep(0.5); continue
                    buf = b""
                    MAX_BYTES = 4_000_000
                    self._frames = 0
                    self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VISÃO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area: boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else: self._persist_hits = 1
            else: self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
            elif ema<=HYST_LOW: guess=0
            else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)

            self._det_frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval: time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {"ok":True,"isFire":self._is_fire,"score":round(self._score_ema,3),
                    "score_raw":round(self._score_raw,3),"score_ema":round(self._score_ema,3),
                    "boxes":self._boxes,"ts":self._last_result_ts,"fps_det":round(self._det_fps,2),
                    "vote":{"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                    "persist":{"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                    "hyst":{"hi":HYST_HIGH,"lo":HYST_LOW}}
detector = Detector(grabber); detector.start()

# ===================== OBJETOS (AutoBackend) =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        # estado
        self.backend = "mobilenet-ssd"   # ou "yolov4-tiny"
        self.net = None
        self.ok = False
        self.proto = None; self.weights = None; self.cfg = None; self.names = None
        self.labels = []
        self.swap_rb = False  # só p/ mnet
        self._nohit = 0
        self._last_conf_max = 0.0

        # FPS/resultado
        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    # ---------- loaders ----------
    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
        self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok = False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok = False; self.net=None

    def _try_load_yolo(self):
        self.backend = "yolov4-tiny"
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    # ---------- thread ----------
    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,MNET_IN_SIZE),
                                     MNET_SCALE, MNET_IN_SIZE, MNET_MEAN, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in MNET_ANIMALS: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, YOLO_IN_SZ, swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        self.start_time = time.time()
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            out=[]; cmax=0.0; backend=self.backend
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        # fallback rgb swap automático se nada por 1s
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:  # YOLO
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False; self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                                              "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            # se MobileNet-SSD não funcionar e YOLO existir, trocamos
            if (backend=="mobilenet-ssd" and cmax<0.05 and
                os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
                self._try_load_yolo()
                backend=self.backend
                if self.ok and self.backend=="yolov4-tiny":
                    out,cmax = self._infer_yolo(frame, max(0.2, OBJ_CONF_THRESH))

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "proto":self.proto,"weights":self.weights,"cfg":YOLO_CFG if backend=="yolov4-tiny" else None,
                            "names":COCO_NAMES if backend=="yolov4-tiny" else None,
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status()
    s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    # fallback rápido
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get()
    backend = o.get("backend")
    det = objects_det

    try:
        if backend=="yolov4-tiny":
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, conf)))
        else:
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, conf)))
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get(); s = grabber.status()
    return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
            "proto":o.get("proto"), "weights":o.get("weights"),
            "cfg":o.get("cfg"), "names":o.get("names"),
            "swap_rb":o.get("swap_rb"), "conf_max":o.get("conf_max"),
            "conf_thresh":OBJ_CONF_THRESH, "fps_obj":o.get("fps_obj"),
            "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
            "num_objects":len(o.get("objects",[])), "error":o.get("error")}




2) Passo a passo (baixar YOLO e testar)






Baixe os arquivos para hydrobot-server/models/:




yolov4-tiny.weights

URL (oficial AlexeyAB):

https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights


yolov4-tiny.cfg

(você já tem; se precisar:

https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg )


coco.names

https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names




Dê exatamente esses nomes dentro de hydrobot-server/models/.






Reinicie o servidor:






uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload







Verifique no navegador (no PC do servidor):




http://SEU_PC:8000/debug_models

Deve mostrar backend: "yolov4-tiny" (se o MobileNet não estiver detectando) e objects_ok: true.


http://SEU_PC:8000/objects_frame?conf=0.25

Deve exibir o JPEG com caixas (person/dog/cat…).








No app (tela Câmera):




Campo Servidor = http://SEU_PC:8000


Tocar Detectar.

“Pessoas: N” e “Animais: M” devem sair de 0 quando alguém entra no quadro.









Se mesmo com YOLO o /objects_frame ficar sem caixas, me diga o que aparece em /debug_models (backend, conf_max, error, stream_hasFrame) que eu ajusto o que faltar.




























































Vale — o app está ok; o problema é o servidor não está retornando objetos. Isso costuma ser por par (prototxt/pesos) diferente ou pré-processamento (swapRB) que não bate com seu caffemodel. Vou te passar:




server_heuristic.py completo com:



suporte a vários nomes de modelo (os que você tem na pasta),


ajuste de threshold por query,


fallback automático de pré-processamento (tenta swapRB=False e, se nada sair, troca pra swapRB=True),


endpoints de debug: /objects_raw, /objects_frame e /debug_models (mostram proto, weights, conf_max, etc).






Passo a passo de teste.






Não mexe na detecção de fogo; só acrescentei a parte de objetos e debug.





Substitua seu hydrobot-server/server_heuristic.py por este (COMPLETO)


# server_heuristic.py
# FOGO (heurístico, inalterado) + OBJETOS (MobileNet-SSD Caffe) com debug
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== CONFIG STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0

JPEG_QUALITY = 85

# ===================== FOGO (igual ao seu) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS (MobileNet-SSD) =====================
OBJECTS_MAX_FPS = 10.0
OBJ_CONF_THRESH = 0.25       # pode trocar em /objects?conf=0.15
OBJ_NMS_THRESH  = 0.45
OBJ_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
ANIMAL_CLASSES = {"bird","cat","cow","dog","horse","sheep"}

DNN_IN_SIZE = (300, 300)
DNN_SCALE   = 0.007843
DNN_MEAN    = 127.5

# aceita os nomes que você tem na pasta
DNN_PROTOTXT_CANDIDATES = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
DNN_CAFFE_WEIGHTS_CANDIDATES = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects", version="1.4.0")
app.add_middleware(
    CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER CONTÍNUO =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip: self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200:
                        time.sleep(0.5); continue
                    buf = b""
                    MAX_BYTES = 4_000_000
                    self._frames = 0
                    self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except requests.exceptions.RequestException:
                time.sleep(0.5)
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== FUNÇÕES VISÃO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    mask = (r.astype(np.int16) > (g.astype(np.int16) + delta)) & (r.astype(np.int16) > (b.astype(np.int16) + delta))
    return (mask.astype(np.uint8)) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    lower = np.array(HSV_LOW, dtype=np.uint8)
    upper = np.array(HSV_HIGH, dtype=np.uint8)
    return cv2.inRange(hsv, lower, upper)

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0, 133, 77), (255, 173, 127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    skin = cv2.bitwise_and(skin, dark)
    return skin

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax + aw, ay + ah; bx2, by2 = bx + bw, by + bh
    ix1, iy1 = max(ax, bx), max(ay, by)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
    inter = iw * ih; union = aw*ah + bw*bh - inter
    return float(inter) / float(union) if union > 0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes: List[List[int]] = []
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if w * h >= min_area:
            boxes.append([x, y, w, h])
    return boxes

# ===================== DETECTOR CONTÍNUO (FOGO) =====================
class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0
        self._score_ema = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW)
        self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None

        self._det_fps = 0.0
        self._det_frames = 0
        self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue

            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (3, 3), 0)
            motion_mask = np.zeros_like(gray, dtype=np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray, self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS > 0:
                    k = np.ones((3, 3), np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[..., 2]
            bright = cv2.threshold(V, 200, 255, cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red, bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
            v_mean = float(np.mean(V)) / 255.0
            score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)

            ratio_combined = float(np.count_nonzero(combined)) / float(combined.size)
            score_combined = min(1.0, ratio_combined * 5.0 + v_mean * 0.1)

            ema = score_combined if self._score_ema == 0.0 else (EMA_ALPHA * score_combined + (1.0 - EMA_ALPHA) * self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)

            main_box = None
            if boxes:
                areas = [w*h for (_,_,w,h) in boxes]
                main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    if iou(tuple(main_box), tuple(self._last_main_box)) >= IOU_MIN:
                        self._persist_hits += 1
                    else:
                        self._persist_hits = 1
                else:
                    self._persist_hits = 1
            else:
                self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema >= HYST_HIGH and self._persist_hits >= PERSIST_CONSEC:
                guess = 1
            elif ema <= HYST_LOW:
                guess = 0
            else:
                guess = (1 if (len(self._votes) > 0 and self._votes[-1] == 1 and self._persist_hits >= PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes) >= VOTE_NEED else 0

            with self._lock:
                self._score_raw = float(score_raw)
                self._score_ema = float(ema)
                self._is_fire = bool(final_fire == 1)
                self._boxes = boxes if self._is_fire else []
                self._last_result_ts = int(time.time() * 1000)

            self._det_frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._det_fps = self._det_frames / (now - self._last_fps_tick)
                self._det_frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get_result(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema, 3),
                "score_raw": round(self._score_raw, 3),
                "score_ema": round(self._score_ema, 3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps, 2),
                "vote": {"win": VOTE_WINDOW, "need": VOTE_NEED, "sum": int(sum(self._votes))},
                "persist": {"hits": self._persist_hits, "need": PERSIST_CONSEC, "iou_min": IOU_MIN},
                "hyst": {"hi": HYST_HIGH, "lo": HYST_LOW},
            }

detector = Detector(grabber)
detector.start()

# ===================== OBJETOS =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None
        self.ok = False
        self.proto_path = None
        self.weights_path = None

        # debug
        self._last_conf_max = 0.0
        self.swap_rb = False           # fallback automático
        self._nohit_streak = 0

        # FPS
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._load_net()

    def _load_net(self):
        for p in DNN_PROTOTXT_CANDIDATES:
            if os.path.exists(p): self.proto_path = p; break
        for w in DNN_CAFFE_WEIGHTS_CANDIDATES:
            if os.path.exists(w): self.weights_path = w; break
        if not self.proto_path:
            self.ok = False; self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0, "error": "prototxt not found"}; return
        if not self.weights_path:
            self.ok = False; self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0, "error": "caffemodel not found"}; return
        try:
            self.net = cv2.dnn.readNetFromCaffe(self.proto_path, self.weights_path)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.ok = True
        except Exception as e:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0, "error": f"load failed: {e}"}

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _nms(self, boxes: List[List[int]], confs: List[float]) -> List[int]:
        if not boxes: return []
        idxs = cv2.dnn.NMSBoxes(boxes, confs, OBJ_CONF_THRESH, OBJ_NMS_THRESH)
        if idxs is None or len(idxs) == 0: return []
        if isinstance(idxs, np.ndarray): return [int(i) for i in idxs.flatten().tolist()]
        return [int(i) for i in idxs]

    def _infer_once(self, frame: np.ndarray, swap_rb: bool, conf_th: float) -> Tuple[List[Dict[str, Any]], float]:
        (h, w) = frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame, DNN_IN_SIZE),
                                     DNN_SCALE, DNN_IN_SIZE, DNN_MEAN, swapRB=swap_rb, crop=False)
        self.net.setInput(blob)
        detections = self.net.forward()
        out_objects: List[Dict[str, Any]] = []
        boxes_all: List[List[int]] = []
        confs_all: List[float] = []
        labels_all: List[str] = []
        conf_max = 0.0

        for i in range(detections.shape[2]):
            conf = float(detections[0, 0, i, 2])
            conf_max = max(conf_max, conf)
            if conf < conf_th: continue
            idx = int(detections[0, 0, i, 1])
            if idx < 0 or idx >= len(OBJ_CLASSES): continue
            label = OBJ_CLASSES[idx]
            if label != "person" and label not in ANIMAL_CLASSES: continue
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            x1, y1, x2, y2 = box.astype("int")
            x, y = max(0, x1), max(0, y1)
            rw, rh = max(0, x2 - x), max(0, y2 - y)
            if rw * rh <= 0: continue
            boxes_all.append([int(x), int(y), int(rw), int(rh)])
            confs_all.append(conf)
            labels_all.append(label)

        keep = self._nms(boxes_all, confs_all)
        for k in keep:
            out_objects.append({"label": labels_all[k], "conf": float(confs_all[k]), "box": [int(v) for v in boxes_all[k]]})
        out_objects.sort(key=lambda o: o["conf"], reverse=True)
        out_objects = out_objects[:15]
        return out_objects, conf_max

    def _run(self):
        min_interval = 1.0 / OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, dtype=np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            out_objects: List[Dict[str, Any]] = []
            conf_max = 0.0

            if self.ok and self.net is not None:
                try:
                    out_objects, conf_max = self._infer_once(frame, self.swap_rb, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok = False
                    self._last = {"ok": False, "backend": self.backend, "fps_obj": round(self._fps,2),
                                  "objects": [], "ts": int(time.time()*1000), "error": f"forward failed: {e}"}
                    time.sleep(0.1)
                    continue

                # Fallback: se não teve nada por um tempo, tente inverter canais e mantenha se melhorar
                if conf_max < 0.05:
                    self._nohit_streak += 1
                else:
                    self._nohit_streak = 0

                if self._nohit_streak >= 10:  # ~1 segundo
                    try_other, conf_other = self._infer_once(frame, not self.swap_rb, max(0.1, OBJ_CONF_THRESH*0.8))
                    if conf_other > conf_max + 0.05:
                        self.swap_rb = not self.swap_rb   # trava no melhor
                        out_objects, conf_max = try_other, conf_other
                    self._nohit_streak = 0

            with self._lock:
                self._last_conf_max = conf_max
                self._last = {
                    "ok": bool(self.ok),
                    "backend": self.backend,
                    "fps_obj": round(self._fps, 2),
                    "objects": out_objects,
                    "ts": int(time.time()*1000),
                    "proto": self.proto_path,
                    "weights": self.weights_path,
                    "conf_max": round(conf_max, 3),
                    "swap_rb": self.swap_rb,
                }

            self._frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._fps = self._frames / (now - self._last_fps_tick)
                self._frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(max(0.0, min_interval - elapsed))

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber)
objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status()
    s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time() * 1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    arr = np.frombuffer(jpeg, dtype=np.uint8)
    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[..., 2])) / 255.0
    score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    res2 = {
        "ok": True, "isFire": is_fire,
        "score": round(float(score_raw), 3),
        "score_raw": round(float(score_raw), 3),
        "score_ema": round(float(score_raw), 3),
        "boxes": [], "ts": int(time.time() * 1000), "fallback": True,
        "objects": objects_det.get()
    }
    return res2

@app.get("/objects")
def objects(conf: float = Query(None, description="override confidence threshold (0..1)")):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_raw")
def objects_raw(conf: float = Query(0.2, description="threshold (0..1)")):
    """Lista TUDO que o modelo vê (sem filtrar só pessoa/animais) para debug."""
    o = objects_det.get()
    return {
        "ok": o.get("ok", False),
        "backend": o.get("backend"),
        "proto": o.get("proto"),
        "weights": o.get("weights"),
        "conf_max": o.get("conf_max"),
        "swap_rb": o.get("swap_rb"),
        "note": "este endpoint só ecoa status; para ver deteções brutas use /objects_frame",
    }

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.2, description="threshold (0..1)")):
    """Retorna um JPEG com caixas desenhadas (pessoa/animais) — debug visual."""
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg, dtype=np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    # roda uma inferência direta (mesmo pipeline do detector)
    det = objects_det
    if not det.ok or det.net is None:
        return Response(content=placeholder_jpeg("NET NOT LOADED"), media_type="image/jpeg")

    objs, _ = det._infer_once(frame, det.swap_rb, max(0.05, min(0.95, conf)))
    for o in objs:
        x,y,w,h = o["box"]
        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)
        cv2.putText(frame, f'{o["label"]} {o["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get()
    s = grabber.status()
    return {
        "ok": True,
        "fire_model": "heuristic-balanced",
        "objects_backend": o.get("backend", "mobilenet-ssd"),
        "objects_ok": o.get("ok", False),
        "fps_obj": o.get("fps_obj", 0.0),
        "num_objects": len(o.get("objects", [])),
        "proto": o.get("proto"),
        "weights": o.get("weights"),
        "conf_max": o.get("conf_max"),
        "swap_rb": o.get("swap_rb"),
        "conf_thresh": OBJ_CONF_THRESH,
        "nms_thresh": OBJ_NMS_THRESH,
        "stream_hasFrame": s.get("hasFrame"),
        "stream_fps_in": s.get("fps_in"),
        "error": o.get("error"),
    }




Passo a passo (rápido)




Reinicie:




uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload





Abra no navegador do PC do servidor:






http://SEU_PC:8000/debug_models

Verifique:



objects_ok: true


proto e weights apontando para os arquivos dentro de models/


stream_hasFrame: true e stream_fps_in > 0


swap_rb (começa false; o servidor muda sozinho se perceber que não tem hits)






http://SEU_PC:8000/objects

Observe conf_max. Se ficar ~0.0, aguarde 2–3s (o fallback tenta swapRB=True sozinho).


http://SEU_PC:8000/objects?conf=0.15

Abaixe o limiar temporariamente (se luz ruim).


http://SEU_PC:8000/objects_frame?conf=0.15

Deve aparecer um JPEG com as caixas em pessoas/animais. Se não aparecer nada, ainda é par de arquivos.






No app (tela Câmera):






Servidor = http://SEU_PC:8000


Clique Detectar. Os badges devem sair de 0 quando alguém entrar no quadro.





Por que isso resolve?




Se o seu caffemodel exigir RGB (incomum em Caffe, mas acontece em forks), o servidor agora detecta e alterna automaticamente (swap_rb muda para true sozinho após ~1s sem hits).


Se o seu par deploy/weights não estiver combinando, o /debug_models mostra quais arquivos e o /objects_frame deixa claro se a saída está vazia por threshold ou por modelo.


Você ainda pode ajustar o threshold via query sem reiniciar.




Se ainda assim o /objects_frame não desenhar nada, me diga o que aparece em /debug_models (proto, weights, conf_max, swap_rb, stream_hasFrame) que eu ajusto pontualmente.







































































Beleza — se o /objects veio vazio mesmo com uma pessoa no quadro, o problema está no servidor (não no app). Provavelmente é par de arquivos não correspondentes (prototxt vs caffemodel) ou limiar de confiança alto para a sua cena/iluminação.


Abaixo te mando um server_heuristic.py atualizado (COMPLETO) que:




aceita vários nomes de prototxt/weights (inclui deploy.prototxt e mobilenet_iter_73000.caffemodel que apareceram no seu clone);


mostra no /debug_models exatamente quais arquivos foram carregados e qual foi a maior confiança da última inferência;


reduz o threshold padrão para 0.25 (mais sensível) — você pode ajustar por query string (/objects?conf=0.35);


mantém todo o detector de fogo inalterado.




Depois do código, tem um passo-a-passo de teste para você validar rapidinho.



server_heuristic.py (substitua o arquivo inteiro)


# server_heuristic.py
# FOGO (heurístico, inalterado) + OBJETOS (MobileNet-SSD Caffe)
import time
import threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os

# ===================== CONFIG =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0

JPEG_QUALITY = 85

# HSV mais amplo p/ fogo real (amarelo/laranja)
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)

# Dominância de vermelho (reforço, não bloqueio)
RED_DELTA = 15

# Detector fogo
DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

# Anti-movimento
MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

# Persistência espacial
PERSIST_CONSEC = 2
IOU_MIN = 0.15

# Idades máximas
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS (MobileNet-SSD) =====================
OBJECTS_MAX_FPS   = 10.0
OBJ_CONF_THRESH   = 0.25     # <= mais sensível; pode subir via /objects?conf=0.4
OBJ_NMS_THRESH    = 0.45
OBJ_CLASSES       = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
ANIMAL_CLASSES    = {"bird","cat","cow","dog","horse","sheep"}
DNN_IN_SIZE       = (300, 300)
DNN_SCALE         = 0.007843
DNN_MEAN          = 127.5

# Candidatos de caminhos — cobrimos os nomes que você tem
DNN_PROTOTXT_CANDIDATES = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",     # só se você colocou assim
]
DNN_CAFFE_WEIGHTS_CANDIDATES = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (MobileNetSSD)", version="1.3.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER CONTÍNUO =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200:
                        time.sleep(0.5); continue
                    buf = b""
                    MAX_BYTES = 4_000_000
                    self._frames = 0
                    self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except requests.exceptions.RequestException:
                time.sleep(0.5)
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== UTILs VISÃO =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    mask = (r.astype(np.int16) > (g.astype(np.int16) + delta)) & (r.astype(np.int16) > (b.astype(np.int16) + delta))
    return (mask.astype(np.uint8)) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    lower = np.array(HSV_LOW, dtype=np.uint8)
    upper = np.array(HSV_HIGH, dtype=np.uint8)
    return cv2.inRange(hsv, lower, upper)

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0, 133, 77), (255, 173, 127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    skin = cv2.bitwise_and(skin, dark)
    return skin

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax + aw, ay + ah; bx2, by2 = bx + bw, by + bh
    ix1, iy1 = max(ax, bx), max(ay, by)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
    inter = iw * ih; union = aw*ah + bw*bh - inter
    return float(inter) / float(union) if union > 0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes: List[List[int]] = []
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if w * h >= min_area:
            boxes.append([x, y, w, h])
    return boxes

# ===================== DETECTOR CONTÍNUO (FOGO) =====================
class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0
        self._score_ema = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW)
        self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None

        self._det_fps = 0.0
        self._det_frames = 0
        self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue

            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            # --- máscaras base ---
            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            # anti-movimento
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (3, 3), 0)
            motion_mask = np.zeros_like(gray, dtype=np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray, self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS > 0:
                    k = np.ones((3, 3), np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            # combinação principal: HSV ∧ ¬pele ∧ ¬movimento
            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            # reforço
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[..., 2]
            bright = cv2.threshold(V, 200, 255, cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red, bright)
            combined = cv2.bitwise_or(stable, red_boost)

            # scores
            ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
            v_mean = float(np.mean(V)) / 255.0
            score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)

            ratio_combined = float(np.count_nonzero(combined)) / float(combined.size)
            score_combined = min(1.0, ratio_combined * 5.0 + v_mean * 0.1)

            ema = score_combined if self._score_ema == 0.0 else (EMA_ALPHA * score_combined + (1.0 - EMA_ALPHA) * self._score_ema)

            # caixas
            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)

            # persistência espacial leve
            main_box = None
            if boxes:
                areas = [w*h for (_,_,w,h) in boxes]
                main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    if iou(tuple(main_box), tuple(self._last_main_box)) >= IOU_MIN:
                        self._persist_hits += 1
                    else:
                        self._persist_hits = 1
                else:
                    self._persist_hits = 1
            else:
                self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            # histerese + votos
            if ema >= HYST_HIGH and self._persist_hits >= PERSIST_CONSEC:
                guess = 1
            elif ema <= HYST_LOW:
                guess = 0
            else:
                guess = (1 if (len(self._votes) > 0 and self._votes[-1] == 1 and self._persist_hits >= PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes) >= VOTE_NEED else 0

            with self._lock:
                self._score_raw = float(score_raw)
                self._score_ema = float(ema)
                self._is_fire = bool(final_fire == 1)
                self._boxes = boxes if self._is_fire else []
                self._last_result_ts = int(time.time() * 1000)

            # FPS detector
            self._det_frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._det_fps = self._det_frames / (now - self._last_fps_tick)
                self._det_frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get_result(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema, 3),
                "score_raw": round(self._score_raw, 3),
                "score_ema": round(self._score_ema, 3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps, 2),
                "vote": {"win": VOTE_WINDOW, "need": VOTE_NEED, "sum": int(sum(self._votes))},
                "persist": {"hits": self._persist_hits, "need": PERSIST_CONSEC, "iou_min": IOU_MIN},
                "hyst": {"hi": HYST_HIGH, "lo": HYST_LOW},
            }

detector = Detector(grabber)
detector.start()

# ===================== DETECTOR DE OBJETOS =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None
        self.ok = False
        self.proto_path = None
        self.weights_path = None

        # métricas p/ debug
        self._last_conf_max = 0.0

        # FPS
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

        # último resultado
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._load_net()

    def _load_net(self):
        # acha prototxt
        for p in DNN_PROTOTXT_CANDIDATES:
            if os.path.exists(p):
                self.proto_path = p
                break
        # acha weights
        for w in DNN_CAFFE_WEIGHTS_CANDIDATES:
            if os.path.exists(w):
                self.weights_path = w
                break

        if not self.proto_path:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": "prototxt not found"}
            return
        if not self.weights_path:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": "caffemodel not found"}
            return
        try:
            self.net = cv2.dnn.readNetFromCaffe(self.proto_path, self.weights_path)
            # força CPU (compatível)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.ok = True
        except Exception as e:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": f"load failed: {e}"}

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _nms(self, boxes: List[List[int]], confs: List[float]) -> List[int]:
        if not boxes: return []
        idxs = cv2.dnn.NMSBoxes(boxes, confs, OBJ_CONF_THRESH, OBJ_NMS_THRESH)
        if idxs is None or len(idxs) == 0: return []
        if isinstance(idxs, np.ndarray):
            return [int(i) for i in idxs.flatten().tolist()]
        return [int(i) for i in idxs]

    def _run(self):
        min_interval = 1.0 / OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue
            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            out_objects: List[Dict[str, Any]] = []
            conf_max = 0.0

            if self.ok and self.net is not None:
                (h, w) = frame.shape[:2]
                blob = cv2.dnn.blobFromImage(cv2.resize(frame, DNN_IN_SIZE),
                                             DNN_SCALE, DNN_IN_SIZE, DNN_MEAN, swapRB=False, crop=False)
                try:
                    self.net.setInput(blob)
                    detections = self.net.forward()
                except Exception as e:
                    self.ok = False
                    self._last = {"ok": False, "backend": self.backend, "fps_obj": round(self._fps,2),
                                  "objects": [], "ts": int(time.time()*1000), "error": f"forward failed: {e}"}
                    time.sleep(0.1)
                    continue

                boxes_all: List[List[int]] = []
                confs_all: List[float] = []
                labels_all: List[str] = []

                # detections: [1,1,N,7] => [img_id, class_id, conf, x1,y1,x2,y2]
                for i in range(detections.shape[2]):
                    conf = float(detections[0, 0, i, 2])
                    conf_max = max(conf_max, conf)
                    if conf < OBJ_CONF_THRESH:
                        continue
                    idx = int(detections[0, 0, i, 1])
                    if idx < 0 or idx >= len(OBJ_CLASSES):
                        continue
                    label = OBJ_CLASSES[idx]
                    if label != "person" and label not in ANIMAL_CLASSES:
                        continue
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    x1, y1, x2, y2 = box.astype("int")
                    x, y = max(0, x1), max(0, y1)
                    rw, rh = max(0, x2 - x), max(0, y2 - y)
                    if rw * rh <= 0: continue
                    boxes_all.append([int(x), int(y), int(rw), int(rh)])
                    confs_all.append(conf)
                    labels_all.append(label)

                keep = self._nms(boxes_all, confs_all)
                for k in keep:
                    out_objects.append({
                        "label": labels_all[k],
                        "conf": float(confs_all[k]),
                        "box": [int(v) for v in boxes_all[k]]
                    })

                out_objects.sort(key=lambda o: o["conf"], reverse=True)
                out_objects = out_objects[:15]

            with self._lock:
                self._last_conf_max = conf_max
                self._last = {
                    "ok": bool(self.ok),
                    "backend": self.backend,
                    "fps_obj": round(self._fps, 2),
                    "objects": out_objects,
                    "ts": int(time.time()*1000),
                    "proto": self.proto_path,
                    "weights": self.weights_path,
                    "conf_max": round(conf_max, 3),
                }

            self._frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._fps = self._frames / (now - self._last_fps_tick)
                self._frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(max(0.0, min_interval - elapsed))

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber)
objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status()
    s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    if res.get("ts", 0) and (int(time.time() * 1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        res["objects"] = objects_det.get()
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    arr = np.frombuffer(jpeg, dtype=np.uint8)
    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[..., 2])) / 255.0
    score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {
        "ok": True, "isFire": is_fire,
        "score": round(float(score_raw), 3),
        "score_raw": round(float(score_raw), 3),
        "score_ema": round(float(score_raw), 3),
        "boxes": [], "ts": int(time.time() * 1000), "fallback": True,
        "objects": objects_det.get()
    }

@app.get("/objects")
def objects(conf: float = Query(None, description="override confidence threshold (0..1)")):
    global OBJ_CONF_THRESH
    if conf is not None:
        # permite ajustar on-the-fly sem reiniciar
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/debug_models")
def debug_models():
    o = objects_det.get()
    return {
        "ok": True,
        "fire_model": "heuristic-balanced",
        "objects_backend": o.get("backend", "mobilenet-ssd"),
        "objects_ok": o.get("ok", False),
        "fps_obj": o.get("fps_obj", 0.0),
        "num_objects": len(o.get("objects", [])),
        "proto": o.get("proto"),
        "weights": o.get("weights"),
        "conf_max": o.get("conf_max"),
        "error": o.get("error"),
        "conf_thresh": OBJ_CONF_THRESH,
        "nms_thresh": OBJ_NMS_THRESH,
    }




Teste rápido (para achar a causa)




Reinicie:




uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload





Abra no navegador (no PC do servidor):






http://SEU_PC:8000/debug_models

Confira:



objects_ok: true


proto aponta para um dos candidatos (ex.: ./models/deploy.prototxt ou ...MobileNetSSD_deploy.prototxt)


weights aponta para mobilenet_iter_73000.caffemodel ou MobileNetSSD_deploy.caffemodel






http://SEU_PC:8000/objects

Fique na frente da câmera por 2–3s e veja conf_max subir (ex.: 0.6, 0.8), e aparecer items em objects.






Se ainda vier vazio:






Tente baixar o limiar no voo:

http://SEU_PC:8000/objects?conf=0.15


Recarregue /objects.

Se então aparecer, ficou claro que era threshold alto para a sua cena.

Depois fixe o valor que funcionar melhor.






Se objects_ok: false ou error: load failed:






É par de arquivos incompatível. Use deploy.prototxt do mesmo repo do mobilenet_iter_73000.caffemodel (o que você clonou).


Atualize OpenCV: pip install --upgrade opencv-python.





No app (Câmera)


Com o servidor ok (objects preenchido), a tela que te passei já mostra:




🔥 fogo (como antes)


👤 Pessoas: N


🐾 Animais: M




Se /objects mostrar itens mas o app não contar, me manda um pequeno JSON retornado por /detect (só as primeiras linhas) para eu ajustar o caminho exato — mas já deixei j.objects.objects (estrutura que sai do servidor acima).


Vamos ver o que aparece no /debug_models (principalmente proto, weights, conf_max) e se baixar conf faz os objetos surgirem.




























































Vamos direto ao ponto: o servidor está ok, mas a tela Câmera não estava exibindo o feedback de pessoas/animais que o endpoint já envia. Abaixo te passo:




como testar o servidor rapidinho (para confirmar que ele está detectando),


o arquivo completo CameraScreen.tsx com as mudanças para mostrar contagem estável de pessoas e animais quando você clica em Detectar (sem depender de novas libs nem desenhar caixas).





1) Teste rápido do servidor (confirma se está detectando)


No PC do servidor, com a câmera apontando para alguém/animal:






Abra http://SEU_PC:8000/debug_models

→ Deve ter: "objects_backend":"mobilenet-ssd", "objects_ok": true.






Abra http://SEU_PC:8000/objects

→ Deve aparecer algo assim quando há alguém no quadro:


{
  "ok": true,
  "backend": "mobilenet-ssd",
  "objects": [
    {"label":"person","conf":0.82,"box":[...]}
  ]
}







Se /objects trouxer lista vazia mesmo com pessoa no quadro, me diga que ajusto os thresholds; mas normalmente aparece.



2) Substitua sua tela por ESTE CameraScreen.tsx (COMPLETO)


Coloque em:

HydroBotApp2/src/screens/CameraScreen.tsx




O que muda: enquanto Detectar estiver ativo, o app consulta /detect ~5 Hz e mostra dois badges com contagem de 👤 Pessoas e 🐾 Animais. Não precisa de bibliotecas novas. O vídeo continua com STREAM (rápido) ≥20 fps ou SNAPSHOT (fallback), como você já tinha.




// HydrobotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet, PanResponder,
  GestureResponderEvent, PanResponderGestureState, Image, Animated,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg: "#000000", card: "#0d0d0d", border: "#1a1a1a", red: "#E53B2F", white: "#ffffff" };

/* ============================
   A) VISUAL 1 — STREAM (≥20fps)
   ============================ */
function LiveMJPEG({ ip }: { ip: string }) {
  const html = `
    <html><head><meta name="viewport" content="width=device-width, initial-scale=1">
      <style>
        html,body{margin:0;padding:0;background:#000;height:100%;}
        .wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;background:#000;}
        img{max-width:100%;max-height:100%;object-fit:contain;background:#000;}
      </style>
    </head>
    <body>
      <div class="wrap">
        <img src="http://${ip}:81/stream" />
      </div>
    </body></html>
  `;
  return (
    <WebView
      originWhitelist={["*"]}
      source={{ html }}
      javaScriptEnabled
      allowsInlineMediaPlayback
      mediaPlaybackRequiresUserAction={false}
      automaticallyAdjustContentInsets={false}
      style={{ flex: 1, backgroundColor: "black" }}
    />
  );
}

/* ==========================================
   B) VISUAL 2 — SNAPSHOT com crossfade (fallback)
   ========================================== */
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: () => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {currentUri ? (
        <Image source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      ) : null}

      {showNext ? (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown();
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      ) : null}
    </View>
  );
}

/* ============================
   TEXTOS
   ============================ */
const textsByLang = {
  pt: {
    espIp: "ESP IP:", test: "Testar", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "BOMBA ON", pumpOff: "BOMBA OFF", server: "Servidor:",
    detect: "Detectar", detecting: "Detectando", saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi e IP.",
    noVideo: "Sem vídeo (snapshot). Verifique o servidor.",
    fireOn: (s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`, fireOff: (s:number)=>`Sem fogo • score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Evento salvo em ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Visão:",
    stream: "STREAM (rápido)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`👤 Pessoas: ${n}`,
    animals: (n:number)=>`🐾 Animais: ${n}`,
  },
  en: {
    espIp: "ESP IP:", test: "Test", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "PUMP ON", pumpOff: "PUMP OFF", server: "Server:",
    detect: "Detect", detecting: "Detecting", saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`, fireOff: (s:number)=>`No fire • score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Event saved at ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "View:",
    stream: "STREAM (fast)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`👤 People: ${n}`,
    animals: (n:number)=>`🐾 Animals: ${n}`,
  },
  es: {
    espIp: "ESP IP:", test: "Probar", ledOn: "LED ENC.", ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.", pumpOff: "BOMBA APAG.", server: "Servidor:",
    detect: "Detectar", detecting: "Detectando", saving: "Guardando...",
    statusFail: "Error de conexión. Revisa Wi-Fi/IP.",
    noVideo: "Sin vídeo (snapshot). Revisa el servidor.",
    fireOn: (s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`, fireOff: (s:number)=>`Sin fuego • score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Evento guardado a las ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vista:",
    stream: "STREAM (rápido)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`👤 Personas: ${n}`,
    animals: (n:number)=>`🐾 Animales: ${n}`,
  },
};

const DEFAULT_IP = "192.168.4.1";
const DEFAULT_SERVER = "http://192.168.4.2:8000";

type ObjDet = { label: string; conf: number; box: [number, number, number, number] };

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conexões
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState("—");
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detecção
  const [detectOn, setDetectOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);

  // pessoas/animais (feedback visual)
  const [peopleCount, setPeopleCount] = useState(0);
  const [animalCount, setAnimalCount] = useState(0);

  // registro automático
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // modo de visualização
  const [useStream, setUseStream] = useState(true);

  // vídeo (snapshot double-buffer)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // URLs do ESP
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl, { method: "GET" });
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(`OK • ip:${j.ip} • mode:${j.mode} • led:${j.led ? "on" : "off"} • pump:${j.pump ? "on" : "off"}`);
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() { try { const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t); } catch { setStatusText(T.statusFail); } }
  async function togglePump() { try { const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); } catch { setStatusText(T.statusFail); } }

  useEffect(() => { pingStatus(); const id = setInterval(pingStatus, 5000); return () => clearInterval(id); }, [statusUrl]);

  /* ===== Vídeo via snapshots — ~25fps (fallback) ===== */
  useEffect(() => {
    if (useStream) return;
    let stop = false;
    const FPS_INTERVAL = 40;
    setCurrentFrameUri(`${server.replace(/\/+$/, "")}/snapshot?ts=${Date.now()}`);
    const tick = () => {
      if (stop) return;
      if (!loadingNextRef.current) {
        const url = `${server.replace(/\/+$/, "")}/snapshot?ts=${Date.now()}`;
        setNextFrameUri(url);
      }
      setTimeout(tick, FPS_INTERVAL);
    };
    tick();
    return () => { stop = true; };
  }, [server, useStream]);

  function onNextLoadStart() { loadingNextRef.current = true; }
  function onNextShown() {
    if (nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== DETECT LOOP ===== */
  useEffect(() => {
    if (!detectOn) { setPeopleCount(0); setAnimalCount(0); return; }
    let stop = false;
    const loop = async () => {
      try {
        const r = await fetch(`${server.replace(/\/+$/, "")}/detect`, { method: "GET" });
        const j = await r.json();
        if (!stop && j && j.ok) {
          // fogo
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          // pessoas/animais vindos do servidor
          const objsRoot = (j.objects && j.objects.objects) ? j.objects.objects : [];
          const people = (objsRoot as ObjDet[]).filter(o => o.label === "person").length;
          const animals = (objsRoot as ObjDet[]).filter(o => o.label !== "person").length;

          setPeopleCount(people);
          setAnimalCount(animals);
        }
      } catch {
        if (!stop) {
          setIsFire(false); setFireScore(0);
          setPeopleCount(0); setAnimalCount(0);
        }
      } finally {
        if (!stop) setTimeout(loop, 120); // ~8–9 Hz de estado (leve)
      }
    };
    loop();
    return () => { stop = true; };
  }, [detectOn, server]);

  /* ===== Registro automático ===== */
  useEffect(() => {
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;
    if (detectOn && rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [detectOn, isFire, server, saving, T]);

  /* ===== Joystick ===== */
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS, ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny); if (len > 1) { nx /= len; ny /= len; }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
      onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    })
  ).current;

  const knobLeft = joy.x * RADIUS, knobTop = -joy.y * RADIUS;

  return (
    <View style={styles.container}>
      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor IA + Detectar + Modo de Visão */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={setServer}
          placeholder={T.placeholderServer}
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Pressable onPress={() => setDetectOn((v) => !v)} style={[styles.btn, detectOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{detectOn ? (saving ? T.saving : T.detecting) : T.detect}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
      </View>

      {/* Seletor de visão */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.view}</Text>
        <Pressable onPress={() => setUseStream(true)}  style={[styles.btn, useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.stream}</Text>
        </Pressable>
        <Pressable onPress={() => setUseStream(false)} style={[styles.btn, !useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.snapshot}</Text>
        </Pressable>
      </View>

      {/* Banners de estado */}
      {detectOn && (
        <>
          <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
            <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
          </View>

          {/* NOVO: badges de pessoas / animais */}
          <View style={styles.badgesRow}>
            <View style={[styles.badge, { backgroundColor: "#1b2a4b" }]}>
              <Text style={styles.badgeTxt}>{T.people(peopleCount)}</Text>
            </View>
            <View style={[styles.badge, { backgroundColor: "#2b3a1b" }]}>
              <Text style={styles.badgeTxt}>{T.animals(animalCount)}</Text>
            </View>
          </View>
        </>
      )}

      {/* Vídeo (STREAM rápido OU SNAPSHOT fallback) */}
      <View style={{ flex: 1 }}>
        {useStream ? (
          <LiveMJPEG ip={ip} />
        ) : (
          <CrossfadeImage
            currentUri={currentFrameUri}
            nextUri={nextFrameUri}
            onNextLoadStart={onNextLoadStart}
            onNextShown={onNextShown}
          />
        )}
      </View>

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: RADIUS * 2 + 24, height: RADIUS * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: RADIUS * 2, height: RADIUS * 2, borderRadius: RADIUS }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: KNOB_R * 2, height: KNOB_R * 2, borderRadius: KNOB_R,
                transform: [{ translateX: knobLeft }, { translateY: knobTop }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)}   y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: PALETTE.bg,
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: "#1e2a4d",
    minWidth: 110,
  },
  btn: {
    backgroundColor: "#2b48ff",
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1730",
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  // NOVO: badges de pessoas/animais
  badgesRow: {
    flexDirection: "row",
    gap: 8,
    paddingHorizontal: 12,
    paddingVertical: 6,
    backgroundColor: "#0b0f1e",
  },
  badge: {
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
  },
  badgeTxt: { color: "white", fontWeight: "700" },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(43,72,255,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});




Checklist rápido




Servidor rodando (/debug_models com objects_ok: true).


App: “Servidor” = http://SEU_PC:8000.


Câmera → botão Detectar.


Veja os badges atualizando: 👤 Pessoas: N e 🐾 Animais: M.




Se /objects mostra itens, mas o app ainda não conta, me manda um exemplo de JSON retornado por /detect (primeiras linhas) para eu alinhar o path exato (j.objects.objects).























































(.venv) PS D:\loud2025\hydrobot-server> uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload   
INFO:     Will watch for changes in these directories: ['D:\\loud2025\\hydrobot-server']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [17572] using WatchFiles
Process SpawnProcess-1:
Traceback (most recent call last):
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\process.py", line 313, in _bootstrap
    self.run()
    ~~~~~~~~^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
    ~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 65, in run
    return asyncio.run(self.serve(sockets=sockets))
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run 
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run 
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 725, in 
run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 69, in serve
    await self._serve(sockets)
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 76, in _serve
    config.load()
    ~~~~~~~~~~~^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\config.py", line 434, in load
    self.loaded_app = import_from_string(self.app)
                      ~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py", line 88, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 1022, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1160, in get_code
  File "<frozen importlib._bootstrap_external>", line 1090, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "D:\loud2025\hydrobot-server\server_heuristic.py", line 259
    self._thread = threading.Thread(target=self._run, daemon=True)
IndentationError: unexpected indent
