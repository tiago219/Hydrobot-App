// src/screens/CameraScreen.tsx
import React, { useCallback, useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  Image,
  AppState,
  AppStateStatus,
} from "react-native";
import { WebView } from "react-native-webview";

type Mode = "mjpeg" | "snapshot";

const PALETTE = { bg: "#0b0b0f", card: "#121218", border: "#25273a", accent: "#e6403a", text: "#e5e7eb" };

export default function CameraScreen() {
  const [ip, setIp] = useState<string>("192.168.4.1"); // ajuste para seu IP (ou mDNS se usar proxy)
  const [testedIp, setTestedIp] = useState<string>(""); // IP efetivo em uso na visualização
  const [mode, setMode] = useState<Mode>("mjpeg");
  const [status, setStatus] = useState<string>("Aguardando IP");
  const [snapTick, setSnapTick] = useState<number>(0);
  const [isRunning, setIsRunning] = useState<boolean>(false);
  const snapTimerRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const appState = useRef<AppStateStatus>(AppState.currentState);

  const streamURL = useMemo(() => (testedIp ? `http://${testedIp}/stream` : ""), [testedIp]);
  const snapshotURL = useMemo(
    () => (testedIp ? `http://${testedIp}/snapshot?_=${snapTick}` : ""),
    [testedIp, snapTick]
  );
  const healthURL = useMemo(() => (testedIp ? `http://${testedIp}/status` : ""), [testedIp]);

  // ---- Controle do modo snapshot (polling) ----
  const startSnapshotLoop = useCallback(() => {
    if (snapTimerRef.current) return;
    snapTimerRef.current = setInterval(() => setSnapTick((t) => (t + 1) % 1_000_000), 150); // ~6-7 FPS
  }, []);

  const stopSnapshotLoop = useCallback(() => {
    if (snapTimerRef.current) {
      clearInterval(snapTimerRef.current);
      snapTimerRef.current = null;
    }
  }, []);

  useEffect(() => {
    if (mode === "snapshot" && testedIp) {
      startSnapshotLoop();
    } else {
      stopSnapshotLoop();
    }
    return stopSnapshotLoop;
  }, [mode, testedIp, startSnapshotLoop, stopSnapshotLoop]);

  // Pausar quando app em background (evita consumo)
  useEffect(() => {
    const sub = AppState.addEventListener("change", (nextState) => {
      const prev = appState.current;
      appState.current = nextState;
      if (prev.match(/active/) && nextState.match(/inactive|background/)) {
        stopSnapshotLoop();
        setIsRunning(false);
      } else if (prev.match(/inactive|background/) && nextState === "active") {
        if (mode === "snapshot" && testedIp) startSnapshotLoop();
        if (testedIp) setIsRunning(true);
      }
    });
    return () => sub.remove();
  }, [mode, testedIp, startSnapshotLoop, stopSnapshotLoop]);

  // ---- Teste de conexão e fallback automático ----
  const testConnection = useCallback(async () => {
    const target = (ip || "").trim();
    if (!target) {
      setStatus("Informe o IP do ESP");
      return;
    }
    setStatus("Testando conexão...");
    setIsRunning(false);
    stopSnapshotLoop();

    // 1) Tenta um GET rápido no /status (se existir)
    try {
      const ctrl = new AbortController();
      const to = setTimeout(() => ctrl.abort(), 2000);
      const r = await fetch(`http://${target}/status`, { signal: ctrl.signal });
      clearTimeout(to);
      if (r.ok) {
        setTestedIp(target);
        setMode("mjpeg");
        setStatus("Conectado (tentando MJPEG)...");
        setIsRunning(true);
        return;
      }
    } catch (_) {
      // segue para checar /stream e /snapshot
    }

    // 2) Checa se /stream responde pelo menos com headers
    try {
      const ctrl = new AbortController();
      const to = setTimeout(() => ctrl.abort(), 2000);
      const r = await fetch(`http://${target}/stream`, { method: "GET", signal: ctrl.signal });
      clearTimeout(to);
      if (r.ok) {
        setTestedIp(target);
        setMode("mjpeg");
        setStatus("Conectado (MJPEG)...");
        setIsRunning(true);
        return;
      }
    } catch (_) {
      // segue
    }

    // 3) Fallback: tenta /snapshot
    try {
      const ctrl = new AbortController();
      const to = setTimeout(() => ctrl.abort(), 2000);
      const r = await fetch(`http://${target}/snapshot`, { method: "GET", signal: ctrl.signal });
      clearTimeout(to);
      if (r.ok) {
        setTestedIp(target);
        setMode("snapshot");
        setStatus("Conectado (Snapshot contínuo)...");
        setIsRunning(true);
        startSnapshotLoop();
        return;
      }
    } catch (_) {
      // segue
    }

    setStatus("Falha ao conectar. Verifique IP/rede/firmware.");
    setIsRunning(false);
  }, [ip, startSnapshotLoop, stopSnapshotLoop]);

  // ---- UI MJPEG via WebView (funciona bem no Android) ----
  const mjpegHTML = useMemo(() => {
    if (!streamURL) return "";
    // HTML simples que carrega o MJPEG e tenta auto-reconectar em caso de erro
    return `
      <!doctype html>
      <html><head><meta name="viewport" content="width=device-width, initial-scale=1" />
      <style>
        html,body{margin:0;padding:0;background:#0b0b0f;height:100%;overflow:hidden;}
        #wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;}
        img{max-width:100vw;max-height:100vh;object-fit:contain;}
        #badge{position:fixed;left:8px;bottom:8px;padding:4px 8px;border-radius:8px;
               background:#121218;color:#e5e7eb;font-family:system-ui,Arial,sans-serif;font-size:12px;opacity:.7}
      </style></head>
      <body>
        <div id="wrap">
          <img id="mjpeg" src="${streamURL}" />
        </div>
        <div id="badge">Stream: ${streamURL}</div>
        <script>
          const img = document.getElementById('mjpeg');
          let retryMs = 1000;
          img.addEventListener('error', () => {
            setTimeout(() => {
              img.src = '${streamURL}' + '?_=' + Date.now();
            }, retryMs);
            retryMs = Math.min(retryMs * 2, 5000);
          });
        </script>
      </body></html>
    `.trim();
  }, [streamURL]);

  // ---- Render ----
  return (
    <View style={styles.container}>
      <Text style={styles.title}>ESP32-CAM Viewer</Text>

      <View style={styles.row}>
        <Text style={styles.label}>ESP IP</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder="ex.: 192.168.4.1"
          placeholderTextColor="#6b7280"
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
        />
        <Pressable style={styles.button} onPress={testConnection}>
          <Text style={styles.buttonText}>Testar</Text>
        </Pressable>
      </View>

      <Text style={styles.status}>
        Status: {status} {testedIp ? `| IP: ${testedIp}` : ""}
        {testedIp ? ` | Modo: ${mode}` : ""}
      </Text>

      <View style={styles.viewer}>
        {testedIp && isRunning ? (
          mode === "mjpeg" ? (
            <WebView
              originWhitelist={["*"]}
              source={{ html: mjpegHTML, baseUrl: `http://${testedIp}` }}
              javaScriptEnabled
              domStorageEnabled
              allowsInlineMediaPlayback
              allowsFullscreenVideo={false}
              mediaPlaybackRequiresUserAction={false}
              onError={() => {
                // Cai para snapshot se o WebView reportar erro
                setMode("snapshot");
                setStatus("MJPEG falhou — alternando para Snapshot...");
              }}
              style={styles.webview}
            />
          ) : (
            <Image
              source={{ uri: snapshotURL }}
              resizeMode="contain"
              style={styles.image}
              onError={() => setStatus("Erro no snapshot — checar conexão")}
            />
          )
        ) : (
          <View style={styles.placeholder}>
            <Text style={{ color: PALETTE.text, opacity: 0.7, textAlign: "center" }}>
              Informe o IP e toque em “Testar” para iniciar o vídeo.
            </Text>
          </View>
        )}
      </View>

      {testedIp ? (
        <View style={styles.footerRow}>
          <Pressable
            style={[styles.smallBtn, mode === "mjpeg" ? styles.smallBtnActive : null]}
            onPress={() => {
              setMode("mjpeg");
              setStatus("Tentando MJPEG /stream...");
            }}
          >
            <Text style={styles.smallBtnText}>Usar MJPEG</Text>
          </Pressable>
          <Pressable
            style={[styles.smallBtn, mode === "snapshot" ? styles.smallBtnActive : null]}
            onPress={() => {
              setMode("snapshot");
              setStatus("Usando /snapshot contínuo...");
            }}
          >
            <Text style={styles.smallBtnText}>Usar Snapshot</Text>
          </Pressable>
        </View>
      ) : null}
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg, padding: 16, gap: 12 },
  title: { color: PALETTE.text, fontSize: 20, fontWeight: "700" },
  row: { flexDirection: "row", alignItems: "center", gap: 8 },
  label: { color: PALETTE.text },
  input: {
    flex: 1,
    backgroundColor: PALETTE.card,
    color: PALETTE.text,
    borderWidth: 1,
    borderColor: PALETTE.border,
    borderRadius: 10,
    paddingHorizontal: 10,
    paddingVertical: 8,
  },
  button: {
    backgroundColor: PALETTE.accent,
    paddingHorizontal: 14,
    paddingVertical: 10,
    borderRadius: 10,
  },
  buttonText: { color: "#fff", fontWeight: "700" },
  status: { color: PALETTE.text, opacity: 0.9 },
  viewer: {
    flex: 1,
    backgroundColor: "#000",
    borderRadius: 12,
    overflow: "hidden",
    borderWidth: 1,
    borderColor: PALETTE.border,
  },
  webview: { flex: 1, backgroundColor: "#000" },
  image: { width: "100%", height: "100%" },
  placeholder: { flex: 1, alignItems: "center", justifyContent: "center", padding: 24 },
  footerRow: { flexDirection: "row", gap: 10, justifyContent: "center" },
  smallBtn: {
    paddingHorizontal: 12,
    paddingVertical: 8,
    borderRadius: 10,
    borderWidth: 1,
    borderColor: PALETTE.border,
    backgroundColor: PALETTE.card,
  },
  smallBtnActive: { borderColor: PALETTE.accent },
  smallBtnText: { color: PALETTE.text, fontWeight: "600" },
});














#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HydroBot Server (ESTÁVEL) – Lê /stream (MJPEG) do ESP32-CAM, guarda o último frame,
serve /frame.jpg e calcula score simples de fogo (HSV + EMA).

Rodar:
  uvicorn server_heuristic:app --host 0.0.0.0 --port 8000
Deps:
  pip install fastapi uvicorn requests opencv-python numpy pydantic
"""

import time
import threading
from typing import Optional, Dict, Any
import re

import requests
import cv2
import numpy as np
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "hydrobot.local"
STREAM_URL_FMT = "http://{}/stream"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 10.0
MAX_FRAME_AGE_MS = 10_000
MAX_RESULT_AGE_MS = 800
JPEG_QUALITY = 85

# Fire (HSV simples)
HSV_LOW = (8, 70, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.3
FIRE_THRESHOLD = 0.15

BOUNDARY_RE = re.compile(br'--[^\r\n]+')
REQ_HEADERS = {"Connection": "keep-alive", "User-Agent": "HydroBot-Grabber/3.0"}

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (Stable)", version="4.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
  camera_ip: str

def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
  img = np.zeros((240, 320, 3), dtype=np.uint8)
  img[:, :] = (50, 50, 150)
  cv2.putText(img, msg, (38, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
  cv2.putText(img, time.strftime("%H:%M:%S"), (38, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
  ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
  return buf.tobytes()

# ========= MJPEG Stream Grabber =========
class StreamGrabber:
  def __init__(self, ip: str):
    self.ip = ip
    self._stop = threading.Event()
    self._lock = threading.Lock()
    self._last_jpeg: Optional[bytes] = None
    self._last_ts = 0
    self._fps_in = 0.0
    self._frames = 0
    self._tick = time.time()
    self._last_err: Optional[str] = None

  def start(self):
    self._stop.clear()
    t = threading.Thread(target=self._run, daemon=True)
    t.start()

  def stop(self):
    self._stop.set()

  def _run(self):
    while not self._stop.is_set():
      url = STREAM_URL_FMT.format(self.ip)
      buf = b""
      try:
        with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQ_HEADERS) as r:
          r.raise_for_status()
          for chunk in r.iter_content(chunk_size=4096):
            if self._stop.is_set():
              break
            if not chunk:
              continue
            buf += chunk

            # procurar boundaries e extrair o penúltimo part (frame completo)
            m = BOUNDARY_RE.search(buf)
            if not m:
              if len(buf) > 2_000_000:
                buf = buf[-200_000:]
              continue

            parts = BOUNDARY_RE.split(buf)
            if len(parts) >= 2:
              frame_blob = parts[-2]
              buf = parts[-1]

              header_end = frame_blob.find(b"\r\n\r\n")
              if header_end == -1:
                continue
              body = frame_blob[header_end+4:]

              if body.startswith(b"\xff\xd8") and body.endswith(b"\xff\xd9"):
                with self._lock:
                  self._last_jpeg = body
                  self._last_ts = int(time.time()*1000)
                  self._last_err = None
                  self._frames += 1
                  now = time.time()
                  if now - self._tick >= 1.0:
                    self._fps_in = self._frames / (now - self._tick)
                    self._frames = 0
                    self._tick = now

      except Exception as e:
        with self._lock:
          self._last_err = str(e)
        time.sleep(0.8)  # backoff curto e reconecta

  def get_latest(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
    with self._lock:
      if not self._last_jpeg:
        return None
      if int(time.time()*1000) - self._last_ts > max_age_ms:
        return None
      return self._last_jpeg

  def status(self) -> Dict[str, Any]:
    with self._lock:
      age = int(time.time()*1000) - self._last_ts if self._last_ts else None
      return {
        "ip": self.ip,
        "hasFrame": self._last_jpeg is not None,
        "age_ms": age,
        "fps_in": round(self._fps_in, 2),
        "last_err": self._last_err
      }

grabber = StreamGrabber(CAMERA_IP)
grabber.start()

# ========= Fire Detection =========
def simple_fire_score(frame_bgr: np.ndarray) -> float:
  try:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))
    fire_ratio = float(np.count_nonzero(mask)) / float(mask.size)
    v_mean = float(np.mean(hsv[:, :, 2])) / 255.0
    score = min(1.0, fire_ratio * 4.0 + v_mean * 0.1)
    return float(score)
  except Exception:
    return 0.0

class FireDetector:
  def __init__(self, src: StreamGrabber):
    self.src = src
    self._lock = threading.Lock()
    self._stop = threading.Event()
    self._thr: Optional[threading.Thread] = None

    self._ema = 0.0
    self._raw = 0.0
    self._is_fire = False
    self._ts = 0
    self._fps = 0.0
    self._frames = 0
    self._tick = time.time()
    self._wh: Optional[tuple] = None

  def start(self):
    self._stop.clear()
    self._thr = threading.Thread(target=self._run, daemon=True)
    self._thr.start()

  def stop(self):
    self._stop.set()
    if self._thr and self._thr.is_alive():
      self._thr.join(timeout=1.0)

  def _run(self):
    interval = 1.0 / 5.0
    while not self._stop.is_set():
      t0 = time.time()
      jpeg = self.src.get_latest()
      if jpeg is None:
        time.sleep(0.1)
        continue
      try:
        frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
        if frame is None:
          time.sleep(0.05)
          continue
        H, W = frame.shape[:2]
        score = simple_fire_score(frame)
        ema = score if self._ema == 0.0 else EMA_ALPHA*score + (1.0-EMA_ALPHA)*self._ema
        is_fire = (ema >= FIRE_THRESHOLD)
        with self._lock:
          self._raw = score
          self._ema = ema
          self._is_fire = is_fire
          self._ts = int(time.time()*1000)
          self._wh = (W, H)
          self._frames += 1
          now = time.time()
          if now - self._tick >= 1.0:
            self._fps = self._frames / (now - self._tick)
            self._frames = 0
            self._tick = now
      except Exception:
        pass
      dt = time.time() - t0
      time.sleep(max(0.0, interval - dt))

  def get(self) -> Dict[str, Any]:
    with self._lock:
      return {
        "ok": True,
        "isFire": bool(self._is_fire),
        "score": round(float(self._ema), 3),
        "score_raw": round(float(self._raw), 3),
        "ts": int(self._ts),
        "fps_det": round(float(self._fps), 2),
        "frame_wh": list(self._wh) if self._wh else None
      }

detector = FireDetector(grabber)
detector.start()

# ========= Endpoints =========
@app.get("/healthz")
def healthz():
  s = grabber.status()
  return {"ok": True, "camera_ip": s.get("ip"), **s}

@app.get("/status")
def status():
  s = grabber.status()
  d = detector.get()
  return {"ok": True, "camera_ip": s.get("ip"), **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
  global CAMERA_IP, grabber, detector
  CAMERA_IP = cfg.camera_ip
  # reinicia o grabber
  grabber.stop()
  grabber = StreamGrabber(CAMERA_IP)
  grabber.start()
  # detector continua usando o mesmo objeto? recria para limpar estado
  detector.stop()
  detector = FireDetector(grabber)
  detector.start()
  return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
  b = grabber.get_latest() or placeholder_jpeg("NO FRAME")
  headers = {
    "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
    "Pragma": "no-cache",
    "Expires": "0",
    "Content-Type": "image/jpeg"
  }
  return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/frame.jpg")
def frame_jpg():
  return snapshot()

@app.get("/detect")
def detect():
  res = detector.get()
  if res.get("ts", 0) and (int(time.time()*1000) - int(res["ts"]) <= MAX_RESULT_AGE_MS):
    return res
  # fallback rápido
  jpeg = grabber.get_latest()
  if jpeg is None:
    return {"ok": False, "error": "no recent frame"}
  frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
  if frame is None:
    return {"ok": False, "error": "decode failed"}
  score = simple_fire_score(frame)
  is_fire = (score >= FIRE_THRESHOLD)
  H, W = frame.shape[:2]
  return {
    "ok": True,
    "isFire": bool(is_fire),
    "score": round(float(score), 3),
    "score_raw": round(float(score), 3),
    "ts": int(time.time()*1000),
    "frame_wh": [W, H],
    "fallback": True
  }

if __name__ == "__main__":
  import uvicorn
  print("HydroBot Server (Stable) — lendo /stream")
  print(f"Camera IP: {CAMERA_IP}")
  uvicorn.run(app, host="0.0.0.0", port=8000)













#include "esp_camera.h"
#include <WiFi.h>

// ===========================
// Select camera model in board_config.h
// ===========================
#include "board_config.h"

// ===========================
// Enter your WiFi credentials
// ===========================
const char *ssid = "HydroBot";
const char *password = "loud2025emibr";

void startCameraServer();
void setupLedFlash();

void setup() {
  Serial.begin(115200);
  Serial.setDebugOutput(true);
  Serial.println();

  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer = LEDC_TIMER_0;
  config.pin_d0 = Y2_GPIO_NUM;
  config.pin_d1 = Y3_GPIO_NUM;
  config.pin_d2 = Y4_GPIO_NUM;
  config.pin_d3 = Y5_GPIO_NUM;
  config.pin_d4 = Y6_GPIO_NUM;
  config.pin_d5 = Y7_GPIO_NUM;
  config.pin_d6 = Y8_GPIO_NUM;
  config.pin_d7 = Y9_GPIO_NUM;
  config.pin_xclk = XCLK_GPIO_NUM;
  config.pin_pclk = PCLK_GPIO_NUM;
  config.pin_vsync = VSYNC_GPIO_NUM;
  config.pin_href = HREF_GPIO_NUM;
  config.pin_sccb_sda = SIOD_GPIO_NUM;
  config.pin_sccb_scl = SIOC_GPIO_NUM;
  config.pin_pwdn = PWDN_GPIO_NUM;
  config.pin_reset = RESET_GPIO_NUM;
  config.xclk_freq_hz = 20000000;
  config.frame_size = FRAMESIZE_UXGA;
  config.pixel_format = PIXFORMAT_JPEG;  // for streaming
  //config.pixel_format = PIXFORMAT_RGB565; // for face detection/recognition
  config.grab_mode = CAMERA_GRAB_WHEN_EMPTY;
  config.fb_location = CAMERA_FB_IN_PSRAM;
  config.jpeg_quality = 12;
  config.fb_count = 1;

  // if PSRAM IC present, init with UXGA resolution and higher JPEG quality
  //                      for larger pre-allocated frame buffer.
  if (config.pixel_format == PIXFORMAT_JPEG) {
    if (psramFound()) {
      config.jpeg_quality = 10;
      config.fb_count = 2;
      config.grab_mode = CAMERA_GRAB_LATEST;
    } else {
      // Limit the frame size when PSRAM is not available
      config.frame_size = FRAMESIZE_SVGA;
      config.fb_location = CAMERA_FB_IN_DRAM;
    }
  } else {
    // Best option for face detection/recognition
    config.frame_size = FRAMESIZE_240X240;
#if CONFIG_IDF_TARGET_ESP32S3
    config.fb_count = 2;
#endif
  }

#if defined(CAMERA_MODEL_ESP_EYE)
  pinMode(13, INPUT_PULLUP);
  pinMode(14, INPUT_PULLUP);
#endif

  // camera init
  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    Serial.printf("Camera init failed with error 0x%x", err);
    return;
  }

  sensor_t *s = esp_camera_sensor_get();
  // initial sensors are flipped vertically and colors are a bit saturated
  if (s->id.PID == OV3660_PID) {
    s->set_vflip(s, 1);        // flip it back
    s->set_brightness(s, 1);   // up the brightness just a bit
    s->set_saturation(s, -2);  // lower the saturation
  }
  // drop down frame size for higher initial frame rate
  if (config.pixel_format == PIXFORMAT_JPEG) {
    s->set_framesize(s, FRAMESIZE_QVGA);
  }

#if defined(CAMERA_MODEL_M5STACK_WIDE) || defined(CAMERA_MODEL_M5STACK_ESP32CAM)
  s->set_vflip(s, 1);
  s->set_hmirror(s, 1);
#endif

#if defined(CAMERA_MODEL_ESP32S3_EYE)
  s->set_vflip(s, 1);
#endif

// Setup LED FLash if LED pin is defined in camera_pins.h
#if defined(LED_GPIO_NUM)
  setupLedFlash();
#endif

  WiFi.begin(ssid, password);
  WiFi.setSleep(false);

  Serial.print("WiFi connecting");
  while (WiFi.status() != WL_CONNECTED) {
    delay(500);
    Serial.print(".");
  }
  Serial.println("");
  Serial.println("WiFi connected");

  startCameraServer();

  Serial.print("Camera Ready! Use 'http://");
  Serial.print(WiFi.localIP());
  Serial.println("' to connect");
}

void loop() {
  // Do nothing. Everything is done in another task by the web server
  delay(10000);
}
