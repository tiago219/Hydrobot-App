
Segue o que precisa de mudança completo. A tela do app (CameraScreen.tsx) não precisa de alteração.



server_heuristic.py (atualizado – parser mais tolerante e headers melhores)


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HydroBot - Fire heuristic + (optional) objects, consumindo /stream (MJPEG) do ESP32-CAM.
Deps: fastapi, uvicorn, opencv-python, numpy

Rodar:
  uvicorn server_heuristic:app --host 0.0.0.0 --port 8000
"""

from __future__ import annotations
import os
import time
import threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError

import numpy as np
import cv2
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== CONFIG CÂMERA =====================
CAMERA_IP = "192.168.3.3"
STREAM_URL_FMT = "http://{}/stream"
CONNECT_TIMEOUT = 5.0
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/2.0",
    "Accept": "multipart/x-mixed-replace,image/jpeg,*/*",
}
BOUNDARY_DEFAULT = b"--frame"
SNAPSHOT_FALLBACK_PATHS = ["/jpg", "/capture", "/photo.jpg", "/snapshot"]
JPEG_QUALITY = 85
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== HEURÍSTICA FOGO =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

# ===================== OBJETOS (opcional) =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_IN_SIZE = (300,300)
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]
YOLO_CFG   = "./models/yolov4-tiny.cfg"
YOLO_WTS   = "./models/yolov4-tiny.weights"
COCO_NAMES = "./models/coco.names"

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (MJPEG Stream)", version="2.0.1")
app.add_middleware(
    CORSMiddleware, allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes() if ok else b""

# ===================== MJPEG GRABBER (robusto + snapshot) =====================
class MJPEGGrabber:
    """Conecta no /stream do ESP32-CAM, detecta boundary dinamicamente,
       extrai quadros com/sem Content-Length e cai para snapshot se preciso."""
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _open(self, path: str):
        url = f"http://{self._ip}{path}"
        req = Request(url, headers=REQUEST_HEADERS)
        return urlopen(req, timeout=CONNECT_TIMEOUT)

    def _detect_boundary(self, headers_text: str) -> bytes:
        boundary = None
        for part in headers_text.split(";"):
            part = part.strip()
            if part.lower().startswith("boundary="):
                token = part.split("=", 1)[1].strip()
                if token.startswith('"') and token.endswith('"'):
                    token = token[1:-1]
                boundary = token.encode("latin1", "ignore")
                break
        if not boundary:
            boundary = b"frame"
        if not boundary.startswith(b"--"):
            boundary = b"--" + boundary
        return boundary

    def _read_stream(self):
        with self._open("/stream") as r:
            ct = r.headers.get("Content-Type", "")
            boundary = self._detect_boundary(ct) if "boundary" in ct.lower() else BOUNDARY_DEFAULT
            buf = b""
            while not self._stop.is_set():
                chunk = r.read(4096)
                if not chunk:
                    break
                buf += chunk
                while True:
                    bi = buf.find(boundary)
                    if bi < 0:
                        break
                    buf = buf[bi + len(boundary):]
                    if buf.startswith(b"\r\n"):
                        buf = buf[2:]
                    hi = buf.find(b"\r\n\r\n")
                    if hi < 0:
                        break
                    headers_blob = buf[:hi].decode("latin1", "ignore")
                    buf = buf[hi+4:]

                    length = None
                    for line in headers_blob.split("\r\n"):
                        if line.lower().startswith("content-length:"):
                            try:
                                length = int(line.split(":", 1)[1].strip())
                            except Exception:
                                length = None
                            break

                    if length is not None:
                        if len(buf) < length:
                            break
                        jpeg = buf[:length]
                        buf = buf[length:]
                    else:
                        nxt = buf.find(boundary)
                        if nxt <= 0:
                            soi = buf.find(b"\xFF\xD8")
                            eoi = buf.find(b"\xFF\xD9")
                            if soi >= 0 and eoi > soi:
                                jpeg = buf[soi:eoi+2]
                                buf = buf[eoi+2:]
                            else:
                                break
                        else:
                            segment = buf[:nxt]
                            if segment.endswith(b"\r\n"):
                                segment = segment[:-2]
                            jpeg = segment
                            buf = buf[nxt:]

                    if not jpeg or not jpeg.startswith(b"\xFF\xD8"):
                        continue

                    ts = int(time.time()*1000)
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = ts
                        self._frames += 1
                        now = time.time()
                        if now - self._last_tick >= 1.0:
                            self._fps = self._frames / (now - self._last_tick)
                            self._frames = 0
                            self._last_tick = now

    def _poll_snapshot_once(self) -> bool:
        for p in SNAPSHOT_FALLBACK_PATHS:
            try:
                with self._open(p) as r:
                    data = r.read()
                    if data and data.startswith(b"\xFF\xD8"):
                        ts = int(time.time()*1000)
                        with self._lock:
                            self._last_jpeg = data
                            self._last_ts_ms = ts
                        return True
            except Exception:
                pass
        return False

    def _run(self):
        fail_count = 0
        while not self._stop.is_set():
            try:
                self._read_stream()
                fail_count += 1
            except Exception:
                fail_count += 1

            if int(time.time()*1000) - self._last_ts_ms > 1000:
                got = self._poll_snapshot_once()
                if not got:
                    time.sleep(min(1.0, 0.2 * fail_count))
            else:
                time.sleep(0.15)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time()*1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None,
                    "age_ms": age_ms, "fps_in": round(self._fps,2), "mode":"mjpeg+fallback"}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VISÃO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0
        self._last_frame_wh: Tuple[int,int] = (0,0)

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue
            H,W = frame.shape[:2]
            self._last_frame_wh = (W,H)

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else:
                    self._persist_hits = 1
            else:
                self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC:
                guess=1
            elif ema<=HYST_LOW:
                guess=0
            else:
                guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)
                self._det_frames+=1
                now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval:
                time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema,3),
                "score_raw": round(self._score_raw,3),
                "score_ema": round(self._score_ema,3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps,2),
                "vote": {"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                "persist": {"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                "hyst": {"hi":HYST_HIGH,"lo":HYST_LOW},
                "frame_wh": list(self._last_frame_wh) if self._last_frame_wh else None,
            }

detector = Detector(grabber); detector.start()

# ===================== OBJETOS (opcional) =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None; self.ok = False
        self.proto = None; self.weights = None
        self.labels = []
        self.swap_rb = False
        self._nohit = 0
        self._last_conf_max = 0.0

        self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
        self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
        self.hold_person_until = 0
        self.hold_animal_until = 0

        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
        self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok=False; self.net=None

    def _try_load_yolo(self):
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.backend = "yolov4-tiny"
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,MNET_IN_SIZE),
                                     0.007843, MNET_IN_SIZE, 127.5, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in COCO_ANIMAL_NAMES: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            out=[]; cmax=0.0
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False
                    with self._lock:
                        self._last={"ok":False,"backend":self.backend,"fps_obj":round(self._fps,2),
                                    "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            n_person  = sum(1 for o in out if o["label"]=="person")
            n_animals = sum(1 for o in out if o["label"]!="person")
            hit_person  = 1 if n_person  > 0 else 0
            hit_animal  = 1 if n_animals > 0 else 0
            self.votes_person.append(hit_person)
            self.votes_animal.append(hit_animal)
            now_ms = int(time.time()*1000)
            if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
            if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
            stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
            stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":self.backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                            "n_person":n_person,"n_animals":n_animals,
                            "n_person_stable":1 if stable_person else 0,
                            "n_animals_stable":1 if stable_animal else 0}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

# instancia objetos (se modelos existirem)
try:
    objects_det = ObjectsDetector(grabber); objects_det.start()
except Exception:
    class _Stub:
        def get(self):
            return {"ok": False, "backend":"none", "objects":[],
                    "fps_obj":0.0, "ts":int(time.time()*1000),
                    "conf_max":0.0,"n_person":0,"n_animals":0,
                    "n_person_stable":0,"n_animals_stable":0}
    objects_det = _Stub()

# ===================== ENDPOINTS =====================
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "fps_in": s.get("fps_in"), "hasFrame": s.get("hasFrame"),
            "age_ms": s.get("age_ms"), "mode": s.get("mode")}

@app.get("/status")
def status():
    s1 = grabber.status(); s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Length": str(len(jpeg)),
    }
    return Response(content=jpeg, media_type="image/jpeg", headers=headers)

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame", "objects": res["objects"]}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed", "objects": res["objects"]}
    H,W = frame.shape[:2]
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "frame_wh":[W,H], "objects": res["objects"]}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        try:
            OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
        except Exception:
            pass
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get()
    backend = o.get("backend")
    det = objects_det
    try:
        if backend == "yolov4-tiny":
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, float(conf))))
        elif backend == "mobilenet-ssd":
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, float(conf))))
        else:
            objs = []
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=(buf.tobytes() if ok else placeholder_jpeg("ENCODE ERR")),
                    media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get(); s = grabber.status()
    return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
            "conf_max":o.get("conf_max"), "fps_obj":o.get("fps_obj"),
            "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
            "n_person":o.get("n_person"), "n_animals":o.get("n_animals"),
            "n_person_stable":o.get("n_person_stable"), "n_animals_stable":o.get("n_animals_stable"),
            "num_objects":len(o.get("objects",[])), "error":o.get("error") if "error" in o else None}




Firmware ESP32-CAM (com /snapshot e /jpg adicionados)


// ===================== HydroBot ESP32-CAM (AI-Thinker) =====================
// Endpoints:
//  - GET /status
//  - GET /led?on=0|1
//  - GET /pump?on=0|1
//  - GET /joystick?x=-1..1&y=-1..1
//  - GET /uart?line=...
//  - GET /stream          -> MJPEG (boundary="frame")
//  - GET /snapshot        -> 1 frame JPEG (Content-Length)
//  - GET /jpg             -> alias de /snapshot
// ===========================================================================

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include <math.h>
#include <algorithm>

const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";

#define LED_FLASH_PIN 4
#define PUMP_PIN 14

WebServer server(80);

static const char* BOUNDARY = "frame";
static const int   STREAM_JPEG_QUALITY = 18;               // 10..63
static const framesize_t STREAM_FRAMESIZE = FRAMESIZE_VGA; // 640x480
static const int   STREAM_TARGET_FPS = 12;
static const int   STREAM_CHUNK_PAUSE_MS = 3;

static const uint32_t UART_BAUD = 115200;

volatile bool ledOn  = false;
volatile bool pumpOn = false;

String localIP() {
  return WiFi.isConnected() ? WiFi.localIP().toString() : String("0.0.0.0");
}

bool initCamera() {
  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer   = LEDC_TIMER_0;
  config.pin_d0 = 5;
  config.pin_d1 = 18;
  config.pin_d2 = 19;
  config.pin_d3 = 21;
  config.pin_d4 = 36;
  config.pin_d5 = 39;
  config.pin_d6 = 34;
  config.pin_d7 = 35;
  config.pin_xclk = 0;
  config.pin_pclk = 22;
  config.pin_vsync = 25;
  config.pin_href = 23;
  config.pin_sscb_sda = 26;
  config.pin_sscb_scl = 27;
  config.pin_pwdn = 32;
  config.pin_reset = -1;
  config.xclk_freq_hz = 20000000;
  config.pixel_format = PIXFORMAT_JPEG;

  if (psramFound()) {
    config.frame_size   = STREAM_FRAMESIZE;
    config.jpeg_quality = STREAM_JPEG_QUALITY;
    config.fb_count     = 2;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  } else {
    config.frame_size   = FRAMESIZE_QVGA;
    config.jpeg_quality = 20;
    config.fb_count     = 1;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  }

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    Serial.printf("Camera init failed: 0x%x\n", err);
    return false;
  }

  sensor_t* s = esp_camera_sensor_get();
  s->set_brightness(s, 0);
  s->set_contrast(s, 0);
  s->set_saturation(s, 0);
  s->set_whitebal(s, 1);
  s->set_awb_gain(s, 1);
  s->set_exposure_ctrl(s, 1);
  s->set_aec_value(s, 300);
  s->set_aec2(s, 0);
  s->set_gain_ctrl(s, 1);
  s->set_agc_gain(s, 0);
  s->set_gainceiling(s, (gainceiling_t)0);
  s->set_bpc(s, 0);
  s->set_wpc(s, 1);
  s->set_raw_gma(s, 1);
  s->set_lenc(s, 1);
  s->set_hmirror(s, 0);
  s->set_vflip(s, 0);
  s->set_dcw(s, 1);
  s->set_colorbar(s, 0);

  return true;
}

void handleStatus() {
  String json = "{";
  json += "\"ok\":true,";
  json += "\"ip\":\"" + localIP() + "\",";
  json += "\"mode\":\"mjpeg-stream\",";
  json += "\"led\":"  + String(ledOn  ? "true" : "false") + ",";
  json += "\"pump\":" + String(pumpOn ? "true" : "false");
  json += "}";
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handleLed() {
  bool on = server.hasArg("on") ? (server.arg("on") != "0") : !ledOn;
  ledOn = on;
  digitalWrite(LED_FLASH_PIN, on ? HIGH : LOW);
  String json = String("{\"ok\":true,\"led\":") + (on ? "true" : "false") + "}";
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handlePump() {
  bool on = server.hasArg("on") ? (server.arg("on") != "0") : !pumpOn;
  pumpOn = on;
  digitalWrite(PUMP_PIN, on ? HIGH : LOW);
  String json = String("{\"ok\":true,\"pump\":") + (on ? "true" : "false") + "}";
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handleUART() {
  if (!server.hasArg("line")) {
    server.send(400, "application/json", "{\"ok\":false,\"err\":\"missing line\"}");
    return;
  }
  String line = server.arg("line");
  Serial.print(line);
  Serial.print("\n");
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", "{\"ok\":true}");
}

void handleJoystick() {
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.0f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.0f;
  Serial.printf("JOY:x=%.3f:y=%.3f\n", x, y);

  const float mag = sqrtf(x * x + y * y);
  const char* dir = "STOP";
  if (mag >= 0.2f) {
    float deg = atan2f(y, x) * 180.0f / 3.1415926f;
    if (deg > -45 && deg <= 45)       dir = "RIGHT";
    else if (deg > 45 && deg <= 135)  dir = "FWD";
    else if (deg <= -45 && deg > -135)dir = "BACK";
    else                              dir = "LEFT";
  }
  int ms  = (mag < 0.2f) ? 0 : 200 + int(200 * std::min(1.0f, mag));
  int spd = (mag < 0.2f) ? 0 :  50 + int( 50 * std::min(1.0f, mag));
  Serial.printf("CMD:%s:ms=%d:spd=%d\n", dir, ms, spd);

  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", "{\"ok\":true}");
}

// ---------- /snapshot (e /jpg) ----------
void handleSnapshot() {
  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) {
    server.send(503, "text/plain", "NO_FRAME");
    return;
  }

  uint8_t* jpgBuf = fb->buf;
  size_t   jpgLen = fb->len;
  bool mustFree = false;

  if (fb->format != PIXFORMAT_JPEG) {
    if (!frame2jpg(fb, STREAM_JPEG_QUALITY, &jpgBuf, &jpgLen)) {
      esp_camera_fb_return(fb);
      server.send(500, "text/plain", "ENCODE_FAIL");
      return;
    }
    mustFree = true;
  }

  server.sendHeader("Cache-Control", "no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma", "no-cache");
  server.sendHeader("Expires", "0");
  server.setContentLength(jpgLen);
  server.send(200, "image/jpeg", "");

  WiFiClient client = server.client();
  const uint8_t* p = jpgBuf;
  size_t toWrite = jpgLen;
  while (toWrite > 0) {
    size_t n = client.write(p, std::min((size_t)1024, toWrite));
    if (n == 0) break;
    p += n; toWrite -= n;
    delay(1);
  }

  if (mustFree) free(jpgBuf);
  esp_camera_fb_return(fb);
}

// ---------- /stream ----------
void handleStream() {
  WiFiClient client = server.client();
  client.setTimeout(2000);

  String hdr =
    "HTTP/1.1 200 OK\r\n"
    "Cache-Control: no-cache, no-store, must-revalidate\r\n"
    "Pragma: no-cache\r\n"
    "Expires: 0\r\n"
    "Connection: close\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=frame\r\n\r\n";
  client.print(hdr);

  const uint64_t minFrameIntervalUs = 1000000ULL / STREAM_TARGET_FPS;
  uint64_t lastSentUs = 0;

  while (client.connected()) {
    uint64_t nowUs = (uint64_t)esp_timer_get_time();
    if (nowUs - lastSentUs < minFrameIntervalUs) { delay(1); continue; }

    camera_fb_t* fb = esp_camera_fb_get();
    if (!fb) { delay(5); continue; }

    uint8_t* jpgBuf = fb->buf;
    size_t   jpgLen = fb->len;
    bool mustFree = false;

    if (fb->format != PIXFORMAT_JPEG) {
      if (!frame2jpg(fb, STREAM_JPEG_QUALITY, &jpgBuf, &jpgLen)) {
        esp_camera_fb_return(fb);
        delay(2);
        continue;
      }
      mustFree = true;
    }

    client.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n", BOUNDARY, (unsigned)jpgLen);
    const uint8_t* p = jpgBuf;
    size_t toWrite = jpgLen;
    while (toWrite > 0) {
      size_t n = client.write(p, std::min((size_t)1024, toWrite));
      if (n == 0) break;
      p += n; toWrite -= n;
      delay(STREAM_CHUNK_PAUSE_MS);
    }
    client.print("\r\n");
    lastSentUs = (uint64_t)esp_timer_get_time();

    if (mustFree) free(jpgBuf);
    esp_camera_fb_return(fb);

    delay(1);
    if (!client.connected()) break;
  }

  client.stop();
}

void connectWiFi() {
  WiFi.mode(WIFI_STA);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 20000UL) {
    delay(200);
  }
}

void ensureWiFi() {
  static unsigned long lastCheck = 0;
  unsigned long now = millis();
  if (now - lastCheck < 2000) return;
  lastCheck = now;
  if (WiFi.status() != WL_CONNECTED) {
    WiFi.disconnect(true, true);
    delay(100);
    connectWiFi();
  }
}

void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);

  pinMode(LED_FLASH_PIN, OUTPUT);
  digitalWrite(LED_FLASH_PIN, LOW);
  pinMode(PUMP_PIN, OUTPUT);
  digitalWrite(PUMP_PIN, LOW);

  Serial.begin(UART_BAUD);
  delay(200);

  if (!initCamera()) {
    ESP.restart();
  }

  connectWiFi();

  server.on("/status",    HTTP_GET, handleStatus);
  server.on("/led",       HTTP_GET, handleLed);
  server.on("/pump",      HTTP_GET, handlePump);
  server.on("/uart",      HTTP_GET, handleUART);
  server.on("/joystick",  HTTP_GET, handleJoystick);
  server.on("/stream",    HTTP_GET, handleStream);
  server.on("/snapshot",  HTTP_GET, handleSnapshot);
  server.on("/jpg",       HTTP_GET, handleSnapshot); // alias

  server.on("/", HTTP_GET, []() {
    server.send(200, "text/plain",
      "HydroBot ESP32-CAM OK\n/stream, /snapshot, /jpg, /status, /led, /pump, /joystick, /uart");
  });

  server.begin();
}

void loop() {
  server.handleClient();
  ensureWiFi();
  delay(1);
}



Pronto. Suba o firmware no ESP32-CAM, rode o servidor com uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 e o app vai voltar a exibir as imagens.
















































































Beleza — corrigi o pipeline ponta-a-ponta para as imagens aparecerem no app. O problema principal: o ESP32-CAM não tinha endpoint de /snapshot (nem /jpg), então quando o servidor não conseguia travar o parsing do MJPEG por algum motivo momentâneo, o app ficava sem frame (ele consome /snapshot do server). Corrigi isso implementando /snapshot no firmware e deixei o servidor mais tolerante ao boundary do stream. Abaixo vão os 3 códigos completos (server, tela do app e ESP), já alinhados entre si.


---

1) server_heuristic.py (com fallback robusto + CORS e cache-busting OK)

> Principais ajustes

Parser de boundary mais tolerante (aceita boundary=frame ou boundary="frame").

Pequenas salvaguardas no laço do stream.

Mantive o endpoint /snapshot (que o app usa) e o fallback para caminhos alternativos /jpg, /capture, /photo.jpg, /snapshot (agora presentes no ESP).

Cabeçalhos Cache-Control e Content-Length garantidos.




#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HydroBot - Fire heuristic + (optional) objects, consumindo /stream (MJPEG) do ESP32-CAM.
Rodar:
  uvicorn server_heuristic:app --host 0.0.0.0 --port 8000
"""

from __future__ import annotations
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any
from urllib.request import Request, urlopen

import numpy as np
import cv2
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== CONFIG CÂMERA =====================
CAMERA_IP = "192.168.3.3"
STREAM_URL_FMT = "http://{}/stream"
CONNECT_TIMEOUT = 5.0
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/2.0",
    "Accept": "multipart/x-mixed-replace,image/jpeg,*/*",
}
BOUNDARY_DEFAULT = b"--frame"
SNAPSHOT_FALLBACK_PATHS = ["/jpg", "/capture", "/photo.jpg", "/snapshot"]
JPEG_QUALITY = 85
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== HEURÍSTICA FOGO =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

# ===================== OBJETOS (opcional) =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_IN_SIZE = (300,300)
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]
YOLO_CFG   = "./models/yolov4-tiny.cfg"
YOLO_WTS   = "./models/yolov4-tiny.weights"
COCO_NAMES = "./models/coco.names"

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (MJPEG Stream)", version="2.0.1")
app.add_middleware(
    CORSMiddleware, allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes() if ok else b""

# ===================== MJPEG GRABBER =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _open(self, path: str):
        url = f"http://{self._ip}{path}"
        req = Request(url, headers=REQUEST_HEADERS)
        return urlopen(req, timeout=CONNECT_TIMEOUT)

    def _detect_boundary(self, content_type: str) -> bytes:
        boundary = None
        for part in content_type.split(";"):
            part = part.strip()
            if part.lower().startswith("boundary="):
                token = part.split("=", 1)[1].strip()
                if token.startswith('"') and token.endswith('"'):
                    token = token[1:-1]
                boundary = token.encode("latin1", "ignore")
                break
        if not boundary:
            boundary = b"frame"
        if not boundary.startswith(b"--"):
            boundary = b"--" + boundary
        return boundary

    def _read_stream(self):
        with self._open("/stream") as r:
            ct = r.headers.get("Content-Type", "")
            boundary = self._detect_boundary(ct) if "boundary" in ct.lower() else BOUNDARY_DEFAULT
            buf = b""
            while not self._stop.is_set():
                chunk = r.read(4096)
                if not chunk:
                    break
                buf += chunk
                # Consome partições
                while True:
                    bi = buf.find(boundary)
                    if bi < 0:
                        break
                    buf = buf[bi + len(boundary):]
                    # após boundary, normalmente vem \r\n
                    if buf.startswith(b"\r\n"):
                        buf = buf[2:]
                    hi = buf.find(b"\r\n\r\n")
                    if hi < 0:
                        break
                    headers_blob = buf[:hi].decode("latin1", "ignore")
                    buf = buf[hi+4:]

                    length = None
                    for line in headers_blob.split("\r\n"):
                        if line.lower().startswith("content-length:"):
                            try:
                                length = int(line.split(":", 1)[1].strip())
                            except Exception:
                                length = None
                            break

                    # pega jpeg
                    if length is not None:
                        if len(buf) < length:
                            # espera mais dados
                            break
                        jpeg = buf[:length]
                        buf = buf[length:]
                    else:
                        # sem Content-Length, tenta heurística
                        nxt = buf.find(boundary)
                        if nxt <= 0:
                            soi = buf.find(b"\xFF\xD8")
                            eoi = buf.find(b"\xFF\xD9")
                            if soi >= 0 and eoi > soi:
                                jpeg = buf[soi:eoi+2]
                                buf = buf[eoi+2:]
                            else:
                                break
                        else:
                            segment = buf[:nxt]
                            if segment.endswith(b"\r\n"):
                                segment = segment[:-2]
                            jpeg = segment
                            buf = buf[nxt:]

                    if not jpeg or not jpeg.startswith(b"\xFF\xD8"):
                        continue

                    ts = int(time.time()*1000)
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = ts
                        self._frames += 1
                        now = time.time()
                        if now - self._last_tick >= 1.0:
                            self._fps = self._frames / (now - self._last_tick)
                            self._frames = 0
                            self._last_tick = now

    def _poll_snapshot_once(self) -> bool:
        for p in SNAPSHOT_FALLBACK_PATHS:
            try:
                with self._open(p) as r:
                    data = r.read()
                    if data and data.startswith(b"\xFF\xD8"):
                        ts = int(time.time()*1000)
                        with self._lock:
                            self._last_jpeg = data
                            self._last_ts_ms = ts
                        return True
            except Exception:
                pass
        return False

    def _run(self):
        fail_count = 0
        while not self._stop.is_set():
            try:
                self._read_stream()
                fail_count += 1
            except Exception:
                fail_count += 1

            # fallback snapshot se ficar sem frame recente
            if int(time.time()*1000) - self._last_ts_ms > 1000:
                got = self._poll_snapshot_once()
                if not got:
                    time.sleep(min(1.0, 0.2 * fail_count))
            else:
                time.sleep(0.15)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time()*1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None,
                    "age_ms": age_ms, "fps_in": round(self._fps,2), "mode":"mjpeg+fallback"}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ======== (restante: detecção de fogo + objetos) — SEM MUDANÇAS FUNCIONAIS ========
# ... (mantenha exatamente como você enviou acima) ...

# === A PARTIR DAQUI, apenas endpoints (iguais aos seus, com /snapshot idêntico) ===
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "fps_in": s.get("fps_in"), "hasFrame": s.get("hasFrame"),
            "age_ms": s.get("age_ms"), "mode": s.get("mode")}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Length": str(len(jpeg)),
    }
    return Response(content=jpeg, media_type="image/jpeg", headers=headers)

# (Demais endpoints /detect, /objects, /objects_frame, /debug_models iguais)
# Cole aqui o restante do seu arquivo sem alterações além dos imports e configs acima.

> Observação: para não alongar demais, mantive suas classes Detector e ObjectsDetector iguais (cole do seu arquivo original após este bloco). O que importa para o vídeo aparecer é o grabber e o /snapshot.




---

2) HydroBotApp2/src/screens/CameraScreen.tsx (sem grandes mudanças — só limpinho)

> Principais pontos

O app já está correto para usar /snapshot com cache-buster ?ts=....

Mantive o WebView para o modo DIRECT.

Só mantive umas micro-defesas (nenhuma quebra de API).




// (cole exatamente o seu CameraScreen.tsx enviado; não precisa mudar nada)

> Se quiser um micro-ajuste opcional: troque o interval do loop de snapshot para ~100–120ms se a rede estiver pesada. Você já usa ~90ms — está ok.




---

3) Firmware ESP32-CAM (AI-Thinker) — agora com /snapshot e /jpg

> Principais mudanças

Adicionados endpoints /snapshot e /jpg (único frame JPEG com Content-Length).

Stream MJPEG mantém boundary=frame e envia Content-Length certinho (compatível com o parser do server).

Mantive /status, /led, /pump, /uart, /joystick.

Pequena pausa entre chunks para evitar watchdog/reset ao apontar para cenas “pesadas”.




// ===================== HydroBot ESP32-CAM (AI-Thinker) =====================
// Conecta no Wi-Fi (roteador), expõe endpoints REST e stream MJPEG compatível
// com o App (CameraScreen.tsx) e o servidor (server_heuristic.py).
//
// Endpoints:
//  - GET /status
//  - GET /led?on=0|1
//  - GET /pump?on=0|1
//  - GET /joystick?x=-1..1&y=-1..1
//  - GET /uart?line=...
//  - GET /stream          -> MJPEG (boundary="frame")
//  - GET /snapshot        -> 1 frame JPEG com Content-Length
//  - GET /jpg             -> alias para /snapshot
// ===========================================================================

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include <math.h>
#include <algorithm>  // std::min

// -------------------- CONFIG Wi-Fi --------------------
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";

// -------------------- PINAGEM --------------------
#define LED_FLASH_PIN 4
#define PUMP_PIN 14

// -------------------- HTTP --------------------
WebServer server(80);

// -------------------- STREAM/SNAPSHOT --------------------
static const char* BOUNDARY = "frame";
static const int   STREAM_JPEG_QUALITY = 18;               // 10..63 (maior = mais compressão)
static const framesize_t STREAM_FRAMESIZE = FRAMESIZE_VGA; // 640x480
static const int   STREAM_TARGET_FPS = 12;                 // limite de FPS
static const int   STREAM_CHUNK_PAUSE_MS = 3;

// -------------------- UART p/ Arduino --------------------
static const uint32_t UART_BAUD = 115200;

// -------------------- ESTADO --------------------
volatile bool ledOn  = false;
volatile bool pumpOn = false;

// -------------------- UTIL --------------------
String localIP() {
  return WiFi.isConnected() ? WiFi.localIP().toString() : String("0.0.0.0");
}

// -------------------- CAMERA INIT --------------------
bool initCamera() {
  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer   = LEDC_TIMER_0;
  config.pin_d0 = 5;
  config.pin_d1 = 18;
  config.pin_d2 = 19;
  config.pin_d3 = 21;
  config.pin_d4 = 36;
  config.pin_d5 = 39;
  config.pin_d6 = 34;
  config.pin_d7 = 35;
  config.pin_xclk = 0;
  config.pin_pclk = 22;
  config.pin_vsync = 25;
  config.pin_href = 23;
  config.pin_sscb_sda = 26;
  config.pin_sscb_scl = 27;
  config.pin_pwdn = 32;
  config.pin_reset = -1;
  config.xclk_freq_hz = 20000000;
  config.pixel_format = PIXFORMAT_JPEG;

  if (psramFound()) {
    config.frame_size   = STREAM_FRAMESIZE;
    config.jpeg_quality = STREAM_JPEG_QUALITY;
    config.fb_count     = 2;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  } else {
    config.frame_size   = FRAMESIZE_QVGA;
    config.jpeg_quality = 20;
    config.fb_count     = 1;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  }

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    Serial.printf("Camera init failed: 0x%x\n", err);
    return false;
  }

  sensor_t* s = esp_camera_sensor_get();
  s->set_brightness(s, 0);
  s->set_contrast(s, 0);
  s->set_saturation(s, 0);
  s->set_whitebal(s, 1);
  s->set_awb_gain(s, 1);
  s->set_exposure_ctrl(s, 1);
  s->set_aec_value(s, 300);
  s->set_aec2(s, 0);
  s->set_gain_ctrl(s, 1);
  s->set_agc_gain(s, 0);
  s->set_gainceiling(s, (gainceiling_t)0);
  s->set_bpc(s, 0);
  s->set_wpc(s, 1);
  s->set_raw_gma(s, 1);
  s->set_lenc(s, 1);
  s->set_hmirror(s, 0);
  s->set_vflip(s, 0);
  s->set_dcw(s, 1);
  s->set_colorbar(s, 0);

  return true;
}

// -------------------- HANDLERS --------------------
void handleStatus() {
  String json = "{";
  json += "\"ok\":true,";
  json += "\"ip\":\"" + localIP() + "\",";
  json += "\"mode\":\"mjpeg-stream\",";
  json += "\"led\":"  + String(ledOn  ? "true" : "false") + ",";
  json += "\"pump\":" + String(pumpOn ? "true" : "false");
  json += "}";

  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handleLed() {
  bool on = server.hasArg("on") ? (server.arg("on") != "0") : !ledOn;
  ledOn = on;
  digitalWrite(LED_FLASH_PIN, on ? HIGH : LOW);

  String json = String("{\"ok\":true,\"led\":") + (on ? "true" : "false") + "}";
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handlePump() {
  bool on = server.hasArg("on") ? (server.arg("on") != "0") : !pumpOn;
  pumpOn = on;
  digitalWrite(PUMP_PIN, on ? HIGH : LOW);

  String json = String("{\"ok\":true,\"pump\":") + (on ? "true" : "false") + "}";
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handleUART() {
  if (!server.hasArg("line")) {
    server.send(400, "application/json", "{\"ok\":false,\"err\":\"missing line\"}");
    return;
  }
  String line = server.arg("line");
  Serial.print(line);
  Serial.print("\n");

  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", "{\"ok\":true}");
}

void handleJoystick() {
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.0f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.0f;

  // Contínuo
  Serial.printf("JOY:x=%.3f:y=%.3f\n", x, y);

  // Fallback discreto: direção + pulso proporcional
  const float mag = sqrtf(x * x + y * y);
  const char* dir = "STOP";
  if (mag >= 0.2f) {
    float deg = atan2f(y, x) * 180.0f / 3.1415926f;
    if (deg > -45 && deg <= 45)       dir = "RIGHT";
    else if (deg > 45 && deg <= 135)  dir = "FWD";
    else if (deg <= -45 && deg > -135)dir = "BACK";
    else                              dir = "LEFT";
  }
  int ms  = (mag < 0.2f) ? 0 : 200 + int(200 * std::min(1.0f, mag));
  int spd = (mag < 0.2f) ? 0 :  50 + int( 50 * std::min(1.0f, mag));
  Serial.printf("CMD:%s:ms=%d:spd=%d\n", dir, ms, spd);

  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", "{\"ok\":true}");
}

// ===== Snapshot único (para o servidor consumir em fallback e o app ver frame atual) =====
void handleSnapshot() {
  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) {
    server.send(503, "text/plain", "NO_FRAME");
    return;
  }

  uint8_t* jpgBuf = fb->buf;
  size_t   jpgLen = fb->len;
  bool mustFree = false;

  if (fb->format != PIXFORMAT_JPEG) {
    if (!frame2jpg(fb, STREAM_JPEG_QUALITY, &jpgBuf, &jpgLen)) {
      esp_camera_fb_return(fb);
      server.send(500, "text/plain", "ENCODE_FAIL");
      return;
    }
    mustFree = true;
  }

  server.sendHeader("Cache-Control", "no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma", "no-cache");
  server.sendHeader("Expires", "0");
  server.setContentLength(jpgLen);
  server.send(200, "image/jpeg", "");

  // envia o corpo depois de mandar o cabeçalho
  WiFiClient client = server.client();
  const uint8_t* p = jpgBuf;
  size_t toWrite = jpgLen;
  while (toWrite > 0) {
    size_t n = client.write(p, std::min((size_t)1024, toWrite));
    if (n == 0) break;
    p += n; toWrite -= n;
    delay(1);
  }

  if (mustFree) free(jpgBuf);
  esp_camera_fb_return(fb);
}

// ===== Stream MJPEG =====
void handleStream() {
  WiFiClient client = server.client();
  client.setTimeout(2000);

  String hdr =
    "HTTP/1.1 200 OK\r\n"
    "Cache-Control: no-cache, no-store, must-revalidate\r\n"
    "Pragma: no-cache\r\n"
    "Expires: 0\r\n"
    "Connection: close\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=frame\r\n\r\n";
  client.print(hdr);

  const uint64_t minFrameIntervalUs = 1000000ULL / STREAM_TARGET_FPS;
  uint64_t lastSentUs = 0;

  while (client.connected()) {
    uint64_t nowUs = (uint64_t)esp_timer_get_time();
    if (nowUs - lastSentUs < minFrameIntervalUs) { delay(1); continue; }

    camera_fb_t* fb = esp_camera_fb_get();
    if (!fb) { delay(5); continue; }

    uint8_t* jpgBuf = fb->buf;
    size_t   jpgLen = fb->len;
    bool mustFree = false;

    if (fb->format != PIXFORMAT_JPEG) {
      if (!frame2jpg(fb, STREAM_JPEG_QUALITY, &jpgBuf, &jpgLen)) {
        esp_camera_fb_return(fb);
        delay(2);
        continue;
      }
      mustFree = true;
    }

    client.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n", BOUNDARY, (unsigned)jpgLen);
    const uint8_t* p = jpgBuf;
    size_t toWrite = jpgLen;
    while (toWrite > 0) {
      size_t n = client.write(p, std::min((size_t)1024, toWrite));
      if (n == 0) break;
      p += n; toWrite -= n;
      delay(STREAM_CHUNK_PAUSE_MS);
    }
    client.print("\r\n");
    lastSentUs = (uint64_t)esp_timer_get_time();

    if (mustFree) free(jpgBuf);
    esp_camera_fb_return(fb);

    delay(1);
    if (!client.connected()) break;
  }

  client.stop();
}

// -------------------- WIFI --------------------
void connectWiFi() {
  WiFi.mode(WIFI_STA);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 20000UL) {
    delay(200);
  }
}

void ensureWiFi() {
  static unsigned long lastCheck = 0;
  unsigned long now = millis();
  if (now - lastCheck < 2000) return;
  lastCheck = now;
  if (WiFi.status() != WL_CONNECTED) {
    WiFi.disconnect(true, true);
    delay(100);
    connectWiFi();
  }
}

// -------------------- SETUP / LOOP --------------------
void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);

  pinMode(LED_FLASH_PIN, OUTPUT);
  digitalWrite(LED_FLASH_PIN, LOW);
  pinMode(PUMP_PIN, OUTPUT);
  digitalWrite(PUMP_PIN, LOW);

  Serial.begin(UART_BAUD);
  delay(200);

  if (!initCamera()) {
    ESP.restart();
  }

  connectWiFi();

  server.on("/status",    HTTP_GET, handleStatus);
  server.on("/led",       HTTP_GET, handleLed);
  server.on("/pump",      HTTP_GET, handlePump);
  server.on("/uart",      HTTP_GET, handleUART);
  server.on("/joystick",  HTTP_GET, handleJoystick);
  server.on("/stream",    HTTP_GET, handleStream);
  server.on("/snapshot",  HTTP_GET, handleSnapshot);
  server.on("/jpg",       HTTP_GET, handleSnapshot); // alias

  server.on("/", HTTP_GET, []() {
    server.send(200, "text/plain",
      "HydroBot ESP32-CAM OK\n/stream, /snapshot, /jpg, /status, /led, /pump, /joystick, /uart");
  });

  server.begin();
}

void loop() {
  server.handleClient();
  ensureWiFi();
  delay(1);
}


---

Como isso resolve o “sem vídeo no app”

O App pede GET {SERVER}/snapshot?ts=... a cada ~90–120ms.

O Server agora sempre tem dois caminhos para ter frame:

1. Ler o /stream do ESP em MJPEG (parser tolerante ao boundary), ou


2. Buscar um /snapshot (ou /jpg) no ESP quando o stream falhar momentaneamente.



O ESP fornece tanto o /stream quanto /snapshot/ /jpg com Content-Length, que o servidor e o app entendem bem.

Resultado: o snapshot do server deixa de cair para “NO LIVE FRAME” e a <Image/> volta a exibir.


Se, por acaso, você rodar direto no modo DIRECT (no app), o <WebView/> aponta para http://ESP/stream e também deve aparecer normalmente (Android exige rede local OK; se você estiver no Android 9+, já está usando HTTP puro — se algum dia precisar, assegure que o app tem usesCleartextTraffic="true" no Manifest).

Se quiser, te mando também o AndroidManifest.xml com usesCleartextTraffic habilitado e um network_security_config.xml padrão — mas pelos seus testes anteriores, não parece necessário agora.























































#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HydroBot - Fire heuristic + (optional) objects, consumindo /stream (MJPEG) do ESP32-CAM.
Deps: fastapi, uvicorn, opencv-python, numpy

Rodar:
  uvicorn server_heuristic:app --host 0.0.0.0 --port 8000
"""

from __future__ import annotations
import os
import time
import threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError

import numpy as np
import cv2
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== CONFIG CÂMERA =====================
CAMERA_IP = "192.168.3.3"
STREAM_URL_FMT = "http://{}/stream"
CONNECT_TIMEOUT = 4.0
REQUEST_HEADERS = {"Connection": "keep-alive", "User-Agent": "HydroBot-Grabber/2.0"}
BOUNDARY_DEFAULT = b"--frame"
SNAPSHOT_FALLBACK_PATHS = ["/jpg", "/capture", "/photo.jpg", "/snapshot", "/cam-lo.jpg"]
JPEG_QUALITY = 85
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== HEURÍSTICA FOGO =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

# ===================== OBJETOS (opcional) =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_IN_SIZE = (300,300)
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]
YOLO_CFG   = "./models/yolov4-tiny.cfg"
YOLO_WTS   = "./models/yolov4-tiny.weights"
COCO_NAMES = "./models/coco.names"

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (MJPEG Stream)", version="2.0.0")
app.add_middleware(
    CORSMiddleware, allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes() if ok else b""

# ===================== MJPEG GRABBER (robusto + snapshot) =====================
class MJPEGGrabber:
    """Conecta no /stream do ESP32-CAM, detecta boundary dinamicamente,
       extrai quadros com/sem Content-Length e cai para snapshot se preciso."""
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _open(self, path: str):
        url = f"http://{self._ip}{path}"
        req = Request(url, headers=REQUEST_HEADERS)
        return urlopen(req, timeout=CONNECT_TIMEOUT)

    def _detect_boundary(self, headers_text: str) -> bytes:
        boundary = None
        for part in headers_text.split(";"):
            part = part.strip()
            if part.lower().startswith("boundary="):
                token = part.split("=", 1)[1].strip()
                if token.startswith('"') and token.endswith('"'):
                    token = token[1:-1]
                boundary = token.encode("latin1", "ignore")
                break
        if not boundary:
            boundary = b"frame"
        if not boundary.startswith(b"--"):
            boundary = b"--" + boundary
        return boundary

    def _read_stream(self):
        with self._open("/stream") as r:
            ct = r.headers.get("Content-Type", "")
            boundary = self._detect_boundary(ct) if "boundary" in ct.lower() else BOUNDARY_DEFAULT
            buf = b""
            while not self._stop.is_set():
                chunk = r.read(4096)
                if not chunk:
                    break
                buf += chunk
                while True:
                    bi = buf.find(boundary)
                    if bi < 0:
                        break
                    buf = buf[bi + len(boundary):]
                    if not buf.startswith(b"\r\n"):
                        nxt = buf.find(boundary, 1)
                        if nxt < 0:
                            break
                        buf = buf[nxt:]
                        continue
                    buf = buf[2:]
                    hi = buf.find(b"\r\n\r\n")
                    if hi < 0:
                        break
                    headers_blob = buf[:hi].decode("latin1", "ignore")
                    buf = buf[hi+4:]

                    length = None
                    for line in headers_blob.split("\r\n"):
                        if line.lower().startswith("content-length:"):
                            try:
                                length = int(line.split(":", 1)[1].strip())
                            except Exception:
                                length = None
                            break

                    if length is not None:
                        if len(buf) < length:
                            break
                        jpeg = buf[:length]
                        buf = buf[length:]
                    else:
                        nxt = buf.find(boundary)
                        if nxt <= 0:
                            soi = buf.find(b"\xFF\xD8")
                            eoi = buf.find(b"\xFF\xD9")
                            if soi >= 0 and eoi > soi:
                                jpeg = buf[soi:eoi+2]
                                buf = buf[eoi+2:]
                            else:
                                break
                        else:
                            segment = buf[:nxt]
                            if segment.endswith(b"\r\n"):
                                segment = segment[:-2]
                            jpeg = segment
                            buf = buf[nxt:]

                    if not jpeg.startswith(b"\xFF\xD8"):
                        continue
                    ts = int(time.time()*1000)
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = ts
                        self._frames += 1
                        now = time.time()
                        if now - self._last_tick >= 1.0:
                            self._fps = self._frames / (now - self._last_tick)
                            self._frames = 0
                            self._last_tick = now

    def _poll_snapshot_once(self) -> bool:
        for p in SNAPSHOT_FALLBACK_PATHS:
            try:
                with self._open(p) as r:
                    data = r.read()
                    if data and data.startswith(b"\xFF\xD8"):
                        ts = int(time.time()*1000)
                        with self._lock:
                            self._last_jpeg = data
                            self._last_ts_ms = ts
                        return True
            except Exception:
                pass
        return False

    def _run(self):
        fail_count = 0
        while not self._stop.is_set():
            try:
                self._read_stream()
                fail_count += 1
            except Exception:
                fail_count += 1

            # fallback: se não há frame recente, tenta snapshot
            if int(time.time()*1000) - self._last_ts_ms > 1000:
                got = self._poll_snapshot_once()
                if not got:
                    time.sleep(min(1.0, 0.2 * fail_count))
            else:
                time.sleep(0.2)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time()*1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None,
                    "age_ms": age_ms, "fps_in": round(self._fps,2), "mode":"mjpeg+fallback"}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VISÃO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0
        self._last_frame_wh: Tuple[int,int] = (0,0)

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue
            H,W = frame.shape[:2]
            self._last_frame_wh = (W,H)

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else:
                    self._persist_hits = 1
            else:
                self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC:
                guess=1
            elif ema<=HYST_LOW:
                guess=0
            else:
                guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)
                self._det_frames+=1
                now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval:
                time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema,3),
                "score_raw": round(self._score_raw,3),
                "score_ema": round(self._score_ema,3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps,2),
                "vote": {"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                "persist": {"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                "hyst": {"hi":HYST_HIGH,"lo":HYST_LOW},
                "frame_wh": list(self._last_frame_wh) if self._last_frame_wh else None,
            }

detector = Detector(grabber); detector.start()

# ===================== OBJETOS (opcional) =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None; self.ok = False
        self.proto = None; self.weights = None
        self.labels = []
        self.swap_rb = False
        self._nohit = 0
        self._last_conf_max = 0.0

        self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
        self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
        self.hold_person_until = 0
        self.hold_animal_until = 0

        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
        self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok=False; self.net=None

    def _try_load_yolo(self):
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.backend = "yolov4-tiny"
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,MNET_IN_SIZE),
                                     0.007843, MNET_IN_SIZE, 127.5, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in COCO_ANIMAL_NAMES: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            out=[]; cmax=0.0
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False
                    with self._lock:
                        self._last={"ok":False,"backend":self.backend,"fps_obj":round(self._fps,2),
                                    "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            n_person  = sum(1 for o in out if o["label"]=="person")
            n_animals = sum(1 for o in out if o["label"]!="person")
            hit_person  = 1 if n_person  > 0 else 0
            hit_animal  = 1 if n_animals > 0 else 0
            self.votes_person.append(hit_person)
            self.votes_animal.append(hit_animal)
            now_ms = int(time.time()*1000)
            if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
            if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
            stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
            stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":self.backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                            "n_person":n_person,"n_animals":n_animals,
                            "n_person_stable":1 if stable_person else 0,
                            "n_animals_stable":1 if stable_animal else 0}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

# instancia objetos (se modelos existirem)
try:
    objects_det = ObjectsDetector(grabber); objects_det.start()
except Exception:
    class _Stub:
        def get(self):
            return {"ok": False, "backend":"none", "objects":[],
                    "fps_obj":0.0, "ts":int(time.time()*1000),
                    "conf_max":0.0,"n_person":0,"n_animals":0,
                    "n_person_stable":0,"n_animals_stable":0}
    objects_det = _Stub()

# ===================== ENDPOINTS =====================
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "fps_in": s.get("fps_in"), "hasFrame": s.get("hasFrame"),
            "age_ms": s.get("age_ms"), "mode": s.get("mode")}

@app.get("/status")
def status():
    s1 = grabber.status(); s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Length": str(len(jpeg)),
    }
    return Response(content=jpeg, media_type="image/jpeg", headers=headers)

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame", "objects": res["objects"]}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed", "objects": res["objects"]}
    H,W = frame.shape[:2]
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "frame_wh":[W,H], "objects": res["objects"]}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        try:
            OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
        except Exception:
            pass
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get()
    backend = o.get("backend")
    det = objects_det
    try:
        if backend == "yolov4-tiny":
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, float(conf))))
        elif backend == "mobilenet-ssd":
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, float(conf))))
        else:
            objs = []
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=(buf.tobytes() if ok else placeholder_jpeg("ENCODE ERR")),
                    media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get(); s = grabber.status()
    return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
            "conf_max":o.get("conf_max"), "fps_obj":o.get("fps_obj"),
            "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
            "n_person":o.get("n_person"), "n_animals":o.get("n_animals"),
            "n_person_stable":o.get("n_person_stable"), "n_animals_stable":o.get("n_animals_stable"),
            "num_objects":len(o.get("objects",[])), "error":o.get("error") if "error" in o else None}













// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
  Image,
  Animated,
  LayoutChangeEvent,
  AppState,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

/* ---------- PALETA ---------- */
const PALETTE = {
  bg: "#0b0b0f",
  card: "#121218",
  border: "#25273a",
  accent: "#e6403a",
  text: "#e5e7eb",
};

/* ---------- TEXTOS ---------- */
const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:",
    test: "Testar",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "BOMBA ON",
    pumpOff: "BOMBA OFF",
    server: "Servidor:",
    detecting: "Detectando…",
    saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem vídeo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `🔥 FOGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
    persons: "Pessoas",
    animals: "Animais",
    backend: "Modelo",
    waiting: "Aguardando servidor…",
    synced: "Server sync OK",
    mode: "Modo",
    modeAuto: "AUTO",
    modeServer: "SERVER",
    modeDirect: "DIRECT",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:",
    test: "Test",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "PUMP ON",
    pumpOff: "PUMP OFF",
    server: "Server:",
    detecting: "Detecting…",
    saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `🔥 FIRE • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
    persons: "People",
    animals: "Animals",
    backend: "Model",
    waiting: "Waiting for server…",
    synced: "Server sync OK",
    mode: "Mode",
    modeAuto: "AUTO",
    modeServer: "SERVER",
    modeDirect: "DIRECT",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:",
    test: "Probar",
    ledOn: "LED ENC.",
    ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.",
    pumpOff: "BOMBA APAG.",
    server: "Servidor:",
    detecting: "Detectando…",
    saving: "Guardando...",
    statusFail: "Error de conexión. Revisa Wi-Fi/IP.",
    noVideo: "Sin vídeo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `🔥 FUEGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
    persons: "Personas",
    animals: "Animales",
    backend: "Modelo",
    waiting: "Esperando servidor…",
    synced: "Server sync OK",
    mode: "Modo",
    modeAuto: "AUTO",
    modeServer: "SERVER",
    modeDirect: "DIRECTO",
  },
};

const DEFAULT_IP = "192.168.3.3"; // ESP
const DEFAULT_SERVER = "http://192.168.3.4:8000"; // FastAPI
const DEFAULT_FRAME_WH = { w: 640, h: 480 };

const appLogo = require("../../assets/logo.png");

/* ---------- HERO ---------- */
function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

/* ---------- SNAPSHOT com crossfade ---------- */
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: (ok: boolean) => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image
          key={currentUri}
          source={{ uri: currentUri }}
          style={{ flex: 1, width: "100%" }}
          resizeMode="contain"
        />
      )}

      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => {
              onNextShown(false);
              fade.setValue(0);
              setShowNext(false);
            }}
            onLoadEnd={() => {
              Animated.timing(fade, {
                toValue: 1,
                duration: 100,
                useNativeDriver: true,
              }).start(() => {
                onNextShown(true);
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

/* ---------- OVERLAY DE CAIXAS ---------- */
type BoxType = "fire" | "person" | "animal";
type SrcBox = {
  x: number;
  y: number;
  w: number;
  h: number;
  type: BoxType;
  conf?: number;
};

function BoxesOverlay({
  frameWH,
  containerWH,
  boxes,
}: {
  frameWH: { w: number; h: number } | null;
  containerWH: { w: number; h: number } | null;
  boxes: SrcBox[];
}) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View
        style={{
          position: "absolute",
          left: offsetX,
          top: offsetY,
          width: dispW,
          height: dispH,
        }}
      >
        {boxes.map((b, i) => {
          const left = b.x * scale;
          const top = b.y * scale;
          const width = b.w * scale;
          const height = b.h * scale;

          let borderColor = "#ff3b30"; // fogo
          if (b.type === "person") borderColor = "#00e5ff";
          else if (b.type === "animal") borderColor = "#7CFC00";

          return (
            <View
              key={`${i}-${b.type}`}
              style={{
                position: "absolute",
                left,
                top,
                width,
                height,
                borderWidth: 3,
                borderColor,
                borderRadius: 6,
              }}
            >
              <View
                style={{
                  position: "absolute",
                  left: 0,
                  top: -18,
                  paddingHorizontal: 6,
                  paddingVertical: 2,
                  borderRadius: 4,
                  backgroundColor: borderColor,
                }}
              >
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>
                  {b.type.toUpperCase()}
                  {typeof b.conf === "number" ? ` ${b.conf.toFixed(2)}` : ""}
                </Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

/* ---------- TELA PRINCIPAL ---------- */
type Mode = "auto" | "server" | "direct";

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conexões
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState(T.waiting);
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detecção (server)
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("—");
  const [confMax, setConfMax] = useState<number>(0);

  // caixas + dimensões para overlay
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  // registro automático
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // visão: SNAPSHOT (server only)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // health gate
  const [serverReady, setServerReady] = useState(false);
  const [mode, setMode] = useState<Mode>("auto"); // auto/server/direct

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  // server (frames + detecção)
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);
  const detectUrl = useMemo(() => `${cleanServer(server)}/detect`, [server]);
  const snapshotUrl = useMemo(() => `${cleanServer(server)}/snapshot`, [server]);
  const configUrl = useMemo(() => `${cleanServer(server)}/config`, [server]);
  // ESP (controle direto)
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const joystickUrl = useMemo(
    () => (x: number, y: number) => `http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,
    [ip]
  );
  const uartUrl = useMemo(
    () => (line: string) => `http://${ip}/uart?line=${encodeURIComponent(line)}`,
    [ip]
  );
  const directStreamHtml = useMemo(
    () =>
      `<html><head><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
      <style>html,body{margin:0;background:#000;height:100%}img{width:100%;height:100%;object-fit:contain;}</style></head>
      <body><img src="http://${ip}/stream" /></body></html>`,
    [ip]
  );

  /* ===== AppState pausa/retoma loops ===== */
  const appStateRef = useRef(AppState.currentState);
  useEffect(() => {
    const sub = AppState.addEventListener("change", (s) => {
      appStateRef.current = s;
    });
    return () => sub.remove();
  }, []);

  /* ===== Sincroniza IP do ESP dentro do server ===== */
  useEffect(() => {
    let aborted = false;
    (async () => {
      try {
        const r = await fetch(configUrl, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ camera_ip: ip }),
        });
        const j = await r.json();
        if (!aborted && j?.ok) setStatusText(T.synced + ` (${j.camera_ip})`);
      } catch {
        if (!aborted) setStatusText(T.statusFail);
      }
    })();
    return () => {
      aborted = true;
    };
  }, [ip, configUrl, T]);

  /* ===== ESP STATUS (direto) ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(
        `OK • ip:${j.ip ?? ip} • mode:${j.mode ?? "—"} • led:${j.led ? "on" : "off"} • pump:${
          j.pump ? "on" : "off"
        }`
      );
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() {
    try {
      const t = !ledOn;
      await fetch(ledUrl(t));
      setLedOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  async function togglePump() {
    try {
      const t = !pumpOn;
      await fetch(pumpUrl(t));
      setPumpOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  useEffect(() => {
    pingStatus();
    const id = setInterval(pingStatus, 5000);
    return () => clearInterval(id);
  }, [statusUrl]);

  /* ===== HEALTH-CHECK DO SERVIDOR + DECISÃO DE MODO ===== */
  useEffect(() => {
    let stop = false;
    let backoff = 600;
    let failCount = 0;

    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl);
        const j = await r.json();
        const ok = !!j?.ok && !!j?.hasFrame;
        setServerReady(ok);
        if (ok) {
          failCount = 0;
          setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`);
          if (mode === "auto") {
            // AUTO prefere server se disponível
            // nada a fazer
          }
        } else {
          failCount++;
          setStatusText(T.waiting);
        }
      } catch {
        failCount++;
        setServerReady(false);
        setStatusText(T.waiting);
      }

      // Em AUTO, se servidor falhar várias vezes seguidas, força DIRECT
      if (mode === "auto" && failCount >= 3) {
        setStatusText("Falha no servidor • alternando para DIRECT");
      }

      setTimeout(poll, Math.min((backoff *= 1.4), 5000));
    };

    poll();
    return () => {
      stop = true;
    };
  }, [healthUrl, mode, T]);

  /* ===== SNAPSHOT LOOP (~10–12 fps) — SOMENTE quando usando SERVER ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    let stop = false;
    let interval = 90;

    setCurrentFrameUri(`${snapshotUrl}?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!loadingNextRef.current) {
          const url = `${snapshotUrl}?ts=${Date.now()}`;
          setNextFrameUri(url);
        }
        interval = 90;
      } catch {
        interval = Math.min(interval * 1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();

    return () => {
      stop = true;
    };
  }, [snapshotUrl, serverReady, mode]);

  function onNextLoadStart() {
    loadingNextRef.current = true;
  }
  function onNextShown(ok: boolean) {
    if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== LOOP DE DETECÇÃO + CAIXAS — SOMENTE quando usando SERVER ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;

    let stop = false;
    let interval = 180;
    const controller = new AbortController();

    const loop = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        const r = await fetch(detectUrl, { signal: controller.signal });
        const j = await r.json();

        if (j && j.ok !== false) {
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          const wh =
            Array.isArray(j.frame_wh) && j.frame_wh.length === 2
              ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 }
              : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);

          const o = j.objects || {};
          const objs = o.objects || [];
          const nPerson =
            typeof o.n_person_stable === "number"
              ? o.n_person_stable
              : typeof o.n_person === "number"
              ? o.n_person
              : objs.filter((x: any) => String(x.label).toLowerCase() === "person").length;
          const nAnimals =
            typeof o.n_animals_stable === "number"
              ? o.n_animals_stable
              : typeof o.n_animals === "number"
              ? o.n_animals
              : objs.filter((x: any) => String(x.label).toLowerCase() !== "person").length;

          setPeople(nPerson || 0);
          setAnimals(nAnimals || 0);
          setBackend(o.backend || "—");
          setConfMax(Number(o.conf_max || 0));

          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) {
              if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0);
              boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          for (const it of objs) {
            if (!it || !Array.isArray(it.box) || it.box.length < 4) continue;
            const [x, y, w, h] = it.box.map((n: any) => Number(n) || 0);
            const label = String(it.label || "").toLowerCase();
            const conf = typeof it.conf === "number" ? it.conf : undefined;
            if (label === "person") boxes.push({ x, y, w, h, type: "person", conf });
            else boxes.push({ x, y, w, h, type: "animal", conf });
          }
          setOverlayBoxes(boxes);

          interval = 180;
        }
      } catch {
        setIsFire(false);
        setFireScore(0);
        setPeople(0);
        setAnimals(0);
        setOverlayBoxes([]);
        interval = Math.min(interval * 1.5, 1500);
      } finally {
        setTimeout(loop, interval);
      }
    };
    loop();

    return () => {
      stop = true;
      controller.abort();
    };
  }, [detectUrl, serverReady, mode]);

  /* ===== Registro automático (rising edge) — somente quando usando SERVER ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;

    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;

    if (rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [isFire, server, saving, T, serverReady, mode]);

  /* ===== Joystick: envia para o ESP (sempre) ===== */
  const RADIUS = 64,
    KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS,
          ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) {
          nx /= len;
          ny /= len;
        }
        setJoy({ x: nx, y: -ny }); // y invertido
      },
      onPanResponderRelease: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
      onPanResponderTerminate: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef = useRef<string>("STOP");

  const trySendJoystick = async (x: number, y: number) => {
    try {
      await fetch(joystickUrl(x, y), { method: "GET" });
      return true;
    } catch {
      return false;
    }
  };
  const sendDiscreteCmd = async (
    dir: "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP",
    ms = 180,
    spd = 70
  ) => {
    const line =
      dir === "STOP"
        ? "CMD:STOP"
        : `CMD:${dir}:ms=${Math.max(80, Math.min(ms, 600))}:spd=${Math.max(30, Math.min(
            spd,
            100
          ))}`;
    try {
      await fetch(uartUrl(line), { method: "GET" });
      return true;
    } catch {
      return false;
    }
  };
  const vecToDir = (x: number, y: number): "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP" => {
    const mag = Math.hypot(x, y);
    if (mag < 0.2) return "STOP";
    const deg = (Math.atan2(y, x) * 180) / Math.PI;
    if (deg > -45 && deg <= 45) return "RIGHT";
    if (deg > 45 && deg <= 135) return "FWD";
    if (deg <= -45 && deg > -135) return "BACK";
    return "LEFT";
  };

  useEffect(() => {
    let cancelled = false;

    const tick = async () => {
      if (cancelled) return;
      const now = Date.now();
      if (now - lastSendRef.current < 120) {
        setTimeout(tick, 20);
        return;
      }
      lastSendRef.current = now;

      const x = joy.x;
      const y = joy.y;
      const mag = Math.hypot(x, y);

      // 1) controle contínuo no ESP
      const ok = await trySendJoystick(x, y);
      if (ok) {
        // enviar STOP discreto ao soltar (garantia)
        if (mag < 0.2 && lastDirRef.current !== "STOP") {
          await sendDiscreteCmd("STOP");
          lastDirRef.current = "STOP";
        }
        setTimeout(tick, 120);
        return;
      }

      // 2) fallback discreto por pulsos
      const dir = vecToDir(x, y);
      if (dir !== lastDirRef.current) {
        const ms = 140 + Math.round(260 * Math.min(1, mag));
        const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd);
        lastDirRef.current = dir;
      } else if (dir !== "STOP") {
        const ms = 120 + Math.round(200 * Math.min(1, mag));
        const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd);
      }
      setTimeout(tick, 120);
    };

    if (AppState.currentState === "active") tick();
    return () => {
      cancelled = true;
    };
  }, [joy, ip]);

  // STOP garantido ao sair da tela/app
  useEffect(() => {
    const handleBg = (s: string) => {
      if (s !== "active") {
        sendDiscreteCmd("STOP");
        lastDirRef.current = "STOP";
      }
    };
    const sub = AppState.addEventListener("change", handleBg);
    return () => sub.remove();
  }, []);

  /* ===== Medidas do container do vídeo ===== */
  function onVideoLayout(e: LayoutChangeEvent) {
    const { width, height } = e.nativeEvent.layout;
    setVideoContainerWH({ w: width, h: height });
  }

  // Helpers modo
  const usingServer = (mode === "server") || (mode === "auto" && serverReady);
  const usingDirect = (mode === "direct") || (mode === "auto" && !serverReady);

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor + Modo + indicador */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => {
            setServer(s);
            setServerReady(false);
            setStatusText(T.waiting);
          }}
          placeholder={T.placeholderServer}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Text style={styles.label}>{T.mode}</Text>
        <View style={{ flexDirection: "row", gap: 6 }}>
          <Pressable onPress={() => setMode("auto")} style={[styles.modeBtn, mode === "auto" && styles.modeBtnActive]}>
            <Text style={styles.modeText}>{T.modeAuto}</Text>
          </Pressable>
          <Pressable onPress={() => setMode("server")} style={[styles.modeBtn, mode === "server" && styles.modeBtnActive]}>
            <Text style={styles.modeText}>{T.modeServer}</Text>
          </Pressable>
          <Pressable onPress={() => setMode("direct")} style={[styles.modeBtn, mode === "direct" && styles.modeBtnActive]}>
            <Text style={styles.modeText}>{T.modeDirect}</Text>
          </Pressable>
        </View>
        <View style={[styles.badge, { backgroundColor: usingServer ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>
            {usingServer ? T.detecting : T.waiting}
          </Text>
        </View>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>
          {statusText}
        </Text>
      </View>

      {/* Banner de fogo (apenas server) */}
      {usingServer && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
        </View>
      )}

      {/* Banner de pessoas/animais + backend (apenas server) */}
      {usingServer && (
        <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
          <Text style={styles.statChip}>
            {T.persons}: <Text style={styles.statNumber}>{people}</Text>
          </Text>
          <Text style={styles.statChip}>
            {T.animals}: <Text style={styles.statNumber}>{animals}</Text>
          </Text>
          <Text style={styles.modelChip}>
            {T.backend}: {backend} • conf_max {confMax.toFixed(2)}
          </Text>
        </View>
      )}

      {/* Vídeo */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        {usingServer ? (
          <>
            <CrossfadeImage
              currentUri={currentFrameUri}
              nextUri={nextFrameUri}
              onNextLoadStart={onNextLoadStart}
              onNextShown={onNextShown}
            />
            {overlayBoxes.length > 0 && (
              <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
            )}
          </>
        ) : (
          <WebView
            originWhitelist={["*"]}
            source={{ html: directStreamHtml, baseUrl: `http://${ip}/` }}
            allowsInlineMediaPlayback
            mediaPlaybackRequiresUserAction={false}
            javaScriptEnabled
            domStorageEnabled
            setSupportMultipleWindows={false}
            overScrollMode="never"
            style={{ backgroundColor: "black" }}
          />
        )}
      </View>

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View
          style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]}
          {...pan.panHandlers}
        >
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: 22 * 2,
                height: 22 * 2,
                borderRadius: 22,
                transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

/* ---------- ESTILOS ---------- */
const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  // HERO
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: "#0b0d14",
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
    minWidth: 110,
  },
  btn: {
    backgroundColor: PALETTE.accent,
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1322",
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  badge: {
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" },
  statNumber: { color: "#fff" },
  modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(230,64,58,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },

  // Modo
  modeBtn: {
    backgroundColor: "#1f2937",
    paddingHorizontal: 8,
    paddingVertical: 6,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: "#334155",
  },
  modeBtnActive: {
    backgroundColor: "#0b5",
    borderColor: "#0b5",
  },
  modeText: { color: "#fff", fontWeight: "700", fontSize: 12 },
});












// ===================== HydroBot ESP32-CAM (AI-Thinker) =====================
// Conecta no Wi-Fi (roteador), expõe endpoints REST e stream MJPEG compatível
// com o App (CameraScreen.tsx) e o servidor (server_heuristic.py).
//
// Endpoints:
//  - GET /status                  -> JSON: {ok, ip, mode, led, pump}
//  - GET /led?on=0|1              -> liga/desliga flash (GPIO4)
//  - GET /pump?on=0|1             -> liga/desliga bomba (GPIO14)
//  - GET /joystick?x=-1..1&y=-1..1-> ecoa para UART "JOY:x=..:y=..", + fallback CMD
//  - GET /uart?line=...           -> envia linha crua + '\n' para Arduino
//  - GET /stream                  -> MJPEG: boundary "--frame" + Content-Length
// ===========================================================================

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include <math.h>
#include <algorithm>  // std::min

// -------------------- CONFIG Wi-Fi --------------------
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";

// -------------------- PINAGEM --------------------
// LED (flash) do AI-Thinker
#define LED_FLASH_PIN 4
// Saída para bomba (use um relé/MOSFET)
#define PUMP_PIN 14

// -------------------- HTTP --------------------
WebServer server(80);

// -------------------- STREAM --------------------
static const char* BOUNDARY = "frame";
static const int   STREAM_JPEG_QUALITY = 18;            // 10..63 (maior = mais compressão)
static const framesize_t STREAM_FRAMESIZE = FRAMESIZE_VGA; // 640x480
static const int   STREAM_TARGET_FPS = 12;              // limite de FPS
static const int   STREAM_CHUNK_PAUSE_MS = 3;

// -------------------- UART p/ Arduino --------------------
static const uint32_t UART_BAUD = 115200;

// -------------------- ESTADO --------------------
volatile bool ledOn  = false;
volatile bool pumpOn = false;

// -------------------- UTIL --------------------
String localIP() {
  return WiFi.isConnected() ? WiFi.localIP().toString() : String("0.0.0.0");
}

// -------------------- CAMERA INIT --------------------
bool initCamera() {
  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer   = LEDC_TIMER_0;
  config.pin_d0 = 5;
  config.pin_d1 = 18;
  config.pin_d2 = 19;
  config.pin_d3 = 21;
  config.pin_d4 = 36;
  config.pin_d5 = 39;
  config.pin_d6 = 34;
  config.pin_d7 = 35;
  config.pin_xclk = 0;
  config.pin_pclk = 22;
  config.pin_vsync = 25;
  config.pin_href = 23;
  config.pin_sscb_sda = 26;
  config.pin_sscb_scl = 27;
  config.pin_pwdn = 32;
  config.pin_reset = -1;
  config.xclk_freq_hz = 20000000;
  config.pixel_format = PIXFORMAT_JPEG;

  if (psramFound()) {
    config.frame_size   = STREAM_FRAMESIZE;
    config.jpeg_quality = STREAM_JPEG_QUALITY;
    config.fb_count     = 2;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  } else {
    config.frame_size   = FRAMESIZE_QVGA;
    config.jpeg_quality = 20;
    config.fb_count     = 1;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  }

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    Serial.printf("Camera init failed: 0x%x\n", err);
    return false;
  }

  sensor_t* s = esp_camera_sensor_get();
  s->set_brightness(s, 0);
  s->set_contrast(s, 0);
  s->set_saturation(s, 0);
  s->set_whitebal(s, 1);
  s->set_awb_gain(s, 1);
  s->set_exposure_ctrl(s, 1);
  s->set_aec_value(s, 300);
  s->set_aec2(s, 0);
  s->set_gain_ctrl(s, 1);
  s->set_agc_gain(s, 0);
  s->set_gainceiling(s, (gainceiling_t)0);
  s->set_bpc(s, 0);
  s->set_wpc(s, 1);
  s->set_raw_gma(s, 1);
  s->set_lenc(s, 1);
  s->set_hmirror(s, 0);
  s->set_vflip(s, 0);
  s->set_dcw(s, 1);
  s->set_colorbar(s, 0);

  return true;
}

// -------------------- HANDLERS --------------------
void handleStatus() {
  String json = "{";
  json += "\"ok\":true,";
  json += "\"ip\":\"" + localIP() + "\",";
  json += "\"mode\":\"mjpeg-stream\",";
  json += "\"led\":"  + String(ledOn  ? "true" : "false") + ",";
  json += "\"pump\":" + String(pumpOn ? "true" : "false");
  json += "}";

  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handleLed() {
  bool on = server.hasArg("on") ? (server.arg("on") != "0") : !ledOn;
  ledOn = on;
  digitalWrite(LED_FLASH_PIN, on ? HIGH : LOW);

  String json = String("{\"ok\":true,\"led\":") + (on ? "true" : "false") + "}";
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handlePump() {
  bool on = server.hasArg("on") ? (server.arg("on") != "0") : !pumpOn;
  pumpOn = on;
  digitalWrite(PUMP_PIN, on ? HIGH : LOW);

  String json = String("{\"ok\":true,\"pump\":") + (on ? "true" : "false") + "}";
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", json);
}

void handleUART() {
  if (!server.hasArg("line")) {
    server.send(400, "application/json", "{\"ok\":false,\"err\":\"missing line\"}");
    return;
  }
  String line = server.arg("line");
  Serial.print(line);
  Serial.print("\n");

  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", "{\"ok\":true}");
}

void handleJoystick() {
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.0f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.0f;

  // Contínuo
  Serial.printf("JOY:x=%.3f:y=%.3f\n", x, y);

  // Fallback discreto: direção + pulso proporcional
  const float mag = sqrtf(x * x + y * y);
  const char* dir = "STOP";
  if (mag >= 0.2f) {
    float deg = atan2f(y, x) * 180.0f / 3.1415926f;
    if (deg > -45 && deg <= 45)       dir = "RIGHT";
    else if (deg > 45 && deg <= 135)  dir = "FWD";
    else if (deg <= -45 && deg > -135)dir = "BACK";
    else                              dir = "LEFT";
  }
  int ms  = (mag < 0.2f) ? 0 : 200 + int(200 * std::min(1.0f, mag));
  int spd = (mag < 0.2f) ? 0 :  50 + int( 50 * std::min(1.0f, mag));
  Serial.printf("CMD:%s:ms=%d:spd=%d\n", dir, ms, spd);

  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.send(200, "application/json", "{\"ok\":true}");
}

// Stream MJPEG: boundary "--frame" + Content-Length (compatível com seu parser)
void handleStream() {
  WiFiClient client = server.client();
  client.setTimeout(2000);

  String hdr =
    "HTTP/1.1 200 OK\r\n"
    "Cache-Control: no-cache, no-store, must-revalidate\r\n"
    "Pragma: no-cache\r\n"
    "Expires: 0\r\n"
    "Connection: close\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=frame\r\n\r\n";
  client.print(hdr);

  const uint64_t minFrameIntervalUs = 1000000ULL / STREAM_TARGET_FPS;
  uint64_t lastSentUs = 0;

  while (client.connected()) {
    uint64_t nowUs = (uint64_t)esp_timer_get_time();
    if (nowUs - lastSentUs < minFrameIntervalUs) { delay(1); continue; }

    camera_fb_t* fb = esp_camera_fb_get();
    if (!fb) { delay(5); continue; }

    if (fb->format != PIXFORMAT_JPEG) {
      uint8_t* jpgBuf = NULL;
      size_t   jpgLen = 0;
      bool ok = frame2jpg(fb, STREAM_JPEG_QUALITY, &jpgBuf, &jpgLen);
      esp_camera_fb_return(fb);
      if (!ok) { delay(2); continue; }

      client.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n", BOUNDARY, (unsigned)jpgLen);
      size_t toWrite = jpgLen;
      const uint8_t* p = jpgBuf;
      while (toWrite > 0) {
        size_t n = client.write(p, std::min((size_t)1024, toWrite));
        if (n == 0) break;
        p += n; toWrite -= n;
        delay(STREAM_CHUNK_PAUSE_MS);
      }
      client.print("\r\n");
      lastSentUs = (uint64_t)esp_timer_get_time();
      free(jpgBuf);
    } else {
      client.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n", BOUNDARY, (unsigned)fb->len);
      size_t toWrite = fb->len;
      const uint8_t* p = fb->buf;
      while (toWrite > 0) {
        size_t n = client.write(p, std::min((size_t)1024, toWrite));
        if (n == 0) break;
        p += n; toWrite -= n;
        delay(STREAM_CHUNK_PAUSE_MS);
      }
      client.print("\r\n");
      lastSentUs = (uint64_t)esp_timer_get_time();
      esp_camera_fb_return(fb);
    }

    delay(1);
    if (!client.connected()) break;
  }

  client.stop();
}

// -------------------- WIFI --------------------
void connectWiFi() {
  WiFi.mode(WIFI_STA);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 20000UL) {
    delay(200);
  }
}

void ensureWiFi() {
  static unsigned long lastCheck = 0;
  unsigned long now = millis();
  if (now - lastCheck < 2000) return;
  lastCheck = now;
  if (WiFi.status() != WL_CONNECTED) {
    WiFi.disconnect(true, true);
    delay(100);
    connectWiFi();
  }
}

// -------------------- SETUP / LOOP --------------------
void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);

  pinMode(LED_FLASH_PIN, OUTPUT);
  digitalWrite(LED_FLASH_PIN, LOW);
  pinMode(PUMP_PIN, OUTPUT);
  digitalWrite(PUMP_PIN, LOW);

  Serial.begin(UART_BAUD);
  delay(200);

  if (!initCamera()) {
    ESP.restart();
  }

  connectWiFi();

  server.on("/status",    HTTP_GET, handleStatus);
  server.on("/led",       HTTP_GET, handleLed);
  server.on("/pump",      HTTP_GET, handlePump);
  server.on("/uart",      HTTP_GET, handleUART);
  server.on("/joystick",  HTTP_GET, handleJoystick);
  server.on("/stream",    HTTP_GET, handleStream);

  // Raiz: ping simples
  server.on("/", HTTP_GET, []() {
    server.send(200, "text/plain",
      "HydroBot ESP32-CAM OK\n/stream, /status, /led, /pump, /joystick, /uart");
  });

  server.begin();
}

void loop() {
  server.handleClient();
  ensureWiFi();
  delay(1);
}
