
Perfeito ‚Äî vamos consertar o /snapshot no ESP.

O problema √© que o handler atual tenta pegar o frame ‚Äúna hora‚Äù (esp_camera_fb_get() dentro do request). Em muitas placas (AI Thinker), isso d√° timeout/NULL intermitente, e o servidor fica em hasFrame=false.


A solu√ß√£o robusta √© capturar frames continuamente em uma tarefa (FreeRTOS) e guardar o √∫ltimo JPEG em mem√≥ria. O endpoint /snapshot apenas devolve o √∫ltimo frame pronto, ent√£o nunca bloqueia esperando a c√¢mera.


Abaixo est√° o firmware completo do ESP32-CAM (AI Thinker) com:




Wi-Fi DHCP + mDNS (http://hydrobot-esp.local)


Task de captura cont√≠nua (cam_task) com retries e auto-reinit da c√¢mera


Buffer PSRAM para o √∫ltimo JPEG (sempre atualizado)


Endpoints: /status, /snapshot, /uart, /pump, /joystick (iguais ao app/servidor)


CORS habilitado


Config de c√¢mera est√°vel: QVGA, jpeg_quality=12, fb_count=2, GRAB_LATEST






No Arduino IDE: Board AI Thinker ESP32-CAM, PSRAM Enabled.

Fontes: ESP com 5V est√°vel ‚â•1A. Ligue GND comum com o Arduino.





ESP32-CAM ‚Äì c√≥digo completo (substitua tudo)


/*  ESP32-CAM (AI Thinker) ‚Äî Snapshot est√°vel (buffer em background) + Bridge HTTP<->UART
    - Wi-Fi DHCP + mDNS: http://hydrobot-esp.local
    - Endpoints:
        /status                 -> JSON (hasFrame, age_ms, fps_cap)
        /snapshot               -> √∫ltimo JPEG em buffer (no-store)
        /uart?line=...          -> Serial.println(line)
        /pump?on=0|1            -> "CMD:PUMP:0|1"
        /joystick?x=&y=         -> redund√¢ncia com CMD discreto
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos c√¢mera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer do √∫ltimo frame ----------
static uint8_t* g_jpeg = nullptr;
static size_t   g_jlen = 0;
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;

static uint32_t g_fail_streak = 0;

// ---------- Utils ----------
static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }

static uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }

// ---------- C√¢mera ----------
static bool camera_begin_qvga() {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 20000000;
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = FRAMESIZE_QVGA;    // 320x240
  cfg.jpeg_quality = 12;                // 10..15 (menor = melhor)
  cfg.fb_count     = psramFound() ? 2 : 1;
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  sensor_t *s = esp_camera_sensor_get();
  if (s && s->id.PID == OV3660_PID) {
    s->set_vflip(s, 1);
    s->set_brightness(s, 1);
    s->set_saturation(s, -2);
  }
  // garante QVGA/qualidade ap√≥s init
  if (s) { s->set_framesize(s, FRAMESIZE_QVGA); s->set_quality(s, 12); }
  return true;
}

static void camera_free_buffer(){
  if(g_jpeg){ heap_caps_free(g_jpeg); g_jpeg=nullptr; g_jlen=0; }
}

// Task de captura cont√≠nua
void cam_task(void*){
  const uint32_t MIN_INTERVAL_MS = 80;  // ~12.5 fps cap
  g_cap_tick = now_ms();
  while(true){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();
    if(!fb){
      g_fail_streak++;
      if(g_fail_streak>=10){
        Serial.println("CAMERA_REINIT");
        esp_camera_deinit();
        delay(50);
        camera_begin_qvga();
        g_fail_streak=0;
      }
      vTaskDelay(pdMS_TO_TICKS(10));
      continue;
    }
    g_fail_streak=0;

    // Garante JPEG
    if(fb->format != PIXFORMAT_JPEG || fb->len<20){
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      continue;
    }

    // Copia para PSRAM pr√≥pria (snapshot independente do fb)
    xSemaphoreTake(g_lock, portMAX_DELAY);
    camera_free_buffer();
    g_jlen = fb->len;
    g_jpeg = (uint8_t*) heap_caps_malloc(g_jlen, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
    if(g_jpeg){
      memcpy(g_jpeg, fb->buf, g_jlen);
      g_ts_ms = now_ms();
    } else {
      g_jlen = 0;
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS calculado
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // cap de taxa
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- Wi-Fi ----------
void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) {
    delay(200);
  }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Handlers ----------
void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot-buffer\","
             "\"hasFrame\":" + String((g_jpeg && age < 12000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) +
             "}";
  server.send(200,"application/json",j);
}

void handle_snapshot(){
  sendCORS();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_jpeg && g_jlen>0);
  if(ok){
    server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
    server.sendHeader("Pragma","no-cache");
    server.sendHeader("Expires","0");
    server.setContentLength(g_jlen);
    server.send(200,"image/jpeg","");
    WiFiClient c = server.client();
    c.write(g_jpeg, g_jlen);
  } else {
    server.send(503,"text/plain","no frame\n");
  }
  xSemaphoreGive(g_lock);
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Encaminha nota GET (compat)
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Comando discreto redundante
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- setup/loop ----------
void setup() {
  // UART0 p/ Arduino
  Serial.begin(115200);
  delay(50);

  // Estabilidade
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  // Sincroniza√ß√£o buffer
  g_lock = xSemaphoreCreateMutex();

  // Wi-Fi
  wifi_begin_dhcp();

  // C√¢mera
  if(!camera_begin_qvga()){
    // tenta mais uma vez ap√≥s 300ms
    delay(300);
    camera_begin_qvga();
  }

  // Task de captura cont√≠nua
  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  // HTTP
  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  // CORS preflight
  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}




Como validar (r√°pido)




Abra o Serial Monitor ‚Üí confirme WIFI_OK e IP: 192.168.3.3 (ou o que o roteador der).


No navegador:



http://<IP_DO_ESP>/status ‚Üí espere hasFrame:true e age_ms baixo.


http://<IP_DO_ESP>/snapshot ‚Üí deve abrir imagem.






Depois disso, o servidor (/healthz) deve passar a hasFrame:true e o app passa a exibir v√≠deo.






Se ainda aparecer hasFrame:false em /status, verifique:




Flat cable da c√¢mera bem encaixado (lado dos contatos para baixo).


Fonte 5V suficiente (‚â•1A).


No ‚ÄúTools‚Äù do IDE, PSRAM: Enabled.


Teste reduzir para QQVGA: mude FRAMESIZE_QVGA ‚Üí FRAMESIZE_QQVGA (e deixe jpeg_quality=15).






Esse desenho, com buffer em background + reinit autom√°tico, elimina o ‚ÄúNO LIVE FRAME‚Äù causado por timeouts do sensor e estabiliza o proxy do servidor.




























































/*  ESP32-CAM (AI Thinker) ‚Äî Bridge HTTP<->UART + Snapshot (DHCP)
    - Conecta ao roteador por DHCP e anuncia mDNS: http://hydrobot-esp.local
    - Endpoints:
        /status                 -> JSON com IP e modo
        /snapshot               -> JPEG (Cache-Control: no-store)
        /uart?line=...          -> envia "line\n" ao Arduino
        /pump?on=0|1            -> envia "CMD:PUMP:0|1\n"
        /joystick?x=&y=         -> encaminha GET e envia CMD discreto redundante
    - Liga√ß√µes:
        ESP U0TXD (GPIO1)  -> Arduino RX (D0)
        Arduino TX (D1) -> (divisor 5V->3V3) -> ESP U0RXD (GPIO3)
        GND comum e fonte 5V dedicada (‚â•1A) para o ESP32-CAM
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"

// --------- Wi-Fi / mDNS ---------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";   // http://hydrobot-esp.local

// --------- WebServer ---------
WebServer server(80);

// --------- Pinos da c√¢mera (AI Thinker) ---------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// --------- Helpers ---------
static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }

// --------- Handlers HTTP ---------
void handle_status(){
  sendCORS();
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot\"}";
  server.send(200,"application/json",j);
}

void handle_uart(){
  sendCORS();
  if(!server.hasArg("line")){ server.send(400,"text/plain","missing 'line'\n"); return; }
  String line = urlDecode(server.arg("line"));
  Serial.print(line);
  if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

void handle_pump(){
  sendCORS();
  if(!server.hasArg("on")){ server.send(400,"text/plain","missing 'on'\n"); return; }
  bool on = server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE";
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on ? "PUMP_ON\n" : "PUMP_OFF\n");
}

void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Encaminha linha GET (compat√≠vel com o teu Arduino)
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Redund√¢ncia com comando discreto (anti-lag)
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){
    Serial.println("CMD:STOP");
  } else {
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);  // 120..380ms
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

void handle_snapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb || fb->format!=PIXFORMAT_JPEG){
    if(fb) esp_camera_fb_return(fb);
    server.send(503,"text/plain","no frame\n");
    return;
  }
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.setContentLength(fb->len);
  server.send(200,"image/jpeg","");
  WiFiClient c = server.client();
  c.write(fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

// --------- Inicializa√ß√£o da c√¢mera (perfil est√°vel) ---------
bool camera_begin_low(){
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;
  cfg.xclk_freq_hz=20000000;
  cfg.pixel_format=PIXFORMAT_JPEG;
  cfg.frame_size=FRAMESIZE_QQVGA;   // 160x120 (comece leve; depois pode subir p/ QVGA)
  cfg.jpeg_quality=15;              // 10~12 mais pesado; 15 √© bem est√°vel
  cfg.fb_count=1;                   // 1 = est√°vel (evita estouro de PSRAM)
  cfg.fb_location=CAMERA_FB_IN_PSRAM;
  cfg.grab_mode=CAMERA_GRAB_LATEST;
  if (esp_camera_init(&cfg) != ESP_OK) return false;

  // ajustes finos opcionais
  sensor_t *s = esp_camera_sensor_get();
  if (s && s->id.PID == OV3660_PID) { s->set_vflip(s,1); s->set_brightness(s,1); s->set_saturation(s,-2); }
  return true;
}

// --------- Wi-Fi (DHCP) ---------
void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 20000) {
    delay(200);
  }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// --------- setup / loop ---------
void setup() {
  // UART0 para Arduino
  Serial.begin(115200);
  delay(50);

  // Estabilidade el√©trica
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout (cuidado: precisa de fonte 5V boa)

  // Wi-Fi
  wifi_begin_dhcp();

  // C√¢mera
  if(!camera_begin_low()){
    Serial.println("CAMERA_INIT_FAIL");
  } else {
    Serial.println("CAMERA_INIT_OK");
  }

  // HTTP
  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  // CORS (preflight)
  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1); // coopera com WDT
}






































Fechado! Aqui v√£o os dois arquivos completos j√° ajustados para o seu ESP32-CAM (com /snapshot, /joystick, /pump, /uart) e com corre√ß√µes para o caso ‚ÄúNO LIVE FRAME‚Äù.


As mudan√ßas principais:




Server agora aceita mais tipos de Content-Type (ex.: image/jpg, application/octet-stream) ou detecta JPEG pelo magic 0xFF 0xD8 ‚Äî isso evita o ‚ÄúNO LIVE FRAME‚Äù quando o ESP n√£o manda o header certinho.


/snapshot tenta direto no ESP primeiro, depois cai no cache ‚Äî inverti a ordem para reduzir lat√™ncia e evitar placeholder.


CameraScreen ganhou fallback autom√°tico: se carregar 3 imagens com erro do servidor, passa a puxar direto do ESP (e volta pro server quando normalizar). Tamb√©m mant√©m o ?ts= contra cache.





1) server_heuristic.py (coloque na raiz do servidor)


# server_heuristic.py
# FastAPI proxy + heur√≠stica de fogo (leve) para ESP32-CAM snapshot
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 8.0
POLL_FPS_TARGET = 8.0                              # ~8 fps est√°vel
MAX_FRAME_AGE_MS = 8000                            # relaxado p/ redes lentas
MAX_RESULT_AGE_MS = 800
JPEG_QUALITY = 85

# Heur√≠stica simples de fogo
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}

ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True  # √†s vezes vem vazio; vamos inspecionar magic bytes
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEUR√çSTICA FOGO =========
def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.02); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.01); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # 1) tenta direto do ESP (melhor lat√™ncia e evita placeholder)
    try:
        b = None
        u = f"{SNAPSHOT_URL_FMT.format(CAMERA_IP)}?ts={int(time.time()*1000)}"
        r = requests.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = (r.headers.get("Content-Type") or "").lower()
            b = r.content or b""
            if not (ct.startswith(ACCEPT_CT_PREFIX) or is_jpeg_bytes(b)):
                b = None
        if not b:
            b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
        if not b:
            b = placeholder_jpeg("NO LIVE FRAME")
    except Exception:
        b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS) or placeholder_jpeg("NO LIVE FRAME")

    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}





Como rodar:


python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install fastapi uvicorn opencv-python-headless numpy requests
uvicorn server_heuristic:app --host 0.0.0.0 --port 8000






2) HydroBotApp2/src/screens/CameraScreen.tsx (substitua por completo)


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando‚Ä¶", waiting:"Aguardando servidor‚Ä¶", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem v√≠deo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo ‚Ä¢ score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting‚Ä¶", waiting:"Waiting for server‚Ä¶", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire ‚Ä¢ score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando‚Ä¶", waiting:"Esperando servidor‚Ä¶", statusFail:"Error de conexi√≥n. Revisa Wi-Fi/IP.",
        noVideo:"Sin v√≠deo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego ‚Ä¢ score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type SrcBox = { x:number; y:number; w:number; h:number; type:"fire" };
function BoxesOverlay({ frameWH, containerWH, boxes }:{
  frameWH:{w:number;h:number}|null; containerWH:{w:number;h:number}|null; boxes:SrcBox[];
}) {
  const f = frameWH && frameWH.w>0 && frameWH.h>0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w<=0 || containerWH.h<=0) return null;
  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale, dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW)/2, offsetY = (containerWH.h - dispH)/2;
  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position:"absolute", left:offsetX, top:offsetY, width:dispW, height:dispH }}>
        {boxes.map((b,i)=>{
          const left=b.x*scale, top=b.y*scale, width=b.w*scale, height=b.h*scale;
          return (
            <View key={i} style={{ position:"absolute", left, top, width, height, borderWidth:3, borderColor:"#ff3b30", borderRadius:6 }}>
              <View style={{ position:"absolute", left:0, top:-18, paddingHorizontal:6, paddingVertical:2, borderRadius:4, backgroundColor:"#ff3b30" }}>
                <Text style={{ color:"#000", fontWeight:"800", fontSize:10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{w:number;h:number}|null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{w:number;h:number}|null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [useDirectSnapshot, setUseDirectSnapshot] = useState(false);
  const failCountRef = useRef(0);

  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);
  const [ready, setReady] = useState(false);

  const clean = (s:string)=>s.replace(/\/+$/,"");

  // Server endpoints
  const healthUrl   = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl   = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const configUrl   = useMemo(()=>`${clean(server)}/config`,[server]);

  // ESP endpoints (controle e snapshot direto - fallback)
  const pumpUrl     = useMemo(()=> (on:boolean)=>`http://${ip}/pump?on=${on?"1":"0"}`,[ip]);
  const joystickUrl = useMemo(()=> (x:number,y:number)=>`http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,[ip]);
  const uartUrl     = useMemo(()=> (line:string)=>`http://${ip}/uart?line=${encodeURIComponent(line)}`,[ip]);
  const snapshotEsp = useMemo(()=> `http://${ip}/snapshot`, [ip]);

  // Sincroniza IP da c√¢mera no server
  useEffect(()=>{
    let aborted=false;
    (async()=>{
      try{
        const r=await fetch(configUrl,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_ip:ip})});
        const j=await r.json();
        if(!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      }catch{ if(!aborted) setStatusText(T.statusFail); }
    })();
    return()=>{aborted=true};
  },[ip, configUrl, T]);

  // Health do servidor
  useEffect(()=>{
    let stop=false, backoff=500;
    const poll=async()=>{
      if(stop) return;
      try{
        const r=await fetch(healthUrl); const j=await r.json();
        if(j?.ok){ setReady(true); setStatusText(`Server OK ‚Ä¢ fps_in:${j.fps_in} ‚Ä¢ hasFrame:${j.hasFrame}`); return; }
      }catch{}
      setReady(false); setStatusText(T.waiting);
      setTimeout(poll, backoff); backoff=Math.min(backoff*1.6, 5000);
    };
    poll(); return()=>{stop=true};
  },[healthUrl, T]);

  // SNAPSHOT loop com fallback server->ESP
  useEffect(()=>{
    if(!ready) return;
    let stop=false, interval=140;
    const pickBase = ()=> useDirectSnapshot ? snapshotEsp : snapshotSrv;

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=140;
      }catch{
        interval=Math.min(interval*1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotEsp, ready, useDirectSnapshot]);

  const onNextLoadStart = ()=>{ loadingNextRef.current=true; };
  const onNextShown = (ok:boolean)=>{
    if(ok){
      failCountRef.current = 0;
      if(useDirectSnapshot){ // tenta voltar ao servidor quando estabilizar
        setUseDirectSnapshot(false);
      }
      if(nextFrameUri) setCurrentFrameUri(nextFrameUri);
    }else{
      failCountRef.current += 1;
      // se falhar 3 vezes seguidas no servidor, troca para ESP direto
      if(!useDirectSnapshot && failCountRef.current >= 3){
        setUseDirectSnapshot(true);
        failCountRef.current = 0;
      }
    }
    loadingNextRef.current=false;
  };

  // DETECT loop
  useEffect(()=>{
    if(!ready) return;
    let stop=false, interval=250;
    const loop=async()=>{
      if(stop) return;
      try{
        const r=await fetch(detectUrl); const j=await r.json();
        if(j && j.ok!==false){
          setIsFire(!!j.isFire); setFireScore(Number(j.score||0));
          const wh = Array.isArray(j.frame_wh)&&j.frame_wh.length===2
                     ? {w:Number(j.frame_wh[0])||0, h:Number(j.frame_wh[1])||0}:null;
          if(wh && wh.w>0 && wh.h>0) setFrameWH(wh);
          const boxes:SrcBox[]=[];
          if(j.isFire && Array.isArray(j.boxes)){
            for(const b of j.boxes){
              if(Array.isArray(b)&&b.length>=4){
                const [x,y,w,h]=b.map((n:any)=>Number(n)||0);
                boxes.push({x,y,w,h,type:"fire"});
              }
            }
          }
          setOverlayBoxes(boxes); interval=250;
        }
      }catch{
        setIsFire(false); setFireScore(0); setOverlayBoxes([]);
        interval=Math.min(interval*1.5,1500);
      }finally{ setTimeout(loop, interval); }
    };
    loop(); return()=>{stop=true};
  },[detectUrl, ready]);

  // Joystick
  const RADIUS=64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder:()=>true,
      onMoveShouldSetPanResponder:()=>true,
      onPanResponderGrant:()=>{},
      onPanResponderMove:(_e:GestureResponderEvent,g:PanResponderGestureState)=>{
        let nx=g.dx/RADIUS, ny=g.dy/RADIUS;
        const len=Math.hypot(nx,ny); if(len>1){ nx/=len; ny/=len; }
        setJoy({x:nx, y:-ny});
      },
      onPanResponderRelease:()=>{ setJoy({x:0,y:0}); },
      onPanResponderTerminate:()=>{ setJoy({x:0,y:0}); },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef  = useRef<string>("STOP");
  const trySendJoystick = async (x:number,y:number)=>{ try{ await fetch(joystickUrl(x,y)); return true; }catch{ return false; } };
  const sendDiscreteCmd  = async (line:string)=>{ try{ await fetch(uartUrl(line)); return true; }catch{ return false; } };
  const vecToDir=(x:number,y:number):"FWD"|"BACK"|"LEFT"|"RIGHT"|"STOP"=>{
    const mag=Math.hypot(x,y); if(mag<0.2) return "STOP";
    const deg=(Math.atan2(y,x)*180)/Math.PI;
    if(deg>-45&&deg<=45) return "RIGHT";
    if(deg>45&&deg<=135) return "FWD";
    if(deg<=-45&&deg>-135) return "BACK";
    return "LEFT";
  };

  useEffect(()=>{
    let cancelled=false;
    const tick=async()=>{
      if(cancelled) return;
      const now=Date.now();
      if(now-lastSendRef.current<120){ setTimeout(tick,20); return; }
      lastSendRef.current=now;

      const {x,y}=joy; const mag=Math.hypot(x,y);
      const ok = await trySendJoystick(x,y);
      if(ok){
        if(mag<0.2 && lastDirRef.current!=="STOP"){ await sendDiscreteCmd("CMD:STOP"); lastDirRef.current="STOP"; }
        setTimeout(tick,120); return;
      }
      const dir=vecToDir(x,y);
      if(dir!==lastDirRef.current){
        const ms=140+Math.round(260*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd( dir==="STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}` );
        lastDirRef.current=dir;
      }else if(dir!=="STOP"){
        const ms=120+Math.round(200*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick,120);
    };
    tick(); return()=>{cancelled=true};
  },[joy, ip]);

  // Bomba
  async function togglePump(){
    try{
      const t=!pumpOn; await fetch(pumpUrl(t)); setPumpOn(t);
    }catch{ setStatusText(T.statusFail); }
  }

  function onVideoLayout(e:LayoutChangeEvent){
    const {width,height}=e.nativeEvent.layout; setVideoContainerWH({w:width,h:height});
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5"
                   autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput value={server} onChangeText={(s)=>{ setServer(s); setReady(false); setStatusText(T.waiting); }}
                   placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
                   style={[styles.input,{minWidth:220}]} />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn?styles.btnOn:styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn?T.pumpOn:T.pumpOff}</Text>
        </Pressable>
      </View>

      <View style={[styles.statusRow,{paddingTop:4,paddingBottom:8}]}>
        <Text numberOfLines={2} style={styles.status}>{statusText} {useDirectSnapshot ? "‚Ä¢ (snapshot direto)" : ""}</Text>
        <View style={[styles.badge,{backgroundColor: ready ? "#065f46" : "#1f2937"}]}>
          <Text style={{ color:"#fff", fontWeight:"800" }}>{ready ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      <View style={[styles.fireBanner, isFire?styles.fireOn:styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      <View style={{ flex:1 }} onLayout={onVideoLayout}>
        <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri}
                        onNextLoadStart={()=> (loadingNextRef.current=true)}
                        onNextShown={onNextShown}/>
        {overlayBoxes.length>0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap,{width:64*2+24,height:64*2+24}]}
              {...pan.panHandlers}>
          <View style={[styles.joyBase,{width:64*2,height:64*2,borderRadius:64}]} />
          <View style={[styles.joyKnob,{width:22*2,height:22*2,borderRadius:22,
                        transform:[{translateX:joy.x*64},{translateY:-joy.y*64}], opacity: dragging?1:0.9}]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container:{ flex:1, backgroundColor:PALETTE.bg },
  hero:{ alignItems:"center", paddingTop:12, paddingBottom:6 },
  heroLogo:{ width:80, height:80, marginBottom:6, resizeMode:"contain" },
  heroTitle:{ color:"#fff", fontSize:22, fontWeight:"800" },
  heroSubtitle:{ color:"#d1d5db", marginTop:2 },

  topbar:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:10, gap:8,
           backgroundColor:PALETTE.card, borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  label:{ color:"#cfd3d8", fontSize:12 },
  input:{ backgroundColor:"#0b0d14", color:"white", borderRadius:8, paddingHorizontal:10, paddingVertical:8,
          borderWidth:1, borderColor:PALETTE.border, minWidth:120 },
  btn:{ backgroundColor:PALETTE.accent, paddingHorizontal:10, paddingVertical:10, borderRadius:10 },
  btnOn:{ backgroundColor:"#17a34a" }, btnOff:{ backgroundColor:"#374151" },
  btnText:{ color:"white", fontWeight:"600" },

  statusRow:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:8, gap:8,
              backgroundColor:"#0f1322", borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  badge:{ paddingHorizontal:10, paddingVertical:6, borderRadius:8, borderWidth:1, borderColor:PALETTE.border },
  status:{ color:"#cbd5ff", flex:1, fontSize:12 },

  fireBanner:{ alignItems:"center", justifyContent:"center", paddingVertical:6 },
  fireOn:{ backgroundColor:"#8b0000" }, fireOff:{ backgroundColor:"#223" },
  fireText:{ color:"white", fontWeight:"800" },

  joyWrap:{ position:"absolute", bottom:24, left:24, alignItems:"center", justifyContent:"center" },
  joyBase:{ position:"absolute", backgroundColor:"rgba(255,255,255,0.08)", borderWidth:2, borderColor:"rgba(255,255,255,0.14)" },
  joyKnob:{ position:"absolute", backgroundColor:"rgba(230,64,58,0.9)", borderWidth:2, borderColor:"rgba(255,255,255,0.85)" },
  joyText:{ position:"absolute", bottom:-22, color:"#cbd5ff", fontSize:12 },
});




Checklist r√°pido




No navegador:






http://192.168.3.3/snapshot abre imagem? (se n√£o, √© o ESP)


http://192.168.3.4:8000/healthz ‚Üí hasFrame:true e veja last_err


http://192.168.3.4:8000/snapshot abre imagem?






No app:






Se o servidor falhar, ele muda sozinho para ‚Äúsnapshot direto‚Äù (aparece um sufixo ‚Äú(snapshot direto)‚Äù no status).


Quando o servidor normalizar, ele volta automaticamente para o proxy.




Se ainda aparecer ‚ÄúNO LIVE FRAME‚Äù, me diga o que retorna GET /healthz (especialmente last_err) ‚Äî com isso d√° pra cravar se √© header do ESP, IP, ou timeout de rede.






































































bora ‚Äî segue os dois arquivos completos (app + servidor) j√° compat√≠veis com o firmware do ESP que exp√µe /status, /snapshot, /uart, /pump, /joystick via roteador.



1) HydroBotApp2/src/screens/CameraScreen.tsx




IP padr√£o do ESP: 192.168.3.3


URL padr√£o do server (FastAPI): http://192.168.3.4:8000


Snapshot vem do server (/snapshot) e usa ?ts= pra evitar cache


Detec√ß√£o simples (heur√≠stica) vem de GET /detect do server


Joystick e Bomba falam direto com o ESP (e t√™m fallback por /uart)




// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
  Image,
  Animated,
  LayoutChangeEvent,
  AppState,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = {
  bg: "#0b0b0f",
  card: "#121218",
  border: "#25273a",
  accent: "#e6403a",
  text: "#e5e7eb",
};

const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:",
    test: "Testar",
    pumpOn: "BOMBA ON",
    pumpOff: "BOMBA OFF",
    server: "Servidor:",
    detecting: "Detectando‚Ä¶",
    waiting: "Aguardando servidor‚Ä¶",
    statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    persons: "Pessoas",
    animals: "Animais",
    backend: "Modelo",
    synced: "Server sincronizado",
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:",
    test: "Test",
    pumpOn: "PUMP ON",
    pumpOff: "PUMP OFF",
    server: "Server:",
    detecting: "Detecting‚Ä¶",
    waiting: "Waiting for server‚Ä¶",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire ‚Ä¢ score ${s.toFixed(2)}`,
    persons: "People",
    animals: "Animals",
    backend: "Model",
    synced: "Server sync OK",
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:",
    test: "Probar",
    pumpOn: "BOMBA ENC.",
    pumpOff: "BOMBA APAG.",
    server: "Servidor:",
    detecting: "Detectando‚Ä¶",
    waiting: "Esperando servidor‚Ä¶",
    statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    persons: "Personas",
    animals: "Animales",
    backend: "Modelo",
    synced: "Sincronizado con servidor",
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
  },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 }; // QQVGA do ESP

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: (ok: boolean) => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image
          key={currentUri}
          source={{ uri: currentUri }}
          style={{ flex: 1, width: "100%" }}
          resizeMode="contain"
        />
      )}

      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => {
              onNextShown(false);
              fade.setValue(0);
              setShowNext(false);
            }}
            onLoadEnd={() => {
              Animated.timing(fade, {
                toValue: 1,
                duration: 80,
                useNativeDriver: true,
              }).start(() => {
                onNextShown(true);
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type BoxType = "fire";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType };

function BoxesOverlay({
  frameWH,
  containerWH,
  boxes,
}: {
  frameWH: { w: number; h: number } | null;
  containerWH: { w: number; h: number } | null;
  boxes: SrcBox[];
}) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale;
          const top = b.y * scale;
          const width = b.w * scale;
          const height = b.h * scale;
          return (
            <View
              key={`${i}`}
              style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor: "#ff3b30", borderRadius: 6 }}
            >
              <View
                style={{ position: "absolute", left: 0, top: -18, paddingHorizontal: 6, paddingVertical: 2, borderRadius: 4, backgroundColor: "#ff3b30" }}
              >
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);

  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  const [ready, setReady] = useState(false);

  const cleanServer = (s: string) => s.replace(/\/+$/, "");

  // Server endpoints
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);
  const detectUrl = useMemo(() => `${cleanServer(server)}/detect`, [server]);
  const snapshotUrl = useMemo(() => `${cleanServer(server)}/snapshot`, [server]);
  const configUrl = useMemo(() => `${cleanServer(server)}/config`, [server]);

  // ESP endpoints (controle direto)
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const joystickUrl = useMemo(() => (x: number, y: number) => `http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`, [ip]);
  const uartUrl = useMemo(() => (line: string) => `http://${ip}/uart?line=${encodeURIComponent(line)}`, [ip]);

  // Sincroniza o IP da c√¢mera dentro do server (para o proxy do /snapshot)
  useEffect(() => {
    let aborted = false;
    (async () => {
      try {
        const r = await fetch(configUrl, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ camera_ip: ip }),
        });
        const j = await r.json();
        if (!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      } catch {
        if (!aborted) setStatusText(T.statusFail);
      }
    })();
    return () => {
      aborted = true;
    };
  }, [ip, configUrl, T]);

  // Health do servidor
  useEffect(() => {
    let stop = false;
    let backoff = 500;
    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl);
        const j = await r.json();
        if (j?.ok) {
          setReady(true);
          setStatusText(`Server OK ‚Ä¢ fps_in:${j.fps_in} ‚Ä¢ hasFrame:${j.hasFrame}`);
          return;
        }
      } catch {}
      setReady(false);
      setStatusText(T.waiting);
      setTimeout(poll, backoff);
      backoff = Math.min(backoff * 1.6, 5000);
    };
    poll();
    return () => {
      stop = true;
    };
  }, [healthUrl, T]);

  // SNAPSHOT loop
  useEffect(() => {
    if (!ready) return;
    let stop = false;
    let interval = 120; // ~8 fps
    setCurrentFrameUri(`${snapshotUrl}?ts=${Date.now()}`);
    const tick = () => {
      if (stop) return;
      try {
        if (!loadingNextRef.current) {
          const url = `${snapshotUrl}?ts=${Date.now()}`;
          setNextFrameUri(url);
        }
        interval = 120;
      } catch {
        interval = Math.min(interval * 1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();
    return () => {
      stop = true;
    };
  }, [snapshotUrl, ready]);

  function onNextLoadStart() {
    loadingNextRef.current = true;
  }
  function onNextShown(ok: boolean) {
    if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  // DETECT loop
  useEffect(() => {
    if (!ready) return;
    let stop = false;
    let interval = 220;
    const loop = async () => {
      if (stop) return;
      try {
        const r = await fetch(detectUrl);
        const j = await r.json();
        if (j && j.ok !== false) {
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));
          const wh =
            Array.isArray(j.frame_wh) && j.frame_wh.length === 2
              ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 }
              : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);
          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) {
              if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0);
              boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          setOverlayBoxes(boxes);
          interval = 220;
        }
      } catch {
        setIsFire(false);
        setFireScore(0);
        setOverlayBoxes([]);
        interval = Math.min(interval * 1.5, 1500);
      } finally {
        setTimeout(loop, interval);
      }
    };
    loop();
    return () => {
      stop = true;
    };
  }, [detectUrl, ready]);

  // Joystick
  const RADIUS = 64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS,
          ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) {
          nx /= len;
          ny /= len;
        }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
      onPanResponderTerminate: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef = useRef<string>("STOP");

  const trySendJoystick = async (x: number, y: number) => {
    try {
      await fetch(joystickUrl(x, y), { method: "GET" });
      return true;
    } catch {
      return false;
    }
  };
  const sendDiscreteCmd = async (line: string) => {
    try {
      await fetch(uartUrl(line), { method: "GET" });
      return true;
    } catch {
      return false;
    }
  };
  const vecToDir = (x: number, y: number): "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP" => {
    const mag = Math.hypot(x, y);
    if (mag < 0.2) return "STOP";
    const deg = (Math.atan2(y, x) * 180) / Math.PI;
    if (deg > -45 && deg <= 45) return "RIGHT";
    if (deg > 45 && deg <= 135) return "FWD";
    if (deg <= -45 && deg > -135) return "BACK";
    return "LEFT";
  };

  useEffect(() => {
    let cancelled = false;
    const tick = async () => {
      if (cancelled) return;
      const now = Date.now();
      if (now - lastSendRef.current < 120) {
        setTimeout(tick, 20);
        return;
      }
      lastSendRef.current = now;

      const x = joy.x;
      const y = joy.y;
      const mag = Math.hypot(x, y);

      const ok = await trySendJoystick(x, y);
      if (ok) {
        if (mag < 0.2 && lastDirRef.current !== "STOP") {
          await sendDiscreteCmd("CMD:STOP");
          lastDirRef.current = "STOP";
        }
        setTimeout(tick, 120);
        return;
      }

      const dir = vecToDir(x, y);
      if (dir !== lastDirRef.current) {
        const ms = 140 + Math.round(260 * Math.min(1, mag));
        const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(
          dir === "STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}`
        );
        lastDirRef.current = dir;
      } else if (dir !== "STOP") {
        const ms = 120 + Math.round(200 * Math.min(1, mag));
        const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick, 120);
    };
    tick();
    return () => {
      cancelled = true;
    };
  }, [joy, ip]);

  // Bomba
  async function togglePump() {
    try {
      const t = !pumpOn;
      await fetch(pumpUrl(t));
      setPumpOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }

  function onVideoLayout(e: LayoutChangeEvent) {
    const { width, height } = e.nativeEvent.layout;
    setVideoContainerWH({ w: width, h: height });
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + Servidor + Bomba */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => {
            setServer(s);
            setReady(false);
            setStatusText(T.waiting);
          }}
          placeholder={T.placeholderServer}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { minWidth: 220 }]}
        />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>
          {statusText}
        </Text>
        <View style={[styles.badge, { backgroundColor: ready ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>
            {ready ? T.detecting : T.waiting}
          </Text>
        </View>
      </View>

      {/* Banner de fogo */}
      <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      {/* V√≠deo (snapshot) + Overlay */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        <CrossfadeImage
          currentUri={currentFrameUri}
          nextUri={nextFrameUri}
          onNextLoadStart={() => (loadingNextRef.current = true)}
          onNextShown={(ok) => {
            if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri);
            loadingNextRef.current = false;
          }}
        />
        {overlayBoxes.length > 0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: 22 * 2,
                height: 22 * 2,
                borderRadius: 22,
                transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: "#0b0d14",
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
    minWidth: 120,
  },
  btn: {
    backgroundColor: PALETTE.accent,
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1322",
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  badge: {
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(230,64,58,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});




2) server_heuristic.py (FastAPI)




Puxa frames do ESP (http://192.168.3.3/snapshot) e faz proxy em /snapshot (com headers no-store).


/healthz informa se h√° frame recente.


/config permite trocar o IP da c√¢mera no runtime.


/detect faz uma heur√≠stica leve (HSV + brilho) s√≥ para manter o banner de fogo do app.






Instalar deps: pip install fastapi uvicorn opencv-python-headless numpy requests




# server_heuristic.py
# FastAPI proxy + heur√≠stica de fogo (leve) para ESP32-CAM snapshot
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 8.0
POLL_FPS_TARGET = 8.0                              # ~8 fps est√°vel
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800
JPEG_QUALITY = 85

# Heur√≠stica simples de fogo
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                url = SNAPSHOT_URL_FMT.format(self._ip)
                u = f"{url}?ts={int(time.time()*1000)}"
                r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQUEST_HEADERS, stream=False)
                if r.status_code == 200 and r.headers.get("Content-Type", "").startswith("image/jpeg"):
                    jpeg = r.content
                    if jpeg:
                        with self._lock:
                            self._last_jpeg = jpeg
                            self._last_ts_ms = int(time.time()*1000)
                        self._frames += 1
                        now = time.time()
                        if now - self._last_fps_tick >= 1.0:
                            self._fps = self._frames / (now - self._last_fps_tick)
                            self._frames = 0
                            self._last_fps_tick = now
                        backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception:
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age, "fps_in": round(self._fps, 2)}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEUR√çSTICA FOGO =========
def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.02); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.01); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            is_fire = False
            if ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW: is_fire = False
            else: is_fire = self._is_fire  # histerese

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber)
det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "fps_in": s.get("fps_in"), "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # Proxy com cabe√ßalhos anti-cache fortes
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        # √∫ltimo recurso: tentar pegar agora
        try:
            r = requests.get(f"{SNAPSHOT_URL_FMT.format(CAMERA_IP)}?ts={int(time.time()*1000)}",
                             timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                             headers=REQUEST_HEADERS, stream=False)
            if r.status_code == 200 and r.headers.get("Content-Type","").startswith("image/jpeg"):
                jpeg = r.content
        except Exception:
            pass
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")

    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=jpeg, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    # fallback: computa no ato
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}



Como rodar o server:


python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate
pip install fastapi uvicorn opencv-python-headless numpy requests
uvicorn server_heuristic:app --host 0.0.0.0 --port 8000




Teste r√°pido (fim a fim)




Navegador:



http://192.168.3.3/status (ESP) ‚Üí JSON


http://192.168.3.3/snapshot ‚Üí imagem (QQVGA)






Servidor:



POST http://192.168.3.4:8000/config com {"camera_ip":"192.168.3.3"}


GET http://192.168.3.4:8000/healthz ‚Üí hasFrame: true


GET http://192.168.3.4:8000/snapshot ‚Üí imagem (app usa isso)






App: abrir a tela; deve aparecer o v√≠deo.

Joystick/bomba: testam direto no ESP (/joystick, /pump).




Se algo n√£o aparecer, me diga o retorno exato de /healthz e o texto de status que o app mostra ‚Äî ajusto na hora.




























































/* ESP32-CAM (AI Thinker) ‚Äî Bridge HTTP<->UART + Snapshot via Roteador
   IP fixo: 192.168.3.3
   Endpoints:
     GET /status                -> JSON
     GET /snapshot              -> JPEG (no-store)
     GET /uart?line=...         -> envia "line\n" ao Arduino (UART0)
     GET /pump?on=0|1           -> envia "CMD:PUMP:0|1\n"
     GET /joystick?x=..&y=..    -> encaminha GET e manda CMD discreto redundante
   Observa√ß√µes:
     - UART0 (GPIO1 TX0 -> RX Arduino | GPIO3 RX0 <- TX Arduino via divisor 5V->3V3)
     - C√¢mera QQVGA, quality 15, fb_count 1 (est√°vel). Ajuste depois se quiser.
*/

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"

// ===== Wi-Fi (roteador) =====
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";
IPAddress IP(192,168,3,3), GW(192,168,3,1), MASK(255,255,255,0), DNS1(8,8,8,8), DNS2(1,1,1,1);

// ===== WebServer =====
WebServer server(80);

// ===== Pinos c√¢mera (AI Thinker) =====
#define PWDN_GPIO_NUM 32
#define RESET_GPIO_NUM -1
#define XCLK_GPIO_NUM 0
#define SIOD_GPIO_NUM 26
#define SIOC_GPIO_NUM 27
#define Y9_GPIO_NUM 35
#define Y8_GPIO_NUM 34
#define Y7_GPIO_NUM 39
#define Y6_GPIO_NUM 36
#define Y5_GPIO_NUM 21
#define Y4_GPIO_NUM 19
#define Y3_GPIO_NUM 18
#define Y2_GPIO_NUM 5
#define VSYNC_GPIO_NUM 25
#define HREF_GPIO_NUM 23
#define PCLK_GPIO_NUM 22

// ===== Utils =====
static String urlDecode(const String &s){
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{ if(c>='0'&&c<='9')return c-'0'; if(c>='A'&&c<='F')return 10+(c-'A'); if(c>='a'&&c<='f')return 10+(c-'a'); return -1; };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){ int h1=hx(s[i+1]),h2=hx(s[i+2]); if(h1>=0&&h2>=0){ o+=(char)((h1<<4)|h2); i+=2; } else o+=c; }
    else o+=c;
  }
  return o;
}
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }

// ===== HTTP Handlers =====
void handle_status(){
  sendCORS();
  String j = "{\"ok\":true,\"ip\":\""+WiFi.localIP().toString()+"\",\"mode\":\"bridge+snapshot\"}";
  server.send(200,"application/json",j);
}
void handle_uart(){
  sendCORS();
  if(!server.hasArg("line")){ server.send(400,"text/plain","missing 'line'\n"); return; }
  String line = urlDecode(server.arg("line"));
  Serial.print(line);
  if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}
void handle_pump(){
  sendCORS();
  if(!server.hasArg("on")){ server.send(400,"text/plain","missing 'on'\n"); return; }
  bool on = server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE";
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on ? "PUMP_ON\n" : "PUMP_OFF\n");
}
void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Encaminha linha GET (seu Arduino entende)
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Redund√¢ncia CMD discreto
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){
    Serial.println("CMD:STOP");
  } else {
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}
void handle_snapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb || fb->format!=PIXFORMAT_JPEG){
    if(fb) esp_camera_fb_return(fb);
    server.send(503,"text/plain","no frame\n");
    return;
  }
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.setContentLength(fb->len);
  server.send(200,"image/jpeg","");
  WiFiClient c = server.client();
  c.write(fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

// ===== Camera init (perfil leve/est√°vel) =====
bool camera_begin_low(){
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;
  cfg.xclk_freq_hz=20000000;
  cfg.pixel_format=PIXFORMAT_JPEG;
  cfg.frame_size=FRAMESIZE_QQVGA;   // comece bem leve; depois pode subir para QVGA
  cfg.jpeg_quality=15;              // 10‚Äì12 √© mais pesado; comece 15
  cfg.fb_count=1;                   // 1 = mais est√°vel
  cfg.fb_location=CAMERA_FB_IN_PSRAM;
  cfg.grab_mode=CAMERA_GRAB_LATEST;
  return esp_camera_init(&cfg) == ESP_OK;
}

// ===== setup/loop =====
void setup(){
  // UART0 para Arduino
  Serial.begin(115200);
  delay(50);

  // estabilidade
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.config(IP,GW,MASK,DNS1,DNS2);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0=millis();
  while(WiFi.status()!=WL_CONNECTED && millis()-t0<15000) delay(200);

  // c√¢mera
  camera_begin_low();

  // HTTP
  server.on("/status",    HTTP_GET, handle_status);
  server.on("/snapshot",  HTTP_GET, handle_snapshot);
  server.on("/uart",      HTTP_GET, handle_uart);
  server.on("/pump",      HTTP_GET, handle_pump);
  server.on("/joystick",  HTTP_GET, handle_joystick);
  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
}
void loop(){ server.handleClient(); delay(1); }


































// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet, PanResponder,
  GestureResponderEvent, PanResponderGestureState, Image, Animated,
  LayoutChangeEvent, AppState, Platform,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

/* ---------- PALETA ---------- */
const PALETTE = { bg: "#0b0b0f", card: "#121218", border: "#25273a", accent: "#e6403a", text: "#e5e7eb" };

/* ---------- TEXTOS ---------- */
const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:", test: "Testar", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "BOMBA ON", pumpOff: "BOMBA OFF", server: "Servidor:",
    detecting: "Detectando‚Ä¶", saving: "Salvando...", statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Pessoas", animals: "Animais", backend: "Modelo",
    waiting: "Aguardando servidor‚Ä¶", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
    switchingToSnapshot: "MJPEG falhou ‚Ä¢ usando snapshot direto",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:", test: "Test", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "PUMP ON", pumpOff: "PUMP OFF", server: "Server:",
    detecting: "Detecting‚Ä¶", saving: "Saving...", statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "People", animals: "Animals", backend: "Model",
    waiting: "Waiting for server‚Ä¶", synced: "Server sync OK",
    mode: "Mode", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
    switchingToSnapshot: "MJPEG failed ‚Ä¢ falling back to direct snapshot",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:", test: "Probar", ledOn: "LED ENC.", ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.", pumpOff: "BOMBA APAG.", server: "Servidor:",
    detecting: "Detectando‚Ä¶", saving: "Guardando...", statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Personas", animals: "Animales", backend: "Modelo",
    waiting: "Esperando servidor‚Ä¶", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECTO",
    switchingToSnapshot: "MJPEG fall√≥ ‚Ä¢ usando snapshot directo",
  },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 640, h: 480 };

const appLogo = require("../../assets/logo.png");

/* ---------- HERO ---------- */
function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

/* ---------- SNAPSHOT com crossfade ---------- */
function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 100, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

/* ---------- OVERLAY ---------- */
type BoxType = "fire" | "person" | "animal";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType; conf?: number; };

function BoxesOverlay({
  frameWH, containerWH, boxes,
}: { frameWH: { w: number; h: number } | null; containerWH: { w: number; h: number } | null; boxes: SrcBox[]; }) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale, top = b.y * scale, width = b.w * scale, height = b.h * scale;
          let borderColor = "#ff3b30"; if (b.type === "person") borderColor = "#00e5ff"; else if (b.type === "animal") borderColor = "#7CFC00";
          return (
            <View key={`${i}-${b.type}`} style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor, borderRadius: 6 }}>
              <View style={{ position: "absolute", left: 0, top: -18, paddingHorizontal: 6, paddingVertical: 2, borderRadius: 4, backgroundColor: borderColor }}>
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>
                  {b.type.toUpperCase()}{typeof b.conf === "number" ? ` ${b.conf.toFixed(2)}` : ""}
                </Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

/* ---------- TELA PRINCIPAL ---------- */
type Mode = "auto" | "server" | "direct";

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conex√µes
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState(T.waiting);
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detec√ß√£o (server)
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("‚Äî");
  const [confMax, setConfMax] = useState<number>(0);

  // caixas + dimens√µes
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  // registro autom√°tico
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // SNAPSHOT (server)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // DIRECT: fallback snapshot
  const [directUseSnapshot, setDirectUseSnapshot] = useState(false);
  const [directCurUri, setDirectCurUri] = useState("");
  const [directNextUri, setDirectNextUri] = useState("");
  const directLoadingRef = useRef(false);
  const directFailMsgShownRef = useRef(false);

  // joystick
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // health/mode
  const [serverReady, setServerReady] = useState(false);
  const [mode, setMode] = useState<Mode>("auto");

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);
  const detectUrl = useMemo(() => `${cleanServer(server)}/detect`, [server]);
  const snapshotUrl = useMemo(() => `${cleanServer(server)}/snapshot`, [server]);
  const configUrl = useMemo(() => `${cleanServer(server)}/config`, [server]);
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const joystickUrl = useMemo(() => (x: number, y: number) => `http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`, [ip]);
  const uartUrl = useMemo(() => (line: string) => `http://${ip}/uart?line=${encodeURIComponent(line)}`, [ip]);
  const directStreamHtml = useMemo(
    () => `<html><head><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
      <style>html,body{margin:0;background:#000;height:100%}img{width:100%;height:100%;object-fit:contain;}</style></head>
      <body><img src="http://${ip}/stream" /></body></html>`,
    [ip]
  );

  /* ===== AppState ===== */
  const appStateRef = useRef(AppState.currentState);
  useEffect(() => {
    const sub = AppState.addEventListener("change", (s) => { appStateRef.current = s; });
    return () => sub.remove();
  }, []);

  /* ===== Sincroniza IP do ESP dentro do server ===== */
  useEffect(() => {
    let aborted = false;
    (async () => {
      try {
        const r = await fetch(configUrl, { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ camera_ip: ip }) });
        const j = await r.json();
        if (!aborted && j?.ok) setStatusText(T.synced + ` (${j.camera_ip})`);
      } catch { if (!aborted) setStatusText(T.statusFail); }
    })();
    return () => { aborted = true; };
  }, [ip, configUrl, T]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led); setPumpOn(!!j.pump);
      setStatusText(`OK ‚Ä¢ ip:${j.ip ?? ip} ‚Ä¢ mode:${j.mode ?? "‚Äî"} ‚Ä¢ led:${j.led ? "on" : "off"} ‚Ä¢ pump:${j.pump ? "on" : "off"} ‚Ä¢ q:${j.q ?? "?"}`);
    } catch { setStatusText(T.statusFail); }
    finally { setIsChecking(false); }
  }
  async function toggleLed() { try { const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t); } catch { setStatusText(T.statusFail); } }
  async function togglePump(){ try { const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); } catch { setStatusText(T.statusFail); } }
  useEffect(() => { pingStatus(); const id = setInterval(pingStatus, 5000); return () => clearInterval(id); }, [statusUrl]);

  /* ===== HEALTH-CHECK DO SERVIDOR ===== */
  useEffect(() => {
    let stop = false;
    let backoff = 600, fail = 0;
    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl);
        const j = await r.json();
        const ok = !!j?.ok && !!j?.hasFrame;
        setServerReady(ok);
        setStatusText(ok ? `Server OK ‚Ä¢ hasFrame:${j.hasFrame}` : T.waiting);
        fail = ok ? 0 : fail + 1;
      } catch { fail++; setServerReady(false); setStatusText(T.waiting); }
      if (mode === "auto" && fail >= 3) setStatusText("Falha no servidor ‚Ä¢ alternando para DIRECT");
      setTimeout(poll, Math.min((backoff *= 1.35), 5000));
    };
    poll(); return () => { stop = true; };
  }, [healthUrl, mode, T]);

  /* ===== SNAPSHOT LOOP (pull do servidor) ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    let stop = false;
    let interval = 110; // ~9 fps

    setCurrentFrameUri(`${snapshotUrl}?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!loadingNextRef.current) setNextFrameUri(`${snapshotUrl}?ts=${Date.now()}`);
        interval = 110;
      } catch { interval = Math.min(interval * 1.6, 1200); }
      setTimeout(tick, interval);
    };
    tick();
    return () => { stop = true; };
  }, [snapshotUrl, serverReady, mode]);

  function onNextLoadStart(){ loadingNextRef.current = true; }
  function onNextShown(ok: boolean){ if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri); loadingNextRef.current = false; }

  /* ===== DETEC√á√ÉO (via servidor) ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;

    let stop = false;
    let interval = 200;
    const controller = new AbortController();

    const loop = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        const r = await fetch(detectUrl, { signal: controller.signal });
        const j = await r.json();
        if (j && j.ok !== false) {
          setIsFire(!!j.isFire); setFireScore(Number(j.score || 0));

          const wh = Array.isArray(j.frame_wh) && j.frame_wh.length === 2 ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 } : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);

          const o = j.objects || {}; const objs = o.objects || [];
          const nPerson = typeof o.n_person_stable === "number" ? o.n_person_stable : (typeof o.n_person === "number" ? o.n_person : objs.filter((x: any) => String(x.label).toLowerCase() === "person").length);
          const nAnimals = typeof o.n_animals_stable === "number" ? o.n_animals_stable : (typeof o.n_animals === "number" ? o.n_animals : objs.filter((x: any) => String(x.label).toLowerCase() !== "person").length);

          setPeople(nPerson || 0); setAnimals(nAnimals || 0);
          setBackend(o.backend || "‚Äî"); setConfMax(Number(o.conf_max || 0));

          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) { if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0); boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          for (const it of objs) {
            if (!it || !Array.isArray(it.box) || it.box.length < 4) continue;
            const [x, y, w, h] = it.box.map((n: any) => Number(n) || 0);
            const label = String(it.label || "").toLowerCase(); const conf = typeof it.conf === "number" ? it.conf : undefined;
            if (label === "person") boxes.push({ x, y, w, h, type: "person", conf }); else boxes.push({ x, y, w, h, type: "animal", conf });
          }
          setOverlayBoxes(boxes);
          interval = 200;
        }
      } catch {
        setIsFire(false); setFireScore(0); setPeople(0); setAnimals(0); setOverlayBoxes([]);
        interval = Math.min(interval * 1.6, 1500);
      } finally { setTimeout(loop, interval); }
    };
    loop();
    return () => { stop = true; controller.abort(); };
  }, [detectUrl, serverReady, mode]);

  /* ===== Registro autom√°tico ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;
    if (rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch { setStatusText(T.noVideo); } finally { setSaving(false); }
      })();
    }
    wasFireRef.current = isFire;
  }, [isFire, server, saving, T, serverReady, mode]);

  /* ===== Joystick ===== */
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(PanResponder.create({
    onStartShouldSetPanResponder: () => true,
    onMoveShouldSetPanResponder: () => true,
    onPanResponderGrant: () => setDragging(true),
    onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
      let nx = g.dx / RADIUS, ny = g.dy / RADIUS; const len = Math.hypot(nx, ny);
      if (len > 1) { nx /= len; ny /= len; } setJoy({ x: nx, y: -ny });
    },
    onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
  })).current;

  const lastSendRef = useRef(0); const lastDirRef = useRef<string>("STOP");
  const trySendJoystick = async (x: number, y: number) => { try { await fetch(joystickUrl(x, y)); return true; } catch { return false; } };
  const sendDiscreteCmd = async (dir: "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP", ms = 180, spd = 70) => {
    const line = dir === "STOP" ? "CMD:STOP"
      : `CMD:${dir}:ms=${Math.max(80, Math.min(ms, 600))}:spd=${Math.max(30, Math.min(spd, 100))}`;
    try { await fetch(uartUrl(line)); return true; } catch { return false; }
  };
  const vecToDir = (x: number, y: number): "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP" => {
    const mag = Math.hypot(x, y); if (mag < 0.2) return "STOP";
    const deg = (Math.atan2(y, x) * 180) / Math.PI;
    if (deg > -45 && deg <= 45) return "RIGHT"; if (deg > 45 && deg <= 135) return "FWD";
    if (deg <= -45 && deg > -135) return "BACK"; return "LEFT";
  };

  useEffect(() => {
    let cancelled = false;
    const tick = async () => {
      if (cancelled) return;
      const now = Date.now(); if (now - lastSendRef.current < 120) { setTimeout(tick, 20); return; }
      lastSendRef.current = now;
      const { x, y } = joy; const mag = Math.hypot(x, y);
      const ok = await trySendJoystick(x, y);
      if (ok) {
        if (mag < 0.2 && lastDirRef.current !== "STOP") { await sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; }
        setTimeout(tick, 120); return;
      }
      const dir = vecToDir(x, y);
      if (dir !== lastDirRef.current) {
        const ms = 140 + Math.round(260 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd); lastDirRef.current = dir;
      } else if (dir !== "STOP") {
        const ms = 120 + Math.round(200 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd);
      }
      setTimeout(tick, 120);
    };
    if (AppState.currentState === "active") tick();
    return () => { cancelled = true; };
  }, [joy, ip]);

  useEffect(() => {
    const handleBg = (s: string) => { if (s !== "active") { sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; } };
    const sub = AppState.addEventListener("change", handleBg);
    return () => sub.remove();
  }, []);

  function onVideoLayout(e: LayoutChangeEvent) { const { width, height } = e.nativeEvent.layout; setVideoContainerWH({ w: width, h: height }); }

  const usingServer = (mode === "server") || (mode === "auto" && serverReady);
  const usingDirect = (mode === "direct") || (mode === "auto" && !serverReady);

  /* ===== DIRECT: fallback snapshot loop ===== */
  useEffect(() => {
    if (!usingDirect || !directUseSnapshot) return;
    let stop = false;
    let interval = 140; // ~7 fps para n√£o sobrecarregar o ESP
    setDirectCurUri(`http://${ip}/snapshot?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!directLoadingRef.current) setDirectNextUri(`http://${ip}/snapshot?ts=${Date.now()}`);
        interval = 140;
      } catch { interval = Math.min(interval * 1.6, 1000); }
      setTimeout(tick, interval);
    };
    tick();
    return () => { stop = true; };
  }, [usingDirect, directUseSnapshot, ip]);

  function onDirectNextStart(){ directLoadingRef.current = true; }
  function onDirectNextShown(ok: boolean){
    if (ok && directNextUri) setDirectCurUri(directNextUri);
    directLoadingRef.current = false;
  }

  // Quando entrar em DIRECT, tentamos o MJPEG primeiro; se falhar -> snapshot
  useEffect(() => {
    if (!usingDirect) { setDirectUseSnapshot(false); return; }
    // se WebView n√£o sinalizar progresso em ~2.5s, troca para snapshot
    const t = setTimeout(() => {
      if (!directUseSnapshot) {
        setDirectUseSnapshot(true);
        if (!directFailMsgShownRef.current) {
          setStatusText(T.switchingToSnapshot);
          directFailMsgShownRef.current = true;
        }
      }
    }, 2500);
    return () => clearTimeout(t);
  }, [usingDirect, ip, T]);

  // Eventos do WebView para cancelar o fallback caso o MJPEG esteja OK
  const onWvLoadProgress = (e: any) => {
    if (usingDirect && !directUseSnapshot && e?.nativeEvent?.progress >= 0.2) {
      // carregou algo; mantemos MJPEG
      directFailMsgShownRef.current = false;
    }
  };
  const onWvError = () => {
    if (usingDirect) {
      setDirectUseSnapshot(true);
      if (!directFailMsgShownRef.current) {
        setStatusText(T.switchingToSnapshot);
        directFailMsgShownRef.current = true;
      }
    }
  };

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Pressable onPress={pingStatus} style={styles.btn}><Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text></Pressable>
        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text></Pressable>
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text></Pressable>
      </View>

      {/* Linha: Servidor + Modo */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => { setServer(s); setServerReady(false); setStatusText(T.waiting); }}
          placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Text style={styles.label}>{T.mode}</Text>
        <View style={{ flexDirection: "row", gap: 6 }}>
          <Pressable onPress={() => setMode("auto")} style={[styles.modeBtn, mode === "auto" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeAuto}</Text></Pressable>
          <Pressable onPress={() => setMode("server")} style={[styles.modeBtn, mode === "server" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeServer}</Text></Pressable>
          <Pressable onPress={() => setMode("direct")} style={[styles.modeBtn, mode === "direct" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeDirect}</Text></Pressable>
        </View>
        <View style={[styles.badge, { backgroundColor: ((mode === "server") || (mode==="auto" && serverReady)) ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>{((mode === "server") || (mode==="auto" && serverReady)) ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
      </View>

      {/* Banner de fogo (apenas server) */}
      {((mode === "server") || (mode==="auto" && serverReady)) && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
        </View>
      )}

      {/* Pessoas/animais */}
      {((mode === "server") || (mode==="auto" && serverReady)) && (
        <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
          <Text style={styles.statChip}>{T.persons}: <Text style={styles.statNumber}>{people}</Text></Text>
          <Text style={styles.statChip}>{T.animals}: <Text style={styles.statNumber}>{animals}</Text></Text>
          <Text style={styles.modelChip}>{T.backend}: {backend} ‚Ä¢ conf_max {confMax.toFixed(2)}</Text>
        </View>
      )}

      {/* V√≠deo */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        {((mode === "server") || (mode==="auto" && serverReady)) ? (
          <>
            <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri} onNextLoadStart={onNextLoadStart} onNextShown={onNextShown} />
            {overlayBoxes.length > 0 && (<BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />)}
          </>
        ) : (
          directUseSnapshot ? (
            <CrossfadeImage
              currentUri={directCurUri}
              nextUri={directNextUri}
              onNextLoadStart={onDirectNextStart}
              onNextShown={onDirectNextShown}
            />
          ) : (
            <WebView
              originWhitelist={["*"]}
              source={{ html: directStreamHtml, baseUrl: `http://${ip}/` }}
              allowsInlineMediaPlayback
              mediaPlaybackRequiresUserAction={false}
              javaScriptEnabled
              domStorageEnabled
              setSupportMultipleWindows={false}
              overScrollMode="never"
              mixedContentMode="always"                 // << chave no Android
              onError={onWvError}
              onHttpError={onWvError}
              onLoadProgress={onWvLoadProgress}
              // estes dois ajudam em alguns devices:
              androidHardwareAccelerationDisabled={false}
              androidLayerType={Platform.OS === "android" ? "hardware" as any : undefined}
              style={{ backgroundColor: "black" }}
            />
          )
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View style={[styles.joyKnob, { width: 22 * 2, height: 22 * 2, borderRadius: 22, transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }], opacity: dragging ? 1 : 0.9 }]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

/* ---------- ESTILOS ---------- */
const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },
  topbar: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 10, gap: 8, backgroundColor: PALETTE.card, borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: { backgroundColor: "#0b0d14", color: "white", borderRadius: 8, paddingHorizontal: 10, paddingVertical: 8, borderWidth: 1, borderColor: PALETTE.border, minWidth: 110 },
  btn: { backgroundColor: PALETTE.accent, paddingHorizontal: 10, paddingVertical: 10, borderRadius: 10 },
  btnOn: { backgroundColor: "#17a34a" }, btnOff: { backgroundColor: "#374151" }, btnText: { color: "white", fontWeight: "600" },
  statusRow: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 8, gap: 8, backgroundColor: "#0f1322", borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  badge: { paddingHorizontal: 10, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: PALETTE.border },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },
  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 }, fireOn: { backgroundColor: "#8b0000" }, fireOff: { backgroundColor: "#223" }, fireText: { color: "white", fontWeight: "800" },
  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" }, statNumber: { color: "#fff" }, modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(230,64,58,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
  modeBtn: { backgroundColor: "#1f2937", paddingHorizontal: 8, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: "#334155" },
  modeBtnActive: { backgroundColor: "#0b5", borderColor: "#0b5" },
  modeText: { color: "#fff", fontWeight: "700", fontSize: 12 },
});
















































Boa ‚Äî ajustei apenas o firmware do ESP32-CAM para estabilizar e garantir que o /stream e o /snapshot entreguem imagem de forma confi√°vel (melhor manuseio de PSRAM, CORS no stream, keep-alive, escrita n√£o-bloqueante mais robusta, ABR e fallback de framesize se a mem√≥ria apertar). Substitua seu arquivo inteiro por este:


// HydroBot ESP32-CAM - Stable MJPEG (fixed IP) 2025-09-26
// Endpoints: /status /led /pump /joystick /uart /stream /snapshot (/jpg)
// Mudan√ßas-chave vs sua vers√£o:
//  - CORS tamb√©m no /stream (evita bloqueios espor√°dicos no WebView/React Native)
//  - Cabe√ßalhos do stream com "keep-alive" (n√£o for√ßa fechamento precoce)
//  - Escrita MJPEG mais resiliente (timeout progressivo e verifica√ß√£o de write estagnado)
//  - Uso seguro de PSRAM: fb_count = 2 se houver PSRAM, sen√£o 1
//  - Fallback din√¢mico de resolu√ß√£o se heap/PSRAM ficarem baixos
//  - /snapshot com envio direto + CORS e sem bloqueio por Content-Length mal negociado

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "esp_task_wdt.h"
#include "esp_idf_version.h"
#include <math.h>
#include <algorithm>

// ===== WiFi (static IP) =====
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";
IPAddress LOCAL_IP(192,168,3,3);
IPAddress GATEWAY (192,168,3,1);
IPAddress SUBNET  (255,255,255,0);
IPAddress DNS1    (8,8,8,8);
IPAddress DNS2    (1,1,1,1);

// ===== Pinos (AI-Thinker) =====
#define LED_FLASH_PIN 4
#define PUMP_PIN      14

WebServer server(80);

// ===== Stream / Encoder =====
static const char*   BOUNDARY              = "frame";
static framesize_t   g_framesize           = FRAMESIZE_QVGA; // 320x240
static int           g_jpeg_quality        = 26;             // 18..34 (ajustado dinamicamente)
static const int     STREAM_TARGET_FPS     = 10;
static const uint32_t UART_BAUD            = 115200;

// Thresholds ABR
static const size_t  ABR_BIG_FRAME   = 52000;   // bytes
static const size_t  ABR_SMALL_FRAME = 24000;   // bytes
static const int     Q_MIN = 18;
static const int     Q_MAX = 34;
static const uint32_t SEND_SLOW_MS = 220;

// Timeout/robustez de escrita
static const uint16_t MAX_ZERO_WRITES = 60;     // toler√¢ncia maior
static const uint32_t WRITE_STALL_MS  = 2500;   // se um frame demora al√©m disso, sobe Q e tenta de novo

volatile bool ledOn=false, pumpOn=false;

String localIP() { return WiFi.isConnected() ? WiFi.localIP().toString() : String("0.0.0.0"); }
static inline void feedWDT(){ esp_task_wdt_reset(); yield(); }

static inline void sendCORS(){ server.sendHeader("Access-Control-Allow-Origin","*"); }

// ===== Camera =====
bool initCamera(){
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0; c.ledc_timer = LEDC_TIMER_0;
  c.pin_d0=5;  c.pin_d1=18; c.pin_d2=19; c.pin_d3=21;
  c.pin_d4=36; c.pin_d5=39; c.pin_d6=34; c.pin_d7=35;
  c.pin_xclk=0; c.pin_pclk=22; c.pin_vsync=25; c.pin_href=23;
  c.pin_sscb_sda=26; c.pin_sscb_scl=27;
  c.pin_pwdn=32; c.pin_reset=-1;
  c.xclk_freq_hz=20000000;
  c.pixel_format=PIXFORMAT_JPEG;

  c.frame_size   = g_framesize;
  c.jpeg_quality = g_jpeg_quality;
  c.fb_location  = CAMERA_FB_IN_PSRAM;
  c.fb_count     = psramFound() ? 2 : 1;           // <<< robustez PSRAM
  c.grab_mode    = CAMERA_GRAB_LATEST;             // drop old, keep newest

  esp_err_t err = esp_camera_init(&c);
  if(err!=ESP_OK){
    Serial.printf("Camera init failed: 0x%x\n", err);
    return false;
  }

  sensor_t* s = esp_camera_sensor_get();
  // Setup padr√£o confi√°vel
  s->set_brightness(s,0); s->set_contrast(s,0); s->set_saturation(s,0);
  s->set_whitebal(s,1); s->set_awb_gain(s,1);
  s->set_exposure_ctrl(s,1); s->set_aec2(s,0);
  s->set_gain_ctrl(s,1); s->set_agc_gain(s,0); s->set_gainceiling(s,(gainceiling_t)0);
  s->set_bpc(s,0); s->set_wpc(s,1); s->set_raw_gma(s,1); s->set_lenc(s,1);
  s->set_hmirror(s,0); s->set_vflip(s,0); s->set_dcw(s,1); s->set_colorbar(s,0);

  return true;
}

void maybeDownscaleForMemory() {
  // Fallback para QQVGA se mem√≥ria/PSRAM estiver apertando
  size_t heap = ESP.getFreeHeap();
  size_t ps   = ESP.getFreePsram();
  if ((heap < 80*1024) || (psramFound() && ps < 200*1024)) {
    sensor_t* s = esp_camera_sensor_get();
    g_framesize = FRAMESIZE_QQVGA; // 160x120
    s->set_framesize(s, g_framesize);
    g_jpeg_quality = std::min(Q_MAX, std::max(22, g_jpeg_quality + 4));
    s->set_quality(s, g_jpeg_quality);
  }
}

// ===== Handlers REST =====
void handleStatus(){
  String j="{\"ok\":true,\"ip\":\""+localIP()+"\",\"mode\":\"mjpeg-stream\",\"led\":"+String(ledOn?"true":"false")+
           ",\"pump\":"+String(pumpOn?"true":"false")+",\"heap\":"+String(ESP.getFreeHeap())+
           ",\"psram\":"+String(ESP.getFreePsram())+
           ",\"q\":"+String(g_jpeg_quality)+",\"fs\":"+String((int)g_framesize)+"}";
  sendCORS(); server.send(200,"application/json",j);
}

void handleLed(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !ledOn;
  ledOn = on; digitalWrite(LED_FLASH_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"led\":")+(on?"true":"false")+"}");
}

void handlePump(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !pumpOn;
  pumpOn = on; digitalWrite(PUMP_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"pump\":")+(on?"true":"false")+"}");
}

void handleUART(){
  if(!server.hasArg("line")){ sendCORS(); server.send(400,"application/json","{\"ok\":false,\"err\":\"missing line\"}"); return; }
  Serial.print(server.arg("line")); Serial.print("\n");
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleJoystick(){
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.0f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.0f;
  Serial.printf("JOY:x=%.3f:y=%.3f\n",x,y);
  float mag = sqrtf(x*x+y*y);
  const char* dir="STOP";
  if(mag>=0.2f){
    float deg = atan2f(y,x)*180.0f/3.1415926f;
    if(deg>-45 && deg<=45) dir="RIGHT";
    else if(deg>45 && deg<=135) dir="FWD";
    else if(deg<=-45 && deg>-135) dir="BACK";
    else dir="LEFT";
  }
  int ms =(mag<0.2f)?0:180+int(200*std::min(1.0f,mag));
  int spd=(mag<0.2f)?0: 50+int( 50*std::min(1.0f,mag));
  Serial.printf("CMD:%s:ms=%d:spd=%d\n",dir,ms,spd);
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleSnapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb){ sendCORS(); server.send(503,"text/plain","NO_FRAME"); return; }

  uint8_t* jpg = fb->buf; size_t len = fb->len; bool freeIt=false;
  if(fb->format!=PIXFORMAT_JPEG){
    if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){
      esp_camera_fb_return(fb);
      sendCORS(); server.send(500,"text/plain","ENCODE_FAIL"); return;
    }
    freeIt=true;
  }

  // Cabe√ßalhos + CORS
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache"); server.sendHeader("Expires","0");
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.setContentLength(len);
  server.send(200,"image/jpeg","");

  // Corpo
  WiFiClient cli = server.client();
  const uint8_t* p=jpg; size_t todo=len;
  uint32_t t0 = millis();
  while(todo>0){
    size_t can = cli.availableForWrite();
    if(can==0){
      if(millis()-t0>WRITE_STALL_MS) break; // evita travar se cliente sumiu
      feedWDT(); continue;
    }
    size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
    if(n==0){
      if(millis()-t0>WRITE_STALL_MS) break;
      feedWDT(); continue;
    }
    p+=n; todo-=n; feedWDT();
  }

  if(freeIt) free(jpg);
  esp_camera_fb_return(fb);
}

// ===== MJPEG Stream (robusto) =====
void handleStream(){
  WiFiClient cli = server.client();
  cli.setTimeout(2000);
  cli.setNoDelay(true);

  // Cabe√ßalhos do stream (mant√©m conex√£o viva)
  cli.print(
    "HTTP/1.1 200 OK\r\n"
    "Cache-Control: no-cache, no-store, must-revalidate\r\n"
    "Pragma: no-cache\r\n"
    "Expires: 0\r\n"
    "Access-Control-Allow-Origin: *\r\n"
    "Connection: keep-alive\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=frame\r\n\r\n"
  );

  const uint64_t minIv = 1000000ULL/STREAM_TARGET_FPS;
  uint64_t last=0;
  uint16_t zeroWrites=0;
  sensor_t* s = esp_camera_sensor_get();

  while(cli.connected()){
    uint64_t now=(uint64_t)esp_timer_get_time();
    if(now-last<minIv){ feedWDT(); continue; }

    camera_fb_t* fb = esp_camera_fb_get();
    if(!fb){ maybeDownscaleForMemory(); feedWDT(); continue; }

    uint8_t* jpg=fb->buf; size_t len=fb->len; bool freeIt=false;
    if(fb->format!=PIXFORMAT_JPEG){
      if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){
        esp_camera_fb_return(fb); feedWDT(); continue;
      }
      freeIt=true;
    }

    // Parte do MJPEG
    cli.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n",BOUNDARY,(unsigned)len);

    const uint8_t* p=jpg; size_t todo=len;
    uint32_t t0 = millis();
    zeroWrites = 0;

    while(todo>0 && cli.connected()){
      size_t can = cli.availableForWrite();
      if(can==0){
        zeroWrites++;
        if(zeroWrites>MAX_ZERO_WRITES || millis()-t0>WRITE_STALL_MS) break; // cliente lento ou travado
        feedWDT(); continue;
      }
      size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
      if(n==0){
        zeroWrites++;
        if(zeroWrites>MAX_ZERO_WRITES || millis()-t0>WRITE_STALL_MS) break;
        feedWDT(); continue;
      }
      zeroWrites = 0;
      p+=n; todo-=n; feedWDT();
    }
    cli.print("\r\n");

    if(freeIt) free(jpg);
    esp_camera_fb_return(fb);
    last=(uint64_t)esp_timer_get_time();

    // ABR: ajusta qualidade baseado no tamanho/tempo
    uint32_t dt = millis() - t0;
    bool slow = (dt > SEND_SLOW_MS);
    if(todo==0){
      if(len > ABR_BIG_FRAME || slow){
        g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 2);
        s->set_quality(s, g_jpeg_quality);
      }else if(len < ABR_SMALL_FRAME && !slow){
        g_jpeg_quality = std::max(Q_MIN, g_jpeg_quality - 1);
        s->set_quality(s, g_jpeg_quality);
      }
    }else{
      // n√£o conseguiu mandar todo o frame -> aumenta Q e tenta de novo no pr√≥ximo loop
      g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 3);
      s->set_quality(s, g_jpeg_quality);
      // quebra para reiniciar cabe√ßalhos da pr√≥xima conex√£o do cliente
      break;
    }

    maybeDownscaleForMemory();
    feedWDT();
  }
  cli.stop();
}

// ===== WiFi =====
void connectWiFi(){
  WiFi.persistent(false);
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  if(!WiFi.config(LOCAL_IP, GATEWAY, SUBNET, DNS1, DNS2)){
    Serial.println("WiFi.config failed; falling back to DHCP");
  }
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0=millis(); while(WiFi.status()!=WL_CONNECTED && millis()-t0<20000UL){ delay(200); }
}

void ensureWiFi(){
  static unsigned long last=0; unsigned long now=millis(); if(now-last<2000) return; last=now;
  if(WiFi.status()!=WL_CONNECTED){ WiFi.disconnect(true,true); delay(100); connectWiFi(); }
}

// ===== Setup / Loop =====
void setup(){
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  pinMode(LED_FLASH_PIN,OUTPUT); digitalWrite(LED_FLASH_PIN,LOW);
  pinMode(PUMP_PIN,OUTPUT);      digitalWrite(PUMP_PIN,LOW);
  setCpuFrequencyMhz(160);
  Serial.begin(UART_BAUD); delay(200);

#if ESP_IDF_VERSION_MAJOR >= 5
  const esp_task_wdt_config_t cfg = { .timeout_ms = 8000, .idle_core_mask = (1<<portNUM_PROCESSORS)-1, .trigger_panic = true };
  esp_task_wdt_init(&cfg);
#else
  esp_task_wdt_init(8,true);
#endif
  esp_task_wdt_add(NULL);

  if(!initCamera()){
    delay(500);
    ESP.restart();
  }
  connectWiFi();

  server.on("/status",   HTTP_GET, handleStatus);
  server.on("/led",      HTTP_GET, handleLed);
  server.on("/pump",     HTTP_GET, handlePump);
  server.on("/uart",     HTTP_GET, handleUART);
  server.on("/joystick", HTTP_GET, handleJoystick);
  server.on("/stream",   HTTP_GET, handleStream);
  server.on("/snapshot", HTTP_GET, handleSnapshot);
  server.on("/jpg",      HTTP_GET, handleSnapshot);
  server.on("/", HTTP_GET, [](){
    sendCORS();
    server.send(200,"text/plain",
      "HydroBot ESP32-CAM OK\n/stream, /snapshot, /jpg, /status, /led, /pump, /joystick, /uart");
  });

  server.begin();
}

void loop(){
  server.handleClient();
  ensureWiFi();
  feedWDT();
}



O que isso corrige na pr√°tica:




Stream MJPEG agora permanece aberto (keep-alive) e tolera clientes lentos sem matar a conex√£o imediatamente.


Envio de partes do MJPEG ficou mais est√°vel (timeouts maiores e detec√ß√£o de ‚Äúwrite estagnado‚Äù).


/snapshot envia com CORS e evita travar se o cliente parar de ler no meio.


Se a mem√≥ria ficar curta, a c√¢mera reduz a resolu√ß√£o automaticamente e aumenta o jpeg_quality para manter estabilidade ‚Äî melhor quando voc√™ aponta para cenas ‚Äúpesadas‚Äù (muito detalhe).




Teste direto:




Direto no app (modo DIRECT): http://192.168.3.3/stream


Servidor (modo SERVER): http://192.168.3.4:8000/snapshot (ele puxa do ESP em /snapshot)




Se ainda n√£o aparecer imagem, confirme:




Celular e ESP no mesmo Wi-Fi (sub-rede 192.168.3.x).


Abra no navegador do celular: http://192.168.3.3/ (deve mostrar a mensagem ‚ÄúHydroBot ESP32-CAM OK‚Äù).


Depois abra http://192.168.3.3/snapshot e http://192.168.3.3/stream.




Me diga o resultado e, se precisar, ajusto os par√¢metros (framesize/quality) para o seu roteador.








































// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet, PanResponder,
  GestureResponderEvent, PanResponderGestureState, Image, Animated,
  LayoutChangeEvent, AppState,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

/* ---------- PALETA ---------- */
const PALETTE = { bg: "#0b0b0f", card: "#121218", border: "#25273a", accent: "#e6403a", text: "#e5e7eb" };

/* ---------- TEXTOS ---------- */
const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:", test: "Testar", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "BOMBA ON", pumpOff: "BOMBA OFF", server: "Servidor:",
    detecting: "Detectando‚Ä¶", saving: "Salvando...", statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Pessoas", animals: "Animais", backend: "Modelo",
    waiting: "Aguardando servidor‚Ä¶", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:", test: "Test", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "PUMP ON", pumpOff: "PUMP OFF", server: "Server:",
    detecting: "Detecting‚Ä¶", saving: "Saving...", statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "People", animals: "Animals", backend: "Model",
    waiting: "Waiting for server‚Ä¶", synced: "Server sync OK",
    mode: "Mode", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:", test: "Probar", ledOn: "LED ENC.", ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.", pumpOff: "BOMBA APAG.", server: "Servidor:",
    detecting: "Detectando‚Ä¶", saving: "Guardando...", statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Personas", animals: "Animales", backend: "Modelo",
    waiting: "Esperando servidor‚Ä¶", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECTO",
  },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 640, h: 480 };

const appLogo = require("../../assets/logo.png");

/* ---------- HERO ---------- */
function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

/* ---------- SNAPSHOT com crossfade ---------- */
function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 100, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

/* ---------- OVERLAY ---------- */
type BoxType = "fire" | "person" | "animal";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType; conf?: number; };

function BoxesOverlay({
  frameWH, containerWH, boxes,
}: { frameWH: { w: number; h: number } | null; containerWH: { w: number; h: number } | null; boxes: SrcBox[]; }) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale, top = b.y * scale, width = b.w * scale, height = b.h * scale;
          let borderColor = "#ff3b30"; if (b.type === "person") borderColor = "#00e5ff"; else if (b.type === "animal") borderColor = "#7CFC00";
          return (
            <View key={`${i}-${b.type}`} style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor, borderRadius: 6 }}>
              <View style={{ position: "absolute", left: 0, top: -18, paddingHorizontal: 6, paddingVertical: 2, borderRadius: 4, backgroundColor: borderColor }}>
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>
                  {b.type.toUpperCase()}{typeof b.conf === "number" ? ` ${b.conf.toFixed(2)}` : ""}
                </Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

/* ---------- TELA PRINCIPAL ---------- */
type Mode = "auto" | "server" | "direct";

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conex√µes
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState(T.waiting);
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detec√ß√£o (server)
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("‚Äî");
  const [confMax, setConfMax] = useState<number>(0);

  // caixas + dimens√µes
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  // registro autom√°tico
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // SNAPSHOT (server)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // health/mode
  const [serverReady, setServerReady] = useState(false);
  const [mode, setMode] = useState<Mode>("auto");

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);
  const detectUrl = useMemo(() => `${cleanServer(server)}/detect`, [server]);
  const snapshotUrl = useMemo(() => `${cleanServer(server)}/snapshot`, [server]);
  const configUrl = useMemo(() => `${cleanServer(server)}/config`, [server]);
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const joystickUrl = useMemo(() => (x: number, y: number) => `http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`, [ip]);
  const uartUrl = useMemo(() => (line: string) => `http://${ip}/uart?line=${encodeURIComponent(line)}`, [ip]);
  const directStreamHtml = useMemo(
    () => `<html><head><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
      <style>html,body{margin:0;background:#000;height:100%}img{width:100%;height:100%;object-fit:contain;}</style></head>
      <body><img src="http://${ip}/stream" /></body></html>`,
    [ip]
  );

  /* ===== AppState ===== */
  const appStateRef = useRef(AppState.currentState);
  useEffect(() => {
    const sub = AppState.addEventListener("change", (s) => { appStateRef.current = s; });
    return () => sub.remove();
  }, []);

  /* ===== Sincroniza IP do ESP dentro do server ===== */
  useEffect(() => {
    let aborted = false;
    (async () => {
      try {
        const r = await fetch(configUrl, { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ camera_ip: ip }) });
        const j = await r.json();
        if (!aborted && j?.ok) setStatusText(T.synced + ` (${j.camera_ip})`);
      } catch { if (!aborted) setStatusText(T.statusFail); }
    })();
    return () => { aborted = true; };
  }, [ip, configUrl, T]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led); setPumpOn(!!j.pump);
      setStatusText(`OK ‚Ä¢ ip:${j.ip ?? ip} ‚Ä¢ mode:${j.mode ?? "‚Äî"} ‚Ä¢ led:${j.led ? "on" : "off"} ‚Ä¢ pump:${j.pump ? "on" : "off"}`);
    } catch { setStatusText(T.statusFail); }
    finally { setIsChecking(false); }
  }
  async function toggleLed() { try { const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t); } catch { setStatusText(T.statusFail); } }
  async function togglePump(){ try { const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); } catch { setStatusText(T.statusFail); } }
  useEffect(() => { pingStatus(); const id = setInterval(pingStatus, 5000); return () => clearInterval(id); }, [statusUrl]);

  /* ===== HEALTH-CHECK DO SERVIDOR ===== */
  useEffect(() => {
    let stop = false;
    let backoff = 600, fail = 0;
    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl);
        const j = await r.json();
        const ok = !!j?.ok && !!j?.hasFrame;
        setServerReady(ok);
        setStatusText(ok ? `Server OK ‚Ä¢ hasFrame:${j.hasFrame}` : T.waiting);
        fail = ok ? 0 : fail + 1;
      } catch { fail++; setServerReady(false); setStatusText(T.waiting); }
      if (mode === "auto" && fail >= 3) setStatusText("Falha no servidor ‚Ä¢ alternando para DIRECT");
      setTimeout(poll, Math.min((backoff *= 1.35), 5000));
    };
    poll(); return () => { stop = true; };
  }, [healthUrl, mode, T]);

  /* ===== SNAPSHOT LOOP (pull do servidor) ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    let stop = false;
    let interval = 110; // ~9 fps (equil√≠brio /snapshot)

    setCurrentFrameUri(`${snapshotUrl}?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!loadingNextRef.current) setNextFrameUri(`${snapshotUrl}?ts=${Date.now()}`);
        interval = 110;
      } catch { interval = Math.min(interval * 1.6, 1200); }
      setTimeout(tick, interval);
    };
    tick();
    return () => { stop = true; };
  }, [snapshotUrl, serverReady, mode]);

  function onNextLoadStart(){ loadingNextRef.current = true; }
  function onNextShown(ok: boolean){ if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri); loadingNextRef.current = false; }

  /* ===== DETEC√á√ÉO ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;

    let stop = false;
    let interval = 200;
    const controller = new AbortController();

    const loop = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        const r = await fetch(detectUrl, { signal: controller.signal });
        const j = await r.json();
        if (j && j.ok !== false) {
          setIsFire(!!j.isFire); setFireScore(Number(j.score || 0));

          const wh = Array.isArray(j.frame_wh) && j.frame_wh.length === 2 ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 } : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);

          const o = j.objects || {}; const objs = o.objects || [];
          const nPerson = typeof o.n_person_stable === "number" ? o.n_person_stable : (typeof o.n_person === "number" ? o.n_person : objs.filter((x: any) => String(x.label).toLowerCase() === "person").length);
          const nAnimals = typeof o.n_animals_stable === "number" ? o.n_animals_stable : (typeof o.n_animals === "number" ? o.n_animals : objs.filter((x: any) => String(x.label).toLowerCase() !== "person").length);

          setPeople(nPerson || 0); setAnimals(nAnimals || 0);
          setBackend(o.backend || "‚Äî"); setConfMax(Number(o.conf_max || 0));

          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) { if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0); boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          for (const it of objs) {
            if (!it || !Array.isArray(it.box) || it.box.length < 4) continue;
            const [x, y, w, h] = it.box.map((n: any) => Number(n) || 0);
            const label = String(it.label || "").toLowerCase(); const conf = typeof it.conf === "number" ? it.conf : undefined;
            if (label === "person") boxes.push({ x, y, w, h, type: "person", conf }); else boxes.push({ x, y, w, h, type: "animal", conf });
          }
          setOverlayBoxes(boxes);
          interval = 200;
        }
      } catch {
        setIsFire(false); setFireScore(0); setPeople(0); setAnimals(0); setOverlayBoxes([]);
        interval = Math.min(interval * 1.6, 1500);
      } finally { setTimeout(loop, interval); }
    };
    loop();
    return () => { stop = true; controller.abort(); };
  }, [detectUrl, serverReady, mode]);

  /* ===== Registro autom√°tico ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;
    if (rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch { setStatusText(T.noVideo); } finally { setSaving(false); }
      })();
    }
    wasFireRef.current = isFire;
  }, [isFire, server, saving, T, serverReady, mode]);

  /* ===== Joystick ===== */
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(PanResponder.create({
    onStartShouldSetPanResponder: () => true,
    onMoveShouldSetPanResponder: () => true,
    onPanResponderGrant: () => setDragging(true),
    onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
      let nx = g.dx / RADIUS, ny = g.dy / RADIUS; const len = Math.hypot(nx, ny);
      if (len > 1) { nx /= len; ny /= len; } setJoy({ x: nx, y: -ny });
    },
    onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
  })).current;

  const lastSendRef = useRef(0); const lastDirRef = useRef<string>("STOP");
  const trySendJoystick = async (x: number, y: number) => { try { await fetch(joystickUrl(x, y)); return true; } catch { return false; } };
  const sendDiscreteCmd = async (dir: "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP", ms = 180, spd = 70) => {
    const line = dir === "STOP" ? "CMD:STOP"
      : `CMD:${dir}:ms=${Math.max(80, Math.min(ms, 600))}:spd=${Math.max(30, Math.min(spd, 100))}`;
    try { await fetch(uartUrl(line)); return true; } catch { return false; }
  };
  const vecToDir = (x: number, y: number): "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP" => {
    const mag = Math.hypot(x, y); if (mag < 0.2) return "STOP";
    const deg = (Math.atan2(y, x) * 180) / Math.PI;
    if (deg > -45 && deg <= 45) return "RIGHT"; if (deg > 45 && deg <= 135) return "FWD";
    if (deg <= -45 && deg > -135) return "BACK"; return "LEFT";
  };

  useEffect(() => {
    let cancelled = false;
    const tick = async () => {
      if (cancelled) return;
      const now = Date.now(); if (now - lastSendRef.current < 120) { setTimeout(tick, 20); return; }
      lastSendRef.current = now;
      const { x, y } = joy; const mag = Math.hypot(x, y);
      const ok = await trySendJoystick(x, y);
      if (ok) {
        if (mag < 0.2 && lastDirRef.current !== "STOP") { await sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; }
        setTimeout(tick, 120); return;
      }
      const dir = vecToDir(x, y);
      if (dir !== lastDirRef.current) {
        const ms = 140 + Math.round(260 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd); lastDirRef.current = dir;
      } else if (dir !== "STOP") {
        const ms = 120 + Math.round(200 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd);
      }
      setTimeout(tick, 120);
    };
    if (AppState.currentState === "active") tick();
    return () => { cancelled = true; };
  }, [joy, ip]);

  useEffect(() => {
    const handleBg = (s: string) => { if (s !== "active") { sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; } };
    const sub = AppState.addEventListener("change", handleBg);
    return () => sub.remove();
  }, []);

  function onVideoLayout(e: LayoutChangeEvent) { const { width, height } = e.nativeEvent.layout; setVideoContainerWH({ w: width, h: height }); }

  const usingServer = (mode === "server") || (mode === "auto" && serverReady);
  const usingDirect = (mode === "direct") || (mode === "auto" && !serverReady);

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Pressable onPress={pingStatus} style={styles.btn}><Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text></Pressable>
        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text></Pressable>
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text></Pressable>
      </View>

      {/* Linha: Servidor + Modo */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => { setServer(s); setServerReady(false); setStatusText(T.waiting); }}
          placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Text style={styles.label}>{T.mode}</Text>
        <View style={{ flexDirection: "row", gap: 6 }}>
          <Pressable onPress={() => setMode("auto")} style={[styles.modeBtn, mode === "auto" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeAuto}</Text></Pressable>
          <Pressable onPress={() => setMode("server")} style={[styles.modeBtn, mode === "server" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeServer}</Text></Pressable>
          <Pressable onPress={() => setMode("direct")} style={[styles.modeBtn, mode === "direct" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeDirect}</Text></Pressable>
        </View>
        <View style={[styles.badge, { backgroundColor: usingServer ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>{usingServer ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
      </View>

      {/* Banner de fogo (apenas server) */}
      {usingServer && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
        </View>
      )}

      {/* Pessoas/animais */}
      {usingServer && (
        <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
          <Text style={styles.statChip}>{T.persons}: <Text style={styles.statNumber}>{people}</Text></Text>
          <Text style={styles.statChip}>{T.animals}: <Text style={styles.statNumber}>{animals}</Text></Text>
          <Text style={styles.modelChip}>{T.backend}: {backend} ‚Ä¢ conf_max {confMax.toFixed(2)}</Text>
        </View>
      )}

      {/* V√≠deo */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        {usingServer ? (
          <>
            <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri} onNextLoadStart={onNextLoadStart} onNextShown={onNextShown} />
            {overlayBoxes.length > 0 && (<BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />)}
          </>
        ) : (
          <WebView originWhitelist={["*"]} source={{ html: directStreamHtml, baseUrl: `http://${ip}/` }}
            allowsInlineMediaPlayback mediaPlaybackRequiresUserAction={false} javaScriptEnabled domStorageEnabled
            setSupportMultipleWindows={false} overScrollMode="never" style={{ backgroundColor: "black" }}
          />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View style={[styles.joyKnob, { width: 22 * 2, height: 22 * 2, borderRadius: 22, transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }], opacity: dragging ? 1 : 0.9 }]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

/* ---------- ESTILOS ---------- */
const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },
  topbar: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 10, gap: 8, backgroundColor: PALETTE.card, borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: { backgroundColor: "#0b0d14", color: "white", borderRadius: 8, paddingHorizontal: 10, paddingVertical: 8, borderWidth: 1, borderColor: PALETTE.border, minWidth: 110 },
  btn: { backgroundColor: PALETTE.accent, paddingHorizontal: 10, paddingVertical: 10, borderRadius: 10 },
  btnOn: { backgroundColor: "#17a34a" }, btnOff: { backgroundColor: "#374151" }, btnText: { color: "white", fontWeight: "600" },
  statusRow: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 8, gap: 8, backgroundColor: "#0f1322", borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  badge: { paddingHorizontal: 10, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: PALETTE.border },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },
  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 }, fireOn: { backgroundColor: "#8b0000" }, fireOff: { backgroundColor: "#223" }, fireText: { color: "white", fontWeight: "800" },
  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" }, statNumber: { color: "#fff" }, modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(230,64,58,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
  modeBtn: { backgroundColor: "#1f2937", paddingHorizontal: 8, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: "#334155" },
  modeBtnActive: { backgroundColor: "#0b5", borderColor: "#0b5" },
  modeText: { color: "#fff", fontWeight: "700", fontSize: 12 },
});







# server_heuristic.py
# FOGO (heur√≠stico) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny) usando "pull snapshot" do ESP
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== CONFIG DA C√ÇMERA =====================
CAMERA_IP = "192.168.3.3"               # IP do ESP no roteador
SNAP_URLS = [                           # tentativas em ordem
    "http://{ip}/snapshot",
    "http://{ip}/jpg",
]
STATUS_URL = "http://{ip}/status"

# Robustez
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 5.0
JPEG_QUALITY = 85

# ===================== FOGO (heur√≠stico) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 12.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 2500
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 10.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}

YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (Snapshot Pull)", version="2.0.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== FONTE DE FRAMES (pull) =====================
class SnapshotSource:
    """Busca JPEGs sob demanda do ESP e mant√©m cache curto."""
    def __init__(self, ip: str):
        self._lock = threading.Lock()
        self.ip = ip
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._session = requests.Session()
        self._last_err = ""

    def set_ip(self, ip: str):
        with self._lock:
            self.ip = ip
            self._last_jpeg = None
            self._last_ts_ms = 0

    def _fetch_once(self) -> Optional[bytes]:
        for fmt in SNAP_URLS:
            url = fmt.format(ip=self.ip)
            try:
                r = self._session.get(url, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT))
                if r.status_code == 200 and r.headers.get("Content-Type","").startswith("image/"):
                    return r.content
            except Exception as e:
                self._last_err = f"{type(e).__name__} on {url}"
        return None

    def fetch_fresh(self) -> Optional[bytes]:
        """Busca um frame novo e atualiza cache."""
        jpeg = self._fetch_once()
        ts_ms = int(time.time()*1000)
        with self._lock:
            if jpeg:
                self._last_jpeg = jpeg
                self._last_ts_ms = ts_ms
                self._last_err = ""
            return self._last_jpeg

    def get_recent_or_fetch(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        """Retorna frame recente; se velho/ausente, tenta buscar."""
        with self._lock:
            has_recent = self._last_jpeg is not None and (int(time.time()*1000)-self._last_ts_ms)<=max_age_ms
            jpeg = self._last_jpeg if has_recent else None
        if jpeg is not None:
            return jpeg
        return self.fetch_fresh()

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = (int(time.time()*1000)-self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self.ip, "hasFrame": self._last_jpeg is not None, "age_ms": age, "last_err": self._last_err}

src = SnapshotSource(CAMERA_IP)

# ===================== VIS√ÉO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area: boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, source: SnapshotSource):
        self.src = source
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0
        self._last_frame_wh: Tuple[int,int] = (0,0)

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_recent_or_fetch()
            if jpeg is None: time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.01); continue
            H,W = frame.shape[:2]
            self._last_frame_wh = (W,H)

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else: self._persist_hits = 1
            else: self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
            elif ema<=HYST_LOW: guess=0
            else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)
                self._det_frames+=1
                now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval: time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema,3),
                "score_raw": round(self._score_raw,3),
                "score_ema": round(self._score_ema,3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps,2),
                "vote": {"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                "persist": {"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                "hyst": {"hi":HYST_HIGH,"lo":HYST_LOW},
                "frame_wh": list(self._last_frame_wh) if self._last_frame_wh else None,
            }

detector = Detector(src); detector.start()

# ===================== OBJETOS =====================
class ObjectsDetector:
    def __init__(self, source: SnapshotSource):
        self.src = source
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None; self.ok = False
        self.proto = None; self.weights = None; self.cfg = None; self.names = None
        self.labels = []
        self.swap_rb = False
        self._nohit = 0
        self._last_conf_max = 0.0

        self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
        self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
        self.hold_person_until = 0
        self.hold_animal_until = 0

        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        cands_p = [
            "./models/MobileNetSSD_deploy.prototxt",
            "./models/MobileNetSSD_deploy.prototxt.txt",
            "./models/deploy.prototxt",
            "./models/voc/MobileNetSSD_test.prototxt",
        ]
        cands_w = [
            "./models/MobileNetSSD_deploy.caffemodel",
            "./models/mobilenet_iter_73000.caffemodel",
        ]
        self.proto = next((p for p in cands_p if os.path.exists(p)), None)
        self.weights = next((w for w in cands_w if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok = False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok = False; self.net=None

    def _try_load_yolo(self):
        self.backend = "yolov4-tiny"
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,(300,300)),
                                     0.007843, (300,300), 127.5, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in {"person","cat","dog","bird","horse","sheep","cow"}: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = src.get_recent_or_fetch()
            if jpeg is None: time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.01); continue

            out=[]; cmax=0.0; backend=self.backend
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False
                    with self._lock:
                        self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                                    "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            n_person  = sum(1 for o in out if o["label"]=="person")
            n_animals = sum(1 for o in out if o["label"]!="person")
            hit_person  = 1 if n_person  > 0 else 0
            hit_animal  = 1 if n_animals > 0 else 0
            self.votes_person.append(hit_person)
            self.votes_animal.append(hit_animal)
            now_ms = int(time.time()*1000)
            if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
            if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
            stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
            stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                            "n_person":n_person,"n_animals":n_animals,
                            "n_person_stable":1 if stable_person else 0,
                            "n_animals_stable":1 if stable_animal else 0}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(src); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/healthz")
def healthz():
    # se h√° frame recente, ok; sen√£o tenta um fetch r√°pido
    st = src.status()
    if not st["hasFrame"] or (st["age_ms"] is None or st["age_ms"]>MAX_FRAME_AGE_MS):
        src.fetch_fresh()
        st = src.status()
    # tenta tamb√©m /status do ESP (n√£o bloqueia o OK do frame)
    esp_info = {}
    try:
        r = requests.get(STATUS_URL.format(ip=src.ip), timeout=(1.5, 2.0))
        if r.ok: esp_info = r.json()
    except Exception:
        pass
    return {"ok": True, "hasFrame": bool(st["hasFrame"]), "age_ms": st["age_ms"], "esp": esp_info}

@app.get("/status")
def status():
    s2 = detector.get_result()
    st = src.status()
    return {"ok": True, "camera_ip": st["ip"], "hasFrame": st["hasFrame"], "age_ms": st["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    src.set_ip(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = src.get_recent_or_fetch(MAX_FRAME_AGE_MS)
    if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res

    # c√°lculo r√°pido em modo fallback
    jpeg = src.get_recent_or_fetch(MAX_FRAME_AGE_MS)
    if jpeg is None: return {"ok": False, "error": "no frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return {"ok": False, "error": "decode failed"}
    H,W = frame.shape[:2]
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "frame_wh":[W,H],
            "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = src.get_recent_or_fetch(MAX_FRAME_AGE_MS)
    if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get(); backend = o.get("backend"); det = objects_det
    try:
        if backend=="yolov4-tiny":
            # usa conf recebido
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, float(conf))))
        else:
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, float(conf))))
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_stream")
def debug_stream():
    return src.status()















// HydroBot ESP32-CAM - Stable (fixed IP) - ASCII only
// Endpoints: /status /led /pump /joystick /uart /stream /snapshot (/jpg)
// Key: fb_count=2 + CAMERA_GRAB_LATEST, adaptive JPEG quality, no Nagle, non-blocking writes.

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "esp_task_wdt.h"
#include "esp_idf_version.h"
#include <math.h>
#include <algorithm>

// WiFi (static IP)
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";
IPAddress LOCAL_IP(192,168,3,3);
IPAddress GATEWAY (192,168,3,1);
IPAddress SUBNET  (255,255,255,0);
IPAddress DNS1    (8,8,8,8);
IPAddress DNS2    (1,1,1,1);

// Pins (AI-Thinker)
#define LED_FLASH_PIN 4
#define PUMP_PIN      14

WebServer server(80);

// Stream params
static const char*   BOUNDARY              = "frame";
static const framesize_t STREAM_FRAMESIZE  = FRAMESIZE_QVGA; // 320x240
static int           g_jpeg_quality        = 26;             // 18..34 adaptive
static const int     STREAM_TARGET_FPS     = 10;
static const uint32_t UART_BAUD            = 115200;

// ABR thresholds
static const size_t  ABR_BIG_FRAME   = 52000;   // bytes
static const size_t  ABR_SMALL_FRAME = 24000;   // bytes
static const int     Q_MIN = 18;
static const int     Q_MAX = 34;
static const uint32_t SEND_SLOW_MS = 220;

volatile bool ledOn=false, pumpOn=false;

String localIP() { return WiFi.isConnected() ? WiFi.localIP().toString() : String("0.0.0.0"); }
static inline void feedWDT(){ esp_task_wdt_reset(); yield(); }

// Camera init
bool initCamera(){
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0; c.ledc_timer = LEDC_TIMER_0;
  c.pin_d0=5;  c.pin_d1=18; c.pin_d2=19; c.pin_d3=21; c.pin_d4=36; c.pin_d5=39; c.pin_d6=34; c.pin_d7=35;
  c.pin_xclk=0; c.pin_pclk=22; c.pin_vsync=25; c.pin_href=23;
  c.pin_sscb_sda=26; c.pin_sscb_scl=27;
  c.pin_pwdn=32; c.pin_reset=-1;
  c.xclk_freq_hz=20000000;
  c.pixel_format=PIXFORMAT_JPEG;

  c.frame_size   = STREAM_FRAMESIZE;
  c.jpeg_quality = g_jpeg_quality;
  c.fb_count     = 2;                        // double buffer
  c.fb_location  = CAMERA_FB_IN_PSRAM;
  c.grab_mode    = CAMERA_GRAB_LATEST;       // drop old, keep newest

  esp_err_t err = esp_camera_init(&c);
  if(err!=ESP_OK){ Serial.printf("Camera init failed: 0x%x\n", err); return false; }

  sensor_t* s = esp_camera_sensor_get();
  s->set_brightness(s,0); s->set_contrast(s,0); s->set_saturation(s,0);
  s->set_whitebal(s,1); s->set_awb_gain(s,1);
  s->set_exposure_ctrl(s,1); s->set_aec2(s,0);
  s->set_gain_ctrl(s,1); s->set_agc_gain(s,0); s->set_gainceiling(s,(gainceiling_t)0);
  s->set_bpc(s,0); s->set_wpc(s,1); s->set_raw_gma(s,1); s->set_lenc(s,1);
  s->set_hmirror(s,0); s->set_vflip(s,0); s->set_dcw(s,1); s->set_colorbar(s,0);
  return true;
}

static inline void sendCORS(){ server.sendHeader("Access-Control-Allow-Origin","*"); }

void handleStatus(){
  String j="{\"ok\":true,\"ip\":\""+localIP()+"\",\"mode\":\"mjpeg-stream\",\"led\":"+String(ledOn?"true":"false")+
           ",\"pump\":"+String(pumpOn?"true":"false")+",\"heap\":"+String(ESP.getFreeHeap())+
           ",\"q\":"+String(g_jpeg_quality)+"}";
  sendCORS(); server.send(200,"application/json",j);
}

void handleLed(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !ledOn;
  ledOn = on; digitalWrite(LED_FLASH_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"led\":")+(on?"true":"false")+"}");
}

void handlePump(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !pumpOn;
  pumpOn = on; digitalWrite(PUMP_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"pump\":")+(on?"true":"false")+"}");
}

void handleUART(){
  if(!server.hasArg("line")){ server.send(400,"application/json","{\"ok\":false,\"err\":\"missing line\"}"); return; }
  Serial.print(server.arg("line")); Serial.print("\n");
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleJoystick(){
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.0f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.0f;
  Serial.printf("JOY:x=%.3f:y=%.3f\n",x,y);
  float mag = sqrtf(x*x+y*y);
  const char* dir="STOP";
  if(mag>=0.2f){
    float deg = atan2f(y,x)*180.0f/3.1415926f;
    if(deg>-45 && deg<=45) dir="RIGHT";
    else if(deg>45 && deg<=135) dir="FWD";
    else if(deg<=-45 && deg>-135) dir="BACK";
    else dir="LEFT";
  }
  int ms=(mag<0.2f)?0:180+int(200*std::min(1.0f,mag));
  int spd=(mag<0.2f)?0: 50+int( 50*std::min(1.0f,mag));
  Serial.printf("CMD:%s:ms=%d:spd=%d\n",dir,ms,spd);
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleSnapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb){ server.send(503,"text/plain","NO_FRAME"); return; }
  uint8_t* jpg = fb->buf; size_t len = fb->len; bool freeIt=false;
  if(fb->format!=PIXFORMAT_JPEG){
    if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){ esp_camera_fb_return(fb); server.send(500,"text/plain","ENCODE_FAIL"); return; }
    freeIt=true;
  }
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache"); server.sendHeader("Expires","0");
  server.setContentLength(len); server.send(200,"image/jpeg","");
  WiFiClient cli = server.client(); const uint8_t* p=jpg; size_t todo=len;
  while(todo>0){
    size_t can = cli.availableForWrite();
    if(can==0){ feedWDT(); continue; }
    size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
    if(n==0){ feedWDT(); continue; }
    p+=n; todo-=n; feedWDT();
  }
  if(freeIt) free(jpg); esp_camera_fb_return(fb);
}

void handleStream(){
  WiFiClient cli = server.client();
  cli.setTimeout(2000);
  cli.setNoDelay(true);
  cli.print(
    "HTTP/1.1 200 OK\r\n"
    "Cache-Control: no-cache, no-store, must-revalidate\r\n"
    "Pragma: no-cache\r\n"
    "Expires: 0\r\n"
    "Connection: close\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=frame\r\n\r\n"
  );

  const uint64_t minIv = 1000000ULL/STREAM_TARGET_FPS;
  uint64_t last=0;
  uint8_t zeroWrites=0;
  sensor_t* s = esp_camera_sensor_get();

  while(cli.connected()){
    uint64_t now=(uint64_t)esp_timer_get_time();
    if(now-last<minIv){ feedWDT(); continue; }

    camera_fb_t* fb = esp_camera_fb_get();
    if(!fb){ feedWDT(); continue; }

    uint8_t* jpg=fb->buf; size_t len=fb->len; bool freeIt=false;
    if(fb->format!=PIXFORMAT_JPEG){
      if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){ esp_camera_fb_return(fb); feedWDT(); continue; }
      freeIt=true;
    }

    cli.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n",BOUNDARY,(unsigned)len);

    uint32_t t0 = millis();
    const uint8_t* p=jpg; size_t todo=len;
    zeroWrites = 0;

    while(todo>0){
      size_t can = cli.availableForWrite();
      if(can==0){
        zeroWrites++;
        if(zeroWrites>40){ break; }
        feedWDT(); continue;
      }
      size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
      if(n==0){
        zeroWrites++;
        if(zeroWrites>40) break;
        feedWDT(); continue;
      }
      zeroWrites = 0;
      p+=n; todo-=n;
      feedWDT();
    }
    cli.print("\r\n");

    if(freeIt) free(jpg);
    esp_camera_fb_return(fb);
    last=(uint64_t)esp_timer_get_time();

    // ABR: adjust quality based on size and send time
    uint32_t dt = millis() - t0;
    bool slow = (dt > SEND_SLOW_MS);
    if(todo==0){
      if(len > ABR_BIG_FRAME || slow){
        g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 2);
        s->set_quality(s, g_jpeg_quality);
      }else if(len < ABR_SMALL_FRAME && !slow){
        g_jpeg_quality = std::max(Q_MIN, g_jpeg_quality - 1);
        s->set_quality(s, g_jpeg_quality);
      }
    }else{
      g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 3);
      s->set_quality(s, g_jpeg_quality);
      break;
    }

    if(!cli.connected()) break;
    feedWDT();
  }
  cli.stop();
}

// WiFi
void connectWiFi(){
  WiFi.persistent(false);
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  if(!WiFi.config(LOCAL_IP, GATEWAY, SUBNET, DNS1, DNS2)){
    Serial.println("WiFi.config failed; falling back to DHCP");
  }
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0=millis(); while(WiFi.status()!=WL_CONNECTED && millis()-t0<20000UL){ delay(200); }
}

void ensureWiFi(){
  static unsigned long last=0; unsigned long now=millis(); if(now-last<2000) return; last=now;
  if(WiFi.status()!=WL_CONNECTED){ WiFi.disconnect(true,true); delay(100); connectWiFi(); }
}

// Setup / Loop
void setup(){
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  pinMode(LED_FLASH_PIN,OUTPUT); digitalWrite(LED_FLASH_PIN,LOW);
  pinMode(PUMP_PIN,OUTPUT);      digitalWrite(PUMP_PIN,LOW);
  setCpuFrequencyMhz(160);
  Serial.begin(UART_BAUD); delay(200);

#if ESP_IDF_VERSION_MAJOR >= 5
  const esp_task_wdt_config_t cfg = { .timeout_ms = 8000, .idle_core_mask = (1<<portNUM_PROCESSORS)-1, .trigger_panic = true };
  esp_task_wdt_init(&cfg);
#else
  esp_task_wdt_init(8,true);
#endif
  esp_task_wdt_add(NULL);

  if(!initCamera()){ delay(500); ESP.restart(); }
  connectWiFi();

  server.on("/status",   HTTP_GET, handleStatus);
  server.on("/led",      HTTP_GET, handleLed);
  server.on("/pump",     HTTP_GET, handlePump);
  server.on("/uart",     HTTP_GET, handleUART);
  server.on("/joystick", HTTP_GET, handleJoystick);
  server.on("/stream",   HTTP_GET, handleStream);
  server.on("/snapshot", HTTP_GET, handleSnapshot);
  server.on("/jpg",      HTTP_GET, handleSnapshot);
  server.on("/", HTTP_GET, [](){ server.send(200,"text/plain",
    "HydroBot ESP32-CAM OK\n/stream, /snapshot, /jpg, /status, /led, /pump, /joystick, /uart"); });

  server.begin();
}

void loop(){
  server.handleClient();
  ensureWiFi();
  feedWDT();
}
