
Perfeito — vamos consertar o /snapshot no ESP.

O problema é que o handler atual tenta pegar o frame “na hora” (esp_camera_fb_get() dentro do request). Em muitas placas (AI Thinker), isso dá timeout/NULL intermitente, e o servidor fica em hasFrame=false.


A solução robusta é capturar frames continuamente em uma tarefa (FreeRTOS) e guardar o último JPEG em memória. O endpoint /snapshot apenas devolve o último frame pronto, então nunca bloqueia esperando a câmera.


Abaixo está o firmware completo do ESP32-CAM (AI Thinker) com:




Wi-Fi DHCP + mDNS (http://hydrobot-esp.local)


Task de captura contínua (cam_task) com retries e auto-reinit da câmera


Buffer PSRAM para o último JPEG (sempre atualizado)


Endpoints: /status, /snapshot, /uart, /pump, /joystick (iguais ao app/servidor)


CORS habilitado


Config de câmera estável: QVGA, jpeg_quality=12, fb_count=2, GRAB_LATEST






No Arduino IDE: Board AI Thinker ESP32-CAM, PSRAM Enabled.

Fontes: ESP com 5V estável ≥1A. Ligue GND comum com o Arduino.





ESP32-CAM – código completo (substitua tudo)


/*  ESP32-CAM (AI Thinker) — Snapshot estável (buffer em background) + Bridge HTTP<->UART
    - Wi-Fi DHCP + mDNS: http://hydrobot-esp.local
    - Endpoints:
        /status                 -> JSON (hasFrame, age_ms, fps_cap)
        /snapshot               -> último JPEG em buffer (no-store)
        /uart?line=...          -> Serial.println(line)
        /pump?on=0|1            -> "CMD:PUMP:0|1"
        /joystick?x=&y=         -> redundância com CMD discreto
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer do último frame ----------
static uint8_t* g_jpeg = nullptr;
static size_t   g_jlen = 0;
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;

static uint32_t g_fail_streak = 0;

// ---------- Utils ----------
static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }

static uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }

// ---------- Câmera ----------
static bool camera_begin_qvga() {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 20000000;
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = FRAMESIZE_QVGA;    // 320x240
  cfg.jpeg_quality = 12;                // 10..15 (menor = melhor)
  cfg.fb_count     = psramFound() ? 2 : 1;
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  sensor_t *s = esp_camera_sensor_get();
  if (s && s->id.PID == OV3660_PID) {
    s->set_vflip(s, 1);
    s->set_brightness(s, 1);
    s->set_saturation(s, -2);
  }
  // garante QVGA/qualidade após init
  if (s) { s->set_framesize(s, FRAMESIZE_QVGA); s->set_quality(s, 12); }
  return true;
}

static void camera_free_buffer(){
  if(g_jpeg){ heap_caps_free(g_jpeg); g_jpeg=nullptr; g_jlen=0; }
}

// Task de captura contínua
void cam_task(void*){
  const uint32_t MIN_INTERVAL_MS = 80;  // ~12.5 fps cap
  g_cap_tick = now_ms();
  while(true){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();
    if(!fb){
      g_fail_streak++;
      if(g_fail_streak>=10){
        Serial.println("CAMERA_REINIT");
        esp_camera_deinit();
        delay(50);
        camera_begin_qvga();
        g_fail_streak=0;
      }
      vTaskDelay(pdMS_TO_TICKS(10));
      continue;
    }
    g_fail_streak=0;

    // Garante JPEG
    if(fb->format != PIXFORMAT_JPEG || fb->len<20){
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      continue;
    }

    // Copia para PSRAM própria (snapshot independente do fb)
    xSemaphoreTake(g_lock, portMAX_DELAY);
    camera_free_buffer();
    g_jlen = fb->len;
    g_jpeg = (uint8_t*) heap_caps_malloc(g_jlen, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
    if(g_jpeg){
      memcpy(g_jpeg, fb->buf, g_jlen);
      g_ts_ms = now_ms();
    } else {
      g_jlen = 0;
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS calculado
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // cap de taxa
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- Wi-Fi ----------
void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) {
    delay(200);
  }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Handlers ----------
void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot-buffer\","
             "\"hasFrame\":" + String((g_jpeg && age < 12000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) +
             "}";
  server.send(200,"application/json",j);
}

void handle_snapshot(){
  sendCORS();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_jpeg && g_jlen>0);
  if(ok){
    server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
    server.sendHeader("Pragma","no-cache");
    server.sendHeader("Expires","0");
    server.setContentLength(g_jlen);
    server.send(200,"image/jpeg","");
    WiFiClient c = server.client();
    c.write(g_jpeg, g_jlen);
  } else {
    server.send(503,"text/plain","no frame\n");
  }
  xSemaphoreGive(g_lock);
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Encaminha nota GET (compat)
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Comando discreto redundante
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- setup/loop ----------
void setup() {
  // UART0 p/ Arduino
  Serial.begin(115200);
  delay(50);

  // Estabilidade
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  // Sincronização buffer
  g_lock = xSemaphoreCreateMutex();

  // Wi-Fi
  wifi_begin_dhcp();

  // Câmera
  if(!camera_begin_qvga()){
    // tenta mais uma vez após 300ms
    delay(300);
    camera_begin_qvga();
  }

  // Task de captura contínua
  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  // HTTP
  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  // CORS preflight
  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}




Como validar (rápido)




Abra o Serial Monitor → confirme WIFI_OK e IP: 192.168.3.3 (ou o que o roteador der).


No navegador:



http://<IP_DO_ESP>/status → espere hasFrame:true e age_ms baixo.


http://<IP_DO_ESP>/snapshot → deve abrir imagem.






Depois disso, o servidor (/healthz) deve passar a hasFrame:true e o app passa a exibir vídeo.






Se ainda aparecer hasFrame:false em /status, verifique:




Flat cable da câmera bem encaixado (lado dos contatos para baixo).


Fonte 5V suficiente (≥1A).


No “Tools” do IDE, PSRAM: Enabled.


Teste reduzir para QQVGA: mude FRAMESIZE_QVGA → FRAMESIZE_QQVGA (e deixe jpeg_quality=15).






Esse desenho, com buffer em background + reinit automático, elimina o “NO LIVE FRAME” causado por timeouts do sensor e estabiliza o proxy do servidor.




























































/*  ESP32-CAM (AI Thinker) — Bridge HTTP<->UART + Snapshot (DHCP)
    - Conecta ao roteador por DHCP e anuncia mDNS: http://hydrobot-esp.local
    - Endpoints:
        /status                 -> JSON com IP e modo
        /snapshot               -> JPEG (Cache-Control: no-store)
        /uart?line=...          -> envia "line\n" ao Arduino
        /pump?on=0|1            -> envia "CMD:PUMP:0|1\n"
        /joystick?x=&y=         -> encaminha GET e envia CMD discreto redundante
    - Ligações:
        ESP U0TXD (GPIO1)  -> Arduino RX (D0)
        Arduino TX (D1) -> (divisor 5V->3V3) -> ESP U0RXD (GPIO3)
        GND comum e fonte 5V dedicada (≥1A) para o ESP32-CAM
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"

// --------- Wi-Fi / mDNS ---------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";   // http://hydrobot-esp.local

// --------- WebServer ---------
WebServer server(80);

// --------- Pinos da câmera (AI Thinker) ---------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// --------- Helpers ---------
static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }

// --------- Handlers HTTP ---------
void handle_status(){
  sendCORS();
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot\"}";
  server.send(200,"application/json",j);
}

void handle_uart(){
  sendCORS();
  if(!server.hasArg("line")){ server.send(400,"text/plain","missing 'line'\n"); return; }
  String line = urlDecode(server.arg("line"));
  Serial.print(line);
  if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

void handle_pump(){
  sendCORS();
  if(!server.hasArg("on")){ server.send(400,"text/plain","missing 'on'\n"); return; }
  bool on = server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE";
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on ? "PUMP_ON\n" : "PUMP_OFF\n");
}

void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Encaminha linha GET (compatível com o teu Arduino)
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Redundância com comando discreto (anti-lag)
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){
    Serial.println("CMD:STOP");
  } else {
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);  // 120..380ms
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

void handle_snapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb || fb->format!=PIXFORMAT_JPEG){
    if(fb) esp_camera_fb_return(fb);
    server.send(503,"text/plain","no frame\n");
    return;
  }
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.setContentLength(fb->len);
  server.send(200,"image/jpeg","");
  WiFiClient c = server.client();
  c.write(fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

// --------- Inicialização da câmera (perfil estável) ---------
bool camera_begin_low(){
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;
  cfg.xclk_freq_hz=20000000;
  cfg.pixel_format=PIXFORMAT_JPEG;
  cfg.frame_size=FRAMESIZE_QQVGA;   // 160x120 (comece leve; depois pode subir p/ QVGA)
  cfg.jpeg_quality=15;              // 10~12 mais pesado; 15 é bem estável
  cfg.fb_count=1;                   // 1 = estável (evita estouro de PSRAM)
  cfg.fb_location=CAMERA_FB_IN_PSRAM;
  cfg.grab_mode=CAMERA_GRAB_LATEST;
  if (esp_camera_init(&cfg) != ESP_OK) return false;

  // ajustes finos opcionais
  sensor_t *s = esp_camera_sensor_get();
  if (s && s->id.PID == OV3660_PID) { s->set_vflip(s,1); s->set_brightness(s,1); s->set_saturation(s,-2); }
  return true;
}

// --------- Wi-Fi (DHCP) ---------
void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 20000) {
    delay(200);
  }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// --------- setup / loop ---------
void setup() {
  // UART0 para Arduino
  Serial.begin(115200);
  delay(50);

  // Estabilidade elétrica
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout (cuidado: precisa de fonte 5V boa)

  // Wi-Fi
  wifi_begin_dhcp();

  // Câmera
  if(!camera_begin_low()){
    Serial.println("CAMERA_INIT_FAIL");
  } else {
    Serial.println("CAMERA_INIT_OK");
  }

  // HTTP
  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  // CORS (preflight)
  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1); // coopera com WDT
}






































Fechado! Aqui vão os dois arquivos completos já ajustados para o seu ESP32-CAM (com /snapshot, /joystick, /pump, /uart) e com correções para o caso “NO LIVE FRAME”.


As mudanças principais:




Server agora aceita mais tipos de Content-Type (ex.: image/jpg, application/octet-stream) ou detecta JPEG pelo magic 0xFF 0xD8 — isso evita o “NO LIVE FRAME” quando o ESP não manda o header certinho.


/snapshot tenta direto no ESP primeiro, depois cai no cache — inverti a ordem para reduzir latência e evitar placeholder.


CameraScreen ganhou fallback automático: se carregar 3 imagens com erro do servidor, passa a puxar direto do ESP (e volta pro server quando normalizar). Também mantém o ?ts= contra cache.





1) server_heuristic.py (coloque na raiz do servidor)


# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 8.0
POLL_FPS_TARGET = 8.0                              # ~8 fps estável
MAX_FRAME_AGE_MS = 8000                            # relaxado p/ redes lentas
MAX_RESULT_AGE_MS = 800
JPEG_QUALITY = 85

# Heurística simples de fogo
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}

ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True  # às vezes vem vazio; vamos inspecionar magic bytes
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEURÍSTICA FOGO =========
def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.02); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.01); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # 1) tenta direto do ESP (melhor latência e evita placeholder)
    try:
        b = None
        u = f"{SNAPSHOT_URL_FMT.format(CAMERA_IP)}?ts={int(time.time()*1000)}"
        r = requests.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = (r.headers.get("Content-Type") or "").lower()
            b = r.content or b""
            if not (ct.startswith(ACCEPT_CT_PREFIX) or is_jpeg_bytes(b)):
                b = None
        if not b:
            b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
        if not b:
            b = placeholder_jpeg("NO LIVE FRAME")
    except Exception:
        b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS) or placeholder_jpeg("NO LIVE FRAME")

    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}





Como rodar:


python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install fastapi uvicorn opencv-python-headless numpy requests
uvicorn server_heuristic:app --host 0.0.0.0 --port 8000






2) HydroBotApp2/src/screens/CameraScreen.tsx (substitua por completo)


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando…", waiting:"Aguardando servidor…", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem vídeo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo • score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting…", waiting:"Waiting for server…", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire • score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando…", waiting:"Esperando servidor…", statusFail:"Error de conexión. Revisa Wi-Fi/IP.",
        noVideo:"Sin vídeo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego • score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type SrcBox = { x:number; y:number; w:number; h:number; type:"fire" };
function BoxesOverlay({ frameWH, containerWH, boxes }:{
  frameWH:{w:number;h:number}|null; containerWH:{w:number;h:number}|null; boxes:SrcBox[];
}) {
  const f = frameWH && frameWH.w>0 && frameWH.h>0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w<=0 || containerWH.h<=0) return null;
  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale, dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW)/2, offsetY = (containerWH.h - dispH)/2;
  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position:"absolute", left:offsetX, top:offsetY, width:dispW, height:dispH }}>
        {boxes.map((b,i)=>{
          const left=b.x*scale, top=b.y*scale, width=b.w*scale, height=b.h*scale;
          return (
            <View key={i} style={{ position:"absolute", left, top, width, height, borderWidth:3, borderColor:"#ff3b30", borderRadius:6 }}>
              <View style={{ position:"absolute", left:0, top:-18, paddingHorizontal:6, paddingVertical:2, borderRadius:4, backgroundColor:"#ff3b30" }}>
                <Text style={{ color:"#000", fontWeight:"800", fontSize:10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{w:number;h:number}|null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{w:number;h:number}|null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [useDirectSnapshot, setUseDirectSnapshot] = useState(false);
  const failCountRef = useRef(0);

  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);
  const [ready, setReady] = useState(false);

  const clean = (s:string)=>s.replace(/\/+$/,"");

  // Server endpoints
  const healthUrl   = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl   = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const configUrl   = useMemo(()=>`${clean(server)}/config`,[server]);

  // ESP endpoints (controle e snapshot direto - fallback)
  const pumpUrl     = useMemo(()=> (on:boolean)=>`http://${ip}/pump?on=${on?"1":"0"}`,[ip]);
  const joystickUrl = useMemo(()=> (x:number,y:number)=>`http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,[ip]);
  const uartUrl     = useMemo(()=> (line:string)=>`http://${ip}/uart?line=${encodeURIComponent(line)}`,[ip]);
  const snapshotEsp = useMemo(()=> `http://${ip}/snapshot`, [ip]);

  // Sincroniza IP da câmera no server
  useEffect(()=>{
    let aborted=false;
    (async()=>{
      try{
        const r=await fetch(configUrl,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_ip:ip})});
        const j=await r.json();
        if(!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      }catch{ if(!aborted) setStatusText(T.statusFail); }
    })();
    return()=>{aborted=true};
  },[ip, configUrl, T]);

  // Health do servidor
  useEffect(()=>{
    let stop=false, backoff=500;
    const poll=async()=>{
      if(stop) return;
      try{
        const r=await fetch(healthUrl); const j=await r.json();
        if(j?.ok){ setReady(true); setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`); return; }
      }catch{}
      setReady(false); setStatusText(T.waiting);
      setTimeout(poll, backoff); backoff=Math.min(backoff*1.6, 5000);
    };
    poll(); return()=>{stop=true};
  },[healthUrl, T]);

  // SNAPSHOT loop com fallback server->ESP
  useEffect(()=>{
    if(!ready) return;
    let stop=false, interval=140;
    const pickBase = ()=> useDirectSnapshot ? snapshotEsp : snapshotSrv;

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=140;
      }catch{
        interval=Math.min(interval*1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotEsp, ready, useDirectSnapshot]);

  const onNextLoadStart = ()=>{ loadingNextRef.current=true; };
  const onNextShown = (ok:boolean)=>{
    if(ok){
      failCountRef.current = 0;
      if(useDirectSnapshot){ // tenta voltar ao servidor quando estabilizar
        setUseDirectSnapshot(false);
      }
      if(nextFrameUri) setCurrentFrameUri(nextFrameUri);
    }else{
      failCountRef.current += 1;
      // se falhar 3 vezes seguidas no servidor, troca para ESP direto
      if(!useDirectSnapshot && failCountRef.current >= 3){
        setUseDirectSnapshot(true);
        failCountRef.current = 0;
      }
    }
    loadingNextRef.current=false;
  };

  // DETECT loop
  useEffect(()=>{
    if(!ready) return;
    let stop=false, interval=250;
    const loop=async()=>{
      if(stop) return;
      try{
        const r=await fetch(detectUrl); const j=await r.json();
        if(j && j.ok!==false){
          setIsFire(!!j.isFire); setFireScore(Number(j.score||0));
          const wh = Array.isArray(j.frame_wh)&&j.frame_wh.length===2
                     ? {w:Number(j.frame_wh[0])||0, h:Number(j.frame_wh[1])||0}:null;
          if(wh && wh.w>0 && wh.h>0) setFrameWH(wh);
          const boxes:SrcBox[]=[];
          if(j.isFire && Array.isArray(j.boxes)){
            for(const b of j.boxes){
              if(Array.isArray(b)&&b.length>=4){
                const [x,y,w,h]=b.map((n:any)=>Number(n)||0);
                boxes.push({x,y,w,h,type:"fire"});
              }
            }
          }
          setOverlayBoxes(boxes); interval=250;
        }
      }catch{
        setIsFire(false); setFireScore(0); setOverlayBoxes([]);
        interval=Math.min(interval*1.5,1500);
      }finally{ setTimeout(loop, interval); }
    };
    loop(); return()=>{stop=true};
  },[detectUrl, ready]);

  // Joystick
  const RADIUS=64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder:()=>true,
      onMoveShouldSetPanResponder:()=>true,
      onPanResponderGrant:()=>{},
      onPanResponderMove:(_e:GestureResponderEvent,g:PanResponderGestureState)=>{
        let nx=g.dx/RADIUS, ny=g.dy/RADIUS;
        const len=Math.hypot(nx,ny); if(len>1){ nx/=len; ny/=len; }
        setJoy({x:nx, y:-ny});
      },
      onPanResponderRelease:()=>{ setJoy({x:0,y:0}); },
      onPanResponderTerminate:()=>{ setJoy({x:0,y:0}); },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef  = useRef<string>("STOP");
  const trySendJoystick = async (x:number,y:number)=>{ try{ await fetch(joystickUrl(x,y)); return true; }catch{ return false; } };
  const sendDiscreteCmd  = async (line:string)=>{ try{ await fetch(uartUrl(line)); return true; }catch{ return false; } };
  const vecToDir=(x:number,y:number):"FWD"|"BACK"|"LEFT"|"RIGHT"|"STOP"=>{
    const mag=Math.hypot(x,y); if(mag<0.2) return "STOP";
    const deg=(Math.atan2(y,x)*180)/Math.PI;
    if(deg>-45&&deg<=45) return "RIGHT";
    if(deg>45&&deg<=135) return "FWD";
    if(deg<=-45&&deg>-135) return "BACK";
    return "LEFT";
  };

  useEffect(()=>{
    let cancelled=false;
    const tick=async()=>{
      if(cancelled) return;
      const now=Date.now();
      if(now-lastSendRef.current<120){ setTimeout(tick,20); return; }
      lastSendRef.current=now;

      const {x,y}=joy; const mag=Math.hypot(x,y);
      const ok = await trySendJoystick(x,y);
      if(ok){
        if(mag<0.2 && lastDirRef.current!=="STOP"){ await sendDiscreteCmd("CMD:STOP"); lastDirRef.current="STOP"; }
        setTimeout(tick,120); return;
      }
      const dir=vecToDir(x,y);
      if(dir!==lastDirRef.current){
        const ms=140+Math.round(260*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd( dir==="STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}` );
        lastDirRef.current=dir;
      }else if(dir!=="STOP"){
        const ms=120+Math.round(200*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick,120);
    };
    tick(); return()=>{cancelled=true};
  },[joy, ip]);

  // Bomba
  async function togglePump(){
    try{
      const t=!pumpOn; await fetch(pumpUrl(t)); setPumpOn(t);
    }catch{ setStatusText(T.statusFail); }
  }

  function onVideoLayout(e:LayoutChangeEvent){
    const {width,height}=e.nativeEvent.layout; setVideoContainerWH({w:width,h:height});
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5"
                   autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput value={server} onChangeText={(s)=>{ setServer(s); setReady(false); setStatusText(T.waiting); }}
                   placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
                   style={[styles.input,{minWidth:220}]} />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn?styles.btnOn:styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn?T.pumpOn:T.pumpOff}</Text>
        </Pressable>
      </View>

      <View style={[styles.statusRow,{paddingTop:4,paddingBottom:8}]}>
        <Text numberOfLines={2} style={styles.status}>{statusText} {useDirectSnapshot ? "• (snapshot direto)" : ""}</Text>
        <View style={[styles.badge,{backgroundColor: ready ? "#065f46" : "#1f2937"}]}>
          <Text style={{ color:"#fff", fontWeight:"800" }}>{ready ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      <View style={[styles.fireBanner, isFire?styles.fireOn:styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      <View style={{ flex:1 }} onLayout={onVideoLayout}>
        <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri}
                        onNextLoadStart={()=> (loadingNextRef.current=true)}
                        onNextShown={onNextShown}/>
        {overlayBoxes.length>0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap,{width:64*2+24,height:64*2+24}]}
              {...pan.panHandlers}>
          <View style={[styles.joyBase,{width:64*2,height:64*2,borderRadius:64}]} />
          <View style={[styles.joyKnob,{width:22*2,height:22*2,borderRadius:22,
                        transform:[{translateX:joy.x*64},{translateY:-joy.y*64}], opacity: dragging?1:0.9}]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container:{ flex:1, backgroundColor:PALETTE.bg },
  hero:{ alignItems:"center", paddingTop:12, paddingBottom:6 },
  heroLogo:{ width:80, height:80, marginBottom:6, resizeMode:"contain" },
  heroTitle:{ color:"#fff", fontSize:22, fontWeight:"800" },
  heroSubtitle:{ color:"#d1d5db", marginTop:2 },

  topbar:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:10, gap:8,
           backgroundColor:PALETTE.card, borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  label:{ color:"#cfd3d8", fontSize:12 },
  input:{ backgroundColor:"#0b0d14", color:"white", borderRadius:8, paddingHorizontal:10, paddingVertical:8,
          borderWidth:1, borderColor:PALETTE.border, minWidth:120 },
  btn:{ backgroundColor:PALETTE.accent, paddingHorizontal:10, paddingVertical:10, borderRadius:10 },
  btnOn:{ backgroundColor:"#17a34a" }, btnOff:{ backgroundColor:"#374151" },
  btnText:{ color:"white", fontWeight:"600" },

  statusRow:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:8, gap:8,
              backgroundColor:"#0f1322", borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  badge:{ paddingHorizontal:10, paddingVertical:6, borderRadius:8, borderWidth:1, borderColor:PALETTE.border },
  status:{ color:"#cbd5ff", flex:1, fontSize:12 },

  fireBanner:{ alignItems:"center", justifyContent:"center", paddingVertical:6 },
  fireOn:{ backgroundColor:"#8b0000" }, fireOff:{ backgroundColor:"#223" },
  fireText:{ color:"white", fontWeight:"800" },

  joyWrap:{ position:"absolute", bottom:24, left:24, alignItems:"center", justifyContent:"center" },
  joyBase:{ position:"absolute", backgroundColor:"rgba(255,255,255,0.08)", borderWidth:2, borderColor:"rgba(255,255,255,0.14)" },
  joyKnob:{ position:"absolute", backgroundColor:"rgba(230,64,58,0.9)", borderWidth:2, borderColor:"rgba(255,255,255,0.85)" },
  joyText:{ position:"absolute", bottom:-22, color:"#cbd5ff", fontSize:12 },
});




Checklist rápido




No navegador:






http://192.168.3.3/snapshot abre imagem? (se não, é o ESP)


http://192.168.3.4:8000/healthz → hasFrame:true e veja last_err


http://192.168.3.4:8000/snapshot abre imagem?






No app:






Se o servidor falhar, ele muda sozinho para “snapshot direto” (aparece um sufixo “(snapshot direto)” no status).


Quando o servidor normalizar, ele volta automaticamente para o proxy.




Se ainda aparecer “NO LIVE FRAME”, me diga o que retorna GET /healthz (especialmente last_err) — com isso dá pra cravar se é header do ESP, IP, ou timeout de rede.






































































bora — segue os dois arquivos completos (app + servidor) já compatíveis com o firmware do ESP que expõe /status, /snapshot, /uart, /pump, /joystick via roteador.



1) HydroBotApp2/src/screens/CameraScreen.tsx




IP padrão do ESP: 192.168.3.3


URL padrão do server (FastAPI): http://192.168.3.4:8000


Snapshot vem do server (/snapshot) e usa ?ts= pra evitar cache


Detecção simples (heurística) vem de GET /detect do server


Joystick e Bomba falam direto com o ESP (e têm fallback por /uart)




// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
  Image,
  Animated,
  LayoutChangeEvent,
  AppState,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = {
  bg: "#0b0b0f",
  card: "#121218",
  border: "#25273a",
  accent: "#e6403a",
  text: "#e5e7eb",
};

const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:",
    test: "Testar",
    pumpOn: "BOMBA ON",
    pumpOff: "BOMBA OFF",
    server: "Servidor:",
    detecting: "Detectando…",
    waiting: "Aguardando servidor…",
    statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem vídeo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `🔥 FOGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo • score ${s.toFixed(2)}`,
    persons: "Pessoas",
    animals: "Animais",
    backend: "Modelo",
    synced: "Server sincronizado",
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:",
    test: "Test",
    pumpOn: "PUMP ON",
    pumpOff: "PUMP OFF",
    server: "Server:",
    detecting: "Detecting…",
    waiting: "Waiting for server…",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `🔥 FIRE • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire • score ${s.toFixed(2)}`,
    persons: "People",
    animals: "Animals",
    backend: "Model",
    synced: "Server sync OK",
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:",
    test: "Probar",
    pumpOn: "BOMBA ENC.",
    pumpOff: "BOMBA APAG.",
    server: "Servidor:",
    detecting: "Detectando…",
    waiting: "Esperando servidor…",
    statusFail: "Error de conexión. Revisa Wi-Fi/IP.",
    noVideo: "Sin vídeo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `🔥 FUEGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego • score ${s.toFixed(2)}`,
    persons: "Personas",
    animals: "Animales",
    backend: "Modelo",
    synced: "Sincronizado con servidor",
    placeholderIp: "192.168.3.3",
    placeholderServer: "http://192.168.3.4:8000",
  },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 }; // QQVGA do ESP

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: (ok: boolean) => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image
          key={currentUri}
          source={{ uri: currentUri }}
          style={{ flex: 1, width: "100%" }}
          resizeMode="contain"
        />
      )}

      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => {
              onNextShown(false);
              fade.setValue(0);
              setShowNext(false);
            }}
            onLoadEnd={() => {
              Animated.timing(fade, {
                toValue: 1,
                duration: 80,
                useNativeDriver: true,
              }).start(() => {
                onNextShown(true);
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type BoxType = "fire";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType };

function BoxesOverlay({
  frameWH,
  containerWH,
  boxes,
}: {
  frameWH: { w: number; h: number } | null;
  containerWH: { w: number; h: number } | null;
  boxes: SrcBox[];
}) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale;
          const top = b.y * scale;
          const width = b.w * scale;
          const height = b.h * scale;
          return (
            <View
              key={`${i}`}
              style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor: "#ff3b30", borderRadius: 6 }}
            >
              <View
                style={{ position: "absolute", left: 0, top: -18, paddingHorizontal: 6, paddingVertical: 2, borderRadius: 4, backgroundColor: "#ff3b30" }}
              >
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);

  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  const [ready, setReady] = useState(false);

  const cleanServer = (s: string) => s.replace(/\/+$/, "");

  // Server endpoints
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);
  const detectUrl = useMemo(() => `${cleanServer(server)}/detect`, [server]);
  const snapshotUrl = useMemo(() => `${cleanServer(server)}/snapshot`, [server]);
  const configUrl = useMemo(() => `${cleanServer(server)}/config`, [server]);

  // ESP endpoints (controle direto)
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const joystickUrl = useMemo(() => (x: number, y: number) => `http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`, [ip]);
  const uartUrl = useMemo(() => (line: string) => `http://${ip}/uart?line=${encodeURIComponent(line)}`, [ip]);

  // Sincroniza o IP da câmera dentro do server (para o proxy do /snapshot)
  useEffect(() => {
    let aborted = false;
    (async () => {
      try {
        const r = await fetch(configUrl, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ camera_ip: ip }),
        });
        const j = await r.json();
        if (!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      } catch {
        if (!aborted) setStatusText(T.statusFail);
      }
    })();
    return () => {
      aborted = true;
    };
  }, [ip, configUrl, T]);

  // Health do servidor
  useEffect(() => {
    let stop = false;
    let backoff = 500;
    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl);
        const j = await r.json();
        if (j?.ok) {
          setReady(true);
          setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`);
          return;
        }
      } catch {}
      setReady(false);
      setStatusText(T.waiting);
      setTimeout(poll, backoff);
      backoff = Math.min(backoff * 1.6, 5000);
    };
    poll();
    return () => {
      stop = true;
    };
  }, [healthUrl, T]);

  // SNAPSHOT loop
  useEffect(() => {
    if (!ready) return;
    let stop = false;
    let interval = 120; // ~8 fps
    setCurrentFrameUri(`${snapshotUrl}?ts=${Date.now()}`);
    const tick = () => {
      if (stop) return;
      try {
        if (!loadingNextRef.current) {
          const url = `${snapshotUrl}?ts=${Date.now()}`;
          setNextFrameUri(url);
        }
        interval = 120;
      } catch {
        interval = Math.min(interval * 1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();
    return () => {
      stop = true;
    };
  }, [snapshotUrl, ready]);

  function onNextLoadStart() {
    loadingNextRef.current = true;
  }
  function onNextShown(ok: boolean) {
    if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  // DETECT loop
  useEffect(() => {
    if (!ready) return;
    let stop = false;
    let interval = 220;
    const loop = async () => {
      if (stop) return;
      try {
        const r = await fetch(detectUrl);
        const j = await r.json();
        if (j && j.ok !== false) {
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));
          const wh =
            Array.isArray(j.frame_wh) && j.frame_wh.length === 2
              ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 }
              : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);
          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) {
              if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0);
              boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          setOverlayBoxes(boxes);
          interval = 220;
        }
      } catch {
        setIsFire(false);
        setFireScore(0);
        setOverlayBoxes([]);
        interval = Math.min(interval * 1.5, 1500);
      } finally {
        setTimeout(loop, interval);
      }
    };
    loop();
    return () => {
      stop = true;
    };
  }, [detectUrl, ready]);

  // Joystick
  const RADIUS = 64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS,
          ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) {
          nx /= len;
          ny /= len;
        }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
      onPanResponderTerminate: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef = useRef<string>("STOP");

  const trySendJoystick = async (x: number, y: number) => {
    try {
      await fetch(joystickUrl(x, y), { method: "GET" });
      return true;
    } catch {
      return false;
    }
  };
  const sendDiscreteCmd = async (line: string) => {
    try {
      await fetch(uartUrl(line), { method: "GET" });
      return true;
    } catch {
      return false;
    }
  };
  const vecToDir = (x: number, y: number): "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP" => {
    const mag = Math.hypot(x, y);
    if (mag < 0.2) return "STOP";
    const deg = (Math.atan2(y, x) * 180) / Math.PI;
    if (deg > -45 && deg <= 45) return "RIGHT";
    if (deg > 45 && deg <= 135) return "FWD";
    if (deg <= -45 && deg > -135) return "BACK";
    return "LEFT";
  };

  useEffect(() => {
    let cancelled = false;
    const tick = async () => {
      if (cancelled) return;
      const now = Date.now();
      if (now - lastSendRef.current < 120) {
        setTimeout(tick, 20);
        return;
      }
      lastSendRef.current = now;

      const x = joy.x;
      const y = joy.y;
      const mag = Math.hypot(x, y);

      const ok = await trySendJoystick(x, y);
      if (ok) {
        if (mag < 0.2 && lastDirRef.current !== "STOP") {
          await sendDiscreteCmd("CMD:STOP");
          lastDirRef.current = "STOP";
        }
        setTimeout(tick, 120);
        return;
      }

      const dir = vecToDir(x, y);
      if (dir !== lastDirRef.current) {
        const ms = 140 + Math.round(260 * Math.min(1, mag));
        const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(
          dir === "STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}`
        );
        lastDirRef.current = dir;
      } else if (dir !== "STOP") {
        const ms = 120 + Math.round(200 * Math.min(1, mag));
        const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick, 120);
    };
    tick();
    return () => {
      cancelled = true;
    };
  }, [joy, ip]);

  // Bomba
  async function togglePump() {
    try {
      const t = !pumpOn;
      await fetch(pumpUrl(t));
      setPumpOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }

  function onVideoLayout(e: LayoutChangeEvent) {
    const { width, height } = e.nativeEvent.layout;
    setVideoContainerWH({ w: width, h: height });
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + Servidor + Bomba */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => {
            setServer(s);
            setReady(false);
            setStatusText(T.waiting);
          }}
          placeholder={T.placeholderServer}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { minWidth: 220 }]}
        />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>
          {statusText}
        </Text>
        <View style={[styles.badge, { backgroundColor: ready ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>
            {ready ? T.detecting : T.waiting}
          </Text>
        </View>
      </View>

      {/* Banner de fogo */}
      <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      {/* Vídeo (snapshot) + Overlay */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        <CrossfadeImage
          currentUri={currentFrameUri}
          nextUri={nextFrameUri}
          onNextLoadStart={() => (loadingNextRef.current = true)}
          onNextShown={(ok) => {
            if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri);
            loadingNextRef.current = false;
          }}
        />
        {overlayBoxes.length > 0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: 22 * 2,
                height: 22 * 2,
                borderRadius: 22,
                transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: "#0b0d14",
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
    minWidth: 120,
  },
  btn: {
    backgroundColor: PALETTE.accent,
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1322",
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  badge: {
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(230,64,58,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});




2) server_heuristic.py (FastAPI)




Puxa frames do ESP (http://192.168.3.3/snapshot) e faz proxy em /snapshot (com headers no-store).


/healthz informa se há frame recente.


/config permite trocar o IP da câmera no runtime.


/detect faz uma heurística leve (HSV + brilho) só para manter o banner de fogo do app.






Instalar deps: pip install fastapi uvicorn opencv-python-headless numpy requests




# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 8.0
POLL_FPS_TARGET = 8.0                              # ~8 fps estável
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800
JPEG_QUALITY = 85

# Heurística simples de fogo
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                url = SNAPSHOT_URL_FMT.format(self._ip)
                u = f"{url}?ts={int(time.time()*1000)}"
                r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQUEST_HEADERS, stream=False)
                if r.status_code == 200 and r.headers.get("Content-Type", "").startswith("image/jpeg"):
                    jpeg = r.content
                    if jpeg:
                        with self._lock:
                            self._last_jpeg = jpeg
                            self._last_ts_ms = int(time.time()*1000)
                        self._frames += 1
                        now = time.time()
                        if now - self._last_fps_tick >= 1.0:
                            self._fps = self._frames / (now - self._last_fps_tick)
                            self._frames = 0
                            self._last_fps_tick = now
                        backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception:
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age, "fps_in": round(self._fps, 2)}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEURÍSTICA FOGO =========
def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.02); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.01); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            is_fire = False
            if ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW: is_fire = False
            else: is_fire = self._is_fire  # histerese

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber)
det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "fps_in": s.get("fps_in"), "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # Proxy com cabeçalhos anti-cache fortes
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        # último recurso: tentar pegar agora
        try:
            r = requests.get(f"{SNAPSHOT_URL_FMT.format(CAMERA_IP)}?ts={int(time.time()*1000)}",
                             timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                             headers=REQUEST_HEADERS, stream=False)
            if r.status_code == 200 and r.headers.get("Content-Type","").startswith("image/jpeg"):
                jpeg = r.content
        except Exception:
            pass
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")

    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=jpeg, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    # fallback: computa no ato
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}



Como rodar o server:


python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate
pip install fastapi uvicorn opencv-python-headless numpy requests
uvicorn server_heuristic:app --host 0.0.0.0 --port 8000




Teste rápido (fim a fim)




Navegador:



http://192.168.3.3/status (ESP) → JSON


http://192.168.3.3/snapshot → imagem (QQVGA)






Servidor:



POST http://192.168.3.4:8000/config com {"camera_ip":"192.168.3.3"}


GET http://192.168.3.4:8000/healthz → hasFrame: true


GET http://192.168.3.4:8000/snapshot → imagem (app usa isso)






App: abrir a tela; deve aparecer o vídeo.

Joystick/bomba: testam direto no ESP (/joystick, /pump).




Se algo não aparecer, me diga o retorno exato de /healthz e o texto de status que o app mostra — ajusto na hora.




























































/* ESP32-CAM (AI Thinker) — Bridge HTTP<->UART + Snapshot via Roteador
   IP fixo: 192.168.3.3
   Endpoints:
     GET /status                -> JSON
     GET /snapshot              -> JPEG (no-store)
     GET /uart?line=...         -> envia "line\n" ao Arduino (UART0)
     GET /pump?on=0|1           -> envia "CMD:PUMP:0|1\n"
     GET /joystick?x=..&y=..    -> encaminha GET e manda CMD discreto redundante
   Observações:
     - UART0 (GPIO1 TX0 -> RX Arduino | GPIO3 RX0 <- TX Arduino via divisor 5V->3V3)
     - Câmera QQVGA, quality 15, fb_count 1 (estável). Ajuste depois se quiser.
*/

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"

// ===== Wi-Fi (roteador) =====
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";
IPAddress IP(192,168,3,3), GW(192,168,3,1), MASK(255,255,255,0), DNS1(8,8,8,8), DNS2(1,1,1,1);

// ===== WebServer =====
WebServer server(80);

// ===== Pinos câmera (AI Thinker) =====
#define PWDN_GPIO_NUM 32
#define RESET_GPIO_NUM -1
#define XCLK_GPIO_NUM 0
#define SIOD_GPIO_NUM 26
#define SIOC_GPIO_NUM 27
#define Y9_GPIO_NUM 35
#define Y8_GPIO_NUM 34
#define Y7_GPIO_NUM 39
#define Y6_GPIO_NUM 36
#define Y5_GPIO_NUM 21
#define Y4_GPIO_NUM 19
#define Y3_GPIO_NUM 18
#define Y2_GPIO_NUM 5
#define VSYNC_GPIO_NUM 25
#define HREF_GPIO_NUM 23
#define PCLK_GPIO_NUM 22

// ===== Utils =====
static String urlDecode(const String &s){
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{ if(c>='0'&&c<='9')return c-'0'; if(c>='A'&&c<='F')return 10+(c-'A'); if(c>='a'&&c<='f')return 10+(c-'a'); return -1; };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){ int h1=hx(s[i+1]),h2=hx(s[i+2]); if(h1>=0&&h2>=0){ o+=(char)((h1<<4)|h2); i+=2; } else o+=c; }
    else o+=c;
  }
  return o;
}
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }

// ===== HTTP Handlers =====
void handle_status(){
  sendCORS();
  String j = "{\"ok\":true,\"ip\":\""+WiFi.localIP().toString()+"\",\"mode\":\"bridge+snapshot\"}";
  server.send(200,"application/json",j);
}
void handle_uart(){
  sendCORS();
  if(!server.hasArg("line")){ server.send(400,"text/plain","missing 'line'\n"); return; }
  String line = urlDecode(server.arg("line"));
  Serial.print(line);
  if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}
void handle_pump(){
  sendCORS();
  if(!server.hasArg("on")){ server.send(400,"text/plain","missing 'on'\n"); return; }
  bool on = server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE";
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on ? "PUMP_ON\n" : "PUMP_OFF\n");
}
void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Encaminha linha GET (seu Arduino entende)
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Redundância CMD discreto
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){
    Serial.println("CMD:STOP");
  } else {
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}
void handle_snapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb || fb->format!=PIXFORMAT_JPEG){
    if(fb) esp_camera_fb_return(fb);
    server.send(503,"text/plain","no frame\n");
    return;
  }
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.setContentLength(fb->len);
  server.send(200,"image/jpeg","");
  WiFiClient c = server.client();
  c.write(fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

// ===== Camera init (perfil leve/estável) =====
bool camera_begin_low(){
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;
  cfg.xclk_freq_hz=20000000;
  cfg.pixel_format=PIXFORMAT_JPEG;
  cfg.frame_size=FRAMESIZE_QQVGA;   // comece bem leve; depois pode subir para QVGA
  cfg.jpeg_quality=15;              // 10–12 é mais pesado; comece 15
  cfg.fb_count=1;                   // 1 = mais estável
  cfg.fb_location=CAMERA_FB_IN_PSRAM;
  cfg.grab_mode=CAMERA_GRAB_LATEST;
  return esp_camera_init(&cfg) == ESP_OK;
}

// ===== setup/loop =====
void setup(){
  // UART0 para Arduino
  Serial.begin(115200);
  delay(50);

  // estabilidade
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.config(IP,GW,MASK,DNS1,DNS2);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0=millis();
  while(WiFi.status()!=WL_CONNECTED && millis()-t0<15000) delay(200);

  // câmera
  camera_begin_low();

  // HTTP
  server.on("/status",    HTTP_GET, handle_status);
  server.on("/snapshot",  HTTP_GET, handle_snapshot);
  server.on("/uart",      HTTP_GET, handle_uart);
  server.on("/pump",      HTTP_GET, handle_pump);
  server.on("/joystick",  HTTP_GET, handle_joystick);
  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
}
void loop(){ server.handleClient(); delay(1); }


































// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet, PanResponder,
  GestureResponderEvent, PanResponderGestureState, Image, Animated,
  LayoutChangeEvent, AppState, Platform,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

/* ---------- PALETA ---------- */
const PALETTE = { bg: "#0b0b0f", card: "#121218", border: "#25273a", accent: "#e6403a", text: "#e5e7eb" };

/* ---------- TEXTOS ---------- */
const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:", test: "Testar", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "BOMBA ON", pumpOff: "BOMBA OFF", server: "Servidor:",
    detecting: "Detectando…", saving: "Salvando...", statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem vídeo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `🔥 FOGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Pessoas", animals: "Animais", backend: "Modelo",
    waiting: "Aguardando servidor…", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
    switchingToSnapshot: "MJPEG falhou • usando snapshot direto",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:", test: "Test", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "PUMP ON", pumpOff: "PUMP OFF", server: "Server:",
    detecting: "Detecting…", saving: "Saving...", statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `🔥 FIRE • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "People", animals: "Animals", backend: "Model",
    waiting: "Waiting for server…", synced: "Server sync OK",
    mode: "Mode", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
    switchingToSnapshot: "MJPEG failed • falling back to direct snapshot",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:", test: "Probar", ledOn: "LED ENC.", ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.", pumpOff: "BOMBA APAG.", server: "Servidor:",
    detecting: "Detectando…", saving: "Guardando...", statusFail: "Error de conexión. Revisa Wi-Fi/IP.",
    noVideo: "Sin vídeo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `🔥 FUEGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Personas", animals: "Animales", backend: "Modelo",
    waiting: "Esperando servidor…", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECTO",
    switchingToSnapshot: "MJPEG falló • usando snapshot directo",
  },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 640, h: 480 };

const appLogo = require("../../assets/logo.png");

/* ---------- HERO ---------- */
function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

/* ---------- SNAPSHOT com crossfade ---------- */
function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 100, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

/* ---------- OVERLAY ---------- */
type BoxType = "fire" | "person" | "animal";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType; conf?: number; };

function BoxesOverlay({
  frameWH, containerWH, boxes,
}: { frameWH: { w: number; h: number } | null; containerWH: { w: number; h: number } | null; boxes: SrcBox[]; }) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale, top = b.y * scale, width = b.w * scale, height = b.h * scale;
          let borderColor = "#ff3b30"; if (b.type === "person") borderColor = "#00e5ff"; else if (b.type === "animal") borderColor = "#7CFC00";
          return (
            <View key={`${i}-${b.type}`} style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor, borderRadius: 6 }}>
              <View style={{ position: "absolute", left: 0, top: -18, paddingHorizontal: 6, paddingVertical: 2, borderRadius: 4, backgroundColor: borderColor }}>
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>
                  {b.type.toUpperCase()}{typeof b.conf === "number" ? ` ${b.conf.toFixed(2)}` : ""}
                </Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

/* ---------- TELA PRINCIPAL ---------- */
type Mode = "auto" | "server" | "direct";

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conexões
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState(T.waiting);
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detecção (server)
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("—");
  const [confMax, setConfMax] = useState<number>(0);

  // caixas + dimensões
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  // registro automático
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // SNAPSHOT (server)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // DIRECT: fallback snapshot
  const [directUseSnapshot, setDirectUseSnapshot] = useState(false);
  const [directCurUri, setDirectCurUri] = useState("");
  const [directNextUri, setDirectNextUri] = useState("");
  const directLoadingRef = useRef(false);
  const directFailMsgShownRef = useRef(false);

  // joystick
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // health/mode
  const [serverReady, setServerReady] = useState(false);
  const [mode, setMode] = useState<Mode>("auto");

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);
  const detectUrl = useMemo(() => `${cleanServer(server)}/detect`, [server]);
  const snapshotUrl = useMemo(() => `${cleanServer(server)}/snapshot`, [server]);
  const configUrl = useMemo(() => `${cleanServer(server)}/config`, [server]);
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const joystickUrl = useMemo(() => (x: number, y: number) => `http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`, [ip]);
  const uartUrl = useMemo(() => (line: string) => `http://${ip}/uart?line=${encodeURIComponent(line)}`, [ip]);
  const directStreamHtml = useMemo(
    () => `<html><head><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
      <style>html,body{margin:0;background:#000;height:100%}img{width:100%;height:100%;object-fit:contain;}</style></head>
      <body><img src="http://${ip}/stream" /></body></html>`,
    [ip]
  );

  /* ===== AppState ===== */
  const appStateRef = useRef(AppState.currentState);
  useEffect(() => {
    const sub = AppState.addEventListener("change", (s) => { appStateRef.current = s; });
    return () => sub.remove();
  }, []);

  /* ===== Sincroniza IP do ESP dentro do server ===== */
  useEffect(() => {
    let aborted = false;
    (async () => {
      try {
        const r = await fetch(configUrl, { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ camera_ip: ip }) });
        const j = await r.json();
        if (!aborted && j?.ok) setStatusText(T.synced + ` (${j.camera_ip})`);
      } catch { if (!aborted) setStatusText(T.statusFail); }
    })();
    return () => { aborted = true; };
  }, [ip, configUrl, T]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led); setPumpOn(!!j.pump);
      setStatusText(`OK • ip:${j.ip ?? ip} • mode:${j.mode ?? "—"} • led:${j.led ? "on" : "off"} • pump:${j.pump ? "on" : "off"} • q:${j.q ?? "?"}`);
    } catch { setStatusText(T.statusFail); }
    finally { setIsChecking(false); }
  }
  async function toggleLed() { try { const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t); } catch { setStatusText(T.statusFail); } }
  async function togglePump(){ try { const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); } catch { setStatusText(T.statusFail); } }
  useEffect(() => { pingStatus(); const id = setInterval(pingStatus, 5000); return () => clearInterval(id); }, [statusUrl]);

  /* ===== HEALTH-CHECK DO SERVIDOR ===== */
  useEffect(() => {
    let stop = false;
    let backoff = 600, fail = 0;
    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl);
        const j = await r.json();
        const ok = !!j?.ok && !!j?.hasFrame;
        setServerReady(ok);
        setStatusText(ok ? `Server OK • hasFrame:${j.hasFrame}` : T.waiting);
        fail = ok ? 0 : fail + 1;
      } catch { fail++; setServerReady(false); setStatusText(T.waiting); }
      if (mode === "auto" && fail >= 3) setStatusText("Falha no servidor • alternando para DIRECT");
      setTimeout(poll, Math.min((backoff *= 1.35), 5000));
    };
    poll(); return () => { stop = true; };
  }, [healthUrl, mode, T]);

  /* ===== SNAPSHOT LOOP (pull do servidor) ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    let stop = false;
    let interval = 110; // ~9 fps

    setCurrentFrameUri(`${snapshotUrl}?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!loadingNextRef.current) setNextFrameUri(`${snapshotUrl}?ts=${Date.now()}`);
        interval = 110;
      } catch { interval = Math.min(interval * 1.6, 1200); }
      setTimeout(tick, interval);
    };
    tick();
    return () => { stop = true; };
  }, [snapshotUrl, serverReady, mode]);

  function onNextLoadStart(){ loadingNextRef.current = true; }
  function onNextShown(ok: boolean){ if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri); loadingNextRef.current = false; }

  /* ===== DETECÇÃO (via servidor) ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;

    let stop = false;
    let interval = 200;
    const controller = new AbortController();

    const loop = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        const r = await fetch(detectUrl, { signal: controller.signal });
        const j = await r.json();
        if (j && j.ok !== false) {
          setIsFire(!!j.isFire); setFireScore(Number(j.score || 0));

          const wh = Array.isArray(j.frame_wh) && j.frame_wh.length === 2 ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 } : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);

          const o = j.objects || {}; const objs = o.objects || [];
          const nPerson = typeof o.n_person_stable === "number" ? o.n_person_stable : (typeof o.n_person === "number" ? o.n_person : objs.filter((x: any) => String(x.label).toLowerCase() === "person").length);
          const nAnimals = typeof o.n_animals_stable === "number" ? o.n_animals_stable : (typeof o.n_animals === "number" ? o.n_animals : objs.filter((x: any) => String(x.label).toLowerCase() !== "person").length);

          setPeople(nPerson || 0); setAnimals(nAnimals || 0);
          setBackend(o.backend || "—"); setConfMax(Number(o.conf_max || 0));

          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) { if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0); boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          for (const it of objs) {
            if (!it || !Array.isArray(it.box) || it.box.length < 4) continue;
            const [x, y, w, h] = it.box.map((n: any) => Number(n) || 0);
            const label = String(it.label || "").toLowerCase(); const conf = typeof it.conf === "number" ? it.conf : undefined;
            if (label === "person") boxes.push({ x, y, w, h, type: "person", conf }); else boxes.push({ x, y, w, h, type: "animal", conf });
          }
          setOverlayBoxes(boxes);
          interval = 200;
        }
      } catch {
        setIsFire(false); setFireScore(0); setPeople(0); setAnimals(0); setOverlayBoxes([]);
        interval = Math.min(interval * 1.6, 1500);
      } finally { setTimeout(loop, interval); }
    };
    loop();
    return () => { stop = true; controller.abort(); };
  }, [detectUrl, serverReady, mode]);

  /* ===== Registro automático ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;
    if (rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch { setStatusText(T.noVideo); } finally { setSaving(false); }
      })();
    }
    wasFireRef.current = isFire;
  }, [isFire, server, saving, T, serverReady, mode]);

  /* ===== Joystick ===== */
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(PanResponder.create({
    onStartShouldSetPanResponder: () => true,
    onMoveShouldSetPanResponder: () => true,
    onPanResponderGrant: () => setDragging(true),
    onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
      let nx = g.dx / RADIUS, ny = g.dy / RADIUS; const len = Math.hypot(nx, ny);
      if (len > 1) { nx /= len; ny /= len; } setJoy({ x: nx, y: -ny });
    },
    onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
  })).current;

  const lastSendRef = useRef(0); const lastDirRef = useRef<string>("STOP");
  const trySendJoystick = async (x: number, y: number) => { try { await fetch(joystickUrl(x, y)); return true; } catch { return false; } };
  const sendDiscreteCmd = async (dir: "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP", ms = 180, spd = 70) => {
    const line = dir === "STOP" ? "CMD:STOP"
      : `CMD:${dir}:ms=${Math.max(80, Math.min(ms, 600))}:spd=${Math.max(30, Math.min(spd, 100))}`;
    try { await fetch(uartUrl(line)); return true; } catch { return false; }
  };
  const vecToDir = (x: number, y: number): "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP" => {
    const mag = Math.hypot(x, y); if (mag < 0.2) return "STOP";
    const deg = (Math.atan2(y, x) * 180) / Math.PI;
    if (deg > -45 && deg <= 45) return "RIGHT"; if (deg > 45 && deg <= 135) return "FWD";
    if (deg <= -45 && deg > -135) return "BACK"; return "LEFT";
  };

  useEffect(() => {
    let cancelled = false;
    const tick = async () => {
      if (cancelled) return;
      const now = Date.now(); if (now - lastSendRef.current < 120) { setTimeout(tick, 20); return; }
      lastSendRef.current = now;
      const { x, y } = joy; const mag = Math.hypot(x, y);
      const ok = await trySendJoystick(x, y);
      if (ok) {
        if (mag < 0.2 && lastDirRef.current !== "STOP") { await sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; }
        setTimeout(tick, 120); return;
      }
      const dir = vecToDir(x, y);
      if (dir !== lastDirRef.current) {
        const ms = 140 + Math.round(260 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd); lastDirRef.current = dir;
      } else if (dir !== "STOP") {
        const ms = 120 + Math.round(200 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd);
      }
      setTimeout(tick, 120);
    };
    if (AppState.currentState === "active") tick();
    return () => { cancelled = true; };
  }, [joy, ip]);

  useEffect(() => {
    const handleBg = (s: string) => { if (s !== "active") { sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; } };
    const sub = AppState.addEventListener("change", handleBg);
    return () => sub.remove();
  }, []);

  function onVideoLayout(e: LayoutChangeEvent) { const { width, height } = e.nativeEvent.layout; setVideoContainerWH({ w: width, h: height }); }

  const usingServer = (mode === "server") || (mode === "auto" && serverReady);
  const usingDirect = (mode === "direct") || (mode === "auto" && !serverReady);

  /* ===== DIRECT: fallback snapshot loop ===== */
  useEffect(() => {
    if (!usingDirect || !directUseSnapshot) return;
    let stop = false;
    let interval = 140; // ~7 fps para não sobrecarregar o ESP
    setDirectCurUri(`http://${ip}/snapshot?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!directLoadingRef.current) setDirectNextUri(`http://${ip}/snapshot?ts=${Date.now()}`);
        interval = 140;
      } catch { interval = Math.min(interval * 1.6, 1000); }
      setTimeout(tick, interval);
    };
    tick();
    return () => { stop = true; };
  }, [usingDirect, directUseSnapshot, ip]);

  function onDirectNextStart(){ directLoadingRef.current = true; }
  function onDirectNextShown(ok: boolean){
    if (ok && directNextUri) setDirectCurUri(directNextUri);
    directLoadingRef.current = false;
  }

  // Quando entrar em DIRECT, tentamos o MJPEG primeiro; se falhar -> snapshot
  useEffect(() => {
    if (!usingDirect) { setDirectUseSnapshot(false); return; }
    // se WebView não sinalizar progresso em ~2.5s, troca para snapshot
    const t = setTimeout(() => {
      if (!directUseSnapshot) {
        setDirectUseSnapshot(true);
        if (!directFailMsgShownRef.current) {
          setStatusText(T.switchingToSnapshot);
          directFailMsgShownRef.current = true;
        }
      }
    }, 2500);
    return () => clearTimeout(t);
  }, [usingDirect, ip, T]);

  // Eventos do WebView para cancelar o fallback caso o MJPEG esteja OK
  const onWvLoadProgress = (e: any) => {
    if (usingDirect && !directUseSnapshot && e?.nativeEvent?.progress >= 0.2) {
      // carregou algo; mantemos MJPEG
      directFailMsgShownRef.current = false;
    }
  };
  const onWvError = () => {
    if (usingDirect) {
      setDirectUseSnapshot(true);
      if (!directFailMsgShownRef.current) {
        setStatusText(T.switchingToSnapshot);
        directFailMsgShownRef.current = true;
      }
    }
  };

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Pressable onPress={pingStatus} style={styles.btn}><Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text></Pressable>
        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text></Pressable>
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text></Pressable>
      </View>

      {/* Linha: Servidor + Modo */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => { setServer(s); setServerReady(false); setStatusText(T.waiting); }}
          placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Text style={styles.label}>{T.mode}</Text>
        <View style={{ flexDirection: "row", gap: 6 }}>
          <Pressable onPress={() => setMode("auto")} style={[styles.modeBtn, mode === "auto" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeAuto}</Text></Pressable>
          <Pressable onPress={() => setMode("server")} style={[styles.modeBtn, mode === "server" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeServer}</Text></Pressable>
          <Pressable onPress={() => setMode("direct")} style={[styles.modeBtn, mode === "direct" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeDirect}</Text></Pressable>
        </View>
        <View style={[styles.badge, { backgroundColor: ((mode === "server") || (mode==="auto" && serverReady)) ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>{((mode === "server") || (mode==="auto" && serverReady)) ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
      </View>

      {/* Banner de fogo (apenas server) */}
      {((mode === "server") || (mode==="auto" && serverReady)) && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
        </View>
      )}

      {/* Pessoas/animais */}
      {((mode === "server") || (mode==="auto" && serverReady)) && (
        <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
          <Text style={styles.statChip}>{T.persons}: <Text style={styles.statNumber}>{people}</Text></Text>
          <Text style={styles.statChip}>{T.animals}: <Text style={styles.statNumber}>{animals}</Text></Text>
          <Text style={styles.modelChip}>{T.backend}: {backend} • conf_max {confMax.toFixed(2)}</Text>
        </View>
      )}

      {/* Vídeo */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        {((mode === "server") || (mode==="auto" && serverReady)) ? (
          <>
            <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri} onNextLoadStart={onNextLoadStart} onNextShown={onNextShown} />
            {overlayBoxes.length > 0 && (<BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />)}
          </>
        ) : (
          directUseSnapshot ? (
            <CrossfadeImage
              currentUri={directCurUri}
              nextUri={directNextUri}
              onNextLoadStart={onDirectNextStart}
              onNextShown={onDirectNextShown}
            />
          ) : (
            <WebView
              originWhitelist={["*"]}
              source={{ html: directStreamHtml, baseUrl: `http://${ip}/` }}
              allowsInlineMediaPlayback
              mediaPlaybackRequiresUserAction={false}
              javaScriptEnabled
              domStorageEnabled
              setSupportMultipleWindows={false}
              overScrollMode="never"
              mixedContentMode="always"                 // << chave no Android
              onError={onWvError}
              onHttpError={onWvError}
              onLoadProgress={onWvLoadProgress}
              // estes dois ajudam em alguns devices:
              androidHardwareAccelerationDisabled={false}
              androidLayerType={Platform.OS === "android" ? "hardware" as any : undefined}
              style={{ backgroundColor: "black" }}
            />
          )
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View style={[styles.joyKnob, { width: 22 * 2, height: 22 * 2, borderRadius: 22, transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }], opacity: dragging ? 1 : 0.9 }]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

/* ---------- ESTILOS ---------- */
const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },
  topbar: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 10, gap: 8, backgroundColor: PALETTE.card, borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: { backgroundColor: "#0b0d14", color: "white", borderRadius: 8, paddingHorizontal: 10, paddingVertical: 8, borderWidth: 1, borderColor: PALETTE.border, minWidth: 110 },
  btn: { backgroundColor: PALETTE.accent, paddingHorizontal: 10, paddingVertical: 10, borderRadius: 10 },
  btnOn: { backgroundColor: "#17a34a" }, btnOff: { backgroundColor: "#374151" }, btnText: { color: "white", fontWeight: "600" },
  statusRow: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 8, gap: 8, backgroundColor: "#0f1322", borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  badge: { paddingHorizontal: 10, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: PALETTE.border },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },
  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 }, fireOn: { backgroundColor: "#8b0000" }, fireOff: { backgroundColor: "#223" }, fireText: { color: "white", fontWeight: "800" },
  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" }, statNumber: { color: "#fff" }, modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(230,64,58,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
  modeBtn: { backgroundColor: "#1f2937", paddingHorizontal: 8, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: "#334155" },
  modeBtnActive: { backgroundColor: "#0b5", borderColor: "#0b5" },
  modeText: { color: "#fff", fontWeight: "700", fontSize: 12 },
});
















































Boa — ajustei apenas o firmware do ESP32-CAM para estabilizar e garantir que o /stream e o /snapshot entreguem imagem de forma confiável (melhor manuseio de PSRAM, CORS no stream, keep-alive, escrita não-bloqueante mais robusta, ABR e fallback de framesize se a memória apertar). Substitua seu arquivo inteiro por este:


// HydroBot ESP32-CAM - Stable MJPEG (fixed IP) 2025-09-26
// Endpoints: /status /led /pump /joystick /uart /stream /snapshot (/jpg)
// Mudanças-chave vs sua versão:
//  - CORS também no /stream (evita bloqueios esporádicos no WebView/React Native)
//  - Cabeçalhos do stream com "keep-alive" (não força fechamento precoce)
//  - Escrita MJPEG mais resiliente (timeout progressivo e verificação de write estagnado)
//  - Uso seguro de PSRAM: fb_count = 2 se houver PSRAM, senão 1
//  - Fallback dinâmico de resolução se heap/PSRAM ficarem baixos
//  - /snapshot com envio direto + CORS e sem bloqueio por Content-Length mal negociado

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "esp_task_wdt.h"
#include "esp_idf_version.h"
#include <math.h>
#include <algorithm>

// ===== WiFi (static IP) =====
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";
IPAddress LOCAL_IP(192,168,3,3);
IPAddress GATEWAY (192,168,3,1);
IPAddress SUBNET  (255,255,255,0);
IPAddress DNS1    (8,8,8,8);
IPAddress DNS2    (1,1,1,1);

// ===== Pinos (AI-Thinker) =====
#define LED_FLASH_PIN 4
#define PUMP_PIN      14

WebServer server(80);

// ===== Stream / Encoder =====
static const char*   BOUNDARY              = "frame";
static framesize_t   g_framesize           = FRAMESIZE_QVGA; // 320x240
static int           g_jpeg_quality        = 26;             // 18..34 (ajustado dinamicamente)
static const int     STREAM_TARGET_FPS     = 10;
static const uint32_t UART_BAUD            = 115200;

// Thresholds ABR
static const size_t  ABR_BIG_FRAME   = 52000;   // bytes
static const size_t  ABR_SMALL_FRAME = 24000;   // bytes
static const int     Q_MIN = 18;
static const int     Q_MAX = 34;
static const uint32_t SEND_SLOW_MS = 220;

// Timeout/robustez de escrita
static const uint16_t MAX_ZERO_WRITES = 60;     // tolerância maior
static const uint32_t WRITE_STALL_MS  = 2500;   // se um frame demora além disso, sobe Q e tenta de novo

volatile bool ledOn=false, pumpOn=false;

String localIP() { return WiFi.isConnected() ? WiFi.localIP().toString() : String("0.0.0.0"); }
static inline void feedWDT(){ esp_task_wdt_reset(); yield(); }

static inline void sendCORS(){ server.sendHeader("Access-Control-Allow-Origin","*"); }

// ===== Camera =====
bool initCamera(){
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0; c.ledc_timer = LEDC_TIMER_0;
  c.pin_d0=5;  c.pin_d1=18; c.pin_d2=19; c.pin_d3=21;
  c.pin_d4=36; c.pin_d5=39; c.pin_d6=34; c.pin_d7=35;
  c.pin_xclk=0; c.pin_pclk=22; c.pin_vsync=25; c.pin_href=23;
  c.pin_sscb_sda=26; c.pin_sscb_scl=27;
  c.pin_pwdn=32; c.pin_reset=-1;
  c.xclk_freq_hz=20000000;
  c.pixel_format=PIXFORMAT_JPEG;

  c.frame_size   = g_framesize;
  c.jpeg_quality = g_jpeg_quality;
  c.fb_location  = CAMERA_FB_IN_PSRAM;
  c.fb_count     = psramFound() ? 2 : 1;           // <<< robustez PSRAM
  c.grab_mode    = CAMERA_GRAB_LATEST;             // drop old, keep newest

  esp_err_t err = esp_camera_init(&c);
  if(err!=ESP_OK){
    Serial.printf("Camera init failed: 0x%x\n", err);
    return false;
  }

  sensor_t* s = esp_camera_sensor_get();
  // Setup padrão confiável
  s->set_brightness(s,0); s->set_contrast(s,0); s->set_saturation(s,0);
  s->set_whitebal(s,1); s->set_awb_gain(s,1);
  s->set_exposure_ctrl(s,1); s->set_aec2(s,0);
  s->set_gain_ctrl(s,1); s->set_agc_gain(s,0); s->set_gainceiling(s,(gainceiling_t)0);
  s->set_bpc(s,0); s->set_wpc(s,1); s->set_raw_gma(s,1); s->set_lenc(s,1);
  s->set_hmirror(s,0); s->set_vflip(s,0); s->set_dcw(s,1); s->set_colorbar(s,0);

  return true;
}

void maybeDownscaleForMemory() {
  // Fallback para QQVGA se memória/PSRAM estiver apertando
  size_t heap = ESP.getFreeHeap();
  size_t ps   = ESP.getFreePsram();
  if ((heap < 80*1024) || (psramFound() && ps < 200*1024)) {
    sensor_t* s = esp_camera_sensor_get();
    g_framesize = FRAMESIZE_QQVGA; // 160x120
    s->set_framesize(s, g_framesize);
    g_jpeg_quality = std::min(Q_MAX, std::max(22, g_jpeg_quality + 4));
    s->set_quality(s, g_jpeg_quality);
  }
}

// ===== Handlers REST =====
void handleStatus(){
  String j="{\"ok\":true,\"ip\":\""+localIP()+"\",\"mode\":\"mjpeg-stream\",\"led\":"+String(ledOn?"true":"false")+
           ",\"pump\":"+String(pumpOn?"true":"false")+",\"heap\":"+String(ESP.getFreeHeap())+
           ",\"psram\":"+String(ESP.getFreePsram())+
           ",\"q\":"+String(g_jpeg_quality)+",\"fs\":"+String((int)g_framesize)+"}";
  sendCORS(); server.send(200,"application/json",j);
}

void handleLed(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !ledOn;
  ledOn = on; digitalWrite(LED_FLASH_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"led\":")+(on?"true":"false")+"}");
}

void handlePump(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !pumpOn;
  pumpOn = on; digitalWrite(PUMP_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"pump\":")+(on?"true":"false")+"}");
}

void handleUART(){
  if(!server.hasArg("line")){ sendCORS(); server.send(400,"application/json","{\"ok\":false,\"err\":\"missing line\"}"); return; }
  Serial.print(server.arg("line")); Serial.print("\n");
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleJoystick(){
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.0f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.0f;
  Serial.printf("JOY:x=%.3f:y=%.3f\n",x,y);
  float mag = sqrtf(x*x+y*y);
  const char* dir="STOP";
  if(mag>=0.2f){
    float deg = atan2f(y,x)*180.0f/3.1415926f;
    if(deg>-45 && deg<=45) dir="RIGHT";
    else if(deg>45 && deg<=135) dir="FWD";
    else if(deg<=-45 && deg>-135) dir="BACK";
    else dir="LEFT";
  }
  int ms =(mag<0.2f)?0:180+int(200*std::min(1.0f,mag));
  int spd=(mag<0.2f)?0: 50+int( 50*std::min(1.0f,mag));
  Serial.printf("CMD:%s:ms=%d:spd=%d\n",dir,ms,spd);
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleSnapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb){ sendCORS(); server.send(503,"text/plain","NO_FRAME"); return; }

  uint8_t* jpg = fb->buf; size_t len = fb->len; bool freeIt=false;
  if(fb->format!=PIXFORMAT_JPEG){
    if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){
      esp_camera_fb_return(fb);
      sendCORS(); server.send(500,"text/plain","ENCODE_FAIL"); return;
    }
    freeIt=true;
  }

  // Cabeçalhos + CORS
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache"); server.sendHeader("Expires","0");
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.setContentLength(len);
  server.send(200,"image/jpeg","");

  // Corpo
  WiFiClient cli = server.client();
  const uint8_t* p=jpg; size_t todo=len;
  uint32_t t0 = millis();
  while(todo>0){
    size_t can = cli.availableForWrite();
    if(can==0){
      if(millis()-t0>WRITE_STALL_MS) break; // evita travar se cliente sumiu
      feedWDT(); continue;
    }
    size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
    if(n==0){
      if(millis()-t0>WRITE_STALL_MS) break;
      feedWDT(); continue;
    }
    p+=n; todo-=n; feedWDT();
  }

  if(freeIt) free(jpg);
  esp_camera_fb_return(fb);
}

// ===== MJPEG Stream (robusto) =====
void handleStream(){
  WiFiClient cli = server.client();
  cli.setTimeout(2000);
  cli.setNoDelay(true);

  // Cabeçalhos do stream (mantém conexão viva)
  cli.print(
    "HTTP/1.1 200 OK\r\n"
    "Cache-Control: no-cache, no-store, must-revalidate\r\n"
    "Pragma: no-cache\r\n"
    "Expires: 0\r\n"
    "Access-Control-Allow-Origin: *\r\n"
    "Connection: keep-alive\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=frame\r\n\r\n"
  );

  const uint64_t minIv = 1000000ULL/STREAM_TARGET_FPS;
  uint64_t last=0;
  uint16_t zeroWrites=0;
  sensor_t* s = esp_camera_sensor_get();

  while(cli.connected()){
    uint64_t now=(uint64_t)esp_timer_get_time();
    if(now-last<minIv){ feedWDT(); continue; }

    camera_fb_t* fb = esp_camera_fb_get();
    if(!fb){ maybeDownscaleForMemory(); feedWDT(); continue; }

    uint8_t* jpg=fb->buf; size_t len=fb->len; bool freeIt=false;
    if(fb->format!=PIXFORMAT_JPEG){
      if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){
        esp_camera_fb_return(fb); feedWDT(); continue;
      }
      freeIt=true;
    }

    // Parte do MJPEG
    cli.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n",BOUNDARY,(unsigned)len);

    const uint8_t* p=jpg; size_t todo=len;
    uint32_t t0 = millis();
    zeroWrites = 0;

    while(todo>0 && cli.connected()){
      size_t can = cli.availableForWrite();
      if(can==0){
        zeroWrites++;
        if(zeroWrites>MAX_ZERO_WRITES || millis()-t0>WRITE_STALL_MS) break; // cliente lento ou travado
        feedWDT(); continue;
      }
      size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
      if(n==0){
        zeroWrites++;
        if(zeroWrites>MAX_ZERO_WRITES || millis()-t0>WRITE_STALL_MS) break;
        feedWDT(); continue;
      }
      zeroWrites = 0;
      p+=n; todo-=n; feedWDT();
    }
    cli.print("\r\n");

    if(freeIt) free(jpg);
    esp_camera_fb_return(fb);
    last=(uint64_t)esp_timer_get_time();

    // ABR: ajusta qualidade baseado no tamanho/tempo
    uint32_t dt = millis() - t0;
    bool slow = (dt > SEND_SLOW_MS);
    if(todo==0){
      if(len > ABR_BIG_FRAME || slow){
        g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 2);
        s->set_quality(s, g_jpeg_quality);
      }else if(len < ABR_SMALL_FRAME && !slow){
        g_jpeg_quality = std::max(Q_MIN, g_jpeg_quality - 1);
        s->set_quality(s, g_jpeg_quality);
      }
    }else{
      // não conseguiu mandar todo o frame -> aumenta Q e tenta de novo no próximo loop
      g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 3);
      s->set_quality(s, g_jpeg_quality);
      // quebra para reiniciar cabeçalhos da próxima conexão do cliente
      break;
    }

    maybeDownscaleForMemory();
    feedWDT();
  }
  cli.stop();
}

// ===== WiFi =====
void connectWiFi(){
  WiFi.persistent(false);
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  if(!WiFi.config(LOCAL_IP, GATEWAY, SUBNET, DNS1, DNS2)){
    Serial.println("WiFi.config failed; falling back to DHCP");
  }
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0=millis(); while(WiFi.status()!=WL_CONNECTED && millis()-t0<20000UL){ delay(200); }
}

void ensureWiFi(){
  static unsigned long last=0; unsigned long now=millis(); if(now-last<2000) return; last=now;
  if(WiFi.status()!=WL_CONNECTED){ WiFi.disconnect(true,true); delay(100); connectWiFi(); }
}

// ===== Setup / Loop =====
void setup(){
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  pinMode(LED_FLASH_PIN,OUTPUT); digitalWrite(LED_FLASH_PIN,LOW);
  pinMode(PUMP_PIN,OUTPUT);      digitalWrite(PUMP_PIN,LOW);
  setCpuFrequencyMhz(160);
  Serial.begin(UART_BAUD); delay(200);

#if ESP_IDF_VERSION_MAJOR >= 5
  const esp_task_wdt_config_t cfg = { .timeout_ms = 8000, .idle_core_mask = (1<<portNUM_PROCESSORS)-1, .trigger_panic = true };
  esp_task_wdt_init(&cfg);
#else
  esp_task_wdt_init(8,true);
#endif
  esp_task_wdt_add(NULL);

  if(!initCamera()){
    delay(500);
    ESP.restart();
  }
  connectWiFi();

  server.on("/status",   HTTP_GET, handleStatus);
  server.on("/led",      HTTP_GET, handleLed);
  server.on("/pump",     HTTP_GET, handlePump);
  server.on("/uart",     HTTP_GET, handleUART);
  server.on("/joystick", HTTP_GET, handleJoystick);
  server.on("/stream",   HTTP_GET, handleStream);
  server.on("/snapshot", HTTP_GET, handleSnapshot);
  server.on("/jpg",      HTTP_GET, handleSnapshot);
  server.on("/", HTTP_GET, [](){
    sendCORS();
    server.send(200,"text/plain",
      "HydroBot ESP32-CAM OK\n/stream, /snapshot, /jpg, /status, /led, /pump, /joystick, /uart");
  });

  server.begin();
}

void loop(){
  server.handleClient();
  ensureWiFi();
  feedWDT();
}



O que isso corrige na prática:




Stream MJPEG agora permanece aberto (keep-alive) e tolera clientes lentos sem matar a conexão imediatamente.


Envio de partes do MJPEG ficou mais estável (timeouts maiores e detecção de “write estagnado”).


/snapshot envia com CORS e evita travar se o cliente parar de ler no meio.


Se a memória ficar curta, a câmera reduz a resolução automaticamente e aumenta o jpeg_quality para manter estabilidade — melhor quando você aponta para cenas “pesadas” (muito detalhe).




Teste direto:




Direto no app (modo DIRECT): http://192.168.3.3/stream


Servidor (modo SERVER): http://192.168.3.4:8000/snapshot (ele puxa do ESP em /snapshot)




Se ainda não aparecer imagem, confirme:




Celular e ESP no mesmo Wi-Fi (sub-rede 192.168.3.x).


Abra no navegador do celular: http://192.168.3.3/ (deve mostrar a mensagem “HydroBot ESP32-CAM OK”).


Depois abra http://192.168.3.3/snapshot e http://192.168.3.3/stream.




Me diga o resultado e, se precisar, ajusto os parâmetros (framesize/quality) para o seu roteador.








































// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet, PanResponder,
  GestureResponderEvent, PanResponderGestureState, Image, Animated,
  LayoutChangeEvent, AppState,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

/* ---------- PALETA ---------- */
const PALETTE = { bg: "#0b0b0f", card: "#121218", border: "#25273a", accent: "#e6403a", text: "#e5e7eb" };

/* ---------- TEXTOS ---------- */
const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:", test: "Testar", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "BOMBA ON", pumpOff: "BOMBA OFF", server: "Servidor:",
    detecting: "Detectando…", saving: "Salvando...", statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem vídeo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `🔥 FOGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Pessoas", animals: "Animais", backend: "Modelo",
    waiting: "Aguardando servidor…", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:", test: "Test", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "PUMP ON", pumpOff: "PUMP OFF", server: "Server:",
    detecting: "Detecting…", saving: "Saving...", statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `🔥 FIRE • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "People", animals: "Animals", backend: "Model",
    waiting: "Waiting for server…", synced: "Server sync OK",
    mode: "Mode", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECT",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:", test: "Probar", ledOn: "LED ENC.", ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.", pumpOff: "BOMBA APAG.", server: "Servidor:",
    detecting: "Detectando…", saving: "Guardando...", statusFail: "Error de conexión. Revisa Wi-Fi/IP.",
    noVideo: "Sin vídeo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `🔥 FUEGO • score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego • score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.3.3", placeholderServer: "http://192.168.3.4:8000",
    persons: "Personas", animals: "Animales", backend: "Modelo",
    waiting: "Esperando servidor…", synced: "Server sync OK",
    mode: "Modo", modeAuto: "AUTO", modeServer: "SERVER", modeDirect: "DIRECTO",
  },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 640, h: 480 };

const appLogo = require("../../assets/logo.png");

/* ---------- HERO ---------- */
function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

/* ---------- SNAPSHOT com crossfade ---------- */
function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 100, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

/* ---------- OVERLAY ---------- */
type BoxType = "fire" | "person" | "animal";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType; conf?: number; };

function BoxesOverlay({
  frameWH, containerWH, boxes,
}: { frameWH: { w: number; h: number } | null; containerWH: { w: number; h: number } | null; boxes: SrcBox[]; }) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale, top = b.y * scale, width = b.w * scale, height = b.h * scale;
          let borderColor = "#ff3b30"; if (b.type === "person") borderColor = "#00e5ff"; else if (b.type === "animal") borderColor = "#7CFC00";
          return (
            <View key={`${i}-${b.type}`} style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor, borderRadius: 6 }}>
              <View style={{ position: "absolute", left: 0, top: -18, paddingHorizontal: 6, paddingVertical: 2, borderRadius: 4, backgroundColor: borderColor }}>
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>
                  {b.type.toUpperCase()}{typeof b.conf === "number" ? ` ${b.conf.toFixed(2)}` : ""}
                </Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

/* ---------- TELA PRINCIPAL ---------- */
type Mode = "auto" | "server" | "direct";

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conexões
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState(T.waiting);
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detecção (server)
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("—");
  const [confMax, setConfMax] = useState<number>(0);

  // caixas + dimensões
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  // registro automático
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // SNAPSHOT (server)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // health/mode
  const [serverReady, setServerReady] = useState(false);
  const [mode, setMode] = useState<Mode>("auto");

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);
  const detectUrl = useMemo(() => `${cleanServer(server)}/detect`, [server]);
  const snapshotUrl = useMemo(() => `${cleanServer(server)}/snapshot`, [server]);
  const configUrl = useMemo(() => `${cleanServer(server)}/config`, [server]);
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const joystickUrl = useMemo(() => (x: number, y: number) => `http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`, [ip]);
  const uartUrl = useMemo(() => (line: string) => `http://${ip}/uart?line=${encodeURIComponent(line)}`, [ip]);
  const directStreamHtml = useMemo(
    () => `<html><head><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
      <style>html,body{margin:0;background:#000;height:100%}img{width:100%;height:100%;object-fit:contain;}</style></head>
      <body><img src="http://${ip}/stream" /></body></html>`,
    [ip]
  );

  /* ===== AppState ===== */
  const appStateRef = useRef(AppState.currentState);
  useEffect(() => {
    const sub = AppState.addEventListener("change", (s) => { appStateRef.current = s; });
    return () => sub.remove();
  }, []);

  /* ===== Sincroniza IP do ESP dentro do server ===== */
  useEffect(() => {
    let aborted = false;
    (async () => {
      try {
        const r = await fetch(configUrl, { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ camera_ip: ip }) });
        const j = await r.json();
        if (!aborted && j?.ok) setStatusText(T.synced + ` (${j.camera_ip})`);
      } catch { if (!aborted) setStatusText(T.statusFail); }
    })();
    return () => { aborted = true; };
  }, [ip, configUrl, T]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led); setPumpOn(!!j.pump);
      setStatusText(`OK • ip:${j.ip ?? ip} • mode:${j.mode ?? "—"} • led:${j.led ? "on" : "off"} • pump:${j.pump ? "on" : "off"}`);
    } catch { setStatusText(T.statusFail); }
    finally { setIsChecking(false); }
  }
  async function toggleLed() { try { const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t); } catch { setStatusText(T.statusFail); } }
  async function togglePump(){ try { const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); } catch { setStatusText(T.statusFail); } }
  useEffect(() => { pingStatus(); const id = setInterval(pingStatus, 5000); return () => clearInterval(id); }, [statusUrl]);

  /* ===== HEALTH-CHECK DO SERVIDOR ===== */
  useEffect(() => {
    let stop = false;
    let backoff = 600, fail = 0;
    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl);
        const j = await r.json();
        const ok = !!j?.ok && !!j?.hasFrame;
        setServerReady(ok);
        setStatusText(ok ? `Server OK • hasFrame:${j.hasFrame}` : T.waiting);
        fail = ok ? 0 : fail + 1;
      } catch { fail++; setServerReady(false); setStatusText(T.waiting); }
      if (mode === "auto" && fail >= 3) setStatusText("Falha no servidor • alternando para DIRECT");
      setTimeout(poll, Math.min((backoff *= 1.35), 5000));
    };
    poll(); return () => { stop = true; };
  }, [healthUrl, mode, T]);

  /* ===== SNAPSHOT LOOP (pull do servidor) ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    let stop = false;
    let interval = 110; // ~9 fps (equilíbrio /snapshot)

    setCurrentFrameUri(`${snapshotUrl}?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!loadingNextRef.current) setNextFrameUri(`${snapshotUrl}?ts=${Date.now()}`);
        interval = 110;
      } catch { interval = Math.min(interval * 1.6, 1200); }
      setTimeout(tick, interval);
    };
    tick();
    return () => { stop = true; };
  }, [snapshotUrl, serverReady, mode]);

  function onNextLoadStart(){ loadingNextRef.current = true; }
  function onNextShown(ok: boolean){ if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri); loadingNextRef.current = false; }

  /* ===== DETECÇÃO ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;

    let stop = false;
    let interval = 200;
    const controller = new AbortController();

    const loop = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        const r = await fetch(detectUrl, { signal: controller.signal });
        const j = await r.json();
        if (j && j.ok !== false) {
          setIsFire(!!j.isFire); setFireScore(Number(j.score || 0));

          const wh = Array.isArray(j.frame_wh) && j.frame_wh.length === 2 ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 } : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);

          const o = j.objects || {}; const objs = o.objects || [];
          const nPerson = typeof o.n_person_stable === "number" ? o.n_person_stable : (typeof o.n_person === "number" ? o.n_person : objs.filter((x: any) => String(x.label).toLowerCase() === "person").length);
          const nAnimals = typeof o.n_animals_stable === "number" ? o.n_animals_stable : (typeof o.n_animals === "number" ? o.n_animals : objs.filter((x: any) => String(x.label).toLowerCase() !== "person").length);

          setPeople(nPerson || 0); setAnimals(nAnimals || 0);
          setBackend(o.backend || "—"); setConfMax(Number(o.conf_max || 0));

          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) { if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0); boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          for (const it of objs) {
            if (!it || !Array.isArray(it.box) || it.box.length < 4) continue;
            const [x, y, w, h] = it.box.map((n: any) => Number(n) || 0);
            const label = String(it.label || "").toLowerCase(); const conf = typeof it.conf === "number" ? it.conf : undefined;
            if (label === "person") boxes.push({ x, y, w, h, type: "person", conf }); else boxes.push({ x, y, w, h, type: "animal", conf });
          }
          setOverlayBoxes(boxes);
          interval = 200;
        }
      } catch {
        setIsFire(false); setFireScore(0); setPeople(0); setAnimals(0); setOverlayBoxes([]);
        interval = Math.min(interval * 1.6, 1500);
      } finally { setTimeout(loop, interval); }
    };
    loop();
    return () => { stop = true; controller.abort(); };
  }, [detectUrl, serverReady, mode]);

  /* ===== Registro automático ===== */
  useEffect(() => {
    const usingServer = (mode === "server") || (mode === "auto" && serverReady);
    if (!usingServer) return;
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;
    if (rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch { setStatusText(T.noVideo); } finally { setSaving(false); }
      })();
    }
    wasFireRef.current = isFire;
  }, [isFire, server, saving, T, serverReady, mode]);

  /* ===== Joystick ===== */
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(PanResponder.create({
    onStartShouldSetPanResponder: () => true,
    onMoveShouldSetPanResponder: () => true,
    onPanResponderGrant: () => setDragging(true),
    onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
      let nx = g.dx / RADIUS, ny = g.dy / RADIUS; const len = Math.hypot(nx, ny);
      if (len > 1) { nx /= len; ny /= len; } setJoy({ x: nx, y: -ny });
    },
    onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
  })).current;

  const lastSendRef = useRef(0); const lastDirRef = useRef<string>("STOP");
  const trySendJoystick = async (x: number, y: number) => { try { await fetch(joystickUrl(x, y)); return true; } catch { return false; } };
  const sendDiscreteCmd = async (dir: "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP", ms = 180, spd = 70) => {
    const line = dir === "STOP" ? "CMD:STOP"
      : `CMD:${dir}:ms=${Math.max(80, Math.min(ms, 600))}:spd=${Math.max(30, Math.min(spd, 100))}`;
    try { await fetch(uartUrl(line)); return true; } catch { return false; }
  };
  const vecToDir = (x: number, y: number): "FWD" | "BACK" | "LEFT" | "RIGHT" | "STOP" => {
    const mag = Math.hypot(x, y); if (mag < 0.2) return "STOP";
    const deg = (Math.atan2(y, x) * 180) / Math.PI;
    if (deg > -45 && deg <= 45) return "RIGHT"; if (deg > 45 && deg <= 135) return "FWD";
    if (deg <= -45 && deg > -135) return "BACK"; return "LEFT";
  };

  useEffect(() => {
    let cancelled = false;
    const tick = async () => {
      if (cancelled) return;
      const now = Date.now(); if (now - lastSendRef.current < 120) { setTimeout(tick, 20); return; }
      lastSendRef.current = now;
      const { x, y } = joy; const mag = Math.hypot(x, y);
      const ok = await trySendJoystick(x, y);
      if (ok) {
        if (mag < 0.2 && lastDirRef.current !== "STOP") { await sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; }
        setTimeout(tick, 120); return;
      }
      const dir = vecToDir(x, y);
      if (dir !== lastDirRef.current) {
        const ms = 140 + Math.round(260 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd); lastDirRef.current = dir;
      } else if (dir !== "STOP") {
        const ms = 120 + Math.round(200 * Math.min(1, mag)); const spd = 50 + Math.round(50 * Math.min(1, mag));
        await sendDiscreteCmd(dir, ms, spd);
      }
      setTimeout(tick, 120);
    };
    if (AppState.currentState === "active") tick();
    return () => { cancelled = true; };
  }, [joy, ip]);

  useEffect(() => {
    const handleBg = (s: string) => { if (s !== "active") { sendDiscreteCmd("STOP"); lastDirRef.current = "STOP"; } };
    const sub = AppState.addEventListener("change", handleBg);
    return () => sub.remove();
  }, []);

  function onVideoLayout(e: LayoutChangeEvent) { const { width, height } = e.nativeEvent.layout; setVideoContainerWH({ w: width, h: height }); }

  const usingServer = (mode === "server") || (mode === "auto" && serverReady);
  const usingDirect = (mode === "direct") || (mode === "auto" && !serverReady);

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Pressable onPress={pingStatus} style={styles.btn}><Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text></Pressable>
        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text></Pressable>
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}><Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text></Pressable>
      </View>

      {/* Linha: Servidor + Modo */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => { setServer(s); setServerReady(false); setStatusText(T.waiting); }}
          placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Text style={styles.label}>{T.mode}</Text>
        <View style={{ flexDirection: "row", gap: 6 }}>
          <Pressable onPress={() => setMode("auto")} style={[styles.modeBtn, mode === "auto" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeAuto}</Text></Pressable>
          <Pressable onPress={() => setMode("server")} style={[styles.modeBtn, mode === "server" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeServer}</Text></Pressable>
          <Pressable onPress={() => setMode("direct")} style={[styles.modeBtn, mode === "direct" && styles.modeBtnActive]}><Text style={styles.modeText}>{T.modeDirect}</Text></Pressable>
        </View>
        <View style={[styles.badge, { backgroundColor: usingServer ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>{usingServer ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
      </View>

      {/* Banner de fogo (apenas server) */}
      {usingServer && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
        </View>
      )}

      {/* Pessoas/animais */}
      {usingServer && (
        <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
          <Text style={styles.statChip}>{T.persons}: <Text style={styles.statNumber}>{people}</Text></Text>
          <Text style={styles.statChip}>{T.animals}: <Text style={styles.statNumber}>{animals}</Text></Text>
          <Text style={styles.modelChip}>{T.backend}: {backend} • conf_max {confMax.toFixed(2)}</Text>
        </View>
      )}

      {/* Vídeo */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        {usingServer ? (
          <>
            <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri} onNextLoadStart={onNextLoadStart} onNextShown={onNextShown} />
            {overlayBoxes.length > 0 && (<BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />)}
          </>
        ) : (
          <WebView originWhitelist={["*"]} source={{ html: directStreamHtml, baseUrl: `http://${ip}/` }}
            allowsInlineMediaPlayback mediaPlaybackRequiresUserAction={false} javaScriptEnabled domStorageEnabled
            setSupportMultipleWindows={false} overScrollMode="never" style={{ backgroundColor: "black" }}
          />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View style={[styles.joyKnob, { width: 22 * 2, height: 22 * 2, borderRadius: 22, transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }], opacity: dragging ? 1 : 0.9 }]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

/* ---------- ESTILOS ---------- */
const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },
  topbar: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 10, gap: 8, backgroundColor: PALETTE.card, borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: { backgroundColor: "#0b0d14", color: "white", borderRadius: 8, paddingHorizontal: 10, paddingVertical: 8, borderWidth: 1, borderColor: PALETTE.border, minWidth: 110 },
  btn: { backgroundColor: PALETTE.accent, paddingHorizontal: 10, paddingVertical: 10, borderRadius: 10 },
  btnOn: { backgroundColor: "#17a34a" }, btnOff: { backgroundColor: "#374151" }, btnText: { color: "white", fontWeight: "600" },
  statusRow: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 8, gap: 8, backgroundColor: "#0f1322", borderBottomWidth: StyleSheet.hairlineWidth, borderBottomColor: PALETTE.border },
  badge: { paddingHorizontal: 10, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: PALETTE.border },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },
  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 }, fireOn: { backgroundColor: "#8b0000" }, fireOff: { backgroundColor: "#223" }, fireText: { color: "white", fontWeight: "800" },
  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" }, statNumber: { color: "#fff" }, modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(230,64,58,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
  modeBtn: { backgroundColor: "#1f2937", paddingHorizontal: 8, paddingVertical: 6, borderRadius: 8, borderWidth: 1, borderColor: "#334155" },
  modeBtnActive: { backgroundColor: "#0b5", borderColor: "#0b5" },
  modeText: { color: "#fff", fontWeight: "700", fontSize: 12 },
});







# server_heuristic.py
# FOGO (heurístico) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny) usando "pull snapshot" do ESP
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== CONFIG DA CÂMERA =====================
CAMERA_IP = "192.168.3.3"               # IP do ESP no roteador
SNAP_URLS = [                           # tentativas em ordem
    "http://{ip}/snapshot",
    "http://{ip}/jpg",
]
STATUS_URL = "http://{ip}/status"

# Robustez
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 5.0
JPEG_QUALITY = 85

# ===================== FOGO (heurístico) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 12.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 2500
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 10.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}

YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (Snapshot Pull)", version="2.0.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== FONTE DE FRAMES (pull) =====================
class SnapshotSource:
    """Busca JPEGs sob demanda do ESP e mantém cache curto."""
    def __init__(self, ip: str):
        self._lock = threading.Lock()
        self.ip = ip
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._session = requests.Session()
        self._last_err = ""

    def set_ip(self, ip: str):
        with self._lock:
            self.ip = ip
            self._last_jpeg = None
            self._last_ts_ms = 0

    def _fetch_once(self) -> Optional[bytes]:
        for fmt in SNAP_URLS:
            url = fmt.format(ip=self.ip)
            try:
                r = self._session.get(url, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT))
                if r.status_code == 200 and r.headers.get("Content-Type","").startswith("image/"):
                    return r.content
            except Exception as e:
                self._last_err = f"{type(e).__name__} on {url}"
        return None

    def fetch_fresh(self) -> Optional[bytes]:
        """Busca um frame novo e atualiza cache."""
        jpeg = self._fetch_once()
        ts_ms = int(time.time()*1000)
        with self._lock:
            if jpeg:
                self._last_jpeg = jpeg
                self._last_ts_ms = ts_ms
                self._last_err = ""
            return self._last_jpeg

    def get_recent_or_fetch(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        """Retorna frame recente; se velho/ausente, tenta buscar."""
        with self._lock:
            has_recent = self._last_jpeg is not None and (int(time.time()*1000)-self._last_ts_ms)<=max_age_ms
            jpeg = self._last_jpeg if has_recent else None
        if jpeg is not None:
            return jpeg
        return self.fetch_fresh()

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = (int(time.time()*1000)-self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self.ip, "hasFrame": self._last_jpeg is not None, "age_ms": age, "last_err": self._last_err}

src = SnapshotSource(CAMERA_IP)

# ===================== VISÃO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area: boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, source: SnapshotSource):
        self.src = source
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0
        self._last_frame_wh: Tuple[int,int] = (0,0)

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_recent_or_fetch()
            if jpeg is None: time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.01); continue
            H,W = frame.shape[:2]
            self._last_frame_wh = (W,H)

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else: self._persist_hits = 1
            else: self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
            elif ema<=HYST_LOW: guess=0
            else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)
                self._det_frames+=1
                now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval: time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema,3),
                "score_raw": round(self._score_raw,3),
                "score_ema": round(self._score_ema,3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps,2),
                "vote": {"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                "persist": {"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                "hyst": {"hi":HYST_HIGH,"lo":HYST_LOW},
                "frame_wh": list(self._last_frame_wh) if self._last_frame_wh else None,
            }

detector = Detector(src); detector.start()

# ===================== OBJETOS =====================
class ObjectsDetector:
    def __init__(self, source: SnapshotSource):
        self.src = source
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None; self.ok = False
        self.proto = None; self.weights = None; self.cfg = None; self.names = None
        self.labels = []
        self.swap_rb = False
        self._nohit = 0
        self._last_conf_max = 0.0

        self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
        self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
        self.hold_person_until = 0
        self.hold_animal_until = 0

        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        cands_p = [
            "./models/MobileNetSSD_deploy.prototxt",
            "./models/MobileNetSSD_deploy.prototxt.txt",
            "./models/deploy.prototxt",
            "./models/voc/MobileNetSSD_test.prototxt",
        ]
        cands_w = [
            "./models/MobileNetSSD_deploy.caffemodel",
            "./models/mobilenet_iter_73000.caffemodel",
        ]
        self.proto = next((p for p in cands_p if os.path.exists(p)), None)
        self.weights = next((w for w in cands_w if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok = False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok = False; self.net=None

    def _try_load_yolo(self):
        self.backend = "yolov4-tiny"
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,(300,300)),
                                     0.007843, (300,300), 127.5, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in {"person","cat","dog","bird","horse","sheep","cow"}: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = src.get_recent_or_fetch()
            if jpeg is None: time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.01); continue

            out=[]; cmax=0.0; backend=self.backend
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False
                    with self._lock:
                        self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                                    "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            n_person  = sum(1 for o in out if o["label"]=="person")
            n_animals = sum(1 for o in out if o["label"]!="person")
            hit_person  = 1 if n_person  > 0 else 0
            hit_animal  = 1 if n_animals > 0 else 0
            self.votes_person.append(hit_person)
            self.votes_animal.append(hit_animal)
            now_ms = int(time.time()*1000)
            if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
            if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
            stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
            stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                            "n_person":n_person,"n_animals":n_animals,
                            "n_person_stable":1 if stable_person else 0,
                            "n_animals_stable":1 if stable_animal else 0}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(src); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/healthz")
def healthz():
    # se há frame recente, ok; senão tenta um fetch rápido
    st = src.status()
    if not st["hasFrame"] or (st["age_ms"] is None or st["age_ms"]>MAX_FRAME_AGE_MS):
        src.fetch_fresh()
        st = src.status()
    # tenta também /status do ESP (não bloqueia o OK do frame)
    esp_info = {}
    try:
        r = requests.get(STATUS_URL.format(ip=src.ip), timeout=(1.5, 2.0))
        if r.ok: esp_info = r.json()
    except Exception:
        pass
    return {"ok": True, "hasFrame": bool(st["hasFrame"]), "age_ms": st["age_ms"], "esp": esp_info}

@app.get("/status")
def status():
    s2 = detector.get_result()
    st = src.status()
    return {"ok": True, "camera_ip": st["ip"], "hasFrame": st["hasFrame"], "age_ms": st["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    src.set_ip(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = src.get_recent_or_fetch(MAX_FRAME_AGE_MS)
    if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res

    # cálculo rápido em modo fallback
    jpeg = src.get_recent_or_fetch(MAX_FRAME_AGE_MS)
    if jpeg is None: return {"ok": False, "error": "no frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return {"ok": False, "error": "decode failed"}
    H,W = frame.shape[:2]
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "frame_wh":[W,H],
            "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = src.get_recent_or_fetch(MAX_FRAME_AGE_MS)
    if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get(); backend = o.get("backend"); det = objects_det
    try:
        if backend=="yolov4-tiny":
            # usa conf recebido
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, float(conf))))
        else:
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, float(conf))))
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_stream")
def debug_stream():
    return src.status()















// HydroBot ESP32-CAM - Stable (fixed IP) - ASCII only
// Endpoints: /status /led /pump /joystick /uart /stream /snapshot (/jpg)
// Key: fb_count=2 + CAMERA_GRAB_LATEST, adaptive JPEG quality, no Nagle, non-blocking writes.

#include <WiFi.h>
#include <WebServer.h>
#include "esp_camera.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "esp_task_wdt.h"
#include "esp_idf_version.h"
#include <math.h>
#include <algorithm>

// WiFi (static IP)
const char* WIFI_SSID = "HydroBot";
const char* WIFI_PASS = "loud2025emibr";
IPAddress LOCAL_IP(192,168,3,3);
IPAddress GATEWAY (192,168,3,1);
IPAddress SUBNET  (255,255,255,0);
IPAddress DNS1    (8,8,8,8);
IPAddress DNS2    (1,1,1,1);

// Pins (AI-Thinker)
#define LED_FLASH_PIN 4
#define PUMP_PIN      14

WebServer server(80);

// Stream params
static const char*   BOUNDARY              = "frame";
static const framesize_t STREAM_FRAMESIZE  = FRAMESIZE_QVGA; // 320x240
static int           g_jpeg_quality        = 26;             // 18..34 adaptive
static const int     STREAM_TARGET_FPS     = 10;
static const uint32_t UART_BAUD            = 115200;

// ABR thresholds
static const size_t  ABR_BIG_FRAME   = 52000;   // bytes
static const size_t  ABR_SMALL_FRAME = 24000;   // bytes
static const int     Q_MIN = 18;
static const int     Q_MAX = 34;
static const uint32_t SEND_SLOW_MS = 220;

volatile bool ledOn=false, pumpOn=false;

String localIP() { return WiFi.isConnected() ? WiFi.localIP().toString() : String("0.0.0.0"); }
static inline void feedWDT(){ esp_task_wdt_reset(); yield(); }

// Camera init
bool initCamera(){
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0; c.ledc_timer = LEDC_TIMER_0;
  c.pin_d0=5;  c.pin_d1=18; c.pin_d2=19; c.pin_d3=21; c.pin_d4=36; c.pin_d5=39; c.pin_d6=34; c.pin_d7=35;
  c.pin_xclk=0; c.pin_pclk=22; c.pin_vsync=25; c.pin_href=23;
  c.pin_sscb_sda=26; c.pin_sscb_scl=27;
  c.pin_pwdn=32; c.pin_reset=-1;
  c.xclk_freq_hz=20000000;
  c.pixel_format=PIXFORMAT_JPEG;

  c.frame_size   = STREAM_FRAMESIZE;
  c.jpeg_quality = g_jpeg_quality;
  c.fb_count     = 2;                        // double buffer
  c.fb_location  = CAMERA_FB_IN_PSRAM;
  c.grab_mode    = CAMERA_GRAB_LATEST;       // drop old, keep newest

  esp_err_t err = esp_camera_init(&c);
  if(err!=ESP_OK){ Serial.printf("Camera init failed: 0x%x\n", err); return false; }

  sensor_t* s = esp_camera_sensor_get();
  s->set_brightness(s,0); s->set_contrast(s,0); s->set_saturation(s,0);
  s->set_whitebal(s,1); s->set_awb_gain(s,1);
  s->set_exposure_ctrl(s,1); s->set_aec2(s,0);
  s->set_gain_ctrl(s,1); s->set_agc_gain(s,0); s->set_gainceiling(s,(gainceiling_t)0);
  s->set_bpc(s,0); s->set_wpc(s,1); s->set_raw_gma(s,1); s->set_lenc(s,1);
  s->set_hmirror(s,0); s->set_vflip(s,0); s->set_dcw(s,1); s->set_colorbar(s,0);
  return true;
}

static inline void sendCORS(){ server.sendHeader("Access-Control-Allow-Origin","*"); }

void handleStatus(){
  String j="{\"ok\":true,\"ip\":\""+localIP()+"\",\"mode\":\"mjpeg-stream\",\"led\":"+String(ledOn?"true":"false")+
           ",\"pump\":"+String(pumpOn?"true":"false")+",\"heap\":"+String(ESP.getFreeHeap())+
           ",\"q\":"+String(g_jpeg_quality)+"}";
  sendCORS(); server.send(200,"application/json",j);
}

void handleLed(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !ledOn;
  ledOn = on; digitalWrite(LED_FLASH_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"led\":")+(on?"true":"false")+"}");
}

void handlePump(){
  bool on = server.hasArg("on") ? (server.arg("on")!="0") : !pumpOn;
  pumpOn = on; digitalWrite(PUMP_PIN,on?HIGH:LOW);
  sendCORS(); server.send(200,"application/json",String("{\"ok\":true,\"pump\":")+(on?"true":"false")+"}");
}

void handleUART(){
  if(!server.hasArg("line")){ server.send(400,"application/json","{\"ok\":false,\"err\":\"missing line\"}"); return; }
  Serial.print(server.arg("line")); Serial.print("\n");
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleJoystick(){
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.0f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.0f;
  Serial.printf("JOY:x=%.3f:y=%.3f\n",x,y);
  float mag = sqrtf(x*x+y*y);
  const char* dir="STOP";
  if(mag>=0.2f){
    float deg = atan2f(y,x)*180.0f/3.1415926f;
    if(deg>-45 && deg<=45) dir="RIGHT";
    else if(deg>45 && deg<=135) dir="FWD";
    else if(deg<=-45 && deg>-135) dir="BACK";
    else dir="LEFT";
  }
  int ms=(mag<0.2f)?0:180+int(200*std::min(1.0f,mag));
  int spd=(mag<0.2f)?0: 50+int( 50*std::min(1.0f,mag));
  Serial.printf("CMD:%s:ms=%d:spd=%d\n",dir,ms,spd);
  sendCORS(); server.send(200,"application/json","{\"ok\":true}");
}

void handleSnapshot(){
  camera_fb_t* fb = esp_camera_fb_get();
  if(!fb){ server.send(503,"text/plain","NO_FRAME"); return; }
  uint8_t* jpg = fb->buf; size_t len = fb->len; bool freeIt=false;
  if(fb->format!=PIXFORMAT_JPEG){
    if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){ esp_camera_fb_return(fb); server.send(500,"text/plain","ENCODE_FAIL"); return; }
    freeIt=true;
  }
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache"); server.sendHeader("Expires","0");
  server.setContentLength(len); server.send(200,"image/jpeg","");
  WiFiClient cli = server.client(); const uint8_t* p=jpg; size_t todo=len;
  while(todo>0){
    size_t can = cli.availableForWrite();
    if(can==0){ feedWDT(); continue; }
    size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
    if(n==0){ feedWDT(); continue; }
    p+=n; todo-=n; feedWDT();
  }
  if(freeIt) free(jpg); esp_camera_fb_return(fb);
}

void handleStream(){
  WiFiClient cli = server.client();
  cli.setTimeout(2000);
  cli.setNoDelay(true);
  cli.print(
    "HTTP/1.1 200 OK\r\n"
    "Cache-Control: no-cache, no-store, must-revalidate\r\n"
    "Pragma: no-cache\r\n"
    "Expires: 0\r\n"
    "Connection: close\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=frame\r\n\r\n"
  );

  const uint64_t minIv = 1000000ULL/STREAM_TARGET_FPS;
  uint64_t last=0;
  uint8_t zeroWrites=0;
  sensor_t* s = esp_camera_sensor_get();

  while(cli.connected()){
    uint64_t now=(uint64_t)esp_timer_get_time();
    if(now-last<minIv){ feedWDT(); continue; }

    camera_fb_t* fb = esp_camera_fb_get();
    if(!fb){ feedWDT(); continue; }

    uint8_t* jpg=fb->buf; size_t len=fb->len; bool freeIt=false;
    if(fb->format!=PIXFORMAT_JPEG){
      if(!frame2jpg(fb,g_jpeg_quality,&jpg,&len)){ esp_camera_fb_return(fb); feedWDT(); continue; }
      freeIt=true;
    }

    cli.printf("--%s\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n",BOUNDARY,(unsigned)len);

    uint32_t t0 = millis();
    const uint8_t* p=jpg; size_t todo=len;
    zeroWrites = 0;

    while(todo>0){
      size_t can = cli.availableForWrite();
      if(can==0){
        zeroWrites++;
        if(zeroWrites>40){ break; }
        feedWDT(); continue;
      }
      size_t n = cli.write(p, std::min((size_t)1460, std::min(todo, can)));
      if(n==0){
        zeroWrites++;
        if(zeroWrites>40) break;
        feedWDT(); continue;
      }
      zeroWrites = 0;
      p+=n; todo-=n;
      feedWDT();
    }
    cli.print("\r\n");

    if(freeIt) free(jpg);
    esp_camera_fb_return(fb);
    last=(uint64_t)esp_timer_get_time();

    // ABR: adjust quality based on size and send time
    uint32_t dt = millis() - t0;
    bool slow = (dt > SEND_SLOW_MS);
    if(todo==0){
      if(len > ABR_BIG_FRAME || slow){
        g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 2);
        s->set_quality(s, g_jpeg_quality);
      }else if(len < ABR_SMALL_FRAME && !slow){
        g_jpeg_quality = std::max(Q_MIN, g_jpeg_quality - 1);
        s->set_quality(s, g_jpeg_quality);
      }
    }else{
      g_jpeg_quality = std::min(Q_MAX, g_jpeg_quality + 3);
      s->set_quality(s, g_jpeg_quality);
      break;
    }

    if(!cli.connected()) break;
    feedWDT();
  }
  cli.stop();
}

// WiFi
void connectWiFi(){
  WiFi.persistent(false);
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  if(!WiFi.config(LOCAL_IP, GATEWAY, SUBNET, DNS1, DNS2)){
    Serial.println("WiFi.config failed; falling back to DHCP");
  }
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  unsigned long t0=millis(); while(WiFi.status()!=WL_CONNECTED && millis()-t0<20000UL){ delay(200); }
}

void ensureWiFi(){
  static unsigned long last=0; unsigned long now=millis(); if(now-last<2000) return; last=now;
  if(WiFi.status()!=WL_CONNECTED){ WiFi.disconnect(true,true); delay(100); connectWiFi(); }
}

// Setup / Loop
void setup(){
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  pinMode(LED_FLASH_PIN,OUTPUT); digitalWrite(LED_FLASH_PIN,LOW);
  pinMode(PUMP_PIN,OUTPUT);      digitalWrite(PUMP_PIN,LOW);
  setCpuFrequencyMhz(160);
  Serial.begin(UART_BAUD); delay(200);

#if ESP_IDF_VERSION_MAJOR >= 5
  const esp_task_wdt_config_t cfg = { .timeout_ms = 8000, .idle_core_mask = (1<<portNUM_PROCESSORS)-1, .trigger_panic = true };
  esp_task_wdt_init(&cfg);
#else
  esp_task_wdt_init(8,true);
#endif
  esp_task_wdt_add(NULL);

  if(!initCamera()){ delay(500); ESP.restart(); }
  connectWiFi();

  server.on("/status",   HTTP_GET, handleStatus);
  server.on("/led",      HTTP_GET, handleLed);
  server.on("/pump",     HTTP_GET, handlePump);
  server.on("/uart",     HTTP_GET, handleUART);
  server.on("/joystick", HTTP_GET, handleJoystick);
  server.on("/stream",   HTTP_GET, handleStream);
  server.on("/snapshot", HTTP_GET, handleSnapshot);
  server.on("/jpg",      HTTP_GET, handleSnapshot);
  server.on("/", HTTP_GET, [](){ server.send(200,"text/plain",
    "HydroBot ESP32-CAM OK\n/stream, /snapshot, /jpg, /status, /led, /pump, /joystick, /uart"); });

  server.begin();
}

void loop(){
  server.handleClient();
  ensureWiFi();
  feedWDT();
}
