https://chatgpt.com/share/68b78dcd-48bc-800d-b32a-aecc510baa8b

https://chatgpt.com/share/68b78dcd-48bc-800d-b32a-aecc510baa8b

Perfeito — vamos migrar o seu projeto para Bluetooth (SPP/Serial), tirar WebView/navegador do app, mover o LED para um pino seguro que não conflita com a roda, e preparar a rota com TensorFlow fora da ESP32-CAM (no Node.js). Já deixo tudo funcionando sem TF e com toggles no app para:




Fonte do vídeo: direto da ESP por Bluetooth (sem TF) ou via servidor (com TF habilitável).


Troca de modo: manual / auto / patrol (via Bluetooth).


Joystick: envia vetores x/y.


Bomba (MOSFET): botão ON/OFF.


LED indicador: realocado para pino seguro.






⚠️ Observações importantes




Bluetooth clássico (SPP) funciona no Android. No iOS o SPP não é suportado; se precisar iOS, usamos Wi-Fi ou BLE (sem vídeo fluido).


Expo Go não tem Bluetooth clássico. Use Expo Dev Build (ou bare) com react-native-bluetooth-serial-next. Abaixo deixo o passo-a-passo.







A) Firmware ESP32-CAM (Bluetooth + vídeo em Base64 + comandos)


O que muda




Sem Wi-Fi/HTTP — tudo por Bluetooth Serial.


Vídeo MJPEG capturado, encodado em base64 e enviado como NDJSON (JSON por linha). FPS baixo (1–2) para caber no throughput do SPP.


Comandos simples por texto (linhas): CMD:MODE:auto, CMD:STREAM:1, CMD:JOY:x,y, CMD:PUMP:1, CMD:LED:1, CMD:TF:1.


LED indicador movido para GPIO 33 (saída OK). PUMP no GPIO 32. (Ambos não conflitam com câmera; fio um LED externo no 33 com resistor).




Crie o arquivo HydroBotBT.ino:


/**
 * HydroBotBT.ino — ESP32-CAM (AI Thinker) via Bluetooth SPP
 * - Captura frames JPEG e envia via Bluetooth como NDJSON (1 linha por evento)
 * - Sem Wi-Fi/HTTP. Tudo por SerialBT.
 * - Comandos por linha (texto): CMD:...
 * - LED indicador em GPIO 33 (não conflita com roda/motores)
 * - MOSFET da bomba em GPIO 32
 * - Sem sensor IR por enquanto
 *
 * OBS: FPS baixo (1–2) por limitação de banda do SPP
 */

#include "esp_camera.h"
#include <BluetoothSerial.h>
#include <time.h>
#include "mbedtls/base64.h"

// ===== Pins (AI Thinker) =====
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ===== Seus atuadores sem conflito =====
#define LED_IND_PIN  33   // LED indicador externo
#define PUMP_PIN     32   // MOSFET da bomba

BluetoothSerial SerialBT;

// ===== Estado =====
String g_mode = "manual";
bool   g_streamOn = true;     // envia frames
bool   g_ledOn    = false;    // LED indicador
bool   g_pumpOn   = false;    // bomba
bool   g_tfOn     = false;    // só espelha no status (TF roda fora)
float  g_joyX     = 0.0f;
float  g_joyY     = 0.0f;

uint32_t lastFrameMs = 0;
uint32_t frameIntervalMs = 700; // ~1.4 fps (ajuste ao seu gosto)
char lineBuf[256];

// ===== Util =====
void writeJsonLine(const String& s) {
  SerialBT.write((const uint8_t*)s.c_str(), s.length());
  SerialBT.write('\n');
}

String isoTsUptime() {
  // sem NTP → uptime
  char buf[64];
  snprintf(buf, sizeof(buf), "{\"uptime_ms\":%lu}", millis());
  return String(buf);
}

// ===== Camera =====
bool initCamera() {
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0;
  c.ledc_timer   = LEDC_TIMER_0;
  c.pin_d0       = Y2_GPIO_NUM;
  c.pin_d1       = Y3_GPIO_NUM;
  c.pin_d2       = Y4_GPIO_NUM;
  c.pin_d3       = Y5_GPIO_NUM;
  c.pin_d4       = Y6_GPIO_NUM;
  c.pin_d5       = Y7_GPIO_NUM;
  c.pin_d6       = Y8_GPIO_NUM;
  c.pin_d7       = Y9_GPIO_NUM;
  c.pin_xclk     = XCLK_GPIO_NUM;
  c.pin_pclk     = PCLK_GPIO_NUM;
  c.pin_vsync    = VSYNC_GPIO_NUM;
  c.pin_href     = HREF_GPIO_NUM;
  c.pin_sscb_sda = SIOD_GPIO_NUM;
  c.pin_sscb_scl = SIOC_GPIO_NUM;
  c.pin_pwdn     = PWDN_GPIO_NUM;
  c.pin_reset    = RESET_GPIO_NUM;
  c.xclk_freq_hz = 20000000;
  c.pixel_format = PIXFORMAT_JPEG;

  if (psramFound()) {
    c.frame_size   = FRAMESIZE_QVGA; // 320x240 para reduzir base64
    c.jpeg_quality = 22;             // + número = + compactação
    c.fb_count     = 2;
    c.fb_location  = CAMERA_FB_IN_PSRAM;
    c.grab_mode    = CAMERA_GRAB_WHEN_EMPTY;
  } else {
    c.frame_size   = FRAMESIZE_QQVGA; // 160x120 fallback
    c.jpeg_quality = 25;
    c.fb_count     = 1;
    c.fb_location  = CAMERA_FB_IN_DRAM;
  }

  esp_err_t err = esp_camera_init(&c);
  if (err != ESP_OK) {
    Serial.printf("Camera init failed: 0x%x\n", err);
    return false;
  }

  sensor_t * s = esp_camera_sensor_get();
  if (s) {
    s->set_exposure_ctrl(s, 1);
    s->set_gain_ctrl(s, 1);
    s->set_brightness(s, 0);
    s->set_contrast(s, 0);
    s->set_saturation(s, 0);
    s->set_vflip(s, 0);
    s->set_hmirror(s, 0);
    s->set_dcw(s, 1);
  }
  return true;
}

// ===== Envio de frame como NDJSON base64 =====
void sendFrameBase64() {
  camera_fb_t * fb = esp_camera_fb_get();
  if (!fb) return;

  // Base64 tamanho ~ 4/3 do JPEG
  size_t outLen = 4 * ((fb->len + 2) / 3) + 4;
  uint8_t* b64 = (uint8_t*)malloc(outLen);
  if (!b64) {
    esp_camera_fb_return(fb);
    return;
  }

  size_t olen = 0;
  int rc = mbedtls_base64_encode(b64, outLen, &olen, fb->buf, fb->len);
  esp_camera_fb_return(fb);
  if (rc != 0) { free(b64); return; }

  // Monta JSON por partes para não estourar buffer interno do BT
  writeJsonLine(String("{\"evt\":\"frame\",\"fmt\":\"jpeg\",\"b64\":\"BEGIN\"}"));
  // envia o base64 em blocos
  const size_t CHUNK = 1000;
  for (size_t i = 0; i < olen; i += CHUNK) {
    size_t n = (i + CHUNK <= olen) ? CHUNK : (olen - i);
    SerialBT.write((const uint8_t*)"{\"chunk\":\"", 10);
    SerialBT.write((const uint8_t*)(b64 + i), n);
    SerialBT.write((const uint8_t*)"\"}\n", 3);
  }
  writeJsonLine(String("{\"evt\":\"frame\",\"b64\":\"END\"}"));
  free(b64);
}

// ===== Parser de comandos "CMD:..." por linha =====
void handleCmd(const String& line) {
  // Formatos aceitos:
  // CMD:MODE:auto
  // CMD:STREAM:1
  // CMD:JOY:x,y
  // CMD:PUMP:1
  // CMD:LED:1
  // CMD:TF:1
  if (!line.startsWith("CMD:")) return;
  int p1 = line.indexOf(':', 4);
  if (p1 < 0) return;
  String key = line.substring(4, p1);
  String val = line.substring(p1 + 1);
  val.trim();

  if (key == "MODE") {
    if (val == "manual" || val == "auto" || val == "patrol") {
      g_mode = val;
      writeJsonLine(String("{\"evt\":\"mode\",\"v\":\"") + g_mode + "\"}");
    }
  } else if (key == "STREAM") {
    g_streamOn = (val == "1" || val == "true");
    writeJsonLine(String("{\"evt\":\"stream\",\"on\":") + (g_streamOn?"true":"false") + "}");
  } else if (key == "LED") {
    g_ledOn = (val == "1" || val == "true");
    digitalWrite(LED_IND_PIN, g_ledOn ? HIGH : LOW);
    writeJsonLine(String("{\"evt\":\"led\",\"on\":") + (g_ledOn?"true":"false") + "}");
  } else if (key == "PUMP") {
    g_pumpOn = (val == "1" || val == "true");
    digitalWrite(PUMP_PIN, g_pumpOn ? HIGH : LOW);
    writeJsonLine(String("{\"evt\":\"pump\",\"on\":") + (g_pumpOn?"true":"false") + "}");
  } else if (key == "TF") {
    g_tfOn = (val == "1" || val == "true");
    writeJsonLine(String("{\"evt\":\"tf\",\"on\":") + (g_tfOn?"true":"false") + "}");
  } else if (key == "JOY") {
    int c = val.indexOf(',');
    if (c > 0) {
      g_joyX = val.substring(0, c).toFloat();
      g_joyY = val.substring(c + 1).toFloat();
      // eco simples
      char buf[96];
      snprintf(buf, sizeof(buf), "{\"evt\":\"joy\",\"x\":%.3f,\"y\":%.3f}", g_joyX, g_joyY);
      writeJsonLine(String(buf));
    }
  }
}

// ===== Setup/Loop =====
void setup() {
  Serial.begin(115200);
  pinMode(LED_IND_PIN, OUTPUT);
  pinMode(PUMP_PIN, OUTPUT);
  digitalWrite(LED_IND_PIN, LOW);
  digitalWrite(PUMP_PIN, LOW);

  if (!initCamera()) {
    Serial.println("Falha camera");
    delay(3000);
    ESP.restart();
  }

  // Bluetooth
  if (!SerialBT.begin("HYDROBOT")) {
    Serial.println("BT falhou");
    while (1) delay(1000);
  }
  Serial.println("BT pronto: HYDROBOT");

  // Status inicial
  writeJsonLine(String("{\"evt\":\"status\",\"ts\":") + isoTsUptime() +
                ",\"mode\":\"" + g_mode + "\",\"stream\":" + (g_streamOn?"true":"false") + "}");
}

void loop() {
  // Leitura de comandos por linha
  static String acc;
  while (SerialBT.available()) {
    char ch = (char)SerialBT.read();
    if (ch == '\n' || ch == '\r') {
      if (acc.length() > 0) { handleCmd(acc); acc = ""; }
    } else {
      if (acc.length() < 200) acc += ch; // evita linhas absurdas
    }
  }

  // Envio periódico de frame
  uint32_t now = millis();
  if (g_streamOn && now - lastFrameMs >= frameIntervalMs && SerialBT.hasClient()) {
    lastFrameMs = now;
    sendFrameBase64();
  }

  // Status ping a cada ~3s
  static uint32_t lastPing = 0;
  if (now - lastPing > 3000) {
    lastPing = now;
    writeJsonLine(String("{\"evt\":\"status\",\"ts\":") + isoTsUptime() +
      ",\"mode\":\"" + g_mode + "\",\"led\":" + (g_ledOn?"true":"false") +
      ",\"pump\":" + (g_pumpOn?"true":"false") + ",\"tf\":" + (g_tfOn?"true":"false") + "}");
  }
}





Fiação:




LED indicador: GPIO33 → resistor 220Ω → LED → GND.


Bomba (MOSFET): GPIO32 → gate (MOSFET logic-level) + resistência 100k pull-down gate-GND; não alimente bomba pelo 3V3 da placa.







B) App React Native (Expo Dev Build, TS) — Bluetooth + vídeo + controles


1) Projeto e dependências


npx create-expo-app hydrobot-bt -t expo-template-blank-typescript
cd hydrobot-bt

# Bluetooth Clássico:
yarn add react-native-bluetooth-serial-next
# se usar npm: npm i react-native-bluetooth-serial-next

# Pré-build (cria projeto nativo)
npx expo prebuild

# Android: habilite BLUETOOTH perms automaticamente pelo pacote.
# Gere Dev Build:
eas build:configure
eas build --profile development --platform android
# Instale o .apk de dev no aparelho e abra o app com ele (não Expo Go).





Se preferir bare, rode npx react-native run-android.




2) Serviço de Bluetooth — src/services/bluetooth.ts


// src/services/bluetooth.ts
import BluetoothSerial from 'react-native-bluetooth-serial-next';
import { NativeEventEmitter } from 'react-native';

type Listener = (msg: any) => void;

let connectedId: string | null = null;
let lineBuffer = '';

const listeners = new Set<Listener>();

export async function ensureEnabled() {
  const ok = await BluetoothSerial.isEnabled();
  if (!ok) await BluetoothSerial.requestEnable();
}

export async function listDevices() {
  const bonded = await BluetoothSerial.list();
  return bonded; // [{id,name,address},...]
}

export async function connectByName(name: string) {
  const devs = await listDevices();
  const dev = devs.find(d => (d.name || '').includes(name));
  if (!dev) throw new Error(`Dispositivo '${name}' não pareado`);
  await BluetoothSerial.connect(dev.id);
  connectedId = dev.id;
  // ler dados contínuos
  BluetoothSerial.withDelimiter('\n'); // separa por \n
  BluetoothSerial.on('read', ({ data }) => {
    // cada 'data' é uma linha (string)
    try {
      const obj = JSON.parse(data);
      for (const cb of listeners) cb(obj);
    } catch {
      // pode chegar chunks do frame ({"chunk":"..."}), ainda é JSON
      try {
        const o2 = JSON.parse(data);
        for (const cb of listeners) cb(o2);
      } catch {}
    }
  });
}

export function onMsg(cb: Listener) { listeners.add(cb); return () => listeners.delete(cb); }

async function send(line: string) {
  if (!connectedId) throw new Error('BT não conectado');
  await BluetoothSerial.write(line + '\n');
}

// === Comandos ===
export async function setMode(v: 'manual'|'auto'|'patrol') {
  await send(`CMD:MODE:${v}`);
}
export async function setStream(on: boolean) {
  await send(`CMD:STREAM:${on ? 1 : 0}`);
}
export async function setLED(on: boolean) {
  await send(`CMD:LED:${on ? 1 : 0}`);
}
export async function setPump(on: boolean) {
  await send(`CMD:PUMP:${on ? 1 : 0}`);
}
export async function setTF(on: boolean) {
  await send(`CMD:TF:${on ? 1 : 0}`);
}
export async function sendJoy(x: number, y: number) {
  const nx = Math.max(-1, Math.min(1, x));
  const ny = Math.max(-1, Math.min(1, y));
  await send(`CMD:JOY:${nx.toFixed(3)},${ny.toFixed(3)}`);
}



3) Componente de Joystick — src/components/Joystick.tsx


// src/components/Joystick.tsx
import React, { useMemo, useState } from 'react';
import { View, PanResponder } from 'react-native';

export default function Joystick({ onMove }:{ onMove:(x:number,y:number)=>void }) {
  const size = 160, knob = 64;
  const r = size/2, rk = knob/2;
  const [p,setP] = useState({x:0,y:0});
  const pan = useMemo(()=>PanResponder.create({
    onStartShouldSetPanResponder:()=>true,
    onPanResponderMove:(_,g)=>{
      const lim = r - rk;
      let x = g.dx, y = g.dy;
      const mag = Math.hypot(x,y);
      if (mag > lim) { const k = lim/mag; x*=k; y*=k; }
      setP({x,y});
      onMove(x/lim, -y/lim);
    },
    onPanResponderRelease:()=>{
      setP({x:0,y:0});
      onMove(0,0);
    }
  }),[]);
  return (
    <View {...pan.panHandlers} style={{
      width:size,height:size,borderRadius:r,backgroundColor:'#101827',
      borderWidth:1,borderColor:'#223',justifyContent:'center',alignItems:'center'
    }}>
      <View style={{
        position:'absolute',width:knob,height:knob,borderRadius:rk,backgroundColor:'#4f7cff',
        transform:[{translateX:p.x},{translateY:p.y}]
      }}/>
    </View>
  );
}



4) Montagem da tela — App.tsx


// App.tsx
import React, { useEffect, useMemo, useRef, useState } from 'react';
import { SafeAreaView, View, Text, TouchableOpacity, TextInput, Image, ScrollView, Alert } from 'react-native';
import Joystick from './src/components/Joystick';
import { ensureEnabled, connectByName, onMsg, setMode, setLED, setPump, setStream, setTF, sendJoy } from './src/services/bluetooth';

type FrameState = { collecting:boolean, chunks:string[], last:string };

export default function App() {
  const [btName,setBtName] = useState('HYDROBOT');
  const [status,setStatus] = useState<any>({});
  const [imgB64,setImgB64] = useState<string>('');
  const [useServer,setUseServer] = useState(false); // fonte do vídeo: false=ESP direto; true=servidor
  const [tfOn,setTfOn] = useState(false);

  useEffect(()=>{ (async()=>{
    try {
      await ensureEnabled();
      await connectByName(btName);
      const off = onMsg((msg)=>{
        // Protocolo:
        // {evt:"frame", b64:"BEGIN"} / {chunk:"..."} / {evt:"frame", b64:"END"}
        // {evt:"status"...} etc.
        if (msg.evt === 'status' || msg.evt === 'mode' || msg.evt === 'led' || msg.evt === 'pump' || msg.evt === 'tf') {
          setStatus((s:any)=>({ ...s, ...msg }));
        } else if (msg.evt === 'frame' && msg.b64 === 'BEGIN') {
          frame.current = { collecting:true, chunks:[], last:'' };
        } else if (msg.evt === 'frame' && msg.b64 === 'END') {
          const b64 = frame.current.chunks.join('');
          setImgB64(b64);
          frame.current = { collecting:false, chunks:[], last:'' };
        } else if (typeof msg.chunk === 'string') {
          if (frame.current.collecting) frame.current.chunks.push(msg.chunk);
        }
      });
      return ()=>off();
    } catch (e:any) {
      Alert.alert('BT', e.message || String(e));
    }
  })(); }, []);

  const frame = useRef<FrameState>({ collecting:false, chunks:[], last:'' });

  async function toggleLED(){ await setLED(!(status.led)); }
  async function togglePump(){ await setPump(!(status.pump)); }
  async function toggleStream(){ await setStream(!(status.stream)); }
  async function switchMode(m:'manual'|'auto'|'patrol'){ await setMode(m); }
  async function toggleTF(){
    const next = !tfOn; setTfOn(next);
    await setTF(next);
    // Quando usar servidor, o TF real roda lá; no app apenas espelhamos estado.
  }

  const videoView = useMemo(()=>{
    if (useServer) {
      return (
        <View style={{height:220, borderRadius:10, backgroundColor:'#000', alignItems:'center', justifyContent:'center'}}>
          <Text style={{color:'#fff', opacity:0.7}}>Vídeo via Servidor (TF)</Text>
          {/* Em próxima etapa, conectamos ao WS ws://servidor:4000 para receber frames processados */}
        </View>
      );
    }
    return (
      <View style={{height:220, borderRadius:10, backgroundColor:'#000', overflow:'hidden', alignItems:'center', justifyContent:'center'}}>
        {imgB64 ? (
          <Image source={{ uri: 'data:image/jpeg;base64,' + imgB64 }} style={{ width:'100%', height:'100%', resizeMode:'contain' }}/>
        ) : (
          <Text style={{color:'#fff', opacity:0.7}}>Sem frame ainda…</Text>
        )}
      </View>
    );
  },[useServer, imgB64]);

  return (
    <SafeAreaView style={{flex:1, backgroundColor:'#0b1220'}}>
      <ScrollView contentContainerStyle={{padding:16, gap:12}}>
        <Text style={{color:'#fff', fontSize:20, fontWeight:'700'}}>HydroBot — Bluetooth</Text>

        <View style={{flexDirection:'row', gap:8}}>
          <TextInput value={btName} onChangeText={setBtName}
            placeholder="Nome BT (pareado) — HYDROBOT" placeholderTextColor="#789"
            style={{flex:1, backgroundColor:'#111a2e', color:'#fff', padding:10, borderRadius:8}} />
        </View>

        {videoView}

        <View style={{flexDirection:'row', gap:8, flexWrap:'wrap'}}>
          <TouchableOpacity onPress={toggleLED} style={{backgroundColor:'#2e374f', padding:10, borderRadius:8}}><Text style={{color:'#fff'}}>LED {status.led ? 'ON' : 'OFF'}</Text></TouchableOpacity>
          <TouchableOpacity onPress={togglePump} style={{backgroundColor:'#2e374f', padding:10, borderRadius:8}}><Text style={{color:'#fff'}}>Bomba {status.pump ? 'ON' : 'OFF'}</Text></TouchableOpacity>
          <TouchableOpacity onPress={()=>switchMode('manual')} style={{backgroundColor: (status.mode==='manual')?'#3a6df0':'#2e374f', padding:10, borderRadius:8}}><Text style={{color:'#fff'}}>Manual</Text></TouchableOpacity>
          <TouchableOpacity onPress={()=>switchMode('auto')} style={{backgroundColor: (status.mode==='auto')?'#3a6df0':'#2e374f', padding:10, borderRadius:8}}><Text style={{color:'#fff'}}>Auto</Text></TouchableOpacity>
          <TouchableOpacity onPress={()=>switchMode('patrol')} style={{backgroundColor: (status.mode==='patrol')?'#3a6df0':'#2e374f', padding:10, borderRadius:8}}><Text style={{color:'#fff'}}>Patrol</Text></TouchableOpacity>
          <TouchableOpacity onPress={toggleStream} style={{backgroundColor:'#2e374f', padding:10, borderRadius:8}}><Text style={{color:'#fff'}}>Stream {status.stream ? 'ON':'OFF'}</Text></TouchableOpacity>
          <TouchableOpacity onPress={toggleTF} style={{backgroundColor: tfOn ? '#22c55e' : '#2e374f', padding:10, borderRadius:8}}>
            <Text style={{color:'#fff'}}>TensorFlow {tfOn ? 'ON' : 'OFF'}</Text>
          </TouchableOpacity>
          <TouchableOpacity onPress={()=>setUseServer(!useServer)} style={{backgroundColor: useServer ? '#22c55e' : '#2e374f', padding:10, borderRadius:8}}>
            <Text style={{color:'#fff'}}>Fonte: {useServer ? 'Servidor (TF)' : 'ESP direto'}</Text>
          </TouchableOpacity>
        </View>

        <View style={{alignItems:'center', marginTop:6}}>
          <Joystick onMove={(x,y)=>{ sendJoy(x,y).catch(()=>{}); }} />
          <Text style={{color:'#8cb', marginTop:6}}>Arraste para enviar JOY (x,y)</Text>
        </View>
      </ScrollView>
    </SafeAreaView>
  );
}





O app acima envia/recebe tudo por Bluetooth e mostra vídeo direto da ESP (sem navegador).

Quando você alternar para “Servidor (TF)”, o painel de vídeo já troca (na próxima seção ligamos o servidor com TF + WebSocket).





C) Servidor intermediário (Node.js) — Bluetooth ↔ TF ↔ App (WebSocket)


Objetivo: rodar TensorFlow fora da ESP e automatizar “detectar fogo ⇒ aciona bomba + ir até o fogo”.


Aqui deixo um servidor funcional que:




Conecta ao Bluetooth SPP da ESP (nome HYDROBOT).


Recebe NDJSON (frames em base64).


(Stub TF) Faz detecção simplificada (lugar do TF real) e envia evento por WebSocket.


Repassa comandos de autonomia para a ESP (ex.: liga bomba quando “fogo” detectado).




server/
  package.json
  index.js



server/package.json


{
  "name": "hydrobot-server",
  "version": "1.0.0",
  "type": "module",
  "dependencies": {
    "bluetooth-serial-port": "^2.2.8",
    "ws": "^8.18.0",
    "jimp": "^0.22.12"
  }
}



server/index.js


import { BluetoothSerialPort } from 'bluetooth-serial-port';
import { WebSocketServer } from 'ws';
import Jimp from 'jimp';

const DEV_NAME = process.env.ESP_NAME || 'HYDROBOT';

const bt = new BluetoothSerialPort();
let btChannelOpen = false;

const wss = new WebSocketServer({ port: 4000 });
const clients = new Set();

wss.on('connection', ws => {
  clients.add(ws);
  ws.on('close', ()=>clients.delete(ws));
});

function broadcast(obj) {
  const s = JSON.stringify(obj);
  for (const ws of clients) {
    try { ws.send(s); } catch {}
  }
}

function findAndConnect() {
  bt.inquire();
  bt.on('found', function(address, name) {
    if (!name) return;
    if (name.includes(DEV_NAME)) {
      bt.findSerialPortChannel(address, channel => {
        bt.connect(address, channel, () => {
          console.log('BT conectado a', name, address, 'ch', channel);
          btChannelOpen = true;

          // peca stream
          writeLine('CMD:STREAM:1');

          let acc = '';
          bt.on('data', (buf) => {
            acc += buf.toString('utf8');
            let i;
            while ((i = acc.indexOf('\n')) >= 0) {
              const line = acc.slice(0, i).trim();
              acc = acc.slice(i + 1);
              if (!line) continue;
              handleLine(line);
            }
          });

        }, () => console.log('Falha BT connect'));
      }, () => console.log('Sem canal SPP'));
    }
  });
}

function writeLine(s) {
  if (!btChannelOpen) return;
  bt.write(Buffer.from(s + '\n', 'utf8'), (err) => {
    if (err) console.log('BT write err', err);
  });
}

// Coleta de frame (BEGIN/chunks/END) vinda da ESP
const frameCollector = { collecting:false, parts:[] };

async function handleLine(line) {
  try {
    const obj = JSON.parse(line);
    if (obj.evt === 'frame' && obj.b64 === 'BEGIN') {
      frameCollector.collecting = true;
      frameCollector.parts = [];
    } else if (obj.evt === 'frame' && obj.b64 === 'END') {
      const b64 = frameCollector.parts.join('');
      frameCollector.collecting = false;
      frameCollector.parts = [];
      broadcast({ evt:'frame', b64 });

      // === STUB de detecção (substitua por TF real) ===
      try {
        const img = await Jimp.read(Buffer.from(b64, 'base64'));
        // regra boba: pixel "vermelho forte" acima de limiar
        let redCount = 0, tot = img.bitmap.width * img.bitmap.height;
        img.scan(0,0,img.bitmap.width,img.bitmap.height,function(x,y,idx){
          const r=this.bitmap.data[idx], g=this.bitmap.data[idx+1], b=this.bitmap.data[idx+2];
          if (r > 200 && g < 120 && b < 120) redCount++;
        });
        const ratio = redCount / tot;
        const fire = ratio > 0.08; // limiar experimental
        broadcast({ evt:'detect', fire, ratio });

        if (fire) {
          writeLine('CMD:PUMP:1');        // liga bomba
          writeLine('CMD:MODE:auto');     // sinaliza modo auto (você pode usar para acionar locomoção)
          // Próximo passo: calcular direção do “centro vermelho” e mandar JOY para perseguir.
        }
      } catch (e) {}
    } else if (typeof obj.chunk === 'string') {
      if (frameCollector.collecting) frameCollector.parts.push(obj.chunk);
    } else {
      broadcast(obj); // status/mode/led/pump/tf/joy…
    }
  } catch {}
}

findAndConnect();
console.log('WS em ws://localhost:4000  (broadcast frames/detections)')





Próxima etapa para TF real: trocar o bloco Jimp pelo @tensorflow/tfjs-node + modelo de “fire detection” (classificação em recortes ou detecção com YOLO-lite). A estrutura acima já envia {evt:'detect', fire, ratio} para o app e comanda a ESP (bomba + modo) ao detectar.





D) App — recebendo do servidor (quando “Servidor (TF)” estiver ativo)


No App.tsx, quando useServer === true, você pode abrir um WebSocket e substituir imgB64/eventos pelos do servidor:


// adicione no App.tsx
useEffect(()=>{
  if (!useServer) return;
  const ws = new WebSocket('ws://<IP_DO_NOTEBOOK>:4000');
  ws.onmessage = (e)=>{
    try{
      const msg = JSON.parse(e.data);
      if (msg.evt === 'frame' && msg.b64) setImgB64(msg.b64);
      if (msg.evt === 'detect') {
        // pode mostrar um badge “🔥”
      }
    }catch{}
  };
  return ()=>{ try{ws.close();}catch{} }
}, [useServer]);





Assim você alterna: ESP direto (Bluetooth) ou Servidor (TF) por um botão — como você pediu.





E) Passo a passo (resumo executável)






Grave a ESP32-CAM com HydroBotBT.ino.




LED indicador → GPIO33 (externo).


MOSFET bomba → GPIO32.


Pareie a ESP no Android (nome HYDROBOT).








App (Expo Dev Build)




Instale dependências, expo prebuild, gere Dev Build e instale o .apk.


Abra o app, BT ligado, nome HYDROBOT, aguarde status → vídeo surgirá (1–2 fps).








Servidor (opcional p/ TF)




cd server && npm i && node index.js


No app, ative “Servidor (TF)” para receber frames do WS.


(Hoje está com detecção stub via “vermelho” e comanda PUMP + MODE:auto automaticamente.)









F) Próximos incrementos (quando você quiser)




Auto-drive real: no servidor, calcule o centro do fogo (momento vermelho) e envie CMD:JOY:x,y para perseguir — já está tudo encadeado.


TF real: trocar o stub por modelo TFJS/Node (ex.: MobileNet+SVM ou YOLO-tiny).


Segurança elétrica: diodo flyback na bomba, fonte 5V/2A, GND comum.


iOS: usar Wi-Fi ou BLE GATT (com streaming reduzido) — podemos te dar uma variação.





Se quiser, eu já acoplo a lógica de perseguição (cálculo de vetor JOY a partir do centro detectado) e deixo curva exponencial/limiar para o joystick, além de debounce da bomba (só ligar por 2–3s e pausar).




















perfeito — seu firmware expõe GET /pump?on=1|0. Vou adicionar um botão Bomba ON/OFF na mesma barra da câmera, espelhando o estado que vem de /status.


Substitua src/screens/CameraScreen.tsx pelo código abaixo (mudanças: estado pumpOn, url pumpUrl, leitura em pingStatus(), botão togglePump()):


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  ActivityIndicator,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
} from "react-native";
import { WebView } from "react-native-webview";

const DEFAULT_IP = "192.168.4.1"; // IP padrão do AP do ESP32-CAM

export default function CameraScreen() {
  const [ip, setIp] = useState(DEFAULT_IP);
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState<string>("—");

  const [ledOn, setLedOn] = useState<boolean>(false);
  const [pumpOn, setPumpOn] = useState<boolean>(false);

  // Joystick state (UI por enquanto)
  const [joy, setJoy] = useState<{ x: number; y: number }>({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  const webref = useRef<WebView>(null);

  const streamUrl = useMemo(() => `http://${ip}:81/stream`, [ip]);
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl   = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl  = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl, { method: "GET" });
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(
        `OK • ip:${j.ip} • mode:${j.mode} • led:${j.led ? "on" : "off"} • pump:${j.pump ? "on" : "off"}`
      );
    } catch {
      setStatusText("Falha ao conectar. Confira o Wi-Fi HYDROBOT-CAM e o IP.");
    } finally {
      setIsChecking(false);
    }
  }

  async function toggleLed() {
    try {
      const target = !ledOn;
      await fetch(ledUrl(target));
      setLedOn(target);
      setStatusText((s) => `LED ${target ? "ligado" : "desligado"} • ` + s.replace(/^LED .* • /, ""));
    } catch {
      setStatusText("Erro ao alternar LED.");
    }
  }

  async function togglePump() {
    try {
      const target = !pumpOn;
      await fetch(pumpUrl(target));
      setPumpOn(target);
      setStatusText((s) => `Bomba ${target ? "ligada" : "desligada"} • ` + s.replace(/^Bomba .* • /, ""));
    } catch {
      setStatusText("Erro ao alternar bomba.");
    }
  }

  useEffect(() => {
    pingStatus();
    const id = setInterval(pingStatus, 5000);
    return () => clearInterval(id);
  }, [statusUrl]);

  // HTML simples p/ MJPEG
  const html = `
    <html>
      <head><meta name="viewport" content="width=device-width, initial-scale=1" /></head>
      <body style="margin:0;background:#000;display:flex;align-items:center;justify-content:center;height:100vh;">
        <img src="${streamUrl}" style="width:100%;height:100%;object-fit:contain;" />
      </body>
    </html>
  `;

  // ===== Joystick (UI) =====
  const RADIUS = 64;
  const KNOB_R = 22;

  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS;
        let ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) { nx /= len; ny /= len; }
        setJoy({ x: nx, y: -ny }); // y para cima positivo
      },
      onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
      onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    })
  ).current;

  const knobLeft = joy.x * RADIUS;
  const knobTop = -joy.y * RADIUS;

  return (
    <View style={styles.container}>
      {/* Barra de controle */}
      <View style={styles.topbar}>
        <Text style={styles.label}>ESP IP:</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder="192.168.4.1"
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : "Testar"}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? "LED ON" : "LED OFF"}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? "BOMBA ON" : "BOMBA OFF"}</Text>
        </Pressable>
      </View>

      {/* Status */}
      <View style={styles.statusRow}>
        {isChecking ? <ActivityIndicator /> : null}
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
        <Pressable onPress={() => webref.current?.reload()} style={[styles.btn, { marginLeft: 8 }]}>
          <Text style={styles.btnText}>Recarregar</Text>
        </Pressable>
      </View>

      {/* Vídeo MJPEG */}
      <WebView
        ref={webref}
        originWhitelist={["*"]}
        source={{ html }}
        style={styles.web}
        allowFileAccess
        allowingReadAccessToURL={"*"}
        javaScriptEnabled
        domStorageEnabled
        allowUniversalAccessFromFileURLs
        allowsInlineMediaPlayback
        mediaPlaybackRequiresUserAction={false}
      />

      {/* Joystick overlay (UI apenas) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View
          style={[styles.joyWrap, { width: RADIUS * 2 + 24, height: RADIUS * 2 + 24 }]}
          {...pan.panHandlers}
        >
          <View style={[styles.joyBase, { width: RADIUS * 2, height: RADIUS * 2, borderRadius: RADIUS }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: KNOB_R * 2,
                height: KNOB_R * 2,
                borderRadius: KNOB_R,
                transform: [{ translateX: knobLeft }, { translateY: knobTop }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)}   y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#0b1220" },
  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: "#111a33",
  },
  label: { color: "#9fb3ff", fontSize: 12 },
  input: {
    flex: 1,
    backgroundColor: "#0b1220",
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: "#1e2a4d",
  },
  btn: {
    backgroundColor: "#2b48ff",
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },
  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1730",
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },
  web: { flex: 1, backgroundColor: "black" },

  // Joystick
  joyWrap: {
    position: "absolute",
    bottom: 24,
    left: 24,
    alignItems: "center",
    justifyContent: "center",
  },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(43,72,255,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: {
    position: "absolute",
    bottom: -22,
    color: "#cbd5ff",
    fontSize: 12,
  },
});



Pronto — o botão BOMBA ON/OFF usa a rota /pump do seu ESP e mantém o estado sincronizado quando o /status é consultado.

Se quiser, no próximo passo adiciono um controle PWM (slider para /pump_pwm?duty=0..255).

















perfeito — vamos deixar o index/Home bonito e adicionar um rodapé com abas (Home, Câmera, Dashboard, Settings).

A navegação passa a usar Bottom Tabs do @react-navigation.



1) App.tsx (tabs + tema escuro)


Substitua o arquivo inteiro:


import { NavigationContainer, DefaultTheme, Theme } from "@react-navigation/native";
import { createBottomTabNavigator } from "@react-navigation/bottom-tabs";
import { Ionicons } from "@expo/vector-icons";

import HomeScreen from "./src/screens/HomeScreen";
import CameraScreen from "./src/screens/CameraScreen";
import DashboardScreen from "./src/screens/DashboardScreen";
import SettingsScreen from "./src/screens/SettingsScreen";

export type TabParamList = {
  Home: undefined;
  Camera: undefined;
  Dashboard: undefined;
  Settings: undefined;
};

const Tab = createBottomTabNavigator<TabParamList>();

// Tema dark do app
const DarkThemeHB: Theme = {
  ...DefaultTheme,
  colors: {
    ...DefaultTheme.colors,
    background: "#0b1220",
    primary: "#2b48ff",
    card: "#111a33",
    text: "#e5e7ff",
    border: "#1e2a4d",
    notification: "#2b48ff",
  },
};

export default function App() {
  return (
    <NavigationContainer theme={DarkThemeHB}>
      <Tab.Navigator
        initialRouteName="Home"
        screenOptions={({ route }) => ({
          headerStyle: { backgroundColor: "#111a33" },
          headerTintColor: "#fff",
          tabBarStyle: { backgroundColor: "#0f1730", borderTopColor: "#0f1730" },
          tabBarActiveTintColor: "#2b48ff",
          tabBarInactiveTintColor: "#8aa0ff",
          tabBarIcon: ({ color, size }) => {
            const icons: Record<keyof TabParamList, keyof typeof Ionicons.glyphMap> = {
              Home: "home",
              Camera: "videocam",
              Dashboard: "pulse",
              Settings: "settings",
            };
            return <Ionicons name={icons[route.name as keyof TabParamList]} size={size} color={color} />;
          },
        })}
      >
        <Tab.Screen name="Home" component={HomeScreen} options={{ title: "Início" }} />
        <Tab.Screen name="Camera" component={CameraScreen} options={{ title: "Câmera" }} />
        <Tab.Screen name="Dashboard" component={DashboardScreen} options={{ title: "Dashboard" }} />
        <Tab.Screen name="Settings" component={SettingsScreen} options={{ title: "Ajustes" }} />
      </Tab.Navigator>
    </NavigationContainer>
  );
}




2) src/screens/HomeScreen.tsx (hero + CTA)


Substitua o arquivo para um layout “hero card” com seu logo e botão para abrir a Câmera (troca para a aba Camera):


import { View, Text, StyleSheet, Image, Pressable } from "react-native";
import { useNavigation } from "@react-navigation/native";
import type { TabParamList } from "../../App";
import type { BottomTabNavigationProp } from "@react-navigation/bottom-tabs";

type Nav = BottomTabNavigationProp<TabParamList>;

export default function HomeScreen() {
  const navigation = useNavigation<Nav>();

  return (
    <View style={styles.container}>
      <View style={styles.card}>
        <Image
          source={require("../../assets/logo.png")} // salve sua imagem como assets/logo.png
          style={styles.logo}
          resizeMode="contain"
        />
        <Text style={styles.title}>HydroBotApp2</Text>
        <Text style={styles.subtitle}>Controle o robô • Vídeo • Bomba • LED</Text>

        <Pressable
          onPress={() => navigation.navigate("Camera")}
          style={({ pressed }) => [styles.cta, pressed && { opacity: 0.9 }]}
        >
          <Text style={styles.ctaText}>Abrir Câmera</Text>
        </Pressable>

        <View style={styles.linksRow}>
          <View style={styles.pill}><Text style={styles.pillText}>Dashboard</Text></View>
          <View style={styles.pill}><Text style={styles.pillText}>Ajustes</Text></View>
        </View>
      </View>

      <Text style={styles.footerHint}>Use as abas no rodapé para navegar</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#0b1220", alignItems: "center", justifyContent: "center", padding: 20 },
  card: {
    width: "100%",
    backgroundColor: "#111a33",
    borderRadius: 20,
    padding: 20,
    alignItems: "center",
    borderWidth: 1,
    borderColor: "#1e2a4d",
  },
  logo: { width: 140, height: 140, marginBottom: 12 },
  title: { color: "white", fontSize: 24, fontWeight: "800" },
  subtitle: { color: "#9fb3ff", fontSize: 14, marginTop: 4, textAlign: "center" },
  cta: {
    marginTop: 16,
    backgroundColor: "#2b48ff",
    borderRadius: 12,
    paddingVertical: 12,
    paddingHorizontal: 22,
    shadowColor: "#2b48ff",
    shadowOpacity: 0.25,
    shadowRadius: 8,
    elevation: 4,
  },
  ctaText: { color: "white", fontWeight: "700", fontSize: 16 },
  linksRow: { flexDirection: "row", gap: 8, marginTop: 16 },
  pill: { backgroundColor: "#0b1220", borderColor: "#1e2a4d", borderWidth: 1, paddingVertical: 6, paddingHorizontal: 10, borderRadius: 999 },
  pillText: { color: "#cbd5ff", fontSize: 12 },
  footerHint: { color: "#8aa0ff", marginTop: 14, fontSize: 12 },
});





Coloque a imagem que você enviou como assets/logo.png (PNG com fundo transparente fica top).





3) Novas telas “placeholder”


src/screens/DashboardScreen.tsx


import { View, Text, StyleSheet } from "react-native";

export default function DashboardScreen() {
  return (
    <View style={styles.container}>
      <Text style={styles.title}>Dashboard</Text>
      <Text style={styles.sub}>Aqui virão telemetria, gráficos e logs.</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#0b1220", alignItems: "center", justifyContent: "center" },
  title: { color: "white", fontSize: 22, fontWeight: "700" },
  sub: { color: "#9fb3ff", marginTop: 6 },
});



src/screens/SettingsScreen.tsx


import { View, Text, StyleSheet } from "react-native";

export default function SettingsScreen() {
  return (
    <View style={styles.container}>
      <Text style={styles.title}>Ajustes</Text>
      <Text style={styles.sub}>Preferências do app e conexões.</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#0b1220", alignItems: "center", justifyContent: "center" },
  title: { color: "white", fontSize: 22, fontWeight: "700" },
  sub: { color: "#9fb3ff", marginTop: 6 },
});





Sua CameraScreen.tsx permanece como fizemos (com LED, Bomba e Joystick UI). Ela já aparece como aba “Câmera”.





4) Ícones


@expo/vector-icons já vem com Expo; não precisa instalar nada extra.



Pronto! Você terá:




Home com hero + botão “Abrir Câmera”


Rodapé com abas: Home, Câmera, Dashboard, Settings


Tema dark consistente com seu logo HB 🔥💧




Se quiser, eu adiciono um badge na aba Câmera quando a conexão com o ESP32 falhar/sucesso, ou coloco labels grandes no tab bar.


























perfeito 👌 vamos deixar a tela inicial (Home) como um menu em grade com botões quadrados grandes, cada um levando para a aba correspondente. Os ícones vão usar Ionicons (já vem com Expo).



src/screens/HomeScreen.tsx (nova versão)


import { View, Text, StyleSheet, Pressable, Dimensions } from "react-native";
import { Ionicons } from "@expo/vector-icons";
import { useNavigation } from "@react-navigation/native";
import type { TabParamList } from "../../App";
import type { BottomTabNavigationProp } from "@react-navigation/bottom-tabs";

type Nav = BottomTabNavigationProp<TabParamList>;

const size = Dimensions.get("window").width / 2 - 32; // 2 colunas com espaçamento

export default function HomeScreen() {
  const navigation = useNavigation<Nav>();

  const items = [
    { name: "Camera" as keyof TabParamList, label: "Câmera", icon: "videocam" as const, color: "#2b48ff" },
    { name: "Dashboard" as keyof TabParamList, label: "Dashboard", icon: "pulse" as const, color: "#17a34a" },
    { name: "Settings" as keyof TabParamList, label: "Ajustes", icon: "settings" as const, color: "#eab308" },
  ];

  return (
    <View style={styles.container}>
      <Text style={styles.title}>HydroBotApp2</Text>
      <View style={styles.grid}>
        {items.map((item) => (
          <Pressable
            key={item.name}
            onPress={() => navigation.navigate(item.name)}
            style={({ pressed }) => [
              styles.card,
              { width: size, height: size, backgroundColor: item.color },
              pressed && { opacity: 0.85 },
            ]}
          >
            <Ionicons name={item.icon} size={42} color="white" />
            <Text style={styles.cardText}>{item.label}</Text>
          </Pressable>
        ))}
      </View>
      <Text style={styles.footerHint}>ou use o rodapé abaixo para navegar</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#0b1220", padding: 20 },
  title: { color: "white", fontSize: 24, fontWeight: "800", marginBottom: 20, textAlign: "center" },
  grid: { flexDirection: "row", flexWrap: "wrap", justifyContent: "space-between" },
  card: {
    borderRadius: 16,
    alignItems: "center",
    justifyContent: "center",
    marginBottom: 20,
    shadowColor: "#000",
    shadowOpacity: 0.3,
    shadowRadius: 6,
    elevation: 5,
  },
  cardText: { color: "white", marginTop: 10, fontWeight: "600", fontSize: 16 },
  footerHint: { textAlign: "center", color: "#8aa0ff", marginTop: 10, fontSize: 12 },
});




Como fica




Título em cima: HydroBotApp2


Grade de botões quadrados grandes (2 colunas):



📹 Câmera (azul)


📊 Dashboard (verde)


⚙️ Ajustes (amarelo)






Rodapé ainda existe (tabs) para navegação alternativa.





quer que eu já adicione também o botão da Home (🏠) nesse grid, ou prefere deixar Home só como hub de acesso às outras telas?





























perfeito! vamos alinhar tudo à paleta do logo (preto #000, vermelho bombeiro, branco gelo).

Vou te passar:




pequenas mudanças no tema (App.tsx)


HomeScreen redesenhada com dois botões quadrados grandes (Câmera e Dashboard) + logo no topo






Coloque a imagem do logo como assets/logo.png (use a que você enviou).





1) Tema no App.tsx (ajuste de cores)


Substitua apenas o bloco do tema e opções do Tab:


// ...
const PALETTE = {
  bg: "#000000",
  card: "#0d0d0d",
  border: "#1a1a1a",
  red: "#E53B2F",   // vermelho do logo
  redSoft: "#FF5A4D",
  white: "#FFFFFF",
  textSoft: "#E6E6E6",
};

const DarkThemeHB: Theme = {
  ...DefaultTheme,
  colors: {
    ...DefaultTheme.colors,
    background: PALETTE.bg,
    primary: PALETTE.red,
    card: PALETTE.card,
    text: PALETTE.white,
    border: PALETTE.border,
    notification: PALETTE.red,
  },
};

export default function App() {
  return (
    <NavigationContainer theme={DarkThemeHB}>
      <Tab.Navigator
        initialRouteName="Home"
        screenOptions={({ route }) => ({
          headerStyle: { backgroundColor: PALETTE.card },
          headerTintColor: PALETTE.white,
          tabBarStyle: { backgroundColor: PALETTE.bg, borderTopColor: PALETTE.border },
          tabBarActiveTintColor: PALETTE.red,
          tabBarInactiveTintColor: "#9c9c9c",
          // ícones mantidos
          tabBarIcon: ({ color, size }) => {
            const icons: Record<keyof TabParamList, keyof typeof Ionicons.glyphMap> = {
              Home: "home",
              Camera: "videocam",
              Dashboard: "pulse",
              Settings: "settings",
            };
            return <Ionicons name={icons[route.name as keyof TabParamList]} size={size} color={color} />;
          },
        })}
      >
        {/* as 4 abas continuam (Home, Camera, Dashboard, Settings) */}
        <Tab.Screen name="Home" component={HomeScreen} options={{ title: "Início" }} />
        <Tab.Screen name="Camera" component={CameraScreen} options={{ title: "Câmera" }} />
        <Tab.Screen name="Dashboard" component={DashboardScreen} options={{ title: "Dashboard" }} />
        <Tab.Screen name="Settings" component={SettingsScreen} options={{ title: "Ajustes" }} />
      </Tab.Navigator>
    </NavigationContainer>
  );
}




2) src/screens/HomeScreen.tsx (apenas Câmera e Dashboard)


import { View, Text, StyleSheet, Pressable, Dimensions, Image } from "react-native";
import { Ionicons } from "@expo/vector-icons";
import { useNavigation } from "@react-navigation/native";
import type { BottomTabNavigationProp } from "@react-navigation/bottom-tabs";
import type { TabParamList } from "../../App";

type Nav = BottomTabNavigationProp<TabParamList>;

const W = Dimensions.get("window").width;
const CARD = W / 2 - 28; // duas colunas com respiro lateral

const PALETTE = {
  bg: "#000000",
  card: "#0d0d0d",
  border: "#1a1a1a",
  red: "#E53B2F",
  redSoft: "#FF5A4D",
  white: "#FFFFFF",
  textSoft: "#E6E6E6",
};

export default function HomeScreen() {
  const navigation = useNavigation<Nav>();

  const tiles = [
    { key: "Camera" as const, label: "Câmera", icon: "videocam" as const, color: PALETTE.red },
    { key: "Dashboard" as const, label: "Dashboard", icon: "pulse" as const, color: PALETTE.redSoft },
  ];

  return (
    <View style={styles.container}>
      {/* topo com logo */}
      <View style={styles.hero}>
        <Image source={require("../../assets/logo.png")} style={styles.logo} resizeMode="contain" />
        <Text style={styles.title}>HydroBot</Text>
        <Text style={styles.sub}>Monitoramento e Controle</Text>
      </View>

      {/* grade de botões (somente 2) */}
      <View style={styles.grid}>
        {tiles.map((t) => (
          <Pressable
            key={t.key}
            onPress={() => navigation.navigate(t.key)}
            style={({ pressed }) => [
              styles.tile,
              { width: CARD, height: CARD, borderColor: t.color },
              pressed && { transform: [{ scale: 0.98 }] },
            ]}
          >
            <View style={[styles.tileInner, { backgroundColor: t.color }]}>
              <Ionicons name={t.icon} size={42} color={PALETTE.white} />
            </View>
            <Text style={styles.tileLabel}>{t.label}</Text>
          </Pressable>
        ))}
      </View>

      <Text style={styles.hint}>Use o rodapé para navegar entre as seções</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg, padding: 18 },
  hero: {
    alignItems: "center",
    marginTop: 6,
    marginBottom: 16,
  },
  logo: { width: 120, height: 120, marginBottom: 6 },
  title: { color: PALETTE.white, fontSize: 24, fontWeight: "800", letterSpacing: 0.5 },
  sub: { color: PALETTE.textSoft, fontSize: 12, marginTop: 2 },
  grid: {
    flexDirection: "row",
    flexWrap: "wrap",
    justifyContent: "space-between",
    rowGap: 16,
  },
  tile: {
    borderRadius: 18,
    borderWidth: 2,
    backgroundColor: PALETTE.card,
    overflow: "hidden",
  },
  tileInner: {
    flex: 1,
    alignItems: "center",
    justifyContent: "center",
  },
  tileLabel: {
    position: "absolute",
    bottom: 8,
    width: "100%",
    textAlign: "center",
    color: PALETTE.white,
    fontWeight: "700",
    fontSize: 16,
    textShadowColor: "rgba(0,0,0,0.4)",
    textShadowOffset: { width: 0, height: 1 },
    textShadowRadius: 2,
  },
  hint: { textAlign: "center", color: "#9c9c9c", marginTop: 12, fontSize: 12 },
});



O que mudou no design




Fundo preto; cartões e tab bar mais escuros (quase preto).


Acentos em vermelho do logo (borda dos cards e preenchimento do ícone).


Tipografia clara (branco e cinza-claro).


Logo no topo como identidade.




Se quiser, eu coloco um gradiente sutil vermelho→preto nos tiles ou um glow vermelho ao pressionar — mas mantive limpo e coerente com o logo.






























ótimo 🚀 vou juntar tudo que já montamos (tabs, tema, Home redesenhada, Câmera com LED+Bomba+Joystick, Dashboard e Settings placeholders).

Estrutura final:


HydroBotApp2/
  App.tsx
  app.json
  babel.config.js
  package.json
  src/
    screens/
      HomeScreen.tsx
      CameraScreen.tsx
      DashboardScreen.tsx
      SettingsScreen.tsx
  assets/
    logo.png   ← (a logo que você mandou, salva aqui)
    icon.png
    splash.png
    adaptive-icon.png




App.tsx


import { NavigationContainer, DefaultTheme, Theme } from "@react-navigation/native";
import { createBottomTabNavigator } from "@react-navigation/bottom-tabs";
import { Ionicons } from "@expo/vector-icons";

import HomeScreen from "./src/screens/HomeScreen";
import CameraScreen from "./src/screens/CameraScreen";
import DashboardScreen from "./src/screens/DashboardScreen";
import SettingsScreen from "./src/screens/SettingsScreen";

export type TabParamList = {
  Home: undefined;
  Camera: undefined;
  Dashboard: undefined;
  Settings: undefined;
};

const Tab = createBottomTabNavigator<TabParamList>();

const PALETTE = {
  bg: "#000000",
  card: "#0d0d0d",
  border: "#1a1a1a",
  red: "#E53B2F",
  redSoft: "#FF5A4D",
  white: "#FFFFFF",
};

const DarkThemeHB: Theme = {
  ...DefaultTheme,
  colors: {
    ...DefaultTheme.colors,
    background: PALETTE.bg,
    primary: PALETTE.red,
    card: PALETTE.card,
    text: PALETTE.white,
    border: PALETTE.border,
    notification: PALETTE.red,
  },
};

export default function App() {
  return (
    <NavigationContainer theme={DarkThemeHB}>
      <Tab.Navigator
        initialRouteName="Home"
        screenOptions={({ route }) => ({
          headerStyle: { backgroundColor: PALETTE.card },
          headerTintColor: PALETTE.white,
          tabBarStyle: { backgroundColor: PALETTE.bg, borderTopColor: PALETTE.border },
          tabBarActiveTintColor: PALETTE.red,
          tabBarInactiveTintColor: "#9c9c9c",
          tabBarIcon: ({ color, size }) => {
            const icons: Record<keyof TabParamList, keyof typeof Ionicons.glyphMap> = {
              Home: "home",
              Camera: "videocam",
              Dashboard: "pulse",
              Settings: "settings",
            };
            return <Ionicons name={icons[route.name as keyof TabParamList]} size={size} color={color} />;
          },
        })}
      >
        <Tab.Screen name="Home" component={HomeScreen} options={{ title: "Início" }} />
        <Tab.Screen name="Camera" component={CameraScreen} options={{ title: "Câmera" }} />
        <Tab.Screen name="Dashboard" component={DashboardScreen} options={{ title: "Dashboard" }} />
        <Tab.Screen name="Settings" component={SettingsScreen} options={{ title: "Ajustes" }} />
      </Tab.Navigator>
    </NavigationContainer>
  );
}




src/screens/HomeScreen.tsx


import { View, Text, StyleSheet, Pressable, Dimensions, Image } from "react-native";
import { Ionicons } from "@expo/vector-icons";
import { useNavigation } from "@react-navigation/native";
import type { BottomTabNavigationProp } from "@react-navigation/bottom-tabs";
import type { TabParamList } from "../../App";

type Nav = BottomTabNavigationProp<TabParamList>;

const W = Dimensions.get("window").width;
const CARD = W / 2 - 28;

const PALETTE = {
  bg: "#000000",
  card: "#0d0d0d",
  border: "#1a1a1a",
  red: "#E53B2F",
  redSoft: "#FF5A4D",
  white: "#FFFFFF",
  textSoft: "#E6E6E6",
};

export default function HomeScreen() {
  const navigation = useNavigation<Nav>();

  const tiles = [
    { key: "Camera" as const, label: "Câmera", icon: "videocam" as const, color: PALETTE.red },
    { key: "Dashboard" as const, label: "Dashboard", icon: "pulse" as const, color: PALETTE.redSoft },
  ];

  return (
    <View style={styles.container}>
      <View style={styles.hero}>
        <Image source={require("../../assets/logo.png")} style={styles.logo} resizeMode="contain" />
        <Text style={styles.title}>HydroBot</Text>
        <Text style={styles.sub}>Monitoramento e Controle</Text>
      </View>

      <View style={styles.grid}>
        {tiles.map((t) => (
          <Pressable
            key={t.key}
            onPress={() => navigation.navigate(t.key)}
            style={({ pressed }) => [
              styles.tile,
              { width: CARD, height: CARD, borderColor: t.color },
              pressed && { transform: [{ scale: 0.98 }] },
            ]}
          >
            <View style={[styles.tileInner, { backgroundColor: t.color }]}>
              <Ionicons name={t.icon} size={42} color={PALETTE.white} />
            </View>
            <Text style={styles.tileLabel}>{t.label}</Text>
          </Pressable>
        ))}
      </View>

      <Text style={styles.hint}>Use o rodapé para navegar entre as seções</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg, padding: 18 },
  hero: { alignItems: "center", marginTop: 6, marginBottom: 16 },
  logo: { width: 120, height: 120, marginBottom: 6 },
  title: { color: PALETTE.white, fontSize: 24, fontWeight: "800" },
  sub: { color: PALETTE.textSoft, fontSize: 12 },
  grid: { flexDirection: "row", flexWrap: "wrap", justifyContent: "space-between", rowGap: 16 },
  tile: { borderRadius: 18, borderWidth: 2, backgroundColor: PALETTE.card, overflow: "hidden" },
  tileInner: { flex: 1, alignItems: "center", justifyContent: "center" },
  tileLabel: {
    position: "absolute",
    bottom: 8,
    width: "100%",
    textAlign: "center",
    color: PALETTE.white,
    fontWeight: "700",
    fontSize: 16,
  },
  hint: { textAlign: "center", color: "#9c9c9c", marginTop: 12, fontSize: 12 },
});




src/screens/CameraScreen.tsx


(versão com LED ON/OFF, Bomba ON/OFF e joystick UI)


(esse é bem longo, mas já te passei a versão completa na última rodada; se quiser eu colo de novo aqui inteiro sem cortar)



src/screens/DashboardScreen.tsx


import { View, Text, StyleSheet } from "react-native";

export default function DashboardScreen() {
  return (
    <View style={styles.container}>
      <Text style={styles.title}>Dashboard</Text>
      <Text style={styles.sub}>Aqui virão telemetria, gráficos e logs.</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#000", alignItems: "center", justifyContent: "center" },
  title: { color: "white", fontSize: 22, fontWeight: "700" },
  sub: { color: "#9fb3ff", marginTop: 6 },
});




src/screens/SettingsScreen.tsx


import { View, Text, StyleSheet } from "react-native";

export default function SettingsScreen() {
  return (
    <View style={styles.container}>
      <Text style={styles.title}>Ajustes</Text>
      <Text style={styles.sub}>Preferências do app e conexões.</Text>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#000", alignItems: "center", justifyContent: "center" },
  title: { color: "white", fontSize: 22, fontWeight: "700" },
  sub: { color: "#9fb3ff", marginTop: 6 },
});




👉 quer que eu cole novamente o código inteiro da CameraScreen.tsx atualizado, junto com esses, para ficar 100% fechado em um só bloco?



















show! vou te entregar um guia passo-a-passo (sem pular nada) + código pronto de um servidor intermediário em Python com TensorFlow “normal” (Keras) e a integração no app para exibir a detecção.



PARTE A — Servidor de IA (TensorFlow)


0) Pré-requisitos




Python 3.10 ou 3.11 (recomendado p/ TF 2.15)


Pip atualizado: python -m pip install -U pip


Máquina que consiga acessar o ESP32 na rede (ex.: conectada ao Wi-Fi HYDROBOT-CAM)






Dica: quando o celular estiver no Wi-Fi do ESP32 (sem internet), rode o Expo com --tunnel para continuar vendo o app.





1) Criar a pasta do servidor


mkdir hydrobot-server
cd hydrobot-server



Crie estes arquivos:


requirements.txt




(TensorFlow 2.15 usa NumPy 1.26.x — importante fixar)




fastapi==0.115.5
uvicorn[standard]==0.32.0
opencv-python==4.10.0.84
numpy==1.26.4
tensorflow==2.15.1



Estrutura


hydrobot-server/
  server_tf.py
  requirements.txt
  models/
    fire_classifier.h5      ← seu modelo Keras (2 classes: [no_fire, fire])



server_tf.py


import cv2
import time
import threading
import numpy as np
from typing import Optional, List, Dict
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from tensorflow.keras.models import load_model  # TensorFlow "normal"

# =========================
# Config do servidor
# =========================
CAMERA_IP = "192.168.4.1"                 # IP padrão do ESP32-CAM em AP
STREAM_URL_FMT = "http://{}:81/stream"
MODEL_PATH = "./models/fire_classifier.h5" # Keras (2 saídas: [no_fire, fire])
SCORE_THRESHOLD = 0.60                     # corte (ajuste depois)
USE_HEURISTIC_IF_MODEL_MISSING = True      # fallback se faltar modelo

app = FastAPI(title="HydroBot Fire TF Server", version="1.0.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# =========================
# Leitor de frames (OpenCV)
# =========================
class CameraReader:
    def __init__(self, ip: str):
        self.ip = ip
        self._cap: Optional[cv2.VideoCapture] = None
        self._lock = threading.Lock()
        self._last_frame: Optional[np.ndarray] = None
        self._fps = 0.0
        self._running = False
        self._thread: Optional[threading.Thread] = None

    def start(self):
        if self._running: return
        self._running = True
        self._thread = threading.Thread(target=self._loop, daemon=True)
        self._thread.start()

    def stop(self):
        self._running = False
        if self._thread: self._thread.join(timeout=2.0)
        if self._cap: self._cap.release()
        self._cap = None

    def set_ip(self, ip: str):
        if ip == self.ip: return
        self.ip = ip
        self.stop(); self.start()

    def _open(self):
        cap = cv2.VideoCapture(STREAM_URL_FMT.format(self.ip))
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        return cap

    def _loop(self):
        self._cap = self._open()
        if not self._cap or not self._cap.isOpened():
            for _ in range(10):
                time.sleep(0.6)
                self._cap = self._open()
                if self._cap.isOpened(): break

        frames, last = 0, time.time()
        while self._running:
            if not self._cap or not self._cap.isOpened():
                time.sleep(0.3); continue
            ok, frame = self._cap.read()
            if not ok or frame is None:
                time.sleep(0.03); continue
            with self._lock:
                self._last_frame = frame
            frames += 1
            now = time.time()
            if now - last >= 1.0:
                self._fps = frames / (now - last)
                frames, last = 0, now

    def get_latest(self) -> Optional[np.ndarray]:
        with self._lock:
            return None if self._last_frame is None else self._last_frame.copy()

    def get_fps(self) -> float:
        return self._fps

reader = CameraReader(CAMERA_IP)
reader.start()

# =========================
# Carregar modelo Keras
# =========================
class FireClassifier:
    def __init__(self, model_path: str):
        self.model = None
        try:
            self.model = load_model(model_path)
        except Exception as e:
            print(f"[WARN] Não foi possível carregar o modelo: {e}")
            self.model = None

        # inferir input shape [H, W, 3]
        if self.model is not None:
            ishape = self.model.inputs[0].shape  # (None, H, W, 3)
            self.H = int(ishape[1]); self.W = int(ishape[2])
        else:
            self.H = 224; self.W = 224  # padrão se faltar modelo

    def preprocess(self, frame_bgr: np.ndarray) -> np.ndarray:
        img = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (self.W, self.H), interpolation=cv2.INTER_AREA)
        x = img.astype(np.float32) / 255.0   # normalização padrão
        return np.expand_dims(x, axis=0)

    def predict(self, frame_bgr: np.ndarray) -> float:
        if self.model is None:
            # fallback heurístico (proporção de pixels "quentes")
            hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
            mask = cv2.inRange(hsv, (5, 80, 120), (40, 255, 255))
            score = float(np.count_nonzero(mask)) / float(mask.size)
            return float(min(1.0, score * 4.0))
        x = self.preprocess(frame_bgr)
        probs = self.model.predict(x, verbose=0)[0]
        # espera [no_fire, fire]; se for 1 saída (sigmoid), trate como fire
        if probs.shape[0] == 2:
            fire_score = float(probs[1])
        else:
            fire_score = float(probs[0])
        return max(0.0, min(1.0, fire_score))

clf = FireClassifier(MODEL_PATH)

# =========================
# Caixas por heurística (opcional)
# =========================
def fire_boxes(frame_bgr: np.ndarray) -> List[List[int]]:
    h, w = frame_bgr.shape[:2]
    scl = min(640, w)
    rs = cv2.resize(frame_bgr, (scl, int(h * scl / w)))
    hsv = cv2.cvtColor(rs, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, (5, 80, 120), (40, 255, 255))
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, 1)
    mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel, 1)
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes: List[List[int]] = []
    rx, ry = w / float(scl), h / float(rs.shape[0])
    for c in cnts:
        x, y, bw, bh = cv2.boundingRect(c)
        if bw * bh < 600: 
            continue
        boxes.append([int(x * rx), int(y * ry), int(bw * rx), int(bh * ry)])
    return boxes

# =========================
# API
# =========================
class ConfigIn(BaseModel):
    camera_ip: str

@app.get("/status")
def status():
    return {
        "ok": True,
        "camera_ip": reader.ip,
        "fps": round(reader.get_fps(), 2),
        "has_frame": reader.get_latest() is not None,
        "model": "keras_h5" if clf.model is not None else ("heuristic" if USE_HEURISTIC_IF_MODEL_MISSING else "none"),
        "ts": int(time.time() * 1000),
    }

@app.post("/config")
def set_config(cfg: ConfigIn):
    reader.set_ip(cfg.camera_ip)
    return {"ok": True, "camera_ip": reader.ip}

@app.get("/snapshot")
def snapshot():
    frame = reader.get_latest()
    if frame is None:
        return {"ok": False, "error": "no frame yet"}
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
    if not ok:
        return {"ok": False, "error": "encode failed"}
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/detect")
def detect():
    frame = reader.get_latest()
    if frame is None:
        return {"ok": False, "error": "no frame"}
    score = clf.predict(frame)
    is_fire = bool(score >= SCORE_THRESHOLD)
    boxes = fire_boxes(frame) if is_fire else []
    return {
        "ok": True,
        "isFire": is_fire,
        "score": round(float(score), 3),
        "boxes": boxes,
        "threshold": SCORE_THRESHOLD,
        "ts": int(time.time() * 1000),
    }




2) Instalar e rodar


# (na pasta hydrobot-server)
python -m venv .venv
# Windows: .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt
uvicorn server_tf:app --reload --host 0.0.0.0 --port 8000





Sem modelo ainda? Pode rodar assim mesmo: ele usa o fallback heurístico.

Quando você colocar models/fire_classifier.h5, ele usa o Keras automaticamente.





3) Conectividade de rede




ESP32-CAM cria o AP HYDROBOT-CAM → IP padrão 192.168.4.1


Servidor (sua máquina) deve conectar a esse AP para ler o stream.


Celular também conecta ao mesmo AP para usar o app.


Para o Expo Go funcionar enquanto está nesse AP (sem internet), rode o bundler com:

npx expo start --tunnel


(o túnel usa a rede móvel para entregar o bundle)




Descubra o IP do servidor dentro do AP (Windows: ipconfig, macOS/Linux: ifconfig).

Geralmente vira 192.168.4.x.



PARTE B — App (React Native) consumindo a IA


Você já tem a CameraScreen.tsx. Vamos adicionar:




Campo de Servidor (http://192.168.4.X:8000)


Botão Detectar (liga/desliga polling)


Banner “🔥 FOGO” com score






Substitua seu src/screens/CameraScreen.tsx pelo abaixo (já inclui LED, Bomba, Joystick e Detecção):




import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  ActivityIndicator,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
} from "react-native";
import { WebView } from "react-native-webview";

const DEFAULT_IP = "192.168.4.1";          // ESP32-CAM
const DEFAULT_SERVER = "http://192.168.4.2:8000"; // <-- troque para o IP do seu servidor no AP

export default function CameraScreen() {
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState<string>("—");
  const [ledOn, setLedOn] = useState<boolean>(false);
  const [pumpOn, setPumpOn] = useState<boolean>(false);

  // Detecção
  const [detectOn, setDetectOn] = useState<boolean>(false);
  const [isFire, setIsFire] = useState<boolean>(false);
  const [fireScore, setFireScore] = useState<number>(0);

  // Joystick UI
  const [joy, setJoy] = useState<{ x: number; y: number }>({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  const webref = useRef<WebView>(null);

  const streamUrl = useMemo(() => `http://${ip}:81/stream`, [ip]);
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl   = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl  = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(
        `OK • ip:${j.ip} • mode:${j.mode} • led:${j.led ? "on" : "off"} • pump:${j.pump ? "on" : "off"}`
      );
    } catch {
      setStatusText("Falha ao conectar. Confira o Wi-Fi HYDROBOT-CAM e o IP.");
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() {
    try {
      const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t);
    } catch { setStatusText("Erro ao alternar LED."); }
  }
  async function togglePump() {
    try {
      const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t);
    } catch { setStatusText("Erro ao alternar bomba."); }
  }

  useEffect(() => {
    pingStatus(); const id = setInterval(pingStatus, 5000);
    return () => clearInterval(id);
  }, [statusUrl]);

  // HTML para MJPEG
  const html = `
    <html>
      <head><meta name="viewport" content="width=device-width, initial-scale=1" /></head>
      <body style="margin:0;background:#000;display:flex;align-items:center;justify-content:center;height:100vh;">
        <img src="${streamUrl}" style="width:100%;height:100%;object-fit:contain;" />
      </body>
    </html>
  `;

  // ======= Polling de detecção =======
  useEffect(() => {
    if (!detectOn) return;
    let stop = false;
    const tick = async () => {
      try {
        const r = await fetch(`${server}/detect`, { method: "GET" });
        const j = await r.json();
        if (!stop && j && j.ok) {
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));
        }
      } catch {
        if (!stop) { setIsFire(false); setFireScore(0); }
      } finally {
        if (!stop) setTimeout(tick, 500); // ~2Hz (ajuste)
      }
    };
    tick();
    return () => { stop = true; };
  }, [detectOn, server]);

  // ===== Joystick (UI) =====
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS, ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny); if (len > 1) { nx /= len; ny /= len; }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
      onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    })
  ).current;
  const knobLeft = joy.x * RADIUS, knobTop = -joy.y * RADIUS;

  return (
    <View style={styles.container}>
      {/* Controles superiores */}
      <View style={styles.topbar}>
        <Text style={styles.label}>ESP IP:</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder="192.168.4.1"
          autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Pressable onPress={pingStatus} style={styles.btn}><Text style={styles.btnText}>{isChecking ? "..." : "Testar"}</Text></Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? "LED ON" : "LED OFF"}</Text>
        </Pressable>
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? "BOMBA ON" : "BOMBA OFF"}</Text>
        </Pressable>
      </View>

      {/* Linha do servidor + detecção */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>Servidor:</Text>
        <TextInput
          value={server}
          onChangeText={setServer}
          placeholder="http://192.168.4.2:8000"
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Pressable onPress={() => setDetectOn((v) => !v)} style={[styles.btn, detectOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{detectOn ? "Detectando" : "Detectar"}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
        <Pressable onPress={() => webref.current?.reload()} style={[styles.btn, { marginLeft: 8 }]}>
          <Text style={styles.btnText}>Recarregar</Text>
        </Pressable>
      </View>

      {/* Banner de fogo */}
      {detectOn && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>
            {isFire ? `🔥 FOGO • score ${fireScore.toFixed(2)}` : `Sem fogo • score ${fireScore.toFixed(2)}`}
          </Text>
        </View>
      )}

      {/* Vídeo */}
      <WebView
        ref={webref}
        originWhitelist={["*"]}
        source={{ html }}
        style={styles.web}
        allowFileAccess
        allowingReadAccessToURL={"*"}
        javaScriptEnabled
        domStorageEnabled
        allowUniversalAccessFromFileURLs
        allowsInlineMediaPlayback
        mediaPlaybackRequiresUserAction={false}
      />

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: RADIUS * 2 + 24, height: RADIUS * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: RADIUS * 2, height: RADIUS * 2, borderRadius: RADIUS }]} />
          <View style={[styles.joyKnob, { width: KNOB_R * 2, height: KNOB_R * 2, borderRadius: KNOB_R, transform: [{ translateX: knobLeft }, { translateY: knobTop }], opacity: dragging ? 1 : 0.9 }]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)}   y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const PALETTE = { bg:"#000", card:"#0d0d0d", border:"#1a1a1a", red:"#E53B2F", white:"#fff" };

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },
  topbar: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 10, gap: 8, backgroundColor: PALETTE.card },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: { backgroundColor: PALETTE.bg, color: "white", borderRadius: 8, paddingHorizontal: 10, paddingVertical: 8, borderWidth: 1, borderColor: "#1e2a4d", minWidth: 110 },
  btn: { backgroundColor: "#2b48ff", paddingHorizontal: 10, paddingVertical: 10, borderRadius: 10 },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },
  statusRow: { flexDirection: "row", alignItems: "center", paddingHorizontal: 12, paddingVertical: 8, gap: 8, backgroundColor: "#0f1730" },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },
  web: { flex: 1, backgroundColor: "black" },
  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(43,72,255,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});




CHECKLIST rápido (do zero até ver “🔥 FOGO” no app)




Ligue o ESP32-CAM (AP HYDROBOT-CAM, senha 12345678).


Conecte o notebook ao AP HYDROBOT-CAM.


Suba o servidor:



Crie a pasta hydrobot-server, cole os arquivos, pip install -r requirements.txt,


Rode: uvicorn server_tf:app --reload --host 0.0.0.0 --port 8000.


(Opcional) Coloque models/fire_classifier.h5. Sem ele, usa heurística.






Descubra o IP do notebook no AP (ex.: 192.168.4.2).


No app, rode npx expo start --tunnel.


No app Câmera:



Campo ESP IP: 192.168.4.1 → tocar Testar (status OK).


Campo Servidor: http://192.168.4.2:8000 (troque pelo seu IP).


Toque Detectar → deve aparecer um banner “Sem fogo • score …”.


Aponte chama/luz quente → quando o score ≥ 0.60, aparece 🔥 FOGO.






(Opcional) Ajuste SCORE_THRESHOLD no server_tf.py conforme seu modelo.




Pronto. Quando quiser, eu:




Troco o fallback por um detector com caixas (SSD/EfficientDet em TF) e desenho overlay.


Automatizo bomba ao detectar fogo (com histerese/timeout para não ligar/superligar).


Adiciono /detect/stream (SSE) para latência menor e menos requisições.




















Sim — dá pra seguir de dois jeitos sem remover o 3.13.5:




(rápido, hoje) rodar a detecção “placeholder” (heurística HSV) 100% compatível com Python 3.13 — funciona agora.


(TensorFlow “de verdade”) rodar o servidor em Docker com Python 3.11 + TensorFlow, independente do Python instalado no Windows.




Abaixo te deixo os dois caminhos completos. Se quiser pular direto pro TensorFlow, vai no Plano B.



Plano A (imediato): servidor compatível com Python 3.13 (heurística)


Isso te deixa testar o fluxo end-to-end (app ⇄ servidor ⇄ ESP32) enquanto a gente prepara o contêiner TF.


1) Arquivos


requirements_heuristic.txt (compatíveis com 3.13):


fastapi==0.115.5
uvicorn[standard]==0.32.0
opencv-python>=4.10.0
numpy>=2.0.0



server_heuristic.py (igual ao que passei antes, só sem TensorFlow):


import cv2, time, threading, numpy as np
from typing import Optional, List
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
SCORE_THRESHOLD = 0.60

app = FastAPI(title="HydroBot Fire (Heuristic)", version="0.1.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class CameraReader:
    def __init__(self, ip: str):
        self.ip = ip; self._cap=None; self._lock=threading.Lock()
        self._last=None; self._fps=0.0; self._run=False; self._th=None
    def start(self):
        if self._run: return
        self._run=True; self._th=threading.Thread(target=self._loop,daemon=True); self._th.start()
    def stop(self):
        self._run=False
        if self._th: self._th.join(timeout=2.0)
        if self._cap: self._cap.release(); self._cap=None
    def set_ip(self, ip:str):
        if ip==self.ip: return
        self.ip=ip; self.stop(); self.start()
    def _open(self):
        cap=cv2.VideoCapture(STREAM_URL_FMT.format(self.ip)); cap.set(cv2.CAP_PROP_BUFFERSIZE,1); return cap
    def _loop(self):
        self._cap=self._open()
        for _ in range(10):
            if self._cap and self._cap.isOpened(): break
            time.sleep(0.6); self._cap=self._open()
        frames=0; last=time.time()
        while self._run:
            if not self._cap or not self._cap.isOpened(): time.sleep(0.3); continue
            ok,frame=self._cap.read()
            if not ok or frame is None: time.sleep(0.03); continue
            with self._lock: self._last=frame
            frames+=1; now=time.time()
            if now-last>=1.0: self._fps=frames/(now-last); frames=0; last=now
    def get_latest(self): 
        with self._lock: return None if self._last is None else self._last.copy()
    def get_fps(self): return self._fps

reader=CameraReader(CAMERA_IP); reader.start()

class ConfigIn(BaseModel): camera_ip: str

def fire_score(frame):
    hsv=cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask=cv2.inRange(hsv,(5,80,120),(40,255,255))
    ratio=float(np.count_nonzero(mask))/float(mask.size)
    v_mean=float(np.mean(hsv[...,2]))/255.0
    return min(1.0, ratio*4.0 + v_mean*0.2)

def fire_boxes(frame):
    h,w=frame.shape[:2]; scl=min(640,w)
    rs=cv2.resize(frame,(scl,int(h*scl/w))); hsv=cv2.cvtColor(rs, cv2.COLOR_BGR2HSV)
    mask=cv2.inRange(hsv,(5,80,120),(40,255,255))
    k=np.ones((5,5),np.uint8)
    mask=cv2.morphologyEx(mask, cv2.MORPH_OPEN, k,1); mask=cv2.morphologyEx(mask, cv2.MORPH_DILATE, k,1)
    cnts,_=cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    rx=w/float(scl); ry=h/float(rs.shape[0]); boxes=[]
    for c in cnts:
        x,y,bw,bh=cv2.boundingRect(c)
        if bw*bh<600: continue
        boxes.append([int(x*rx),int(y*ry),int(bw*rx),int(bh*ry)])
    return boxes

@app.get("/status")
def status(): 
    return {"ok":True,"camera_ip":reader.ip,"fps":round(reader.get_fps(),2),"has_frame":reader.get_latest() is not None,"model":"heuristic","ts":int(time.time()*1000)}

@app.post("/config")
def set_config(cfg:ConfigIn):
    reader.set_ip(cfg.camera_ip); return {"ok":True,"camera_ip":reader.ip}

@app.get("/snapshot")
def snapshot():
    f=reader.get_latest()
    if f is None: return {"ok":False,"error":"no frame"}
    ok,buf=cv2.imencode(".jpg",f,[int(cv2.IMWRITE_JPEG_QUALITY),85])
    if not ok: return {"ok":False,"error":"encode failed"}
    return Response(content=buf.tobytes(),media_type="image/jpeg")

@app.get("/detect")
def detect():
    f=reader.get_latest()
    if f is None: return {"ok":False,"error":"no frame"}
    s=fire_score(f); is_fire=bool(s>=SCORE_THRESHOLD)
    return {"ok":True,"isFire":is_fire,"score":round(float(s),3),"boxes":(fire_boxes(f) if is_fire else []),"threshold":SCORE_THRESHOLD,"ts":int(time.time()*1000)}



2) Instalar e rodar (com seu Python 3.13)


python -m pip install -U pip
pip install -r requirements_heuristic.txt
uvicorn server_heuristic:app --reload --host 0.0.0.0 --port 8000



No app (tela Câmera), aponte Servidor para http://<IP_DO_PC_NO_AP>:8000 e toque Detectar.

Você já verá o banner com o score; quando houver chama/área quente, ele sobe.




Depois, quando quiser trocar para TensorFlow “real”, você não muda nada no app, só troca o servidor.





Plano B (recomendado p/ TensorFlow): Docker com Python 3.11 + TF


Mesmo mantendo Python 3.13 no Windows, o servidor roda dentro do contêiner com 3.11 + TF.


0) Pré-requisitos




Docker Desktop instalado e rodando.




1) Arquivos


Dockerfile


FROM python:3.11-slim

# libs p/ OpenCV
RUN apt-get update && apt-get install -y --no-install-recommends \
    libglib2.0-0 libsm6 libxrender1 libxext6 && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# requirements (TF 2.15 + numpy compatível)
COPY requirements_tf.txt /app/requirements_tf.txt
RUN pip install --no-cache-dir -r requirements_tf.txt

# código e modelos
COPY server_tf.py /app/server_tf.py
COPY models /app/models

EXPOSE 8000
CMD ["uvicorn", "server_tf:app", "--host", "0.0.0.0", "--port", "8000"]



requirements_tf.txt


fastapi==0.115.5
uvicorn[standard]==0.32.0
opencv-python-headless==4.10.0.84
numpy==1.26.4
tensorflow==2.15.1





Uso opencv-python-headless no contêiner para evitar dependências de GUI.




server_tf.py

— é exatamente o que te passei anteriormente (TensorFlow “normal”, modelo Keras .h5). Se quiser, eu reenvio o arquivo inteiro de novo aqui.


Estrutura:


hydrobot-server/
  Dockerfile
  requirements_tf.txt
  server_tf.py
  models/
    fire_classifier.h5   ← (opcional; se faltar, usa heurística fallback)



2) Build & run


# dentro da pasta hydrobot-server
docker build -t hydrobot-tf .
docker run --rm -p 8000:8000 --network host --name hydrobot-tf hydrobot-tf





Se --network host não funcionar no Windows Docker Desktop, use:


docker run --rm -p 8000:8000 --name hydrobot-tf hydrobot-tf



e no app aponte para http://SEU-IP:8000 (o IP da sua máquina na rede do ESP32).




Testes:




http://SEU-IP:8000/status


http://SEU-IP:8000/detect




Quando você colocar models/fire_classifier.h5 dentro da pasta antes do build, o servidor passará a usar TF de fato.



Qual caminho eu recomendo agora?




Se você quer seguir hoje, use o Plano A (heurística) com o Python 3.13 e já integre ao app.


Em paralelo, prepare o Plano B (Docker) para usar seu modelo TensorFlow sem esquentar com a versão do Python do Windows.




Se quiser, eu te mando o server_tf.py completo novamente, e/ou um docker-compose.yml pra subir com um comando só.

