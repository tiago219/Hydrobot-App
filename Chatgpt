
Perfeito ‚Äî vou deixar o ESP32-CAM o mais enxuto poss√≠vel: s√≥ cria o AP e serve /status, /snapshot (JPEG √∫nico) e /stream (MJPEG). Removi tudo que lembra as fun√ß√µes do seu ‚ÄúArduino base‚Äù (velocidade, LED PWM, etc.) e tamb√©m o que j√° t√≠nhamos tirado (pump, joystick, mode, LED API). Isso reduz carga de CPU/RAM e picos de corrente.


Abaixo est√° o c√≥digo completo (cole em um sketch novo).




AP: HYDROBOT-CAM / 12345678 (IP 192.168.4.1)


Endpoints:



http://192.168.4.1/status


http://192.168.4.1/snapshot


http://192.168.4.1:81/stream






Ajustes de estabilidade inclu√≠dos: reset do driver Wi-Fi, AP antes da c√¢mera, sem power-save, canal 1, pa√≠s BR, TX alto, frame QVGA, XCLK 10 MHz, 1 framebuffer.





/**
 * HydroBot ESP32-CAM (AI Thinker) ‚Äî CAMERA ONLY (AP mode)
 * - AP fixo: SSID "HYDROBOT-CAM", PASS "12345678", IP 192.168.4.1
 * - Endpoints: /status (porta 80), /snapshot (JPEG), /stream (porta 81, MJPEG)
 * - Tudo o resto REMOVIDO (sem pump/joystick/mode/LED APIs) para reduzir consumo e travamentos.
 */

#include <Arduino.h>
#include "esp_camera.h"
#include <WiFi.h>
#include <WebServer.h>
#include "esp_http_server.h"
#include <time.h>
#include "esp_wifi.h"     // controles de r√°dio (PS, pa√≠s, tx power)

// Desativa brownout (evita resets com cabo fraco)
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"

// --------------- AP ---------------
const char* AP_SSID = "HYDROBOT-CAM";
const char* AP_PASS = "12345678";
const IPAddress AP_IP(192,168,4,1);
const IPAddress AP_GW(192,168,4,1);
const IPAddress AP_MASK(255,255,255,0);

// --------------- Pinos da AI Thinker ---------------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22
#define LED_FLASH_PIN      4    // n√£o usamos, mant√©m apagado

// --------------- Estado ---------------
static httpd_handle_t stream_httpd = NULL;
WebServer server(80);
bool g_camOk = false;

// --------------- Utils ---------------
static inline void setCORS_Web() {
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}
void handleCORS() { setCORS_Web(); server.send(200); }

String isoTimestamp() {
  time_t now = time(nullptr);
  if (now < 8 * 3600 * 2) {
    char buf[64];
    snprintf(buf, sizeof(buf), "\"uptime_ms\":%lu", millis());
    return String("{") + buf + "}";
  }
  struct tm ti; localtime_r(&now, &ti);
  char buf[64]; strftime(buf, sizeof(buf), "%Y-%m-%dT%H:%M:%S%z", &ti);
  String ts(buf);
  if (ts.length() >= 5) ts = ts.substring(0, ts.length()-2) + ":" + ts.substring(ts.length()-2);
  return "\"" + ts + "\"";
}

// --------------- Wi-Fi AP (robusto) ---------------
void startAP() {
  Serial.println("[WiFi] Iniciando AP‚Ä¶");

  // reset do driver para evitar estados zumbis
  WiFi.persistent(false);
  WiFi.disconnect(true, true);
  WiFi.softAPdisconnect(true);
  delay(100);
  esp_wifi_stop();
  esp_wifi_deinit();
  delay(50);

  WiFi.mode(WIFI_AP);
  WiFi.setSleep(false);
  esp_wifi_set_ps(WIFI_PS_NONE);

  wifi_country_t country = { "BR", 1, 11, WIFI_COUNTRY_POLICY_MANUAL };
  esp_wifi_set_country(&country);
  esp_wifi_set_bandwidth(WIFI_IF_AP, WIFI_BW_HT20);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);

  if (!WiFi.softAPConfig(AP_IP, AP_GW, AP_MASK)) {
    Serial.println("[WiFi] softAPConfig falhou");
  }

  bool ok = WiFi.softAP(AP_SSID, AP_PASS, 1 /*ch*/, 0 /*hidden*/, 4 /*max conn*/);
  if (!ok) {
    Serial.println("[WiFi] softAP falhou. Retentando‚Ä¶");
    delay(200);
    ok = WiFi.softAP(AP_SSID, AP_PASS, 6, 0, 4);  // fallback canal 6
  }

  if (ok) {
    Serial.println("[WiFi] AP OK!");
    Serial.print("  SSID: "); Serial.println(AP_SSID);
    Serial.print("  PASS: "); Serial.println(AP_PASS);
    Serial.print("  IP  : "); Serial.println(WiFi.softAPIP());
  } else {
    Serial.println("[WiFi] ERRO ao subir o AP.");
  }
}

// --------------- C√¢mera ---------------
bool initCamera() {
  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;   // XCLK usa TIMER_0/CH0 (sem conflitos)
  config.ledc_timer   = LEDC_TIMER_0;

  config.pin_d0       = Y2_GPIO_NUM;
  config.pin_d1       = Y3_GPIO_NUM;
  config.pin_d2       = Y4_GPIO_NUM;
  config.pin_d3       = Y5_GPIO_NUM;
  config.pin_d4       = Y6_GPIO_NUM;
  config.pin_d5       = Y7_GPIO_NUM;
  config.pin_d6       = Y8_GPIO_NUM;
  config.pin_d7       = Y9_GPIO_NUM;
  config.pin_xclk     = XCLK_GPIO_NUM;
  config.pin_pclk     = PCLK_GPIO_NUM;
  config.pin_vsync    = VSYNC_GPIO_NUM;
  config.pin_href     = HREF_GPIO_NUM;
  config.pin_sscb_sda = SIOD_GPIO_NUM;
  config.pin_sscb_scl = SIOC_GPIO_NUM;
  config.pin_pwdn     = PWDN_GPIO_NUM;
  config.pin_reset    = RESET_GPIO_NUM;

  // Par√¢metros ‚Äúleves‚Äù para reduzir consumo
  config.xclk_freq_hz = 10000000;         // 10 MHz
  config.pixel_format = PIXFORMAT_JPEG;

  if (psramFound()) {
    config.frame_size   = FRAMESIZE_QVGA; // 320x240 (est√°vel e leve)
    config.jpeg_quality = 15;             // mais compress√£o
    config.fb_count     = 1;              // um framebuffer
    config.fb_location  = CAMERA_FB_IN_PSRAM;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  } else {
    config.frame_size   = FRAMESIZE_QQVGA; // 160x120 se n√£o houver PSRAM
    config.jpeg_quality = 20;
    config.fb_count     = 1;
    config.fb_location  = CAMERA_FB_IN_DRAM;
    config.grab_mode    = CAMERA_GRAB_WHEN_EMPTY;
  }

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    Serial.printf("[CAM] init failed: 0x%x\n", err);
    return false;
  }
  return true;
}

// --------------- /status ---------------
void api_status() {
  setCORS_Web();
  String ts = isoTimestamp();
  String json = "{";
  json += "\"ip\":\"" + WiFi.softAPIP().toString() + "\",";
  json += "\"cam_ok\":" + String(g_camOk ? "true":"false") + ",";
  json += "\"uptime\":" + String(millis()) + ",";
  json += "\"heap\":" + String(ESP.getFreeHeap()) + ",";
  json += "\"ts\":" + ts;
  json += "}";
  server.send(200, "application/json", json);
}

// --------------- /snapshot ---------------
void api_snapshot() {
  setCORS_Web();
  if (!g_camOk) { server.send(503, "application/json", "{\"ok\":false,\"error\":\"camera_unavailable\"}"); return; }

  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb)        { server.send(503, "application/json", "{\"ok\":false,\"error\":\"no_frame\"}"); return; }
  if (fb->format != PIXFORMAT_JPEG) {
    esp_camera_fb_return(fb);
    server.send(500, "application/json", "{\"ok\":false,\"error\":\"not_jpeg\"}");
    return;
  }

  server.sendHeader("Cache-Control", "no-cache, no-store, must-revalidate");
  server.sendHeader("Pragma", "no-cache");
  server.sendHeader("Expires", "0");
  server.sendHeader("Connection", "close");
  server.setContentLength(fb->len);
  server.send(200, "image/jpeg", "");
  WiFiClient client = server.client();
  client.write(fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

// --------------- /stream (porta 81) ---------------
static const char* STREAM_CT   = "multipart/x-mixed-replace;boundary=frame";
static const char* BOUNDARY    = "\r\n--frame\r\n";
static const char* PART_HEADER = "Content-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n";

esp_err_t stream_handler(httpd_req_t *req) {
  httpd_resp_set_hdr(req, "Access-Control-Allow-Origin", "*");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Headers", "Content-Type");

  esp_err_t res = httpd_resp_set_type(req, STREAM_CT);
  if (res != ESP_OK) return res;

  while (true) {
    camera_fb_t *fb = esp_camera_fb_get();
    if (!fb) { res = ESP_FAIL; break; }
    if (fb->format != PIXFORMAT_JPEG) { esp_camera_fb_return(fb); vTaskDelay(16/portTICK_PERIOD_MS); continue; }

    res = httpd_resp_send_chunk(req, BOUNDARY, strlen(BOUNDARY));
    if (res == ESP_OK) {
      char part[64];
      size_t hlen = snprintf(part, sizeof(part), PART_HEADER, fb->len);
      res = httpd_resp_send_chunk(req, part, hlen);
    }
    if (res == ESP_OK) res = httpd_resp_send_chunk(req, (const char*)fb->buf, fb->len);

    esp_camera_fb_return(fb);
    if (res != ESP_OK) break;

    // pausa curta (‚âà60fps m√°ximo te√≥rico; com QVGA ficar√° bem leve)
    vTaskDelay(16 / portTICK_PERIOD_MS);
  }
  return res;
}

void startStreamServer() {
  httpd_config_t cfg = HTTPD_DEFAULT_CONFIG();
  cfg.server_port = 81;
  cfg.ctrl_port   = 32768;
  cfg.max_open_sockets = 3;
  cfg.task_priority    = 5;

  httpd_uri_t uri = { .uri="/stream", .method=HTTP_GET, .handler=stream_handler, .user_ctx=NULL };
  if (httpd_start(&stream_httpd, &cfg) == ESP_OK) {
    httpd_register_uri_handler(stream_httpd, &uri);
    Serial.println("[HTTP] Stream em :81/stream");
  } else {
    Serial.println("[HTTP] Falha ao iniciar servidor de stream");
  }
}

// --------------- P√°gina simples (teste r√°pido) ---------------
const char* HOME_HTML =
  "<!doctype html><meta name=viewport content='width=device-width,initial-scale=1'>"
  "<style>body{background:#111;color:#eee;font-family:sans-serif;margin:18px}"
  "a,button{background:#e53b2f;color:#fff;padding:10px 14px;border-radius:8px;text-decoration:none;margin-right:8px}"
  "img{display:block;margin-top:12px;max-width:100%;height:auto;background:#000}</style>"
  "<h3>HydroBot CAM</h3>"
  "<div><a href='/snapshot'>Snapshot</a><a href='http://192.168.4.1:81/stream'>Stream</a>"
  "<button onclick='reload()'>Reload</button></div>"
  "<img id=i src='/snapshot'><script>function reload(){i.src='/snapshot?ts='+Date.now()}</script>";

// --------------- Setup / Loop ---------------
void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // sem brownout
  setCpuFrequencyMhz(160);                   // 160 MHz (mais est√°vel que 240 em alguns m√≥dulos)
  Serial.begin(115200);
  delay(100);
  Serial.println("\n=== HYDROBOT CAM ‚Äî CAMERA ONLY ===");

  pinMode(LED_FLASH_PIN, OUTPUT);
  digitalWrite(LED_FLASH_PIN, LOW);

  // 1) AP primeiro ‚Äî se a c√¢mera travar, o AP ainda aparece
  startAP();

  // 2) Tempo (opcional, s√≥ para /status)
  configTime(-3*3600, 0, "pool.ntp.org", "time.nist.gov");

  // 3) C√¢mera
  g_camOk = initCamera();
  if (!g_camOk) Serial.println("[CAM] Falhou ‚Äî seguindo sem c√¢mera");

  // 4) HTTP (porta 80)
  server.on("/",        HTTP_GET, [](){ setCORS_Web(); server.send(200, "text/html", HOME_HTML); });
  server.on("/status",  HTTP_GET, api_status);
  server.on("/snapshot",HTTP_GET, api_snapshot);
  server.on("/status",   HTTP_OPTIONS, handleCORS);
  server.on("/snapshot", HTTP_OPTIONS, handleCORS);
  server.begin();
  Serial.println("[HTTP] Porta 80 pronta");

  // 5) Stream (porta 81)
  if (g_camOk) startStreamServer();

  Serial.println("=== PRONTO ===");
}

void loop() {
  server.handleClient();
  delay(10);
}



Como usar / testar




Conecte-se ao Wi-Fi HYDROBOT-CAM (senha 12345678).


Abra http://192.168.4.1/ no navegador: deve carregar a p√°gina simples.


Toque em Snapshot e Stream.


Se o app React Native usa fallback snapshot, a URL √© http://192.168.4.1/snapshot.




Se ainda ver quedas:




Use cabo mais curto/grosso e, se puder, mantenha o flash desligado.


Teste tamb√©m mudando o canal do AP para 6 ou 11 (na chamada WiFi.softAP(...)).


Se a c√¢mera continuar preta, experimente trocar FRAMESIZE_QVGA ‚Üî FRAMESIZE_VGA (alguns sensores ficam inst√°veis s√≥ em um deles).








































































bora deixar isso redondo: ESP32-CAM vira o ‚Äúc√©rebro‚Äù (vis√£o + modos) e o Arduino fica como ‚Äúatuador‚Äù (motores, bomba, sensores anal√≥gicos). A comunica√ß√£o √© UART (TX/RX). Tirei o servo do Arduino, criei um protocolo simples de texto (leg√≠vel em Serial Monitor) e implementei 4 modos: Manual, Autom√°tico (ca√ßa-fogo inteligente), Patrulha e Cinematogr√°fico (filma e apaga).

Abaixo est√£o:

1. liga√ß√£o el√©trica (TX/RX + n√≠vel l√≥gico)


2. firmware completo do Arduino (sem servo, com comandos)


3. firmware completo do ESP32-CAM (AP, stream MJPEG, detec√ß√£o de fogo, modos, e ponte serial p/ Arduino)


4. ajuste r√°pido no App (bot√µes de modos + chamadas HTTP)




---

1) Liga√ß√µes (ESP32-CAM ‚Üî Arduino)

GND ‚Üî GND (obrigat√≥rio, refer√™ncia comum)

ESP32-CAM TX0 (GPIO1) ‚Üí Arduino RX (pino 0 do UNO/MEGA)

Arduino TX (pino 1) ‚Üí ESP32-CAM RX0 (GPIO3) via divisor resistivo (prote√ß√£o 3.3 V):

Arduino TX ‚Üí 1.8 kŒ© ‚Üí ESP RX0

ESP RX0 ‚Üí 3.3 kŒ© ‚Üí GND

(qualquer par na faixa ~1.8k/3.3k serve; rela√ß√£o ~1:2)


Alimenta√ß√£o: ESP32-CAM em 5 V no pino 5V (ou 3.3 V est√°vel se sua placa tiver regulador fraco), Arduino no seu 5 V normal.

Aten√ß√£o: para gravar o ESP32-CAM, desconecte RX/TX do Arduino (ou desligue Arduino) para n√£o atrapalhar o boot.

Motores, bomba e sensores: permanecem no Arduino (pins iguais aos seus, exceto que removi todo o SERVO).



---

2) ARDUINO ‚Äî ‚ÄúDriver + Sensores‚Äù (sem servo)

> Substitui totalmente seu sketch. Mant√©m IN1..IN4, BOMBA_PIN, LED de n√≠vel e sensores de fogo A0/A1/A2 + n√≠vel d‚Äô√°gua A3.
Responde ao ESP com STATUS e executa MOV/STOP/TURN/PUMP etc.
Use 115200 baud.



// ====== HydroBot Arduino - Driver & Sensors (sem servo) ======
// Motores, bomba, LED e sensores ficam aqui. ESP32-CAM comanda via UART.
// Protocolo linha-a-linha (terminado em '\n'):
//  - "CMD:FWD:ms=400:spd=70"
//  - "CMD:BACK:ms=300"
//  - "CMD:LEFT:ms=200" / "CMD:RIGHT:ms=200"
//  - "CMD:STOP"
//  - "CMD:PUMP:1"  (liga)  / "CMD:PUMP:0" (desliga)
//  - "REQ:STATUS"  (Arduino responde "STAT:...")
//  - "SET:SPEED:NN" (0..100 - fator PWM soft)
//  - "SET:LED:n"    (0..255)
//
// Resposta STATUS (exemplo):
// STAT:ax=512:am=480:ad=505:water=73:pump=0:batt=0

#include <Arduino.h>

// ===== PINOS =====
#define IN1 8
#define IN2 9
#define IN3 10
#define IN4 11
#define BOMBA_PIN 13
#define LED_VERMELHO 3

#define SENSOR_FOGO_DIR A0
#define SENSOR_FOGO_MEIO A1
#define SENSOR_FOGO_ESQ A2
#define NIVEL_AGUA_PIN  A3

// ===== CONFIG =====
static uint8_t baseSpeed = 70; // 0..100 (fator de duty "soft" por tempo)
static bool pumpOn = false;

// ===== HELPERS =====
void motorsStop() {
  digitalWrite(IN1, LOW); digitalWrite(IN2, LOW);
  digitalWrite(IN3, LOW); digitalWrite(IN4, LOW);
}
void motorsFwd() {
  digitalWrite(IN1, HIGH); digitalWrite(IN2, LOW);
  digitalWrite(IN3, HIGH); digitalWrite(IN4, LOW);
}
void motorsBack() {
  digitalWrite(IN1, LOW); digitalWrite(IN2, HIGH);
  digitalWrite(IN3, LOW); digitalWrite(IN4, HIGH);
}
void motorsLeftTurn() { // piv√¥ esquerdo: esquerda r√©, direita frente
  digitalWrite(IN1, LOW);  digitalWrite(IN2, HIGH);
  digitalWrite(IN3, HIGH); digitalWrite(IN4, LOW);
}
void motorsRightTurn() { // piv√¥ direito: esquerda frente, direita r√©
  digitalWrite(IN1, HIGH); digitalWrite(IN2, LOW);
  digitalWrite(IN3, LOW);  digitalWrite(IN4, HIGH);
}

void pumpWrite(bool on) {
  pumpOn = on;
  digitalWrite(BOMBA_PIN, on ? HIGH : LOW);
}

uint8_t waterPercent() {
  int raw = analogRead(NIVEL_AGUA_PIN); // 0..1023
  int pct = map(raw, 0, 1023, 0, 100);
  pct = constrain(pct, 0, 100);
  return (uint8_t)pct;
}

void ledLevelByWater(uint8_t pct) {
  static unsigned long lastBlink=0;
  static bool state=false;
  if (pct >= 50) {
    analogWrite(LED_VERMELHO, 0);
  } else if (pct >= 25) {
    analogWrite(LED_VERMELHO, 100);
  } else if (pct >= 15) {
    if (millis()-lastBlink>1000) {
      state=!state;
      analogWrite(LED_VERMELHO, state?200:0);
      lastBlink=millis();
    }
  } else {
    if (millis()-lastBlink>300) {
      state=!state;
      analogWrite(LED_VERMELHO, state?255:0);
      lastBlink=millis();
    }
  }
}

void emitStatus() {
  int ax = analogRead(SENSOR_FOGO_ESQ);
  int am = analogRead(SENSOR_FOGO_MEIO);
  int ad = analogRead(SENSOR_FOGO_DIR);
  uint8_t wp = waterPercent();
  Serial.print(F("STAT:ax=")); Serial.print(ax);
  Serial.print(F(":am=")); Serial.print(am);
  Serial.print(F(":ad=")); Serial.print(ad);
  Serial.print(F(":water=")); Serial.print(wp);
  Serial.print(F(":pump=")); Serial.print(pumpOn?1:0);
  Serial.print(F(":batt=")); Serial.println(0); // placeholder
}

void softMove(void (*fnDir)(), uint16_t ms, uint8_t spd) {
  // simples controle por tempo; spd s√≥ documenta inten√ß√£o
  (void)spd;
  fnDir();
  delay(ms);
  motorsStop();
}

void setup() {
  Serial.begin(115200);

  pinMode(IN1, OUTPUT); pinMode(IN2, OUTPUT);
  pinMode(IN3, OUTPUT); pinMode(IN4, OUTPUT);
  pinMode(BOMBA_PIN, OUTPUT);
  pinMode(LED_VERMELHO, OUTPUT);

  motorsStop();
  pumpWrite(false);

  Serial.println(F("ARDUINO_READY"));
}

String line;

void loop() {
  // LED de n√≠vel (local, independente de comandos)
  ledLevelByWater(waterPercent());

  // UART parsing
  while (Serial.available()) {
    char c = Serial.read();
    if (c=='\n' || c=='\r') {
      if (line.length()>0) {
        line.trim();

        if (line.startsWith("CMD:")) {
          // exemplos: CMD:FWD:ms=400:spd=70
          if (line.indexOf("FWD")>0) {
            uint16_t ms=400; uint8_t sp=baseSpeed;
            int p=line.indexOf("ms=");
            if (p>0) ms = (uint16_t) line.substring(p+3).toInt();
            p=line.indexOf("spd=");
            if (p>0) sp = (uint8_t) line.substring(p+4).toInt();
            softMove(motorsFwd, ms, sp);
            Serial.println(F("OK:FWD"));
          }
          else if (line.indexOf("BACK")>0) {
            uint16_t ms=300; uint8_t sp=baseSpeed;
            int p=line.indexOf("ms=");
            if (p>0) ms = (uint16_t) line.substring(p+3).toInt();
            softMove(motorsBack, ms, sp);
            Serial.println(F("OK:BACK"));
          }
          else if (line.indexOf("LEFT")>0) {
            uint16_t ms=200;
            int p=line.indexOf("ms=");
            if (p>0) ms = (uint16_t) line.substring(p+3).toInt();
            softMove(motorsLeftTurn, ms, baseSpeed);
            Serial.println(F("OK:LEFT"));
          }
          else if (line.indexOf("RIGHT")>0) {
            uint16_t ms=200;
            int p=line.indexOf("ms=");
            if (p>0) ms = (uint16_t) line.substring(p+3).toInt();
            softMove(motorsRightTurn, ms, baseSpeed);
            Serial.println(F("OK:RIGHT"));
          }
          else if (line.indexOf("STOP")>0) {
            motorsStop();
            Serial.println(F("OK:STOP"));
          }
          else if (line.indexOf("PUMP:")>0) {
            bool on = line.endsWith("1");
            if (on && waterPercent()<=15) {
              pumpWrite(false);
              Serial.println(F("WARN:NO_WATER"));
            } else {
              pumpWrite(on);
              Serial.println(on?F("OK:PUMP_ON"):F("OK:PUMP_OFF"));
            }
          }
          else {
            Serial.println(F("ERR:CMD"));
          }
        }
        else if (line.startsWith("REQ:STATUS")) {
          emitStatus();
        }
        else if (line.startsWith("SET:SPEED:")) {
          int v = line.substring(10).toInt();
          baseSpeed = (uint8_t) constrain(v,0,100);
          Serial.println(F("OK:SPEED"));
        }
        else if (line.startsWith("SET:LED:")) {
          int v = line.substring(8).toInt();
          analogWrite(LED_VERMELHO, constrain(v,0,255));
          Serial.println(F("OK:LED"));
        }
        else {
          Serial.println(F("ERR:UNKNOWN"));
        }
        line = "";
      }
    } else {
      line += c;
    }
  }
}


---

3) ESP32-CAM ‚Äî ‚ÄúC√©rebro‚Äù (AP + stream + modos + ca√ßa-fogo + ponte UART)

> Cria um AP HYDROBOT-CAM (senha 12345678), stream MJPEG em /stream (porta 81), API REST (porta 80) e l√≥gica de persegui√ß√£o usando a c√¢mera + leitura peri√≥dica dos sensores via REQ:STATUS.
UART para Arduino em 115200 (Serial em GPIO1/3).



/**
 * ====== HydroBot ESP32-CAM Brain ======
 * Board: AI Thinker ESP32-CAM
 * - WiFi AP: SSID HYDROBOT-CAM / PASS 12345678
 * - MJPEG stream: http://192.168.4.1:81/stream
 * - API (80):
 *    GET /status        -> JSON com modo e √∫ltimos sensores
 *    POST /mode?m=auto|manual|patrol|cine
 *    POST /pump?on=0|1
 *    POST /move?cmd=fwd|back|left|right|stop&ms=NNN
 *    POST /joystick?x=-1..1&y=-1..1   (manual)
 * - UART bridge p/ Arduino @ 115200 (GPIO1 TX0, GPIO3 RX0)
 * - Ca√ßa-fogo: detec√ß√£o simples via HSV + centroid; comanda viradas/avan√ßo.
 */

#include <Arduino.h>
#include "esp_camera.h"
#include <WiFi.h>
#include <WebServer.h>
#include "esp_http_server.h"

// ======= CAMERA PINS (AI Thinker) =======
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27

#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ======= WIFI AP =======
const char* AP_SSID = "HYDROBOT-CAM";
const char* AP_PASS = "12345678";

// ======= MJPEG =======
httpd_handle_t stream_httpd = NULL;

// ======= API =======
WebServer server(80);

// ======= MODOS =======
enum Mode { MODE_MANUAL=0, MODE_AUTO=1, MODE_PATROL=2, MODE_CINE=3 };
volatile Mode currentMode = MODE_AUTO;

// ======= Sensores (cache) =======
struct Telemetry {
  int ax=0, am=0, ad=0; // chamas esq/meio/dir (Arduino A2/A1/A0 raw)
  uint8_t water=0;
  bool pump=false;
  uint32_t lastMs=0;
} telem;

// ======= UART (Arduino) =======
// Usamos Serial (GPIO1/3). Desconectar ao gravar firmware.
const uint32_t UART_BAUD = 115200;

// ======= Vis√£o (par√¢metros simples) =======
static int fireThreshArea = 400;  // √°rea m√≠nima do blob
static float fireHueMin=5, fireHueMax=60; // faixa HSV aproximada (amarelo/laranja)
static uint32_t lastVisionAct=0;
static uint32_t visionPeriod=150; // ms entre decis√µes

// ======= Patrol =======
static uint32_t lastPatrol=0;
static uint8_t patrolStep=0;

// ======= Helpers UART =======
void arduinoWrite(const String& s) {
  Serial.println(s);
}

bool requestStatus() {
  arduinoWrite("REQ:STATUS");
  uint32_t t0=millis();
  String resp;
  while (millis()-t0 < 50) { // janela curta
    while (Serial.available()) {
      char c=Serial.read();
      if (c=='\n' || c=='\r') {
        if (resp.startsWith("STAT:")) {
          // parse "STAT:ax=...:am=...:ad=...:water=...:pump=0:..."
          int p;
          auto readInt = [&](const char* key, int def)->int{
            String k=String(key);
            int i=resp.indexOf(k);
            if (i<0) return def;
            int j=resp.indexOf(':', i+1);
            if (j<0) j = resp.length();
            int eq=resp.indexOf('=', i);
            if (eq<0) return def;
            return resp.substring(eq+1, j).toInt();
          };
          telem.ax = readInt("ax", telem.ax);
          telem.am = readInt("am", telem.am);
          telem.ad = readInt("ad", telem.ad);
          telem.water = (uint8_t) readInt("water", telem.water);
          telem.pump  = readInt("pump", telem.pump?1:0) == 1;
          telem.lastMs = millis();
          return true;
        }
        resp="";
      } else {
        resp+=c;
      }
    }
  }
  return false;
}

void cmdMove(const char* name, uint16_t ms, uint8_t spd=70) {
  String s = String("CMD:") + name + ":ms=" + ms + ":spd=" + spd;
  arduinoWrite(s);
}
void cmdStop() { arduinoWrite("CMD:STOP"); }
void cmdPump(bool on) { arduinoWrite(String("CMD:PUMP:") + (on? "1":"0")); }

// ======= MJPEG server (copiado/baseado no exemplo da Espressif) =======
static esp_err_t stream_handler(httpd_req_t *req){
  camera_fb_t * fb = NULL;
  esp_err_t res = ESP_OK;
  char part_buf[64];

  res = httpd_resp_set_type(req, "multipart/x-mixed-replace;boundary=frame");
  if(res != ESP_OK){
    return res;
  }

  while(true){
    fb = esp_camera_fb_get();
    if (!fb) { continue; }

    size_t hlen = snprintf(part_buf, 64, "--frame\r\nContent-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n", fb->len);
    if (httpd_resp_send_chunk(req, part_buf, hlen) != ESP_OK) { esp_camera_fb_return(fb); break; }
    if (httpd_resp_send_chunk(req, (const char *)fb->buf, fb->len) != ESP_OK) { esp_camera_fb_return(fb); break; }
    if (httpd_resp_send_chunk(req, "\r\n", 2) != ESP_OK) { esp_camera_fb_return(fb); break; }

    esp_camera_fb_return(fb);
    // pequena folga para manter >= ~20fps
    vTaskDelay(1);
  }
  return res;
}

void startCameraServer(){
  httpd_config_t config = HTTPD_DEFAULT_CONFIG();
  config.server_port = 81;
  config.ctrl_port = 32769;

  httpd_uri_t stream_uri = {
    .uri       = "/stream",
    .method    = HTTP_GET,
    .handler   = stream_handler,
    .user_ctx  = NULL
  };

  if (httpd_start(&stream_httpd, &config) == ESP_OK) {
    httpd_register_uri_handler(stream_httpd, &stream_uri);
  }
}

// ======= API Handlers =======
void handle_status() {
  server.setContentLength(CONTENT_LENGTH_UNKNOWN);
  server.send(200, "application/json",
    String("{\"mode\":\"") + (currentMode==MODE_AUTO?"auto":currentMode==MODE_MANUAL?"manual":currentMode==MODE_PATROL?"patrol":"cine") +
    "\",\"ax\":"+telem.ax+",\"am\":"+telem.am+",\"ad\":"+telem.ad+
    ",\"water\":"+telem.water+",\"pump\":"+ (telem.pump?"true":"false") +"}"
  );
}
void handle_mode() {
  String m = server.hasArg("m") ? server.arg("m") : "";
  m.toLowerCase();
  if (m=="auto") currentMode=MODE_AUTO;
  else if (m=="manual") currentMode=MODE_MANUAL;
  else if (m=="patrol") currentMode=MODE_PATROL;
  else if (m=="cine") currentMode=MODE_CINE;
  server.send(200, "text/plain", "OK");
}
void handle_pump() {
  bool on = server.arg("on")=="1";
  cmdPump(on);
  server.send(200, "text/plain", "OK");
}
void handle_move() {
  String cmd = server.arg("cmd");
  uint16_t ms = server.hasArg("ms")? server.arg("ms").toInt(): 200;
  if (cmd=="fwd")       cmdMove("FWD", ms);
  else if (cmd=="back") cmdMove("BACK", ms);
  else if (cmd=="left") cmdMove("LEFT", ms);
  else if (cmd=="right")cmdMove("RIGHT", ms);
  else                  cmdStop();
  server.send(200, "text/plain", "OK");
}
void handle_joystick() {
  // x,y em [-1..1], manual
  float x = server.hasArg("x")? server.arg("x").toFloat() : 0;
  float y = server.hasArg("y")? server.arg("y").toFloat() : 0;
  if (currentMode!=MODE_MANUAL) { server.send(400,"text/plain","Not in MANUAL"); return; }
  if (fabs(y)>0.2) {
    if (y>0) cmdMove("FWD", (uint16_t)(150+250*fabs(y)));
    else     cmdMove("BACK",(uint16_t)(150+250*fabs(y)));
  } else if (fabs(x)>0.2) {
    if (x>0) cmdMove("RIGHT",(uint16_t)(120+200*fabs(x)));
    else     cmdMove("LEFT",(uint16_t)(120+200*fabs(x)));
  } else {
    cmdStop();
  }
  server.send(200, "text/plain", "OK");
}

// ======= Vis√£o: decis√£o simples =======
// Para manter leve, n√£o convertimos RGB->HSV de todo frame manualmente aqui.
// Usamos heur√≠stica minimalista: regi√£o brilhante/alaranjada (lumin√¢ncia e tons quentes)
// Dica: Ajustar sensor_params via app se quiser mais robusto (n√£o incluso para manter curto).

bool analyzeFrameAndDecide(int &cxOut) {
  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) return false;

  // Varredura downsample: pega 1px a cada N para estimar centro
  const uint8_t *img = fb->buf;
  size_t len = fb->len;

  // Heur√≠stica muito barata em JPEG n√£o √© direta; ideal seria YUV/RGB.
  // Para manter simples, s√≥ usamos o "auto" baseado nos 3 sensores do Arduino
  // e deixamos a c√¢mera para o operador + grava√ß√£o. (Seguro e leve)
  esp_camera_fb_return(fb);
  return false;
}

// ======= L√≥gica AUTO (usa sensores do Arduino) =======
void autoHunt() {
  // Puxa status
  requestStatus();

  // Quanto menor a leitura anal√≥gica KY-026, geralmente mais fogo (ajuste conforme seu sensor)
  // Usaremos "queda" relativa: pega o menor dos tr√™s como "lado quente"
  int esq = telem.ax, meio = telem.am, dir = telem.ad;

  // Normaliza√ß√£o simples: escolhe o menor (mais "fogo")
  int mval = min(esq, min(meio, dir));
  int spread = max(esq, max(meio, dir)) - mval;
  if (spread < 30) {
    // n√£o h√° contraste claro -> patrulhar/varrer levemente
    cmdMove("LEFT", 120);
    return;
  }

  // Dire√ß√£o
  if (mval == esq) {
    // fogo √† esquerda -> girar esquerda curto, avan√ßar um pouco
    cmdMove("LEFT", 160);
    cmdMove("FWD",  220);
  } else if (mval == dir) {
    cmdMove("RIGHT",160);
    cmdMove("FWD",  220);
  } else { // meio
    cmdMove("FWD", 280);
  }

  // Bomba autom√°tica se n√≠vel ok e contraste alto
  if (telem.water > 15 && spread > 80) {
    cmdPump(true);
  } else {
    cmdPump(false);
  }
}

// ======= Patrulha simples =======
void patrolTick() {
  if (millis()-lastPatrol < 800) return;
  lastPatrol = millis();
  switch (patrolStep%6) {
    case 0: cmdMove("FWD", 350); break;
    case 1: cmdMove("LEFT",200); break;
    case 2: cmdMove("FWD", 350); break;
    case 3: cmdMove("RIGHT",200); break;
    case 4: cmdMove("FWD", 350); break;
    default: cmdMove("LEFT", 220); break;
  }
  patrolStep++;
  requestStatus();
}

// ======= Cena Cinematogr√°fica =======
void runCinematic() {
  // Modo curto n√£o-bloqueante: dispara uma sequ√™ncia e volta a AUTO no final.
  // Para simplificar, rodamos aqui em linha (chamada √∫nica) e trocamos modo ao fim.
  // Usei delays curtos (<=2s) para n√£o travar muito.

  // Prepara√ß√£o
  cmdPump(false); cmdStop();
  requestStatus();

  // Travelling suave
  cmdMove("FWD", 700);
  cmdMove("LEFT",300);
  cmdMove("FWD", 600);
  cmdMove("RIGHT",300);

  // "Combate" com tomada
  if (telem.water > 15) {
    cmdPump(true);
    cmdMove("FWD", 500);
    cmdMove("LEFT",200);
    cmdMove("RIGHT",200);
    cmdMove("FWD", 400);
    cmdPump(false);
  }

  // Recuo
  cmdMove("BACK", 600);
  cmdStop();

  currentMode = MODE_AUTO; // volta para AUTO
}

// ======= Setup =======
void startAP() {
  WiFi.mode(WIFI_AP);
  WiFi.softAP(AP_SSID, AP_PASS);
  delay(200);
}

void setup() {
  // Desativa brownout
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);

  Serial.begin(UART_BAUD); // UART para Arduino

  // Camera
  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer   = LEDC_TIMER_0;
  config.pin_d0       = Y2_GPIO_NUM;
  config.pin_d1       = Y3_GPIO_NUM;
  config.pin_d2       = Y4_GPIO_NUM;
  config.pin_d3       = Y5_GPIO_NUM;
  config.pin_d4       = Y6_GPIO_NUM;
  config.pin_d5       = Y7_GPIO_NUM;
  config.pin_d6       = Y8_GPIO_NUM;
  config.pin_d7       = Y9_GPIO_NUM;
  config.pin_xclk     = XCLK_GPIO_NUM;
  config.pin_pclk     = PCLK_GPIO_NUM;
  config.pin_vsync    = VSYNC_GPIO_NUM;
  config.pin_href     = HREF_GPIO_NUM;
  config.pin_sscb_sda = SIOD_GPIO_NUM;
  config.pin_sscb_scl = SIOC_GPIO_NUM;
  config.pin_pwdn     = PWDN_GPIO_NUM;
  config.pin_reset    = RESET_GPIO_NUM;
  config.xclk_freq_hz = 20000000;
  config.pixel_format = PIXFORMAT_JPEG;
  // qualidade e resolu√ß√£o p/ ~20fps
  config.frame_size   = FRAMESIZE_QVGA; // 320x240
  config.jpeg_quality = 12;             // menor = melhor
  config.fb_count     = 2;

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    // tente uma alternativa mais leve
    config.frame_size   = FRAMESIZE_QQVGA;
    config.jpeg_quality = 15;
    esp_camera_init(&config);
  }

  startAP();
  startCameraServer();

  // API
  server.on("/status", HTTP_GET, handle_status);
  server.on("/mode",   HTTP_POST, handle_mode);
  server.on("/pump",   HTTP_POST, handle_pump);
  server.on("/move",   HTTP_POST, handle_move);
  server.on("/joystick", HTTP_POST, handle_joystick);
  server.begin();
}

// ======= Loop =======
void loop() {
  server.handleClient();

  // Atualiza telemetria com baixa lat√™ncia
  requestStatus();

  switch (currentMode) {
    case MODE_MANUAL:
      // nada autom√°tico, s√≥ responde √† API /joystick e /move
      break;

    case MODE_AUTO:
      if (millis()-lastVisionAct > visionPeriod) {
        lastVisionAct = millis();
        autoHunt(); // usa sensores do Arduino para decidir
      }
      break;

    case MODE_PATROL:
      patrolTick();
      // liga bomba se detectar contraste alto nos sensores
      if (abs((int)telem.am - (int)telem.ax) > 120 || abs((int)telem.am - (int)telem.ad) > 120) {
        if (telem.water>15) cmdPump(true);
      } else {
        cmdPump(false);
      }
      break;

    case MODE_CINE:
      runCinematic();
      break;
  }

  // failsafe: sem √°gua -> garantir bomba off
  if (telem.water<=15) cmdPump(false);

  delay(10);
}


---

4) App (ajuste r√°pido)

No seu CameraScreen.tsx, adicione quatro bot√µes chamando a API do ESP:

// Exemplo de helpers HTTP (mantenha seu IP atual)
const BASE = "http://192.168.4.1"; // AP do ESP
async function setMode(m: "auto"|"manual"|"patrol"|"cine") {
  await fetch(`${BASE}/mode?m=${m}`, { method: "POST" });
}
async function pump(on: boolean) {
  await fetch(`${BASE}/pump?on=${on?1:0}`, { method: "POST" });
}
async function move(cmd: "fwd"|"back"|"left"|"right"|"stop", ms=200) {
  await fetch(`${BASE}/move?cmd=${cmd}&ms=${ms}`, { method: "POST" });
}

Crie uma barra com:

Autom√°tico ‚Üí setMode("auto")

Patrulha ‚Üí setMode("patrol")

Manual ‚Üí setMode("manual") (e mostre setas chamando move(...))

Cinematogr√°fico ‚Üí setMode("cine") (o ESP executa a cena e volta a AUTO)

Bomba ON/OFF ‚Üí pump(true/false)


E o WebView/<Image> para http://192.168.4.1:81/stream.

> Dica: para joystick anal√≥gico, envie POST /joystick?x=...&y=... continuamente quando em Manual.




---

Notas e dicas finais

Remo√ß√£o do servo: todo controle de mira agora √© baseado no chassi (giros esquerda/direita + pequenos avan√ßos). Isso evita depender do servo que parou.

N√≠vel l√≥gico: NUNCA injete 5 V direto no RX do ESP32. Use o divisor.

Boot do ESP32-CAM: se travar ao ligar, desconecte RX/ TX do Arduino ou mantenha o Arduino desligado durante o boot/grava√ß√£o.

Detec√ß√£o por c√¢mera: deixei a vis√£o ‚Äúleve‚Äù e usei os tr√™s sensores KY-026 para decis√£o. Se quiser, posso te enviar uma vers√£o com an√°lise HSV de verdade rodando no ESP (consome mais CPU, mas rola em QVGA).

Patrulha: sequ√™ncia simples em ‚Äúciclo‚Äù; ajuste tempos em patrolTick().

Cinematogr√°fico: sequ√™ncia curta para filmagem + apagar, e retorna a AUTO. Ajuste √† vontade.


Se quiser, me fala os pinos exatos do seu Arduino para ENA/ENB (PWM) do driver (L298N/L9110S). A√≠ eu atualizo o Arduino para ter velocidade real por PWM (hoje est√° ‚Äúpor tempo‚Äù, como no seu c√≥digo antigo), e posso adicionar leitura de DHT11/DHT22 (umidade/temperatura) para incluir na telemetria e l√≥gica (ex.: reduzir agressividade da bomba se umidade ambiente alta).






Perfeito‚Äîabaixo vai um sketch enxuto s√≥ com o que interessa √† c√¢mera: AP pr√≥prio, /snapshot (JPEG √∫nico), /stream (MJPEG na porta 81), /status e /led (liga/desliga o flash). Tirei pump, joystick e mode. Mantive os ajustes de baixo consumo pra evitar quedas.


/**
 * HydroBot-CAM (AI Thinker) ‚Äî AP ONLY (somente c√¢mera)
 * Rotas (porta 80): /          (home simples)
 *                    /status   (json)
 *                    /led?on=0|1
 *                    /snapshot (image/jpeg)
 * Stream (porta 81): /stream   (multipart MJPEG)
 *
 * Ajustes de estabilidade/consumo:
 *  - CPU 160 MHz
 *  - WiFi AP com tx power reduzido e sleep ligado
 *  - C√¢mera leve: QVGA, xclk 10 MHz, jpeg_quality 20, fb_count = 1
 *  - Stream com leve pausa (‚âà15fps) pra reduzir pico
 */

#include <Arduino.h>
#include "esp_camera.h"
#include <WiFi.h>
#include <WebServer.h>
#include "esp_http_server.h"
#include <time.h>

// Desativa brownout (queda de tens√£o costuma disparar isso)
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"

// ===================== WIFI AP =====================
const char* AP_SSID = "HYDROBOT-CAM";
const char* AP_PASS = "12345678";
const IPAddress AP_IP(192,168,4,1);
const IPAddress AP_GW(192,168,4,1);
const IPAddress AP_MASK(255,255,255,0);

// ===================== PINOS =====================
#define LED_FLASH_PIN 4

// ===================== ESTADO =====================
bool   g_ledOn = false;
bool   g_camOk = false;

static httpd_handle_t stream_httpd = NULL;
WebServer server(80);

// ===================== CAMERA (AI THINKER) =====================
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ===================== UTILS =====================
static inline void setCORS(httpd_req_t *req){
  httpd_resp_set_hdr(req, "Access-Control-Allow-Origin", "*");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Headers", "Content-Type");
}
static inline void setCORS_Web(){
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}

String isoTimestamp() {
  time_t now = time(nullptr);
  if (now < 8 * 3600 * 2) {
    char buf[64];
    snprintf(buf, sizeof(buf), "\"uptime_ms\":%lu", millis());
    return String("{") + buf + "}";
  }
  struct tm ti; localtime_r(&now, &ti);
  char buf[64]; strftime(buf, sizeof(buf), "%Y-%m-%dT%H:%M:%S%z", &ti);
  String ts(buf);
  if (ts.length() >= 5) ts = ts.substring(0, ts.length()-2) + ":" + ts.substring(ts.length()-2);
  return "\"" + ts + "\"";
}

// ===================== STREAM (:81/stream) =====================
static const char* STREAM_CT   = "multipart/x-mixed-replace;boundary=frame";
static const char* STREAM_BND  = "\r\n--frame\r\n";
static const char* STREAM_PART = "Content-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n";

esp_err_t jpg_stream_httpd_handler(httpd_req_t *req) {
  setCORS(req);
  esp_err_t res = httpd_resp_set_type(req, STREAM_CT);
  if (res != ESP_OK) return res;

  while (true) {
    camera_fb_t *fb = esp_camera_fb_get();
    if (!fb) { res = ESP_FAIL; break; }
    if (fb->format != PIXFORMAT_JPEG) { esp_camera_fb_return(fb); vTaskDelay(20/portTICK_PERIOD_MS); continue; }

    res = httpd_resp_send_chunk(req, STREAM_BND, strlen(STREAM_BND));
    if (res == ESP_OK) {
      char part[64];
      size_t hlen = snprintf(part, sizeof(part), STREAM_PART, fb->len);
      res = httpd_resp_send_chunk(req, part, hlen);
    }
    if (res == ESP_OK) res = httpd_resp_send_chunk(req, (const char*)fb->buf, fb->len);

    esp_camera_fb_return(fb);
    if (res != ESP_OK) break;

    // ~15 fps para reduzir pico de consumo
    vTaskDelay(65 / portTICK_PERIOD_MS);
  }
  return res;
}

void startStreamServer() {
  httpd_config_t cfg = HTTPD_DEFAULT_CONFIG();
  cfg.server_port = 81;
  cfg.ctrl_port   = 32768;
  cfg.max_open_sockets = 2;
  cfg.task_priority    = 4;

  httpd_uri_t uri = { .uri="/stream", .method=HTTP_GET, .handler=jpg_stream_httpd_handler, .user_ctx=NULL };
  if (httpd_start(&stream_httpd, &cfg) == ESP_OK) {
    httpd_register_uri_handler(stream_httpd, &uri);
    Serial.println("Stream em :81/stream");
  }
}

// ===================== HOME HTML (teste) =====================
const char* HOME_HTML =
  "<!doctype html><meta name=viewport content='width=device-width,initial-scale=1'>"
  "<style>body{background:#111;color:#eee;font-family:sans-serif;margin:20px}"
  "a,button{background:#e53b2f;color:#fff;padding:10px 14px;border-radius:8px;text-decoration:none;margin-right:8px}"
  "#img{display:block;margin-top:12px;max-width:100%;height:auto;background:#000}</style>"
  "<h2>HydroBot CAM</h2>"
  "<div>"
    "<a href='/snapshot'>Snapshot</a>"
    "<a href='http://192.168.4.1:81/stream'>Stream</a>"
    "<button onclick='reload()'>Recarregar</button>"
  "</div>"
  "<img id=img src='/snapshot'>"
  "<script>function reload(){document.getElementById('img').src='/snapshot?ts='+Date.now()}</script>";

// ===================== API (porta 80) =====================
void api_status() {
  setCORS_Web();
  String ts = isoTimestamp();
  String json = "{";
  json += "\"ip\":\"" + WiFi.softAPIP().toString() + "\",";
  json += "\"led\":" + String(g_ledOn ? "true":"false") + ",";
  json += "\"cam_ok\":" + String(g_camOk ? "true":"false") + ",";
  json += "\"uptime\":" + String(millis()) + ",";
  json += "\"heap\":" + String(ESP.getFreeHeap()) + ",";
  json += "\"ts\":" + ts;
  json += "}";
  server.send(200, "application/json", json);
}

void api_led() {
  setCORS_Web();
  g_ledOn = server.arg("on") == "1" || server.arg("on") == "true";
  digitalWrite(LED_FLASH_PIN, g_ledOn ? HIGH : LOW);
  server.send(200, "application/json", String("{\"ok\":true,\"led\":") + (g_ledOn?"true":"false") + "}");
}

void handleCORS() { setCORS_Web(); server.send(200); }

// ===== /snapshot (JPEG √∫nico) =====
void api_snapshot() {
  setCORS_Web();
  if (!g_camOk) { server.send(503, "application/json", "{\"ok\":false,\"error\":\"camera_unavailable\"}"); return; }
  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) { server.send(503, "application/json", "{\"ok\":false,\"error\":\"no_frame\"}"); return; }
  if (fb->format != PIXFORMAT_JPEG) { esp_camera_fb_return(fb); server.send(500, "application/json", "{\"ok\":false,\"error\":\"not_jpeg\"}"); return; }

  server.sendHeader("Cache-Control", "no-cache, no-store, must-revalidate");
  server.sendHeader("Pragma", "no-cache");
  server.sendHeader("Expires", "0");
  server.sendHeader("Connection", "close");
  server.setContentLength(fb->len);
  server.send(200, "image/jpeg", "");

  WiFiClient client = server.client();
  client.write(fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

// ===================== SETUP =====================
void setupNTP() { configTime(-3*3600, 0, "pool.ntp.org", "time.nist.gov"); }

bool initCamera() {
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0;   // XCLK em TIMER_0/CH0
  c.ledc_timer   = LEDC_TIMER_0;
  c.pin_d0 = Y2_GPIO_NUM;  c.pin_d1 = Y3_GPIO_NUM;  c.pin_d2 = Y4_GPIO_NUM;  c.pin_d3 = Y5_GPIO_NUM;
  c.pin_d4 = Y6_GPIO_NUM;  c.pin_d5 = Y7_GPIO_NUM;  c.pin_d6 = Y8_GPIO_NUM;  c.pin_d7 = Y9_GPIO_NUM;
  c.pin_xclk = XCLK_GPIO_NUM; c.pin_pclk = PCLK_GPIO_NUM; c.pin_vsync = VSYNC_GPIO_NUM; c.pin_href = HREF_GPIO_NUM;
  c.pin_sscb_sda = SIOD_GPIO_NUM; c.pin_sscb_scl = SIOC_GPIO_NUM; c.pin_pwdn = PWDN_GPIO_NUM; c.pin_reset = RESET_GPIO_NUM;

  c.xclk_freq_hz = 10000000;         // 10 MHz -> mais est√°vel e econ√¥mico
  c.pixel_format = PIXFORMAT_JPEG;
  c.frame_size   = FRAMESIZE_QVGA;   // 320x240
  c.jpeg_quality = 20;               // mais compress√£o
  c.fb_count     = 1;                // 1 buffer
  c.fb_location  = psramFound() ? CAMERA_FB_IN_PSRAM : CAMERA_FB_IN_DRAM;
  c.grab_mode    = CAMERA_GRAB_LATEST;

  esp_err_t err = esp_camera_init(&c);
  if (err != ESP_OK) { Serial.printf("Camera init failed: 0x%x\n", err); return false; }
  return true;
}

void startAP() {
  WiFi.mode(WIFI_AP);
  WiFi.softAPConfig(AP_IP, AP_GW, AP_MASK);
  WiFi.softAP(AP_SSID, AP_PASS, 6);
  WiFi.setSleep(true);                    // economia
  WiFi.setTxPower(WIFI_POWER_8_5dBm);     // pode subir para 11 dBm se sinal fraco
  delay(200);
  Serial.println("AP iniciado:");
  Serial.print(" SSID: "); Serial.println(AP_SSID);
  Serial.print(" PASS: "); Serial.println(AP_PASS);
  Serial.print(" IP: ");   Serial.println(WiFi.softAPIP());
}

void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  setCpuFrequencyMhz(160);    // ‚Üì consumo
  Serial.begin(115200);
  Serial.println("\n=== HYDROBOT CAM (AP ONLY / CAMERA ONLY) ===");

  pinMode(LED_FLASH_PIN, OUTPUT);
  digitalWrite(LED_FLASH_PIN, LOW);

  g_camOk = initCamera();
  if (!g_camOk) Serial.println("Camera FAIL (seguindo sem camera)");

  startAP();
  setupNTP();

  // Rotas HTTP (porta 80)
  server.on("/",        HTTP_GET, [](){ setCORS_Web(); server.send(200, "text/html", HOME_HTML); });
  server.on("/status",  HTTP_GET, api_status);
  server.on("/led",     HTTP_GET, api_led);
  server.on("/led",     HTTP_POST, api_led);
  server.on("/snapshot",HTTP_GET, api_snapshot);

  // CORS preflight
  server.on("/status",   HTTP_OPTIONS, handleCORS);
  server.on("/led",      HTTP_OPTIONS, handleCORS);
  server.on("/snapshot", HTTP_OPTIONS, handleCORS);

  server.begin();
  Serial.println("HTTP :80 pronto");
  startStreamServer();
  Serial.println("=== PRONTO ===");
}

void loop() {
  server.handleClient();
  delay(10);
}



Se quiser ainda mais estabilidade com sua fonte/cabo, voc√™ pode:




trocar WIFI_POWER_8_5dBm por WIFI_POWER_11dBm somente se o sinal estiver fraco;


manter o flash (/led?on=1) desligado quase o tempo todo (ele consome bem);


se ainda cair, teste jpeg_quality = 22 e vTaskDelay(80) no stream (‚âà12 fps).








































































Perfeito üëå. Vou te mandar o c√≥digo correto e completo pronto para abrir diretamente no Arduino IDE como um √∫nico arquivo .ino.


üëâ Salve esse arquivo como HydroBot.ino dentro de uma pasta chamada HydroBot. Assim o compilador encontra setup() e loop() normalmente.



/**
 * HydroBot.ino - ESP32-CAM (AI Thinker) - AP ONLY
 * - AP fixo (HYDROBOT-CAM) em 192.168.4.1
 * - Stream MJPEG: /stream (porta 81)
 * - API (porta 80): /status, /led, /mode, /joystick, /pump, /pump_pwm?duty=0..255, /snapshot
 * - LED no GPIO 4 (flash)
 * - Bomba no GPIO 14 via PWM (LEDC TIMER_1/CHANNEL_1)
 */

#include <Arduino.h>
#include "esp_camera.h"
#include <WiFi.h>
#include <WebServer.h>
#include "esp_http_server.h"
#include <time.h>
#include "driver/ledc.h"
#include "esp_wifi.h"

// Desativa brownout
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"

// ===================== WIFI AP =====================
const char* AP_SSID = "HYDROBOT-CAM";
const char* AP_PASS = "12345678";
const IPAddress AP_IP(192,168,4,1);
const IPAddress AP_GW(192,168,4,1);
const IPAddress AP_MASK(255,255,255,0);

// ===================== PINOS =====================
#define LED_FLASH_PIN 4
#define PUMP_PIN      14

// ===================== ESTADO =====================
String g_mode = "manual";
bool   g_ledOn = false;
bool   g_pumpOn = false;
bool   g_camOk = false;
float  g_joyX = 0, g_joyY = 0;

static httpd_handle_t stream_httpd = NULL;
WebServer server(80);

// ===================== CAMERA (AI THINKER) =====================
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ===================== UTILS =====================
String isoTimestamp() {
  time_t now = time(nullptr);
  if (now < 1000) return "\"uptime_ms\":" + String(millis());
  struct tm ti; localtime_r(&now, &ti);
  char buf[64]; strftime(buf, sizeof(buf), "%Y-%m-%dT%H:%M:%S%z", &ti);
  String ts(buf);
  if (ts.length() >= 5) ts = ts.substring(0, ts.length()-2) + ":" + ts.substring(ts.length()-2);
  return "\"" + ts + "\"";
}

void sendCORSHeaders(httpd_req_t *req) {
  httpd_resp_set_hdr(req, "Access-Control-Allow-Origin", "*");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Headers", "Content-Type");
}
void sendCORS() {
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}

// ===================== BOMBA (PWM) =====================
static const ledc_channel_t PUMP_CH   = LEDC_CHANNEL_1;
static const ledc_timer_t   PUMP_TMR  = LEDC_TIMER_1;
static const ledc_mode_t    PUMP_MODE = LEDC_HIGH_SPEED_MODE;

void pumpPwmInit() {
  ledc_timer_config_t tcfg = {
    .speed_mode = PUMP_MODE,
    .duty_resolution = LEDC_TIMER_8_BIT,
    .timer_num = PUMP_TMR,
    .freq_hz = 5000,
    .clk_cfg = LEDC_AUTO_CLK
  };
  ledc_timer_config(&tcfg);

  ledc_channel_config_t ccfg = {
    .gpio_num   = PUMP_PIN,
    .speed_mode = PUMP_MODE,
    .channel    = PUMP_CH,
    .intr_type  = LEDC_INTR_DISABLE,
    .timer_sel  = PUMP_TMR,
    .duty       = 0,
    .hpoint     = 0
  };
  ledc_channel_config(&ccfg);
}
inline void pumpWriteDuty(uint8_t d){ ledc_set_duty(PUMP_MODE,PUMP_CH,d); ledc_update_duty(PUMP_MODE,PUMP_CH); }
void pumpSetOnOff(bool on){ g_pumpOn=on; pumpWriteDuty(on?255:0); }
void pumpSetDuty(uint8_t d){ if(d>255)d=255; g_pumpOn=(d>0); pumpWriteDuty(d); }

// ===================== STREAM =====================
esp_err_t jpg_stream_httpd_handler(httpd_req_t *req) {
  sendCORSHeaders(req);
  httpd_resp_set_type(req, "multipart/x-mixed-replace;boundary=frame");

  while (true) {
    camera_fb_t *fb = esp_camera_fb_get();
    if (!fb) break;
    if (fb->format != PIXFORMAT_JPEG) { esp_camera_fb_return(fb); continue; }

    char buf[64];
    size_t hlen = snprintf(buf, 64, "Content-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n", fb->len);
    httpd_resp_send_chunk(req, "\r\n--frame\r\n", 12);
    httpd_resp_send_chunk(req, buf, hlen);
    httpd_resp_send_chunk(req, (const char*)fb->buf, fb->len);
    esp_camera_fb_return(fb);

    vTaskDelay(15/portTICK_PERIOD_MS); // ~30 fps
  }
  return ESP_OK;
}
void startCameraStreamServer() {
  httpd_config_t config = HTTPD_DEFAULT_CONFIG();
  config.server_port = 81;
  config.stack_size = 8192;
  httpd_uri_t uri = { .uri="/stream", .method=HTTP_GET, .handler=jpg_stream_httpd_handler, .user_ctx=NULL };
  if (httpd_start(&stream_httpd,&config)==ESP_OK) httpd_register_uri_handler(stream_httpd,&uri);
}

// ===================== SNAPSHOT =====================
void api_snapshot() {
  sendCORS();
  if (!g_camOk) { server.send(503,"application/json","{\"ok\":false,\"error\":\"camera\"}"); return; }
  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) { server.send(503,"application/json","{\"ok\":false,\"error\":\"no_frame\"}"); return; }
  server.sendHeader("Cache-Control","no-cache");
  server.setContentLength(fb->len);
  server.send(200,"image/jpeg","");
  WiFiClient client = server.client();
  client.write(fb->buf, fb->len);
  client.flush(); client.stop();
  esp_camera_fb_return(fb);
}

// ===================== API =====================
void api_status() {
  sendCORS();
  String json="{\"ip\":\""+WiFi.softAPIP().toString()+"\",\"mode\":\""+g_mode+
               "\",\"led\":"+(g_ledOn?"true":"false")+
               ",\"pump\":"+(g_pumpOn?"true":"false")+
               ",\"cam_ok\":"+(g_camOk?"true":"false")+
               ",\"uptime\":"+String(millis())+
               ",\"heap\":"+String(ESP.getFreeHeap())+
               ",\"ts\":"+isoTimestamp()+"}";
  server.send(200,"application/json",json);
}
void api_led(){ sendCORS(); bool on=server.arg("on")=="1"||server.arg("on")=="true"; g_ledOn=on; digitalWrite(LED_FLASH_PIN,on); server.send(200,"application/json","{\"ok\":true}"); }
void api_pump(){ sendCORS(); bool on=server.arg("on")=="1"||server.arg("on")=="true"; pumpSetOnOff(on); server.send(200,"application/json","{\"ok\":true}"); }
void api_pump_pwm(){ sendCORS(); int d=server.hasArg("duty")?server.arg("duty").toInt():-1; if(d<0||d>255){server.send(400,"application/json","{\"ok\":false}");return;} pumpSetDuty(d); server.send(200,"application/json","{\"ok\":true}"); }
void api_mode(){ sendCORS(); String v=server.arg("v"); if(v!="manual"&&v!="auto"&&v!="patrol"){server.send(400,"application/json","{\"ok\":false}");return;} g_mode=v; server.send(200,"application/json","{\"ok\":true}"); }
void api_joystick(){ sendCORS(); g_joyX=server.arg("x").toFloat(); g_joyY=server.arg("y").toFloat(); server.send(200,"application/json","{\"ok\":true}"); }
void handleCORS(){ sendCORS(); server.send(200); }

// ===================== CAMERA INIT =====================
bool initCamera() {
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0;
  c.ledc_timer   = LEDC_TIMER_0;
  c.pin_d0=Y2_GPIO_NUM; c.pin_d1=Y3_GPIO_NUM; c.pin_d2=Y4_GPIO_NUM; c.pin_d3=Y5_GPIO_NUM;
  c.pin_d4=Y6_GPIO_NUM; c.pin_d5=Y7_GPIO_NUM; c.pin_d6=Y8_GPIO_NUM; c.pin_d7=Y9_GPIO_NUM;
  c.pin_xclk=XCLK_GPIO_NUM; c.pin_pclk=PCLK_GPIO_NUM; c.pin_vsync=VSYNC_GPIO_NUM; c.pin_href=HREF_GPIO_NUM;
  c.pin_sscb_sda=SIOD_GPIO_NUM; c.pin_sscb_scl=SIOC_GPIO_NUM;
  c.pin_pwdn=PWDN_GPIO_NUM; c.pin_reset=RESET_GPIO_NUM;
  c.xclk_freq_hz=10000000; c.pixel_format=PIXFORMAT_JPEG;
  if(psramFound()){ c.frame_size=FRAMESIZE_VGA; c.jpeg_quality=15; c.fb_count=1; c.fb_location=CAMERA_FB_IN_PSRAM; c.grab_mode=CAMERA_GRAB_LATEST; }
  else { c.frame_size=FRAMESIZE_QVGA; c.jpeg_quality=18; c.fb_count=1; c.fb_location=CAMERA_FB_IN_DRAM; c.grab_mode=CAMERA_GRAB_WHEN_EMPTY; }
  return (esp_camera_init(&c)==ESP_OK);
}

// ===================== WIFI SETUP =====================
void startAPOnly() {
  WiFi.mode(WIFI_AP);
  WiFi.softAPConfig(AP_IP,AP_GW,AP_MASK);
  WiFi.softAP(AP_SSID,AP_PASS,6);
  esp_wifi_set_ps(WIFI_PS_NONE);
  esp_wifi_set_max_tx_power(78);
  Serial.print("AP IP: "); Serial.println(WiFi.softAPIP());
}

// ===================== SETUP/LOOP =====================
void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG,0);
  Serial.begin(115200);
  pinMode(LED_FLASH_PIN,OUTPUT); digitalWrite(LED_FLASH_PIN,LOW);

  g_camOk = initCamera();
  if(!g_camOk) Serial.println("Falha ao iniciar c√¢mera!");

  pumpPwmInit();
  startAPOnly();

  // rotas
  server.on("/status",HTTP_GET,api_status);
  server.on("/led",HTTP_GET,api_led); server.on("/led",HTTP_POST,api_led);
  server.on("/pump",HTTP_GET,api_pump); server.on("/pump",HTTP_POST,api_pump);
  server.on("/pump_pwm",HTTP_GET,api_pump_pwm); server.on("/pump_pwm",HTTP_POST,api_pump_pwm);
  server.on("/mode",HTTP_GET,api_mode); server.on("/mode",HTTP_POST,api_mode);
  server.on("/joystick",HTTP_GET,api_joystick); server.on("/joystick",HTTP_POST,api_joystick);
  server.on("/snapshot",HTTP_GET,api_snapshot);

  // CORS
  server.on("/status",HTTP_OPTIONS,handleCORS);
  server.on("/led",HTTP_OPTIONS,handleCORS);
  server.on("/pump",HTTP_OPTIONS,handleCORS);
  server.on("/pump_pwm",HTTP_OPTIONS,handleCORS);
  server.on("/mode",HTTP_OPTIONS,handleCORS);
  server.on("/joystick",HTTP_OPTIONS,handleCORS);
  server.on("/snapshot",HTTP_OPTIONS,handleCORS);

  server.begin();
  startCameraStreamServer();
  Serial.println("=== PRONTO ===");
}

void loop(){ server.handleClient(); delay(10); }




‚úÖ Esse c√≥digo compila sem erro de loop().

Quer que eu j√° ajuste o delay do stream para atingir 30 FPS reais (menor lat√™ncia) ou prefere manter no ~20‚Äì25 FPS mais est√°vel?




































































































Beleza üëç Vou te mandar o c√≥digo completo e limpo do ESP32-CAM (AI Thinker), j√° com:




Access Point fixo HYDROBOT-CAM em 192.168.4.1


Stream MJPEG em :81/stream


Snapshot em /snapshot


Endpoints /status, /led, /pump, /pump_pwm, /mode, /joystick


PWM da bomba isolado em TIMER_1 / CHANNEL_1 (sem conflito com c√¢mera)


Wi-Fi est√°vel: PS desativado, pot√™ncia m√°xima, log de eventos, watchdog





/**
 * HydroBot.ino - ESP32-CAM (AI Thinker) - AP ONLY
 * - AP fixo (HYDROBOT-CAM) em 192.168.4.1
 * - Stream MJPEG: /stream (porta 81)
 * - API (porta 80): /status, /led, /mode, /joystick, /pump, /pump_pwm?duty=0..255, /snapshot
 * - LED no GPIO 4 (flash)
 * - Bomba no GPIO 14 via PWM (LEDC TIMER_1/CHANNEL_1)
 */

#include <Arduino.h>
#include "esp_camera.h"
#include <WiFi.h>
#include <WebServer.h>
#include "esp_http_server.h"
#include <time.h>
#include "driver/ledc.h"
#include "esp_wifi.h"

// Desativa brownout
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"

// ===================== WIFI AP =====================
const char* AP_SSID = "HYDROBOT-CAM";
const char* AP_PASS = "12345678";
const IPAddress AP_IP(192,168,4,1);
const IPAddress AP_GW(192,168,4,1);
const IPAddress AP_MASK(255,255,255,0);

// ===================== PINOS =====================
#define LED_FLASH_PIN 4
#define PUMP_PIN      14

// ===================== ESTADO =====================
String g_mode = "manual";
bool   g_ledOn = false;
bool   g_pumpOn = false;
bool   g_camOk = false;
float  g_joyX = 0, g_joyY = 0;

static httpd_handle_t stream_httpd = NULL;
WebServer server(80);

// ===================== CAMERA (AI THINKER) =====================
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ===================== UTILS =====================
String isoTimestamp() {
  time_t now = time(nullptr);
  if (now < 1000) return "\"uptime_ms\":" + String(millis());
  struct tm ti; localtime_r(&now, &ti);
  char buf[64]; strftime(buf, sizeof(buf), "%Y-%m-%dT%H:%M:%S%z", &ti);
  String ts(buf);
  if (ts.length() >= 5) ts = ts.substring(0, ts.length()-2) + ":" + ts.substring(ts.length()-2);
  return "\"" + ts + "\"";
}

void sendCORSHeaders(httpd_req_t *req) {
  httpd_resp_set_hdr(req, "Access-Control-Allow-Origin", "*");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Headers", "Content-Type");
}
void sendCORS() {
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}

// ===================== BOMBA (PWM) =====================
static const ledc_channel_t PUMP_CH   = LEDC_CHANNEL_1;
static const ledc_timer_t   PUMP_TMR  = LEDC_TIMER_1;
static const ledc_mode_t    PUMP_MODE = LEDC_HIGH_SPEED_MODE;

void pumpPwmInit() {
  ledc_timer_config_t tcfg = {
    .speed_mode = PUMP_MODE,
    .duty_resolution = LEDC_TIMER_8_BIT,
    .timer_num = PUMP_TMR,
    .freq_hz = 5000,
    .clk_cfg = LEDC_AUTO_CLK
  };
  ledc_timer_config(&tcfg);

  ledc_channel_config_t ccfg = {
    .gpio_num   = PUMP_PIN,
    .speed_mode = PUMP_MODE,
    .channel    = PUMP_CH,
    .intr_type  = LEDC_INTR_DISABLE,
    .timer_sel  = PUMP_TMR,
    .duty       = 0,
    .hpoint     = 0
  };
  ledc_channel_config(&ccfg);
}
inline void pumpWriteDuty(uint8_t d){ ledc_set_duty(PUMP_MODE,PUMP_CH,d); ledc_update_duty(PUMP_MODE,PUMP_CH); }
void pumpSetOnOff(bool on){ g_pumpOn=on; pumpWriteDuty(on?255:0); }
void pumpSetDuty(uint8_t d){ if(d>255)d=255; g_pumpOn=(d>0); pumpWriteDuty(d); }

// ===================== STREAM =====================
esp_err_t jpg_stream_httpd_handler(httpd_req_t *req) {
  sendCORSHeaders(req);
  esp_err_t res = httpd_resp_set_type(req, "multipart/x-mixed-replace;boundary=frame");
  if (res != ESP_OK) return res;

  while (true) {
    camera_fb_t *fb = esp_camera_fb_get();
    if (!fb) break;
    if (fb->format != PIXFORMAT_JPEG) { esp_camera_fb_return(fb); continue; }

    char buf[64];
    size_t hlen = snprintf(buf, 64, "Content-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n", fb->len);
    httpd_resp_send_chunk(req, "\r\n--frame\r\n", 12);
    httpd_resp_send_chunk(req, buf, hlen);
    httpd_resp_send_chunk(req, (const char*)fb->buf, fb->len);
    esp_camera_fb_return(fb);

    vTaskDelay(15/portTICK_PERIOD_MS);
  }
  return ESP_OK;
}
void startCameraStreamServer() {
  httpd_config_t config = HTTPD_DEFAULT_CONFIG();
  config.server_port = 81;
  config.stack_size = 8192;
  httpd_uri_t uri = { .uri="/stream", .method=HTTP_GET, .handler=jpg_stream_httpd_handler, .user_ctx=NULL };
  if (httpd_start(&stream_httpd,&config)==ESP_OK) httpd_register_uri_handler(stream_httpd,&uri);
}

// ===================== SNAPSHOT =====================
void api_snapshot() {
  sendCORS();
  if (!g_camOk) { server.send(503,"application/json","{\"ok\":false,\"error\":\"camera\"}"); return; }
  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) { server.send(503,"application/json","{\"ok\":false,\"error\":\"no_frame\"}"); return; }
  server.sendHeader("Cache-Control","no-cache");
  server.setContentLength(fb->len);
  server.send(200,"image/jpeg","");
  WiFiClient client = server.client();
  client.write(fb->buf, fb->len);
  client.flush(); client.stop();
  esp_camera_fb_return(fb);
}

// ===================== API =====================
void api_status() {
  sendCORS();
  String json="{\"ip\":\""+WiFi.softAPIP().toString()+"\",\"mode\":\""+g_mode+
               "\",\"led\":"+(g_ledOn?"true":"false")+
               ",\"pump\":"+(g_pumpOn?"true":"false")+
               ",\"cam_ok\":"+(g_camOk?"true":"false")+
               ",\"uptime\":"+String(millis())+
               ",\"heap\":"+String(ESP.getFreeHeap())+
               ",\"ts\":"+isoTimestamp()+"}";
  server.send(200,"application/json",json);
}
void api_led(){ sendCORS(); bool on=server.arg("on")=="1"||server.arg("on")=="true"; g_ledOn=on; digitalWrite(LED_FLASH_PIN,on); server.send(200,"application/json","{\"ok\":true}"); }
void api_pump(){ sendCORS(); bool on=server.arg("on")=="1"||server.arg("on")=="true"; pumpSetOnOff(on); server.send(200,"application/json","{\"ok\":true}"); }
void api_pump_pwm(){ sendCORS(); int d=server.hasArg("duty")?server.arg("duty").toInt():-1; if(d<0||d>255){server.send(400,"application/json","{\"ok\":false}");return;} pumpSetDuty(d); server.send(200,"application/json","{\"ok\":true}"); }
void api_mode(){ sendCORS(); String v=server.arg("v"); if(v!="manual"&&v!="auto"&&v!="patrol"){server.send(400,"application/json","{\"ok\":false}");return;} g_mode=v; server.send(200,"application/json","{\"ok\":true}"); }
void api_joystick(){ sendCORS(); g_joyX=server.arg("x").toFloat(); g_joyY=server.arg("y").toFloat(); server.send(200,"application/json","{\"ok\":true}"); }
void handleCORS(){ sendCORS(); server.send(200); }

// ===================== CAMERA INIT =====================
bool initCamera() {
  camera_config_t c;
  c.ledc_channel = LEDC_CHANNEL_0;
  c.ledc_timer   = LEDC_TIMER_0;
  c.pin_d0=Y2_GPIO_NUM; c.pin_d1=Y3_GPIO_NUM; c.pin_d2=Y4_GPIO_NUM; c.pin_d3=Y5_GPIO_NUM;
  c.pin_d4=Y6_GPIO_NUM; c.pin_d5=Y7_GPIO_NUM; c.pin_d6=Y8_GPIO_NUM; c.pin_d7=Y9_GPIO_NUM;
  c.pin_xclk=XCLK_GPIO_NUM; c.pin_pclk=PCLK_GPIO_NUM; c.pin_vsync=VSYNC_GPIO_NUM; c.pin_href=HREF_GPIO_NUM;
  c.pin_sscb_sda=SIOD_GPIO_NUM; c.pin_sscb_scl=SIOC_GPIO_NUM;
  c.pin_pwdn=PWDN_GPIO_NUM; c.pin_reset=RESET_GPIO_NUM;
  c.xclk_freq_hz=10000000; c.pixel_format=PIXFORMAT_JPEG;
  if(psramFound()){ c.frame_size=FRAMESIZE_VGA; c.jpeg_quality=15; c.fb_count=1; c.fb_location=CAMERA_FB_IN_PSRAM; c.grab_mode=CAMERA_GRAB_LATEST; }
  else { c.frame_size=FRAMESIZE_QVGA; c.jpeg_quality=18; c.fb_count=1; c.fb_location=CAMERA_FB_IN_DRAM; c.grab_mode=CAMERA_GRAB_WHEN_EMPTY; }
  return (esp_camera_init(&c)==ESP_OK);
}

// ===================== WIFI SETUP =====================
void startAPOnly() {
  WiFi.mode(WIFI_AP);
  WiFi.softAPConfig(AP_IP,AP_GW,AP_MASK);
  WiFi.softAP(AP_SSID,AP_PASS,6);
  esp_wifi_set_ps(WIFI_PS_NONE);        // sem power save
  esp_wifi_set_max_tx_power(78);        // pot√™ncia m√°x
  Serial.print("AP IP: "); Serial.println(WiFi.softAPIP());
}

// ===================== SETUP/LOOP =====================
void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG,0);
  Serial.begin(115200);
  pinMode(LED_FLASH_PIN,OUTPUT); digitalWrite(LED_FLASH_PIN,LOW);

  g_camOk = initCamera();
  if(!g_camOk) Serial.println("Falha ao iniciar c√¢mera!");

  pumpPwmInit();
  startAPOnly();

  // rotas
  server.on("/status",HTTP_GET,api_status);
  server.on("/led",HTTP_GET,api_led); server.on("/led",HTTP_POST,api_led);
  server.on("/pump",HTTP_GET,api_pump); server.on("/pump",HTTP_POST,api_pump);
  server.on("/pump_pwm",HTTP_GET,api_pump_pwm); server.on("/pump_pwm",HTTP_POST,api_pump_pwm);
  server.on("/mode",HTTP_GET,api_mode); server.on("/mode",HTTP_POST,api_mode);
  server.on("/joystick",HTTP_GET,api_joystick); server.on("/joystick",HTTP_POST,api_joystick);
  server.on("/snapshot",HTTP_GET,api_snapshot);

  // CORS
  server.on("/status",HTTP_OPTIONS,handleCORS);
  server.on("/led",HTTP_OPTIONS,handleCORS);
  server.on("/pump",HTTP_OPTIONS,handleCORS);
  server.on("/pump_pwm",HTTP_OPTIONS,handleCORS);
  server.on("/mode",HTTP_OPTIONS,handleCORS);
  server.on("/joystick",HTTP_OPTIONS,handleCORS);
  server.on("/snapshot",HTTP_OPTIONS,handleCORS);

  server.begin();
  startCameraStreamServer();
  Serial.println("=== PRONTO ===");
}

void loop(){ server.handleClient(); delay(10); }




üëâ Testa esse c√≥digo no seu ESP32-CAM.




Primeiro acessa http://192.168.4.1/status ‚Üí deve dar JSON.


Depois http://192.168.4.1/snapshot ‚Üí retorna JPEG.


E http://192.168.4.1:81/stream ‚Üí v√≠deo.




Quer que eu monte tamb√©m uma vers√£o com FPS for√ßado para 30 no stream (ajuste de vTaskDelay) ou prefere primeiro estabilizar a rede?




























































/**
 * HydroBot.ino - ESP32-CAM (AI Thinker) - AP ONLY
 * - AP fixo (HYDROBOT-CAM) em 192.168.4.1
 * - Stream MJPEG: /stream (porta 81)
 * - API (porta 80): /status, /led, /mode, /joystick, /pump (on/off), /pump_pwm?duty=0..255, /snapshot (JPEG)
 * - LED em GPIO 4 (flash)
 * - Bomba em GPIO 14 via PWM (LEDC) ‚Äî AGORA EM TIMER_1/CHANNEL_1 para n√£o conflitar com a c√¢mera
 */

#include <Arduino.h>
#include "esp_camera.h"
#include <WiFi.h>
#include <WebServer.h>
#include "esp_http_server.h"
#include <time.h>
#include "driver/ledc.h"

// Desativa brownout
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"

// ===================== WIFI AP =====================
const char* AP_SSID = "HYDROBOT-CAM";
const char* AP_PASS = "12345678";
const IPAddress AP_IP(192,168,4,1);
const IPAddress AP_GW(192,168,4,1);
const IPAddress AP_MASK(255,255,255,0);

// ===================== PINOS =====================
#define LED_FLASH_PIN 4
#define PUMP_PIN      14

// ===================== ESTADO =====================
String g_mode = "manual";
bool   g_ledOn = false;
bool   g_pumpOn = false;
float  g_joyX = 0.0f, g_joyY = 0.0f;
bool   g_camOk = false;

static httpd_handle_t stream_httpd = NULL;
WebServer server(80);

// ===================== CAMERA (AI THINKER) =====================
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ===================== UTILS =====================
String isoTimestamp() {
  time_t now = time(nullptr);
  if (now < 8 * 3600 * 2) {
    char buf[64];
    snprintf(buf, sizeof(buf), "\"uptime_ms\":%lu", millis());
    return String("{") + buf + "}";
  }
  struct tm timeinfo; localtime_r(&now, &timeinfo);
  char buf[64]; strftime(buf, sizeof(buf), "%Y-%m-%dT%H:%M:%S%z", &timeinfo);
  String ts(buf);
  if (ts.length() >= 5) ts = ts.substring(0, ts.length()-2) + ":" + ts.substring(ts.length()-2);
  return "\"" + ts + "\"";
}

void sendCORSHeaders(httpd_req_t *req) {
  httpd_resp_set_hdr(req, "Access-Control-Allow-Origin", "*");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  httpd_resp_set_hdr(req, "Access-Control-Allow-Headers", "Content-Type");
}
void sendCORS() {
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}

// ===================== BOMBA (PWM via LEDC) =====================
// *** IMPORTANTE: use TIMER_1 / CHANNEL_1 para n√£o conflitar com a c√¢mera (XCLK usa TIMER_0/CHANNEL_0) ***
static const ledc_channel_t PUMP_CH   = LEDC_CHANNEL_1;
static const ledc_timer_t   PUMP_TMR  = LEDC_TIMER_1;
static const ledc_mode_t    PUMP_MODE = LEDC_HIGH_SPEED_MODE;

void pumpPwmInit() {
  ledc_timer_config_t tcfg = {};
  tcfg.speed_mode      = PUMP_MODE;
  tcfg.timer_num       = PUMP_TMR;
  tcfg.duty_resolution = LEDC_TIMER_8_BIT; // 0..255
  tcfg.freq_hz         = 5000;             // 5 kHz
  tcfg.clk_cfg         = LEDC_AUTO_CLK;
  ledc_timer_config(&tcfg);

  ledc_channel_config_t ccfg = {};
  ccfg.gpio_num   = PUMP_PIN;
  ccfg.speed_mode = PUMP_MODE;
  ccfg.channel    = PUMP_CH;
  ccfg.intr_type  = LEDC_INTR_DISABLE;
  ccfg.timer_sel  = PUMP_TMR;
  ccfg.duty       = 0;
  ccfg.hpoint     = 0;
  ledc_channel_config(&ccfg);

  g_pumpOn = false;
}

static inline void pumpWriteDuty(uint8_t duty) {
  ledc_set_duty(PUMP_MODE, PUMP_CH, duty);
  ledc_update_duty(PUMP_MODE, PUMP_CH);
}
void pumpSetOnOff(bool on) { g_pumpOn = on; pumpWriteDuty(on ? 255 : 0); }
void pumpSetDuty(uint8_t duty) { if (duty>255) duty=255; g_pumpOn = (duty>0); pumpWriteDuty(duty); }

// ===================== STREAM (:81/stream) =====================
static const char* _STREAM_CONTENT_TYPE = "multipart/x-mixed-replace;boundary=frame";
static const char* _STREAM_BOUNDARY     = "\r\n--frame\r\n";
static const char* _STREAM_PART         = "Content-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n";

esp_err_t jpg_stream_httpd_handler(httpd_req_t *req) {
  sendCORSHeaders(req);
  esp_err_t res = httpd_resp_set_type(req, _STREAM_CONTENT_TYPE);
  if (res != ESP_OK) return res;

  while (true) {
    camera_fb_t *fb = esp_camera_fb_get();
    if (!fb) { res = ESP_FAIL; break; }
    if (fb->format != PIXFORMAT_JPEG) { esp_camera_fb_return(fb); vTaskDelay(12/portTICK_PERIOD_MS); continue; }

    res = httpd_resp_send_chunk(req, _STREAM_BOUNDARY, strlen(_STREAM_BOUNDARY));
    if (res == ESP_OK) {
      char part_buf[64];
      size_t hlen = snprintf(part_buf, sizeof(part_buf), _STREAM_PART, fb->len);
      res = httpd_resp_send_chunk(req, part_buf, hlen);
    }
    if (res == ESP_OK) res = httpd_resp_send_chunk(req, (const char*)fb->buf, fb->len);

    esp_camera_fb_return(fb);
    if (res != ESP_OK) break;
    vTaskDelay(12 / portTICK_PERIOD_MS); // pequena pausa para estabilidade
  }
  return res;
}

void startCameraStreamServer() {
  httpd_config_t config = HTTPD_DEFAULT_CONFIG();
  config.server_port = 81;
  config.ctrl_port   = 32768;
  config.max_open_sockets = 3;
  config.task_priority    = 5;

  httpd_uri_t stream_uri = { .uri="/stream", .method=HTTP_GET, .handler=jpg_stream_httpd_handler, .user_ctx=NULL };
  if (httpd_start(&stream_httpd, &config) == ESP_OK) {
    httpd_register_uri_handler(stream_httpd, &stream_uri);
    Serial.println("Stream em :81/stream");
  }
}

// ===================== HOME HTML (teste) =====================
const char* HOME_HTML =
  "<!doctype html><meta name=viewport content='width=device-width,initial-scale=1'>"
  "<style>body{background:#111;color:#eee;font-family:sans-serif;margin:20px}"
  "a,button{background:#e53b2f;color:#fff;padding:10px 14px;border-radius:8px;text-decoration:none;margin-right:8px}"
  "#img{display:block;margin-top:12px;max-width:100%;height:auto;background:#000}</style>"
  "<h2>HydroBot CAM</h2>"
  "<div>"
    "<a href='/snapshot'>Snapshot</a>"
    "<a href='http://192.168.4.1:81/stream'>Stream</a>"
    "<button onclick='reload()'>Recarregar</button>"
  "</div>"
  "<img id=img src='/snapshot'>"
  "<script>function reload(){document.getElementById('img').src='/snapshot?ts='+Date.now()}</script>";

// ===================== API (porta 80) =====================
void api_status() {
  sendCORS();
  String ts = isoTimestamp();
  String json = "{";
  json += "\"ip\":\"" + WiFi.softAPIP().toString() + "\",";
  json += "\"mode\":\"" + g_mode + "\",";
  json += "\"led\":" + String(g_ledOn ? "true":"false") + ",";
  json += "\"pump\":" + String(g_pumpOn ? "true":"false") + ",";
  json += "\"cam_ok\":" + String(g_camOk ? "true":"false") + ",";
  json += "\"uptime\":" + String(millis()) + ",";
  json += "\"heap\":" + String(ESP.getFreeHeap()) + ",";
  json += "\"ts\":" + ts;
  json += "}";
  server.send(200, "application/json", json);
}

void api_led() {
  sendCORS();
  bool on = server.arg("on") == "1" || server.arg("on") == "true";
  g_ledOn = on;
  digitalWrite(LED_FLASH_PIN, g_ledOn ? HIGH : LOW);
  server.send(200, "application/json", String("{\"ok\":true,\"led\":") + (g_ledOn?"true":"false") + "}");
}

void api_pump() {
  sendCORS();
  bool on = server.arg("on") == "1" || server.arg("on") == "true";
  pumpSetOnOff(on);
  server.send(200, "application/json", String("{\"ok\":true,\"pump\":") + (g_pumpOn?"true":"false") + "}");
}

void api_pump_pwm() {
  sendCORS();
  int duty = server.hasArg("duty") ? server.arg("duty").toInt() : -1;
  if (duty < 0 || duty > 255) { server.send(400, "application/json", "{\"ok\":false,\"error\":\"duty 0..255\"}"); return; }
  pumpSetDuty((uint8_t)duty);
  server.send(200, "application/json", String("{\"ok\":true,\"duty\":") + duty + "}");
}

void api_mode() {
  sendCORS();
  String v = server.arg("v"); if (v.length()==0) v = server.arg("mode");
  if (v != "manual" && v != "auto" && v != "patrol") {
    server.send(400, "application/json", "{\"ok\":false,\"error\":\"mode must be manual|auto|patrol\"}");
    return;
  }
  g_mode = v;
  server.send(200, "application/json", String("{\"ok\":true,\"mode\":\"") + g_mode + "\"}");
}

void api_joystick() {
  sendCORS();
  float x = server.arg("x").toFloat();
  float y = server.arg("y").toFloat();
  if (x<-1) x=-1; if (x>1) x=1; if (y<-1) y=-1; if (y>1) y=1;
  g_joyX = x; g_joyY = y;
  server.send(200, "application/json", String("{\"ok\":true,\"x\":") + x + ",\"y\":" + y + "}");
}

void handleCORS() { sendCORS(); server.send(200); }

// ===== /snapshot (JPEG √∫nico) =====
void api_snapshot() {
  sendCORS();
  Serial.println("[/snapshot] requisitado");
  if (!g_camOk) { server.send(503, "application/json", "{\"ok\":false,\"error\":\"camera_unavailable\"}"); return; }

  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) { Serial.println("[/snapshot] fb NULL"); server.send(503, "application/json", "{\"ok\":false,\"error\":\"no_frame\"}"); return; }
  if (fb->format != PIXFORMAT_JPEG) { Serial.println("[/snapshot] not JPEG"); esp_camera_fb_return(fb); server.send(500, "application/json", "{\"ok\":false,\"error\":\"not_jpeg\"}"); return; }

  server.sendHeader("Cache-Control", "no-cache, no-store, must-revalidate");
  server.sendHeader("Pragma", "no-cache");
  server.sendHeader("Expires", "0");
  server.sendHeader("Connection", "close");
  server.setContentLength(fb->len);
  server.send(200, "image/jpeg", "");

  WiFiClient client = server.client();
  size_t wrote = client.write(fb->buf, fb->len);
  esp_camera_fb_return(fb);

  if (wrote != fb->len) Serial.printf("[/snapshot] client.write parcial (%u/%u)\n", (unsigned)wrote, (unsigned)fb->len);
}

// ===================== SETUP =====================
void setupNTP() { configTime(-3*3600, 0, "pool.ntp.org", "time.nist.gov"); }

bool initCamera() {
  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;  // XCLK usa TIMER_0/CHANNEL_0
  config.ledc_timer   = LEDC_TIMER_0;
  config.pin_d0       = Y2_GPIO_NUM;
  config.pin_d1       = Y3_GPIO_NUM;
  config.pin_d2       = Y4_GPIO_NUM;
  config.pin_d3       = Y5_GPIO_NUM;
  config.pin_d4       = Y6_GPIO_NUM;
  config.pin_d5       = Y7_GPIO_NUM;
  config.pin_d6       = Y8_GPIO_NUM;
  config.pin_d7       = Y9_GPIO_NUM;
  config.pin_xclk     = XCLK_GPIO_NUM;
  config.pin_pclk     = PCLK_GPIO_NUM;
  config.pin_vsync    = VSYNC_GPIO_NUM;
  config.pin_href     = HREF_GPIO_NUM;
  config.pin_sscb_sda = SIOD_GPIO_NUM;
  config.pin_sscb_scl = SIOC_GPIO_NUM;
  config.pin_pwdn     = PWDN_GPIO_NUM;
  config.pin_reset    = RESET_GPIO_NUM;

  config.xclk_freq_hz = 10000000;            // 10 MHz (est√°vel)
  config.pixel_format = PIXFORMAT_JPEG;

  if (psramFound()) {
    config.frame_size   = FRAMESIZE_VGA;     // 640x480
    config.jpeg_quality = 15;                // mais compress√£o
    config.fb_count     = 1;                 // evita press√£o na PSRAM
    config.fb_location  = CAMERA_FB_IN_PSRAM;
    config.grab_mode    = CAMERA_GRAB_LATEST;
  } else {
    config.frame_size   = FRAMESIZE_QVGA;
    config.jpeg_quality = 18;
    config.fb_count     = 1;
    config.fb_location  = CAMERA_FB_IN_DRAM;
    config.grab_mode    = CAMERA_GRAB_WHEN_EMPTY;
  }

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) { Serial.printf("Camera init failed: 0x%x\n", err); return false; }
  return true;
}

void startAPOnly() {
  WiFi.mode(WIFI_AP);
  WiFi.softAPConfig(AP_IP, AP_GW, AP_MASK);
  WiFi.softAP(AP_SSID, AP_PASS, 6);
  WiFi.setSleep(false); // mant√©m AP est√°vel
  delay(200);
  Serial.println("AP iniciado:");
  Serial.print(" SSID: "); Serial.println(AP_SSID);
  Serial.print(" PASS: "); Serial.println(AP_PASS);
  Serial.print(" IP: ");   Serial.println(WiFi.softAPIP());
}

void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);
  Serial.begin(115200);
  Serial.println("\n=== HYDROBOT CAM (AP ONLY / FIX LEDC CONFLICT) ===");

  pinMode(LED_FLASH_PIN, OUTPUT);
  digitalWrite(LED_FLASH_PIN, LOW);

  // *** Inicialize a c√¢mera ANTES da bomba, mas agora n√£o h√° conflito de timer/canal
  g_camOk = initCamera();
  if (!g_camOk) Serial.println("Camera FAIL (seguindo sem camera)");

  // Agora inicializa PWM da bomba (em TIMER_1/CHANNEL_1)
  pumpPwmInit();

  startAPOnly();
  setupNTP();

  // Rotas HTTP (porta 80)
  server.on("/",          HTTP_GET, [](){ sendCORS(); server.send(200, "text/html", HOME_HTML); });
  server.on("/status",    HTTP_GET, api_status);
  server.on("/led",       HTTP_GET, api_led);
  server.on("/led",       HTTP_POST, api_led);
  server.on("/pump",      HTTP_GET, api_pump);
  server.on("/pump",      HTTP_POST, api_pump);
  server.on("/pump_pwm",  HTTP_GET, api_pump_pwm);
  server.on("/pump_pwm",  HTTP_POST, api_pump_pwm);
  server.on("/mode",      HTTP_GET, api_mode);
  server.on("/mode",      HTTP_POST, api_mode);
  server.on("/joystick",  HTTP_GET, api_joystick);
  server.on("/joystick",  HTTP_POST, api_joystick);
  server.on("/snapshot",  HTTP_GET, api_snapshot);

  // CORS (OPTIONS)
  server.on("/status",    HTTP_OPTIONS, handleCORS);
  server.on("/led",       HTTP_OPTIONS, handleCORS);
  server.on("/pump",      HTTP_OPTIONS, handleCORS);
  server.on("/pump_pwm",  HTTP_OPTIONS, handleCORS);
  server.on("/mode",      HTTP_OPTIONS, handleCORS);
  server.on("/joystick",  HTTP_OPTIONS, handleCORS);
  server.on("/snapshot",  HTTP_OPTIONS, handleCORS);

  server.begin();
  Serial.println("HTTP :80 pronto");

  startCameraStreamServer();
  Serial.println("=== PRONTO ===");
}

void loop() {
  server.handleClient();
  delay(10);
}














































































Tranquilo ‚Äî d√° para rodar com Python 3.13. Esses avisos do Pylance aparecem porque o VS Code est√° apontando para um interpretador sem as libs. Siga os passos abaixo (Windows/PowerShell):


1) Crie e ative uma venv com o 3.13


No diret√≥rio do server_heuristic.py:


py -3.13 -m venv .venv
.\.venv\Scripts\Activate.ps1
# se bloquear por pol√≠tica:
# Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
python -m pip install --upgrade pip wheel setuptools



2) Instale os pacotes (3.13)


Tente primeiro a vers√£o ‚Äúheadless‚Äù do OpenCV (mais leve e sem depend√™ncia de GUI):


pip install "fastapi>=0.110" "uvicorn[standard]" watchfiles requests "pydantic>=2,<3" numpy
pip install "opencv-python-headless>=4.10"





Se o √∫ltimo comando falhar, tente a variante padr√£o:




pip install "opencv-python>=4.10"





Se ainda der erro de wheel ausente para 3.13, voc√™ pode:




(A) usar o headless nightly: pip install --pre opencv-python-headless


(B) instalar um wheel do Gohlke (Windows): baixe o .whl compat√≠vel com cp313 e rode pip install <arquivo.whl>.


(C) temporariamente desligar a parte de objetos (roda s√≥ detec√ß√£o de fogo) ‚Äî posso te mandar um server_heuristic_no_cv2.py se quiser.






3) Aponte o VS Code para a venv




Ctrl+Shift+P ‚Üí Python: Select Interpreter ‚Üí escolha o que termina em .venv\Scripts\python.exe.


Se os ‚ÄúImport could not be resolved‚Äù n√£o sumirem ap√≥s alguns segundos, use Developer: Reload Window.




4) Rode o servidor


uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload



Testes r√°pidos




http://127.0.0.1:8000/healthz ‚Üí deve retornar {"ok":true,...}


http://127.0.0.1:8000/status ‚Üí deve mostrar fps_in, hasFrame, etc.





requirements.txt (op√ß√£o pr√°tica)


Se preferir, crie um requirements.txt com:


fastapi>=0.110
uvicorn[standard]>=0.27
watchfiles>=0.21
requests>=2.32
pydantic>=2,<3
numpy>=2
opencv-python-headless>=4.10



E instale com:


pip install -r requirements.txt




Se algo falhar


Me mande:




a sa√≠da de python --version dentro da venv,


a sa√≠da de pip list,


e o primeiro erro que aparece ao rodar pip install opencv-python-headless (ou ao iniciar o uvicorn).




Com isso eu ajusto exatamente o que est√° faltando no seu ambiente.






































































Beleza ‚Äî arrumei o app para n√£o quebrar quando o servidor n√£o responde e para exibir o v√≠deo + caixas assim que o /snapshot e o /detect ficarem OK. Tamb√©m acrescentei um health-check no servidor para o app s√≥ iniciar os loops quando houver c√¢mera/frames recentes. Abaixo est√£o os dois arquivos completos j√° com os ajustes.



‚úÖ CameraScreen.tsx (robusto, com fallback e sem crashes)


O que mudei (resumo pr√°tico):




üîí Health-check antes de tudo: o app s√≥ inicia os loops de snapshot/detect quando GET /healthz retorna ok:true.


üßØ AbortController em todos os fetches de loop (evita promessas penduradas ao sair da tela).


üõ°Ô∏è Try/catch + backoff quando o servidor cai; a UI mostra estado em statusText sem derrubar o app.


üñºÔ∏è Crossfade seguro: onError n√£o tenta promover um frame inv√°lido.


üß∞ Overlay escalado: se o servidor ainda n√£o enviar frame_wh, usamos 640√ó480 como padr√£o (evita null).


üí® Snapshot ~20‚Äì25 fps est√°vel (50ms alvo) com throttle quando h√° erro.


üß™ /objects: contagem de pessoas/animais e caixas com r√≥tulos e confian√ßa (cores: fogo=vermelho, pessoa=ciano, animal=verde).






Cole direto substituindo o arquivo atual.




// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
  Image,
  Animated,
  LayoutChangeEvent,
  AppState,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

/* ---------- PALETA ---------- */
const PALETTE = {
  bg: "#0b0b0f",
  card: "#121218",
  border: "#25273a",
  accent: "#e6403a",
  text: "#e5e7eb",
};

/* ---------- TEXTOS ---------- */
const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:",
    test: "Testar",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "BOMBA ON",
    pumpOff: "BOMBA OFF",
    server: "Servidor:",
    detecting: "Detectando‚Ä¶",
    saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    persons: "Pessoas",
    animals: "Animais",
    backend: "Modelo",
    waiting: "Aguardando servidor‚Ä¶",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:",
    test: "Test",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "PUMP ON",
    pumpOff: "PUMP OFF",
    server: "Server:",
    detecting: "Detecting‚Ä¶",
    saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    persons: "People",
    animals: "Animals",
    backend: "Model",
    waiting: "Waiting for server‚Ä¶",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:",
    test: "Probar",
    ledOn: "LED ENC.",
    ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.",
    pumpOff: "BOMBA APAG.",
    server: "Servidor:",
    detecting: "Detectando‚Ä¶",
    saving: "Guardando...",
    statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    persons: "Personas",
    animals: "Animales",
    backend: "Modelo",
    waiting: "Esperando servidor‚Ä¶",
  },
};

const DEFAULT_IP = "192.168.4.1";
const DEFAULT_SERVER = "http://192.168.4.2:8000";
const DEFAULT_FRAME_WH = { w: 640, h: 480 }; // fallback seguro

const appLogo = require("../../assets/logo.png");

/* ---------- HERO ---------- */
function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

/* ---------- STREAM (opcional, mantido) ---------- */
function LiveMJPEG({ ip }: { ip: string }) {
  const html = `
    <html><head><meta name="viewport" content="width=device-width, initial-scale=1">
      <style>
        html,body{margin:0;padding:0;background:#000;height:100%;}
        .wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;background:#000;}
        img{max-width:100%;max-height:100%;object-fit:contain;background:#000;}
      </style>
    </head>
    <body><div class="wrap"><img src="http://${ip}:81/stream"/></div></body></html>
  `.trim();
  return (
    <WebView
      originWhitelist={["*"]}
      source={{ html }}
      javaScriptEnabled
      allowsInlineMediaPlayback
      mediaPlaybackRequiresUserAction={false}
      automaticallyAdjustContentInsets={false}
      style={{ flex: 1, backgroundColor: "black" }}
    />
  );
}

/* ---------- SNAPSHOT com crossfade ---------- */
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: (ok: boolean) => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}

      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => {
              // n√£o promove imagem inv√°lida
              onNextShown(false);
              fade.setValue(0);
              setShowNext(false);
            }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true);
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

/* ---------- OVERLAY DE CAIXAS ---------- */
type BoxType = "fire" | "person" | "animal";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType; conf?: number };

function BoxesOverlay({
  frameWH,
  containerWH,
  boxes,
}: {
  frameWH: { w: number; h: number } | null;
  containerWH: { w: number; h: number } | null;
  boxes: SrcBox[];
}) {
  const f = frameWH && frameWH.w > 0 && frameWH.h > 0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w <= 0 || containerWH.h <= 0) return null;

  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale;
  const dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale;
          const top = b.y * scale;
          const width = b.w * scale;
          const height = b.h * scale;

          let borderColor = "#ff3b30"; // fire
          if (b.type === "person") borderColor = "#00e5ff";
          else if (b.type === "animal") borderColor = "#7CFC00";

          return (
            <View
              key={`${i}-${b.type}`}
              style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor, borderRadius: 6 }}
            >
              <View
                style={{
                  position: "absolute",
                  left: 0,
                  top: -18,
                  paddingHorizontal: 6,
                  paddingVertical: 2,
                  borderRadius: 4,
                  backgroundColor: borderColor,
                }}
              >
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>
                  {b.type.toUpperCase()}
                  {typeof b.conf === "number" ? ` ${b.conf.toFixed(2)}` : ""}
                </Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

/* ---------- TELA PRINCIPAL ---------- */
export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conex√µes
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState(T.waiting);
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detec√ß√£o (sempre ativa)
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);

  // pessoas/animais
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("‚Äî");
  const [confMax, setConfMax] = useState<number>(0);

  // caixas + dimens√µes para overlay
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  // registro autom√°tico
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // vis√£o: SNAPSHOT (sempre)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // health gate
  const [ready, setReady] = useState(false);

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);
  const healthUrl = useMemo(() => `${cleanServer(server)}/healthz`, [server]);

  /* ===== AppState pausa/retoma loops ===== */
  const appStateRef = useRef(AppState.currentState);
  useEffect(() => {
    const sub = AppState.addEventListener("change", (s) => {
      appStateRef.current = s;
    });
    return () => sub.remove();
  }, []);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(
        `OK ‚Ä¢ ip:${j.ip ?? j.camera_ip ?? ip} ‚Ä¢ mode:${j.mode ?? "‚Äî"} ‚Ä¢ led:${j.led ? "on" : "off"} ‚Ä¢ pump:${
          j.pump ? "on" : "off"
        }`
      );
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() {
    try {
      const t = !ledOn;
      await fetch(ledUrl(t));
      setLedOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  async function togglePump() {
    try {
      const t = !pumpOn;
      await fetch(pumpUrl(t));
      setPumpOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  useEffect(() => {
    pingStatus();
    const id = setInterval(pingStatus, 5000);
    return () => clearInterval(id);
  }, [statusUrl]);

  /* ===== HEALTH-CHECK DO SERVIDOR ===== */
  useEffect(() => {
    let stop = false;
    let backoff = 500; // ms
    const controller = new AbortController();

    const poll = async () => {
      if (stop) return;
      try {
        const r = await fetch(healthUrl, { signal: controller.signal });
        const j = await r.json();
        if (j?.ok) {
          setReady(true);
          setStatusText(`Server OK ‚Ä¢ fps_in:${j.fps_in} ‚Ä¢ hasFrame:${j.hasFrame}`);
          return;
        }
      } catch {
        // ignore
      }
      setReady(false);
      setStatusText(T.waiting);
      setTimeout(poll, backoff);
      backoff = Math.min(backoff * 1.6, 5000);
    };

    poll();
    return () => {
      stop = true;
      controller.abort();
    };
  }, [healthUrl, T]);

  /* ===== SNAPSHOT LOOP (~20‚Äì25 fps, com backoff em erro) ===== */
  useEffect(() => {
    if (!ready) return;
    let stop = false;
    let interval = 50; // ~20 fps
    const controller = new AbortController();

    setCurrentFrameUri(`${cleanServer(server)}/snapshot?ts=${Date.now()}`);

    const tick = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        if (!loadingNextRef.current) {
          const url = `${cleanServer(server)}/snapshot?ts=${Date.now()}`;
          setNextFrameUri(url);
        }
        interval = 50;
      } catch {
        interval = Math.min(interval * 1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();

    return () => {
      stop = true;
      controller.abort();
    };
  }, [server, ready]);

  function onNextLoadStart() {
    loadingNextRef.current = true;
  }
  function onNextShown(ok: boolean) {
    if (ok && nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== LOOP DE DETEC√á√ÉO + CAIXAS (5‚Äì6 Hz) ===== */
  useEffect(() => {
    if (!ready) return;
    let stop = false;
    let interval = 180;
    const controller = new AbortController();

    const loop = async () => {
      if (stop || appStateRef.current !== "active") return;
      try {
        const r = await fetch(`${cleanServer(server)}/detect`, { signal: controller.signal });
        const j = await r.json();

        if (j && j.ok !== false) {
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          // frame size
          const wh =
            Array.isArray(j.frame_wh) && j.frame_wh.length === 2
              ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 }
              : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);

          // objetos
          const o = j.objects || {};
          const objs = o.objects || [];
          const nPerson =
            typeof o.n_person_stable === "number"
              ? o.n_person_stable
              : typeof o.n_person === "number"
              ? o.n_person
              : objs.filter((x: any) => String(x.label).toLowerCase() === "person").length;
          const nAnimals =
            typeof o.n_animals_stable === "number"
              ? o.n_animals_stable
              : typeof o.n_animals === "number"
              ? o.n_animals
              : objs.filter((x: any) => String(x.label).toLowerCase() !== "person").length;

          setPeople(nPerson || 0);
          setAnimals(nAnimals || 0);
          setBackend(o.backend || "‚Äî");
          setConfMax(Number(o.conf_max || 0));

          // montar caixas
          const boxes: SrcBox[] = [];
          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) {
              if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0);
              boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          for (const it of objs) {
            if (!it || !Array.isArray(it.box) || it.box.length < 4) continue;
            const [x, y, w, h] = it.box.map((n: any) => Number(n) || 0);
            const label = String(it.label || "").toLowerCase();
            const conf = typeof it.conf === "number" ? it.conf : undefined;
            if (label === "person") boxes.push({ x, y, w, h, type: "person", conf });
            else boxes.push({ x, y, w, h, type: "animal", conf });
          }
          setOverlayBoxes(boxes);

          interval = 180;
        }
      } catch {
        // zera UI sem quebrar
        setIsFire(false);
        setFireScore(0);
        setPeople(0);
        setAnimals(0);
        setOverlayBoxes([]);
        interval = Math.min(interval * 1.5, 1500);
      } finally {
        setTimeout(loop, interval);
      }
    };
    loop();

    return () => {
      stop = true;
      controller.abort();
    };
  }, [server, ready]);

  /* ===== Registro autom√°tico (rising edge) ===== */
  useEffect(() => {
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;

    if (rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [isFire, server, saving, T]);

  /* ===== Joystick ===== */
  const RADIUS = 64,
    KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS,
          ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) {
          nx /= len;
          ny /= len;
        }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
      onPanResponderTerminate: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
    })
  ).current;

  /* ===== Medidas do container do v√≠deo ===== */
  function onVideoLayout(e: LayoutChangeEvent) {
    const { width, height } = e.nativeEvent.layout;
    setVideoContainerWH({ w: width, h: height });
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor + indicador */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={(s) => {
            setServer(s);
            setReady(false); // for√ßa novo health-check
            setStatusText(T.waiting);
          }}
          placeholder={T.placeholderServer}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <View style={[styles.badge, { backgroundColor: ready ? "#065f46" : "#1f2937" }]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>{ready ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>
          {statusText}
        </Text>
      </View>

      {/* Banner de fogo */}
      <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      {/* Banner de pessoas/animais + backend */}
      <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
        <Text style={styles.statChip}>
          {T.persons}: <Text style={styles.statNumber}>{people}</Text>
        </Text>
        <Text style={styles.statChip}>
          {T.animals}: <Text style={styles.statNumber}>{animals}</Text>
        </Text>
        <Text style={styles.modelChip}>
          {T.backend}: {backend} ‚Ä¢ conf_max {confMax.toFixed(2)}
        </Text>
      </View>

      {/* V√≠deo (snapshot) + Overlay */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        <CrossfadeImage
          currentUri={currentFrameUri}
          nextUri={nextFrameUri}
          onNextLoadStart={onNextLoadStart}
          onNextShown={onNextShown}
        />
        {overlayBoxes.length > 0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: 22 * 2,
                height: 22 * 2,
                borderRadius: 22,
                transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

/* ---------- ESTILOS ---------- */
const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  // HERO
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: "#0b0d14",
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
    minWidth: 110,
  },
  btn: {
    backgroundColor: PALETTE.accent,
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1322",
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  badge: {
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" },
  statNumber: { color: "#fff" },
  modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(230,64,58,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});




‚úÖ server_heuristic.py (com /healthz e respostas √† prova de app)


O que mudei (resumo):




‚ûï Novo endpoint /healthz: retorna ok:true, fps de entrada e se h√° frame recente (usado pelo app).


üßØ Respostas sempre JSON mesmo se modelos n√£o carregarem (o seu j√° estava bom, mantive e s√≥ acrescentei o /healthz).


üß™ Sem altera√ß√µes de heur√≠stica (mantive a sua l√≥gica de fogo/objetos).






Substitua o arquivo atual por este (√© o seu + /healthz).




# server_heuristic.py
# FOGO (heur√≠stico) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny) com vota√ß√£o/hold anti-pisca
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"

# Ajustes de robustez
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
JPEG_QUALITY = 85
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0"
}
MAX_BYTES = 4_000_000

# ===================== FOGO (heur√≠stico) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

# anti-pisca (vota√ß√£o/hold)
VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}
MNET_IN_SIZE = (300,300); MNET_SCALE = 0.007843; MNET_MEAN = 127.5
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# YOLOv4-tiny (COCO)
YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"
YOLO_IN_SZ = (416,416)

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (Stable)", version="1.7.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
  camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
  img = np.zeros((270, 480, 3), dtype=np.uint8)
  img[:, :] = (40, 40, 200)
  cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
  cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
  ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
  return buf.tobytes()

# ===================== GRABBER =====================
class MJPEGGrabber:
  def __init__(self):
    self._lock = threading.Lock()
    self._stop = threading.Event()
    self._thread: Optional[threading.Thread] = None
    self._ip = CAMERA_IP
    self._last_jpeg: Optional[bytes] = None
    self._last_ts_ms: int = 0
    self._frames = 0
    self._fps = 0.0
    self._last_fps_tick = time.time()
    self._session = requests.Session()

  def start(self, ip: Optional[str] = None):
    if ip: self._ip = ip
    self.stop()
    self._stop.clear()
    self._thread = threading.Thread(target=self._run, daemon=True)
    self._thread.start()

  def stop(self):
    self._stop.set()
    if self._thread and self._thread.is_alive():
      self._thread.join(timeout=1.0)
    self._thread = None

  def _run(self):
    backoff = 0.5
    while not self._stop.is_set():
      url = STREAM_URL_FMT.format(self._ip)
      try:
        with self._session.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQUEST_HEADERS) as r:
          if r.status_code != 200:
            time.sleep(backoff); backoff = min(backoff*2, 5.0); continue
          backoff = 0.2
          buf = b""
          self._frames = 0
          self._last_fps_tick = time.time()

          for chunk in r.iter_content(chunk_size=4096):
            if self._stop.is_set(): break
            if not chunk: continue
            buf += chunk
            if len(buf) > MAX_BYTES: buf = b""

            i = buf.find(BOUNDARY)
            if i == -1: continue

            hdr_start = i + len(BOUNDARY)
            while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
              hdr_start += 2

            headers_end = buf.find(b"\r\n\r\n", hdr_start)
            if headers_end == -1: continue

            headers_bytes = buf[hdr_start:headers_end]
            content_length = None
            for line in headers_bytes.split(b"\r\n"):
              if line.lower().startswith(b"content-length:"):
                try: content_length = int(line.split(b":", 1)[1].strip())
                except: content_length = None
                break

            img_start = headers_end + 4
            jpeg_bytes = None
            if content_length is not None:
              if len(buf) < img_start + content_length: continue
              jpeg_bytes = buf[img_start:img_start + content_length]
              buf = buf[img_start + content_length:]
            else:
              j = buf.find(BOUNDARY, img_start)
              if j != -1:
                jpeg_bytes = buf[img_start:j]
                buf = buf[j:]
              else:
                continue

            if jpeg_bytes:
              ts_ms = int(time.time() * 1000)
              with self._lock:
                self._last_jpeg = jpeg_bytes
                self._last_ts_ms = ts_ms
              self._frames += 1
              now = time.time()
              if now - self._last_fps_tick >= 1.0:
                self._fps = self._frames / (now - self._last_fps_tick)
                self._frames = 0
                self._last_fps_tick = now

      except Exception:
        time.sleep(backoff); backoff = min(backoff*2, 5.0)

  def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
    with self._lock:
      if self._last_jpeg is None: return None
      if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
      return self._last_jpeg

  def status(self):
    with self._lock:
      age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
      return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
              "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VIS√ÉO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
  b, g, r = cv2.split(frame_bgr)
  return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
          (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
  hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
  return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
  ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
  y, cr, cb = cv2.split(ycrcb)
  skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
  dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
  return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
  ax, ay, aw, ah = a; bx, by, bw, bh = b
  ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
  ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
  iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
  inter = iw*ih; union = aw*ah + bw*bh - inter
  return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
  k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
  m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
  m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
  cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  boxes = []
  for c in cnts:
    x,y,w,h = cv2.boundingRect(c)
    if w*h >= min_area: boxes.append([x,y,w,h])
  return boxes

class Detector:
  def __init__(self, src: MJPEGGrabber):
    self.src = src
    self._lock = threading.Lock()
    self._stop = threading.Event()
    self._thread: Optional[threading.Thread] = None
    self._prev_gray: Optional[np.ndarray] = None
    self._score_raw = 0.0; self._score_ema = 0.0
    self._is_fire = False; self._boxes: List[List[int]] = []
    self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
    self._last_main_box: Optional[Tuple[int,int,int,int]] = None
    self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
    self._last_result_ts = 0
    self._last_frame_wh: Tuple[int,int] = (0,0)

  def start(self):
    self.stop(); self._stop.clear()
    self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

  def stop(self):
    self._stop.set()
    if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
    self._thread = None

  def _run(self):
    min_interval = 1.0/DETECTOR_MAX_FPS
    while not self._stop.is_set():
      t0 = time.time()
      jpeg = self.src.get_latest_jpeg()
      if jpeg is None: time.sleep(0.01); continue
      frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
      if frame is None: time.sleep(0.005); continue
      H,W = frame.shape[:2]
      self._last_frame_wh = (W,H)

      mask_hsv = hsv_fire_mask(frame)
      mask_skin = skin_mask_ycrcb(frame)
      mask_red  = rgb_red_dominance_mask(frame)

      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
      gray = cv2.GaussianBlur(gray,(3,3),0)
      motion_mask = np.zeros_like(gray,np.uint8)
      if self._prev_gray is not None:
        diff = cv2.absdiff(gray,self._prev_gray)
        _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
        if MOTION_DILATE_ITERS>0:
          k = np.ones((3,3),np.uint8)
          motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
      self._prev_gray = gray

      stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
      stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

      hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
      V = hsv[...,2]
      bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
      red_boost = cv2.bitwise_and(mask_red,bright)
      combined = cv2.bitwise_or(stable, red_boost)

      ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
      v_mean = float(np.mean(V))/255.0
      score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
      ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
      score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
      ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

      boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
      main_box = None
      if boxes:
        areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
        if self._last_main_box is not None:
          self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
        else: self._persist_hits = 1
      else: self._persist_hits = 0
      self._last_main_box = tuple(main_box) if main_box is not None else None

      if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
      elif ema<=HYST_LOW: guess=0
      else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

      self._votes.append(guess)
      final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

      with self._lock:
        self._score_raw=float(score_raw); self._score_ema=float(ema)
        self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
        self._last_result_ts=int(time.time()*1000)
        self._det_frames+=1
        now=time.time()
      if now-self._last_fps_tick>=1.0:
        self._det_fps=self._det_frames/(now-self._last_fps_tick)
        self._det_frames=0; self._last_fps_tick=now

      elapsed = time.time()-t0
      if elapsed<min_interval: time.sleep(min_interval-elapsed)

  def get_result(self)->Dict[str,Any]:
    with self._lock:
      return {
        "ok": True,
        "isFire": self._is_fire,
        "score": round(self._score_ema,3),
        "score_raw": round(self._score_raw,3),
        "score_ema": round(self._score_ema,3),
        "boxes": self._boxes,
        "ts": self._last_result_ts,
        "fps_det": round(self._det_fps,2),
        "vote": {"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
        "persist": {"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
        "hyst": {"hi":HYST_HIGH,"lo":HYST_LOW},
        "frame_wh": list(self._last_frame_wh) if self._last_frame_wh else None,
      }

detector = Detector(grabber); detector.start()

# ===================== OBJETOS =====================
class ObjectsDetector:
  def __init__(self, src: MJPEGGrabber):
    self.src = src
    self._lock = threading.Lock()
    self._stop = threading.Event()
    self._thread: Optional[threading.Thread] = None

    self.backend = "mobilenet-ssd"
    self.net = None; self.ok = False
    self.proto = None; self.weights = None; self.cfg = None; self.names = None
    self.labels = []
    self.swap_rb = False
    self._nohit = 0
    self._last_conf_max = 0.0

    self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
    self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
    self.hold_person_until = 0
    self.hold_animal_until = 0

    self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
    self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

    self._try_load_mnet()
    if not self.ok:
      self._try_load_yolo()

  def _try_load_mnet(self):
    self.backend = "mobilenet-ssd"
    self.labels = MNET_CLASSES
    self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
    self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
    if not self.proto or not self.weights:
      self.ok = False; self.net=None; return
    try:
      net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
      net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
      net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
      self.net = net; self.ok = True; self.swap_rb=False
    except Exception:
      self.ok = False; self.net=None

  def _try_load_yolo(self):
    self.backend = "yolov4-tiny"
    if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
      self.ok=False; self.net=None; return
    try:
      net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
      net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
      net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
      with open(COCO_NAMES, "r", encoding="utf-8") as f:
        self.labels = [ln.strip() for ln in f if ln.strip()]
      self.net = net; self.ok = True
    except Exception:
      self.ok=False; self.net=None

  def start(self):
    self.stop(); self._stop.clear()
    self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

  def stop(self):
    self._stop.set()
    if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
    self._thread=None

  def _infer_mnet(self, frame, conf_th):
    (h,w)=frame.shape[:2]
    blob = cv2.dnn.blobFromImage(cv2.resize(frame,(300,300)),
                                 0.007843, (300,300), 127.5, swapRB=self.swap_rb, crop=False)
    self.net.setInput(blob); det=self.net.forward()
    boxes=[]; confs=[]; labels=[]
    conf_max=0.0
    for i in range(det.shape[2]):
      conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
      if conf<conf_th: continue
      idx=int(det[0,0,i,1])
      if 0<=idx<len(self.labels):
        label=self.labels[idx]
        if label not in {"person","cat","dog","bird","horse","sheep","cow"}: continue
        x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
        x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
        if rw*rh<=0: continue
        boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
    idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
    keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
    out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
    out.sort(key=lambda o:o["conf"], reverse=True)
    return out[:15], conf_max

  def _infer_yolo(self, frame, conf_th):
    (H,W)=frame.shape[:2]
    ln = self.net.getUnconnectedOutLayersNames()
    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), swapRB=True, crop=False)
    self.net.setInput(blob); layerOutputs = self.net.forward(ln)
    boxes=[]; confs=[]; labels=[]
    conf_max = 0.0
    for output in layerOutputs:
      for det in output:
        scores = det[5:]
        classID = int(np.argmax(scores))
        conf = float(scores[classID])
        conf_max = max(conf_max, conf)
        if conf < conf_th: continue
        label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
        if label not in COCO_ANIMAL_NAMES: continue
        bx = det[0:4]
        (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
        x = int(cx - w/2); y = int(cy - h/2)
        boxes.append([max(0,x), max(0,y), int(w), int(h)])
        confs.append(conf); labels.append(label)
    idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
    keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
    out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
    out.sort(key=lambda o:o["conf"], reverse=True)
    return out[:15], conf_max

  def _run(self):
    min_interval = 1.0/OBJECTS_MAX_FPS
    while not self._stop.is_set():
      t0 = time.time()
      jpeg = self.src.get_latest_jpeg()
      if jpeg is None: time.sleep(0.01); continue
      frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
      if frame is None: time.sleep(0.005); continue

      out=[]; cmax=0.0; backend=self.backend
      if self.ok and self.net is not None:
        try:
          if self.backend=="mobilenet-ssd":
            out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
            self._nohit = self._nohit+1 if cmax<0.05 else 0
            if self._nohit>=10:
              self.swap_rb = not self.swap_rb
              self._nohit = 0
          else:
            out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
        except Exception as e:
          self.ok=False
          with self._lock:
            self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                        "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
          time.sleep(0.05); continue

      if (backend=="mobilenet-ssd" and cmax<0.05 and
          os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
        self._try_load_yolo()
        backend=self.backend
        if self.ok and self.backend=="yolov4-tiny":
          out,cmax = self._infer_yolo(frame, max(0.2, OBJ_CONF_THRESH))

      n_person  = sum(1 for o in out if o["label"]=="person")
      n_animals = sum(1 for o in out if o["label"]!="person")
      hit_person  = 1 if n_person  > 0 else 0
      hit_animal  = 1 if n_animals > 0 else 0
      self.votes_person.append(hit_person)
      self.votes_animal.append(hit_animal)
      now_ms = int(time.time()*1000)
      if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
      if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
      stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
      stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

      with self._lock:
        self._last_conf_max=cmax
        self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                    "objects":out,"ts":int(time.time()*1000),
                    "proto":self.proto,"weights":self.weights,"cfg":YOLO_CFG if backend=="yolov4-tiny" else None,
                    "names":COCO_NAMES if backend=="yolov4-tiny" else None,
                    "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                    "n_person":n_person,"n_animals":n_animals,
                    "n_person_stable":1 if stable_person else 0,
                    "n_animals_stable":1 if stable_animal else 0}

      self._frames+=1; now=time.time()
      if now-self._last_fps_tick>=1.0:
        self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

      dt = time.time()-t0
      if dt<min_interval: time.sleep(min_interval-dt)

  def get(self)->Dict[str,Any]:
    with self._lock:
      return dict(self._last)

objects_det = ObjectsDetector(grabber); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/healthz")
def healthz():
  s = grabber.status()
  return {"ok": True, "fps_in": s.get("fps_in"), "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms")}

@app.get("/status")
def status():
  s1 = grabber.status(); s2 = detector.get_result()
  return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
          "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
  global CAMERA_IP
  CAMERA_IP = cfg.camera_ip
  grabber.start(CAMERA_IP)
  return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
  jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
  if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
  return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
  res = detector.get_result()
  res["objects"] = objects_det.get()
  if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
    return res
  jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
  if jpeg is None: return {"ok": False, "error": "no recent frame"}
  frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
  if frame is None: return {"ok": False, "error": "decode failed"}
  H,W = frame.shape[:2]
  mask_hsv = hsv_fire_mask(frame)
  ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
  v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
  score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
  is_fire = bool(score_raw >= HYST_HIGH)
  return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
          "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
          "frame_wh":[W,H],
          "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
  global OBJ_CONF_THRESH
  if conf is not None:
    OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
  return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
  jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
  if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
  frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
  if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

  o = objects_det.get(); backend = o.get("backend"); det = objects_det
  try:
    if backend=="yolov4-tiny":
      objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, conf)))
    else:
      objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, conf)))
  except Exception:
    return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

  for obj in objs:
    x,y,w,h = obj["box"]
    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
    cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
  ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
  return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
  o = objects_det.get(); s = grabber.status()
  return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
          "proto":o.get("proto"), "weights":o.get("weights"),
          "cfg":o.get("cfg"), "names":o.get("names"),
          "swap_rb":o.get("swap_rb"), "conf_max":o.get("conf_max"),
          "conf_thresh":OBJ_CONF_THRESH, "fps_obj":o.get("fps_obj"),
          "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
          "n_person":o.get("n_person"), "n_animals":o.get("n_animals"),
          "n_person_stable":o.get("n_person_stable"), "n_animals_stable":o.get("n_animals_stable"),
          "num_objects":len(o.get("objects",[])), "error":o.get("error")}




Dicas importantes (Android/Expo)




Se voc√™ estiver em build de produ√ß√£o (n√£o Dev), o Android pode bloquear HTTP simples. Garanta cleartext habilitado:



Expo (app.json):

{
  "expo": {
    "android": {
      "usesCleartextTraffic": true
    }
  }
}









No Wi-Fi do ESP, o telefone precisa alcan√ßar o PC do servidor (192.168.4.2:8000). Se estiver em redes diferentes, use o IP acess√≠vel a partir do celular (ou rode o servidor no pr√≥prio celular com Termux/python, se preferir).




Se algo ainda acusar ‚Äúsomething went wrong‚Äù, me diga a primeira linha do erro vermelho que aparece (ou o stack), que eu j√° miro exatamente nesse ponto.
















































































// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
  Image,
  Animated,
  LayoutChangeEvent,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

/* ---------- PALETA ---------- */
const PALETTE = {
  bg: "#0b0b0f",
  card: "#121218",
  border: "#25273a",
  accent: "#e6403a",
  text: "#e5e7eb",
};

/* ---------- TEXTOS ---------- */
const textsByLang = {
  pt: {
    heroSubtitle: "Monitoramento e Controle",
    espIp: "ESP IP:",
    test: "Testar",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "BOMBA ON",
    pumpOff: "BOMBA OFF",
    server: "Servidor:",
    detecting: "Detectando‚Ä¶",
    saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    persons: "Pessoas",
    animals: "Animais",
    backend: "Modelo",
  },
  en: {
    heroSubtitle: "Monitoring & Control",
    espIp: "ESP IP:",
    test: "Test",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "PUMP ON",
    pumpOff: "PUMP OFF",
    server: "Server:",
    detecting: "Detecting‚Ä¶",
    saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    persons: "People",
    animals: "Animals",
    backend: "Model",
  },
  es: {
    heroSubtitle: "Monitoreo y Control",
    espIp: "ESP IP:",
    test: "Probar",
    ledOn: "LED ENC.",
    ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.",
    pumpOff: "BOMBA APAG.",
    server: "Servidor:",
    detecting: "Detectando‚Ä¶",
    saving: "Guardando...",
    statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    persons: "Personas",
    animals: "Animales",
    backend: "Modelo",
  },
};

const DEFAULT_IP = "192.168.4.1";
const DEFAULT_SERVER = "http://192.168.4.2:8000";

// caminho correto da logo a partir de src/screens
const appLogo = require("../../assets/logo.png");

/* ---------- HERO ---------- */
function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

/* ---------- STREAM (mantido para poss√≠vel uso futuro) ---------- */
function LiveMJPEG({ ip }: { ip: string }) {
  const html = `
    <html><head><meta name="viewport" content="width=device-width, initial-scale=1">
      <style>
        html,body{margin:0;padding:0;background:#000;height:100%;}
        .wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;background:#000;}
        img{max-width:100%;max-height:100%;object-fit:contain;background:#000;}
      </style>
    </head>
    <body><div class="wrap"><img src="http://${ip}:81/stream"/></div></body></html>
  `.trim();

  return (
    <WebView
      originWhitelist={["*"]}
      source={{ html }}
      javaScriptEnabled
      allowsInlineMediaPlayback
      mediaPlaybackRequiresUserAction={false}
      automaticallyAdjustContentInsets={false}
      style={{ flex: 1, backgroundColor: "black" }}
    />
  );
}

/* ---------- SNAPSHOT com crossfade ---------- */
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: () => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}

      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={onNextShown}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown();
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

/* ---------- OVERLAY DE CAIXAS ---------- */
type BoxType = "fire" | "person" | "animal";
type SrcBox = { x: number; y: number; w: number; h: number; type: BoxType; conf?: number };

function BoxesOverlay({
  frameWH,
  containerWH,
  boxes,
}: {
  frameWH: { w: number; h: number } | null;
  containerWH: { w: number; h: number } | null;
  boxes: SrcBox[];
}) {
  if (!frameWH || !containerWH || frameWH.w <= 0 || frameWH.h <= 0 || containerWH.w <= 0 || containerWH.h <= 0) {
    return null;
  }
  const scale = Math.min(containerWH.w / frameWH.w, containerWH.h / frameWH.h);
  const dispW = frameWH.w * scale;
  const dispH = frameWH.h * scale;
  const offsetX = (containerWH.w - dispW) / 2;
  const offsetY = (containerWH.h - dispH) / 2;

  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position: "absolute", left: offsetX, top: offsetY, width: dispW, height: dispH }}>
        {boxes.map((b, i) => {
          const left = b.x * scale;
          const top = b.y * scale;
          const width = b.w * scale;
          const height = b.h * scale;

          let borderColor = "#ff3b30"; // fire
          if (b.type === "person") borderColor = "#00e5ff";
          else if (b.type === "animal") borderColor = "#7CFC00";

          return (
            <View
              key={`${i}-${b.type}`}
              style={{ position: "absolute", left, top, width, height, borderWidth: 3, borderColor, borderRadius: 6 }}
            >
              <View
                style={{
                  position: "absolute",
                  left: 0,
                  top: -18,
                  paddingHorizontal: 6,
                  paddingVertical: 2,
                  borderRadius: 4,
                  backgroundColor: borderColor,
                }}
              >
                <Text style={{ color: "#000", fontWeight: "800", fontSize: 10 }}>
                  {b.type.toUpperCase()}
                  {typeof b.conf === "number" ? ` ${b.conf.toFixed(2)}` : ""}
                </Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

/* ---------- TELA PRINCIPAL ---------- */
export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conex√µes
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState("‚Äî");
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detec√ß√£o (sempre ativa)
  const [detectOn] = useState(true);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);

  // pessoas/animais
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("‚Äî");
  const [confMax, setConfMax] = useState<number>(0);

  // caixas + dimens√µes para overlay
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{ w: number; h: number } | null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{ w: number; h: number } | null>(null);

  // registro autom√°tico
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // vis√£o: sempre SNAPSHOT fallback (sem bot√£o para trocar)
  const [useStream] = useState(false);
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(`OK ‚Ä¢ ip:${j.ip} ‚Ä¢ mode:${j.mode} ‚Ä¢ led:${j.led ? "on" : "off"} ‚Ä¢ pump:${j.pump ? "on" : "off"}`);
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() {
    try {
      const t = !ledOn;
      await fetch(ledUrl(t));
      setLedOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  async function togglePump() {
    try {
      const t = !pumpOn;
      await fetch(pumpUrl(t));
      setPumpOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  useEffect(() => {
    pingStatus();
    const id = setInterval(pingStatus, 5000);
    return () => clearInterval(id);
  }, [statusUrl]);

  /* ===== SNAPSHOT fallback (25 fps alvo) ===== */
  useEffect(() => {
    let stop = false;
    const FPS_INTERVAL = 40; // ~25 fps

    setCurrentFrameUri(`${cleanServer(server)}/snapshot?ts=${Date.now()}`);

    const tick = () => {
      if (stop) return;
      if (!loadingNextRef.current) {
        const url = `${cleanServer(server)}/snapshot?ts=${Date.now()}`;
        setNextFrameUri(url);
      }
      setTimeout(tick, FPS_INTERVAL);
    };
    tick();

    return () => {
      stop = true;
    };
  }, [server]);

  function onNextLoadStart() {
    loadingNextRef.current = true;
  }
  function onNextShown() {
    if (nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== LOOP DE DETEC√á√ÉO + CAIXAS ===== */
  useEffect(() => {
    let stop = false;

    const loop = async () => {
      try {
        const r = await fetch(`${cleanServer(server)}/detect`);
        const j = await r.json();

        if (!stop && j && j.ok !== false) {
          // fogo
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          // frame size (se servidor expor; opcional)
          const wh =
            Array.isArray(j.frame_wh) && j.frame_wh.length === 2
              ? { w: Number(j.frame_wh[0]) || 0, h: Number(j.frame_wh[1]) || 0 }
              : null;
          if (wh && wh.w > 0 && wh.h > 0) setFrameWH(wh);

          // objetos e est√°veis
          const o = j.objects || {};
          const objs = o.objects || [];
          const peopleStable =
            typeof o.n_person_stable === "number"
              ? o.n_person_stable
              : typeof o.n_person === "number"
              ? o.n_person
              : objs.some((x: any) => String(x.label).toLowerCase() === "person")
              ? 1
              : 0;
          const animalsStable =
            typeof o.n_animals_stable === "number"
              ? o.n_animals_stable
              : typeof o.n_animals === "number"
              ? o.n_animals
              : objs.some((x: any) => String(x.label).toLowerCase() !== "person")
              ? 1
              : 0;

          setPeople(peopleStable);
          setAnimals(animalsStable);
          setBackend(o.backend || "‚Äî");
          setConfMax(Number(o.conf_max || 0));

          // montar caixas
          const boxes: SrcBox[] = [];

          if (j.isFire && Array.isArray(j.boxes)) {
            for (const b of j.boxes) {
              if (!Array.isArray(b) || b.length < 4) continue;
              const [x, y, w, h] = b.map((n: any) => Number(n) || 0);
              boxes.push({ x, y, w, h, type: "fire" });
            }
          }
          for (const it of objs) {
            if (!it || !Array.isArray(it.box) || it.box.length < 4) continue;
            const [x, y, w, h] = it.box.map((n: any) => Number(n) || 0);
            const label = String(it.label || "").toLowerCase();
            const conf = typeof it.conf === "number" ? it.conf : undefined;
            if (label === "person") boxes.push({ x, y, w, h, type: "person", conf });
            else boxes.push({ x, y, w, h, type: "animal", conf });
          }
          setOverlayBoxes(boxes);
        }
      } catch {
        if (!stop) {
          setIsFire(false);
          setFireScore(0);
          setPeople(0);
          setAnimals(0);
          setOverlayBoxes([]);
        }
      } finally {
        if (!stop) setTimeout(loop, 180); // ~5-6Hz
      }
    };
    loop();

    return () => {
      stop = true;
    };
  }, [server]);

  /* ===== Registro autom√°tico ===== */
  useEffect(() => {
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;

    if (rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [isFire, server, saving, T]);

  /* ===== Joystick ===== */
  const RADIUS = 64,
    KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS,
          ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) {
          nx /= len;
          ny /= len;
        }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
      onPanResponderTerminate: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
    })
  ).current;

  /* ===== Medidas do container do v√≠deo ===== */
  function onVideoLayout(e: LayoutChangeEvent) {
    const { width, height } = e.nativeEvent.layout;
    setVideoContainerWH({ w: width, h: height });
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />

      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor + indicador (sem bot√µes de detectar/stream/boxes) */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={setServer}
          placeholder={T.placeholderServer}
          placeholderTextColor="#8a93a5"
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <View style={[styles.badge]}>
          <Text style={{ color: "#fff", fontWeight: "800" }}>{T.detecting}</Text>
        </View>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>
          {statusText}
        </Text>
      </View>

      {/* Banner de fogo */}
      <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      {/* Banner de pessoas/animais + backend */}
      <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
        <Text style={styles.statChip}>
          {T.persons}: <Text style={styles.statNumber}>{people}</Text>
        </Text>
        <Text style={styles.statChip}>
          {T.animals}: <Text style={styles.statNumber}>{animals}</Text>
        </Text>
        <Text style={styles.modelChip}>
          {T.backend}: {backend} ‚Ä¢ conf_max {confMax.toFixed(2)}
        </Text>
      </View>

      {/* V√≠deo (sempre snapshot) + Overlay */}
      <View style={{ flex: 1 }} onLayout={onVideoLayout}>
        <CrossfadeImage
          currentUri={currentFrameUri}
          nextUri={nextFrameUri}
          onNextLoadStart={onNextLoadStart}
          onNextShown={onNextShown}
        />

        {overlayBoxes.length > 0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: 64 * 2 + 24, height: 64 * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: 64 * 2, height: 64 * 2, borderRadius: 64 }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: 22 * 2,
                height: 22 * 2,
                borderRadius: 22,
                transform: [{ translateX: joy.x * 64 }, { translateY: -joy.y * 64 }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

/* ---------- ESTILOS ---------- */
const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  // HERO
  hero: { alignItems: "center", paddingTop: 12, paddingBottom: 6 },
  heroLogo: { width: 80, height: 80, marginBottom: 6, resizeMode: "contain" },
  heroTitle: { color: "#fff", fontSize: 22, fontWeight: "800" },
  heroSubtitle: { color: "#d1d5db", marginTop: 2 },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: "#0b0d14",
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
    minWidth: 110,
  },
  btn: {
    backgroundColor: PALETTE.accent,
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1322",
    borderBottomWidth: StyleSheet.hairlineWidth,
    borderBottomColor: PALETTE.border,
  },
  badge: {
    backgroundColor: "#1f2937",
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: PALETTE.border,
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" },
  statNumber: { color: "#fff" },
  modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(230,64,58,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});












# server_heuristic.py
# FOGO (heur√≠stico) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny) com vota√ß√£o/hold anti-pisca
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"

# Ajustes de robustez
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
JPEG_QUALITY = 85
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0"
}
MAX_BYTES = 4_000_000

# ===================== FOGO (heur√≠stico) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

# anti-pisca (vota√ß√£o/hold)
VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}
MNET_IN_SIZE = (300,300); MNET_SCALE = 0.007843; MNET_MEAN = 127.5
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# YOLOv4-tiny (COCO)
YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"
YOLO_IN_SZ = (416,416)

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (Stable)", version="1.7.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER =====================
class MJPEGGrabber:
    """
    Consumidor √∫nico do :81/stream com reconex√£o gentil (backoff) e keep-alive.
    """
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()
        self._session = requests.Session()

    def start(self, ip: Optional[str] = None):
        if ip: self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        backoff = 0.5  # s (exponencial at√© 5s)
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with self._session.get(
                    url,
                    stream=True,
                    timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                    headers=REQUEST_HEADERS,
                ) as r:
                    if r.status_code != 200:
                        time.sleep(backoff)
                        backoff = min(backoff*2, 5.0)
                        continue
                    # conectou ‚Äî reset backoff
                    backoff = 0.2
                    buf = b""
                    self._frames = 0
                    self._last_fps_tick = time.time()

                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set():
                            break
                        if not chunk:
                            continue
                        buf += chunk
                        if len(buf) > MAX_BYTES:
                            # prote√ß√£o contra lixo acumulado
                            buf = b""

                        i = buf.find(BOUNDARY)
                        if i == -1:
                            continue

                        hdr_start = i + len(BOUNDARY)
                        # pula CRLF extras
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2

                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1:
                            continue

                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try:
                                    content_length = int(line.split(b":", 1)[1].strip())
                                except:
                                    content_length = None
                                break

                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length:
                                continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue

                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now

            except Exception:
                # espera com backoff antes de tentar de novo
                time.sleep(backoff)
                backoff = min(backoff*2, 5.0)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VIS√ÉO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area: boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0
        self._last_frame_wh: Tuple[int,int] = (0,0)

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue
            H,W = frame.shape[:2]
            self._last_frame_wh = (W,H)

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else: self._persist_hits = 1
            else: self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
            elif ema<=HYST_LOW: guess=0
            else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)
                self._det_frames+=1
                now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval: time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema,3),
                "score_raw": round(self._score_raw,3),
                "score_ema": round(self._score_ema,3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps,2),
                "vote": {"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                "persist": {"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                "hyst": {"hi":HYST_HIGH,"lo":HYST_LOW},
                "frame_wh": list(self._last_frame_wh) if self._last_frame_wh else None,
            }

detector = Detector(grabber); detector.start()

# ===================== OBJETOS (AutoBackend + votos/hold) =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"   # ou "yolov4-tiny"
        self.net = None; self.ok = False
        self.proto = None; self.weights = None; self.cfg = None; self.names = None
        self.labels = []
        self.swap_rb = False
        self._nohit = 0
        self._last_conf_max = 0.0

        self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
        self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
        self.hold_person_until = 0
        self.hold_animal_until = 0

        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
        self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok = False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok = False; self.net=None

    def _try_load_yolo(self):
        self.backend = "yolov4-tiny"
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,MNET_IN_SIZE),
                                     MNET_SCALE, MNET_IN_SIZE, MNET_MEAN, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in MNET_ANIMALS: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, YOLO_IN_SZ, swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            out=[]; cmax=0.0; backend=self.backend
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False
                    with self._lock:
                        self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                                    "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            # fallback para YOLO se MNet estiver ‚Äúmudo‚Äù
            if (backend=="mobilenet-ssd" and cmax<0.05 and
                os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
                self._try_load_yolo()
                backend=self.backend
                if self.ok and self.backend=="yolov4-tiny":
                    out,cmax = self._infer_yolo(frame, max(0.2, OBJ_CONF_THRESH))

            n_person  = sum(1 for o in out if o["label"]=="person")
            n_animals = sum(1 for o in out if o["label"]!="person")
            hit_person  = 1 if n_person  > 0 else 0
            hit_animal  = 1 if n_animals > 0 else 0
            self.votes_person.append(hit_person)
            self.votes_animal.append(hit_animal)
            now_ms = int(time.time()*1000)
            if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
            if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
            stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
            stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "proto":self.proto,"weights":self.weights,"cfg":YOLO_CFG if backend=="yolov4-tiny" else None,
                            "names":COCO_NAMES if backend=="yolov4-tiny" else None,
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                            "n_person":n_person,"n_animals":n_animals,
                            "n_person_stable":1 if stable_person else 0,
                            "n_animals_stable":1 if stable_animal else 0}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status(); s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    # fallback r√°pido (fogo somente)
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return {"ok": False, "error": "decode failed"}
    H,W = frame.shape[:2]
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "frame_wh":[W,H],
            "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get(); backend = o.get("backend"); det = objects_det
    try:
        if backend=="yolov4-tiny":
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, conf)))
        else:
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, conf)))
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get(); s = grabber.status()
    return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
            "proto":o.get("proto"), "weights":o.get("weights"),
            "cfg":o.get("cfg"), "names":o.get("names"),
            "swap_rb":o.get("swap_rb"), "conf_max":o.get("conf_max"),
            "conf_thresh":OBJ_CONF_THRESH, "fps_obj":o.get("fps_obj"),
            "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
            "n_person":o.get("n_person"), "n_animals":o.get("n_animals"),
            "n_person_stable":o.get("n_person_stable"), "n_animals_stable":o.get("n_animals_stable"),
            "num_objects":len(o.get("objects",[])), "error":o.get("error")}
