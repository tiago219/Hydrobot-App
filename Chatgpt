# server_heuristic.py
# FOGO (heurístico) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny) com votação/hold anti-pisca
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"

# Ajustes de robustez
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
JPEG_QUALITY = 85
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0"
}
MAX_BYTES = 4_000_000

# ===================== FOGO (heurístico) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

# anti-pisca (votação/hold)
VOTE_WIN_OBJ   = 10
VOTE_NEED_OBJ  = 3
HOLD_MS_OBJ    = 900

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}
MNET_IN_SIZE = (300,300); MNET_SCALE = 0.007843; MNET_MEAN = 127.5
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# YOLOv4-tiny (COCO)
YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"
YOLO_IN_SZ = (416,416)

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (Stable)", version="1.7.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
  camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
  img = np.zeros((270, 480, 3), dtype=np.uint8)
  img[:, :] = (40, 40, 200)
  cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
  cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
  ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
  return buf.tobytes()

# ===================== GRABBER =====================
class MJPEGGrabber:
  def __init__(self):
    self._lock = threading.Lock()
    self._stop = threading.Event()
    self._thread: Optional[threading.Thread] = None
    self._ip = CAMERA_IP
    self._last_jpeg: Optional[bytes] = None
    self._last_ts_ms: int = 0
    self._frames = 0
    self._fps = 0.0
    self._last_fps_tick = time.time()
    self._session = requests.Session()

  def start(self, ip: Optional[str] = None):
    if ip: self._ip = ip
    self.stop()
    self._stop.clear()
    self._thread = threading.Thread(target=self._run, daemon=True)
    self._thread.start()

  def stop(self):
    self._stop.set()
    if self._thread and self._thread.is_alive():
      self._thread.join(timeout=1.0)
    self._thread = None

  def _run(self):
    backoff = 0.5
    while not self._stop.is_set():
      url = STREAM_URL_FMT.format(self._ip)
      try:
        with self._session.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQUEST_HEADERS) as r:
          if r.status_code != 200:
            time.sleep(backoff); backoff = min(backoff*2, 5.0); continue
          backoff = 0.2
          buf = b""
          self._frames = 0
          self._last_fps_tick = time.time()

          for chunk in r.iter_content(chunk_size=4096):
            if self._stop.is_set(): break
            if not chunk: continue
            buf += chunk
            if len(buf) > MAX_BYTES: buf = b""

            i = buf.find(BOUNDARY)
            if i == -1: continue

            hdr_start = i + len(BOUNDARY)
            while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
              hdr_start += 2

            headers_end = buf.find(b"\r\n\r\n", hdr_start)
            if headers_end == -1: continue

            headers_bytes = buf[hdr_start:headers_end]
            content_length = None
            for line in headers_bytes.split(b"\r\n"):
              if line.lower().startswith(b"content-length:"):
                try: content_length = int(line.split(b":", 1)[1].strip())
                except: content_length = None
                break

            img_start = headers_end + 4
            jpeg_bytes = None
            if content_length is not None:
              if len(buf) < img_start + content_length: continue
              jpeg_bytes = buf[img_start:img_start + content_length]
              buf = buf[img_start + content_length:]
            else:
              j = buf.find(BOUNDARY, img_start)
              if j != -1:
                jpeg_bytes = buf[img_start:j]
                buf = buf[j:]
              else:
                continue

            if jpeg_bytes:
              ts_ms = int(time.time() * 1000)
              with self._lock:
                self._last_jpeg = jpeg_bytes
                self._last_ts_ms = ts_ms
              self._frames += 1
              now = time.time()
              if now - self._last_fps_tick >= 1.0:
                self._fps = self._frames / (now - self._last_fps_tick)
                self._frames = 0
                self._last_fps_tick = now

      except Exception:
        time.sleep(backoff); backoff = min(backoff*2, 5.0)

  def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
    with self._lock:
      if self._last_jpeg is None: return None
      if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
      return self._last_jpeg

  def status(self):
    with self._lock:
      age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
      return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
              "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VISÃO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
  b, g, r = cv2.split(frame_bgr)
  return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
          (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
  hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
  return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
  ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
  y, cr, cb = cv2.split(ycrcb)
  skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
  dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
  return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
  ax, ay, aw, ah = a; bx, by, bw, bh = b
  ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
  ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
  iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
  inter = iw*ih; union = aw*ah + bw*bh - inter
  return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
  k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
  m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
  m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
  cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  boxes = []
  for c in cnts:
    x,y,w,h = cv2.boundingRect(c)
    if w*h >= min_area: boxes.append([x,y,w,h])
  return boxes

class Detector:
  def __init__(self, src: MJPEGGrabber):
    self.src = src
    self._lock = threading.Lock()
    self._stop = threading.Event()
    self._thread: Optional[threading.Thread] = None
    self._prev_gray: Optional[np.ndarray] = None
    self._score_raw = 0.0; self._score_ema = 0.0
    self._is_fire = False; self._boxes: List[List[int]] = []
    self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
    self._last_main_box: Optional[Tuple[int,int,int,int]] = None
    self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
    self._last_result_ts = 0
    self._last_frame_wh: Tuple[int,int] = (0,0)

  def start(self):
    self.stop(); self._stop.clear()
    self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

  def stop(self):
    self._stop.set()
    if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
    self._thread = None

  def _run(self):
    min_interval = 1.0/DETECTOR_MAX_FPS
    while not self._stop.is_set():
      t0 = time.time()
      jpeg = self.src.get_latest_jpeg()
      if jpeg is None: time.sleep(0.01); continue
      frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
      if frame is None: time.sleep(0.005); continue
      H,W = frame.shape[:2]
      self._last_frame_wh = (W,H)

      mask_hsv = hsv_fire_mask(frame)
      mask_skin = skin_mask_ycrcb(frame)
      mask_red  = rgb_red_dominance_mask(frame)

      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
      gray = cv2.GaussianBlur(gray,(3,3),0)
      motion_mask = np.zeros_like(gray,np.uint8)
      if self._prev_gray is not None:
        diff = cv2.absdiff(gray,self._prev_gray)
        _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
        if MOTION_DILATE_ITERS>0:
          k = np.ones((3,3),np.uint8)
          motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
      self._prev_gray = gray

      stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
      stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

      hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
      V = hsv[...,2]
      bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
      red_boost = cv2.bitwise_and(mask_red,bright)
      combined = cv2.bitwise_or(stable, red_boost)

      ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
      v_mean = float(np.mean(V))/255.0
      score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
      ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
      score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
      ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

      boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
      main_box = None
      if boxes:
        areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
        if self._last_main_box is not None:
          self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
        else: self._persist_hits = 1
      else: self._persist_hits = 0
      self._last_main_box = tuple(main_box) if main_box is not None else None

      if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
      elif ema<=HYST_LOW: guess=0
      else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

      self._votes.append(guess)
      final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

      with self._lock:
        self._score_raw=float(score_raw); self._score_ema=float(ema)
        self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
        self._last_result_ts=int(time.time()*1000)
        self._det_frames+=1
        now=time.time()
      if now-self._last_fps_tick>=1.0:
        self._det_fps=self._det_frames/(now-self._last_fps_tick)
        self._det_frames=0; self._last_fps_tick=now

      elapsed = time.time()-t0
      if elapsed<min_interval: time.sleep(min_interval-elapsed)

  def get_result(self)->Dict[str,Any]:
    with self._lock:
      return {
        "ok": True,
        "isFire": self._is_fire,
        "score": round(self._score_ema,3),
        "score_raw": round(self._score_raw,3),
        "score_ema": round(self._score_ema,3),
        "boxes": self._boxes,
        "ts": self._last_result_ts,
        "fps_det": round(self._det_fps,2),
        "vote": {"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
        "persist": {"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
        "hyst": {"hi":HYST_HIGH,"lo":HYST_LOW},
        "frame_wh": list(self._last_frame_wh) if self._last_frame_wh else None,
      }

detector = Detector(grabber); detector.start()

# ===================== OBJETOS =====================
class ObjectsDetector:
  def __init__(self, src: MJPEGGrabber):
    self.src = src
    self._lock = threading.Lock()
    self._stop = threading.Event()
    self._thread: Optional[threading.Thread] = None

    self.backend = "mobilenet-ssd"
    self.net = None; self.ok = False
    self.proto = None; self.weights = None; self.cfg = None; self.names = None
    self.labels = []
    self.swap_rb = False
    self._nohit = 0
    self._last_conf_max = 0.0

    self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
    self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
    self.hold_person_until = 0
    self.hold_animal_until = 0

    self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
    self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

    self._try_load_mnet()
    if not self.ok:
      self._try_load_yolo()

  def _try_load_mnet(self):
    self.backend = "mobilenet-ssd"
    self.labels = MNET_CLASSES
    self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
    self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
    if not self.proto or not self.weights:
      self.ok = False; self.net=None; return
    try:
      net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
      net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
      net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
      self.net = net; self.ok = True; self.swap_rb=False
    except Exception:
      self.ok = False; self.net=None

  def _try_load_yolo(self):
    self.backend = "yolov4-tiny"
    if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
      self.ok=False; self.net=None; return
    try:
      net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
      net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
      net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
      with open(COCO_NAMES, "r", encoding="utf-8") as f:
        self.labels = [ln.strip() for ln in f if ln.strip()]
      self.net = net; self.ok = True
    except Exception:
      self.ok=False; self.net=None

  def start(self):
    self.stop(); self._stop.clear()
    self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

  def stop(self):
    self._stop.set()
    if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
    self._thread=None

  def _infer_mnet(self, frame, conf_th):
    (h,w)=frame.shape[:2]
    blob = cv2.dnn.blobFromImage(cv2.resize(frame,(300,300)),
                                 0.007843, (300,300), 127.5, swapRB=self.swap_rb, crop=False)
    self.net.setInput(blob); det=self.net.forward()
    boxes=[]; confs=[]; labels=[]
    conf_max=0.0
    for i in range(det.shape[2]):
      conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
      if conf<conf_th: continue
      idx=int(det[0,0,i,1])
      if 0<=idx<len(self.labels):
        label=self.labels[idx]
        if label not in {"person","cat","dog","bird","horse","sheep","cow"}: continue
        x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
        x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
        if rw*rh<=0: continue
        boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
    idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
    keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
    out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
    out.sort(key=lambda o:o["conf"], reverse=True)
    return out[:15], conf_max

  def _infer_yolo(self, frame, conf_th):
    (H,W)=frame.shape[:2]
    ln = self.net.getUnconnectedOutLayersNames()
    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), swapRB=True, crop=False)
    self.net.setInput(blob); layerOutputs = self.net.forward(ln)
    boxes=[]; confs=[]; labels=[]
    conf_max = 0.0
    for output in layerOutputs:
      for det in output:
        scores = det[5:]
        classID = int(np.argmax(scores))
        conf = float(scores[classID])
        conf_max = max(conf_max, conf)
        if conf < conf_th: continue
        label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
        if label not in COCO_ANIMAL_NAMES: continue
        bx = det[0:4]
        (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
        x = int(cx - w/2); y = int(cy - h/2)
        boxes.append([max(0,x), max(0,y), int(w), int(h)])
        confs.append(conf); labels.append(label)
    idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,0.45)
    keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
    out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
    out.sort(key=lambda o:o["conf"], reverse=True)
    return out[:15], conf_max

  def _run(self):
    min_interval = 1.0/OBJECTS_MAX_FPS
    while not self._stop.is_set():
      t0 = time.time()
      jpeg = self.src.get_latest_jpeg()
      if jpeg is None: time.sleep(0.01); continue
      frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
      if frame is None: time.sleep(0.005); continue

      out=[]; cmax=0.0; backend=self.backend
      if self.ok and self.net is not None:
        try:
          if self.backend=="mobilenet-ssd":
            out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
            self._nohit = self._nohit+1 if cmax<0.05 else 0
            if self._nohit>=10:
              self.swap_rb = not self.swap_rb
              self._nohit = 0
          else:
            out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
        except Exception as e:
          self.ok=False
          with self._lock:
            self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                        "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
          time.sleep(0.05); continue

      if (backend=="mobilenet-ssd" and cmax<0.05 and
          os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
        self._try_load_yolo()
        backend=self.backend
        if self.ok and self.backend=="yolov4-tiny":
          out,cmax = self._infer_yolo(frame, max(0.2, OBJ_CONF_THRESH))

      n_person  = sum(1 for o in out if o["label"]=="person")
      n_animals = sum(1 for o in out if o["label"]!="person")
      hit_person  = 1 if n_person  > 0 else 0
      hit_animal  = 1 if n_animals > 0 else 0
      self.votes_person.append(hit_person)
      self.votes_animal.append(hit_animal)
      now_ms = int(time.time()*1000)
      if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
      if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
      stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
      stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

      with self._lock:
        self._last_conf_max=cmax
        self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                    "objects":out,"ts":int(time.time()*1000),
                    "proto":self.proto,"weights":self.weights,"cfg":YOLO_CFG if backend=="yolov4-tiny" else None,
                    "names":COCO_NAMES if backend=="yolov4-tiny" else None,
                    "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                    "n_person":n_person,"n_animals":n_animals,
                    "n_person_stable":1 if stable_person else 0,
                    "n_animals_stable":1 if stable_animal else 0}

      self._frames+=1; now=time.time()
      if now-self._last_fps_tick>=1.0:
        self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

      dt = time.time()-t0
      if dt<min_interval: time.sleep(min_interval-dt)

  def get(self)->Dict[str,Any]:
    with self._lock:
      return dict(self._last)

objects_det = ObjectsDetector(grabber); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/healthz")
def healthz():
  s = grabber.status()
  return {"ok": True, "fps_in": s.get("fps_in"), "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms")}

@app.get("/status")
def status():
  s1 = grabber.status(); s2 = detector.get_result()
  return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
          "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
  global CAMERA_IP
  CAMERA_IP = cfg.camera_ip
  grabber.start(CAMERA_IP)
  return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
  jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
  if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
  return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
  res = detector.get_result()
  res["objects"] = objects_det.get()
  if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
    return res
  jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
  if jpeg is None: return {"ok": False, "error": "no recent frame"}
  frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
  if frame is None: return {"ok": False, "error": "decode failed"}
  H,W = frame.shape[:2]
  mask_hsv = hsv_fire_mask(frame)
  ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
  v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
  score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
  is_fire = bool(score_raw >= HYST_HIGH)
  return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
          "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
          "frame_wh":[W,H],
          "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
  global OBJ_CONF_THRESH
  if conf is not None:
    OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
  return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
  jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
  if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
  frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
  if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

  o = objects_det.get(); backend = o.get("backend"); det = objects_det
  try:
    if backend=="yolov4-tiny":
      objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, conf)))
    else:
      objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, conf)))
  except Exception:
    return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

  for obj in objs:
    x,y,w,h = obj["box"]
    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
    cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
  ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
  return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
  o = objects_det.get(); s = grabber.status()
  return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
          "proto":o.get("proto"), "weights":o.get("weights"),
          "cfg":o.get("cfg"), "names":o.get("names"),
          "swap_rb":o.get("swap_rb"), "conf_max":o.get("conf_max"),
          "conf_thresh":OBJ_CONF_THRESH, "fps_obj":o.get("fps_obj"),
          "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
          "n_person":o.get("n_person"), "n_animals":o.get("n_animals"),
          "n_person_stable":o.get("n_person_stable"), "n_animals_stable":o.get("n_animals_stable"),
          "num_objects":len(o.get("objects",[])), "error":o.get("error")}
