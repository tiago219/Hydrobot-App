
Beleza ‚Äî se o /objects veio vazio mesmo com uma pessoa no quadro, o problema est√° no servidor (n√£o no app). Provavelmente √© par de arquivos n√£o correspondentes (prototxt vs caffemodel) ou limiar de confian√ßa alto para a sua cena/ilumina√ß√£o.


Abaixo te mando um server_heuristic.py atualizado (COMPLETO) que:




aceita v√°rios nomes de prototxt/weights (inclui deploy.prototxt e mobilenet_iter_73000.caffemodel que apareceram no seu clone);


mostra no /debug_models exatamente quais arquivos foram carregados e qual foi a maior confian√ßa da √∫ltima infer√™ncia;


reduz o threshold padr√£o para 0.25 (mais sens√≠vel) ‚Äî voc√™ pode ajustar por query string (/objects?conf=0.35);


mant√©m todo o detector de fogo inalterado.




Depois do c√≥digo, tem um passo-a-passo de teste para voc√™ validar rapidinho.



server_heuristic.py (substitua o arquivo inteiro)


# server_heuristic.py
# FOGO (heur√≠stico, inalterado) + OBJETOS (MobileNet-SSD Caffe)
import time
import threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os

# ===================== CONFIG =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0

JPEG_QUALITY = 85

# HSV mais amplo p/ fogo real (amarelo/laranja)
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)

# Domin√¢ncia de vermelho (refor√ßo, n√£o bloqueio)
RED_DELTA = 15

# Detector fogo
DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

# Anti-movimento
MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

# Persist√™ncia espacial
PERSIST_CONSEC = 2
IOU_MIN = 0.15

# Idades m√°ximas
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS (MobileNet-SSD) =====================
OBJECTS_MAX_FPS   = 10.0
OBJ_CONF_THRESH   = 0.25     # <= mais sens√≠vel; pode subir via /objects?conf=0.4
OBJ_NMS_THRESH    = 0.45
OBJ_CLASSES       = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
ANIMAL_CLASSES    = {"bird","cat","cow","dog","horse","sheep"}
DNN_IN_SIZE       = (300, 300)
DNN_SCALE         = 0.007843
DNN_MEAN          = 127.5

# Candidatos de caminhos ‚Äî cobrimos os nomes que voc√™ tem
DNN_PROTOTXT_CANDIDATES = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",     # s√≥ se voc√™ colocou assim
]
DNN_CAFFE_WEIGHTS_CANDIDATES = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (MobileNetSSD)", version="1.3.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER CONT√çNUO =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200:
                        time.sleep(0.5); continue
                    buf = b""
                    MAX_BYTES = 4_000_000
                    self._frames = 0
                    self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except requests.exceptions.RequestException:
                time.sleep(0.5)
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== UTILs VIS√ÉO =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    mask = (r.astype(np.int16) > (g.astype(np.int16) + delta)) & (r.astype(np.int16) > (b.astype(np.int16) + delta))
    return (mask.astype(np.uint8)) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    lower = np.array(HSV_LOW, dtype=np.uint8)
    upper = np.array(HSV_HIGH, dtype=np.uint8)
    return cv2.inRange(hsv, lower, upper)

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0, 133, 77), (255, 173, 127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    skin = cv2.bitwise_and(skin, dark)
    return skin

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax + aw, ay + ah; bx2, by2 = bx + bw, by + bh
    ix1, iy1 = max(ax, bx), max(ay, by)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
    inter = iw * ih; union = aw*ah + bw*bh - inter
    return float(inter) / float(union) if union > 0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes: List[List[int]] = []
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if w * h >= min_area:
            boxes.append([x, y, w, h])
    return boxes

# ===================== DETECTOR CONT√çNUO (FOGO) =====================
class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0
        self._score_ema = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW)
        self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None

        self._det_fps = 0.0
        self._det_frames = 0
        self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue

            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            # --- m√°scaras base ---
            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            # anti-movimento
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (3, 3), 0)
            motion_mask = np.zeros_like(gray, dtype=np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray, self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS > 0:
                    k = np.ones((3, 3), np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            # combina√ß√£o principal: HSV ‚àß ¬¨pele ‚àß ¬¨movimento
            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            # refor√ßo
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[..., 2]
            bright = cv2.threshold(V, 200, 255, cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red, bright)
            combined = cv2.bitwise_or(stable, red_boost)

            # scores
            ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
            v_mean = float(np.mean(V)) / 255.0
            score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)

            ratio_combined = float(np.count_nonzero(combined)) / float(combined.size)
            score_combined = min(1.0, ratio_combined * 5.0 + v_mean * 0.1)

            ema = score_combined if self._score_ema == 0.0 else (EMA_ALPHA * score_combined + (1.0 - EMA_ALPHA) * self._score_ema)

            # caixas
            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)

            # persist√™ncia espacial leve
            main_box = None
            if boxes:
                areas = [w*h for (_,_,w,h) in boxes]
                main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    if iou(tuple(main_box), tuple(self._last_main_box)) >= IOU_MIN:
                        self._persist_hits += 1
                    else:
                        self._persist_hits = 1
                else:
                    self._persist_hits = 1
            else:
                self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            # histerese + votos
            if ema >= HYST_HIGH and self._persist_hits >= PERSIST_CONSEC:
                guess = 1
            elif ema <= HYST_LOW:
                guess = 0
            else:
                guess = (1 if (len(self._votes) > 0 and self._votes[-1] == 1 and self._persist_hits >= PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes) >= VOTE_NEED else 0

            with self._lock:
                self._score_raw = float(score_raw)
                self._score_ema = float(ema)
                self._is_fire = bool(final_fire == 1)
                self._boxes = boxes if self._is_fire else []
                self._last_result_ts = int(time.time() * 1000)

            # FPS detector
            self._det_frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._det_fps = self._det_frames / (now - self._last_fps_tick)
                self._det_frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get_result(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema, 3),
                "score_raw": round(self._score_raw, 3),
                "score_ema": round(self._score_ema, 3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps, 2),
                "vote": {"win": VOTE_WINDOW, "need": VOTE_NEED, "sum": int(sum(self._votes))},
                "persist": {"hits": self._persist_hits, "need": PERSIST_CONSEC, "iou_min": IOU_MIN},
                "hyst": {"hi": HYST_HIGH, "lo": HYST_LOW},
            }

detector = Detector(grabber)
detector.start()

# ===================== DETECTOR DE OBJETOS =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None
        self.ok = False
        self.proto_path = None
        self.weights_path = None

        # m√©tricas p/ debug
        self._last_conf_max = 0.0

        # FPS
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

        # √∫ltimo resultado
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._load_net()

    def _load_net(self):
        # acha prototxt
        for p in DNN_PROTOTXT_CANDIDATES:
            if os.path.exists(p):
                self.proto_path = p
                break
        # acha weights
        for w in DNN_CAFFE_WEIGHTS_CANDIDATES:
            if os.path.exists(w):
                self.weights_path = w
                break

        if not self.proto_path:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": "prototxt not found"}
            return
        if not self.weights_path:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": "caffemodel not found"}
            return
        try:
            self.net = cv2.dnn.readNetFromCaffe(self.proto_path, self.weights_path)
            # for√ßa CPU (compat√≠vel)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.ok = True
        except Exception as e:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": f"load failed: {e}"}

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _nms(self, boxes: List[List[int]], confs: List[float]) -> List[int]:
        if not boxes: return []
        idxs = cv2.dnn.NMSBoxes(boxes, confs, OBJ_CONF_THRESH, OBJ_NMS_THRESH)
        if idxs is None or len(idxs) == 0: return []
        if isinstance(idxs, np.ndarray):
            return [int(i) for i in idxs.flatten().tolist()]
        return [int(i) for i in idxs]

    def _run(self):
        min_interval = 1.0 / OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue
            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            out_objects: List[Dict[str, Any]] = []
            conf_max = 0.0

            if self.ok and self.net is not None:
                (h, w) = frame.shape[:2]
                blob = cv2.dnn.blobFromImage(cv2.resize(frame, DNN_IN_SIZE),
                                             DNN_SCALE, DNN_IN_SIZE, DNN_MEAN, swapRB=False, crop=False)
                try:
                    self.net.setInput(blob)
                    detections = self.net.forward()
                except Exception as e:
                    self.ok = False
                    self._last = {"ok": False, "backend": self.backend, "fps_obj": round(self._fps,2),
                                  "objects": [], "ts": int(time.time()*1000), "error": f"forward failed: {e}"}
                    time.sleep(0.1)
                    continue

                boxes_all: List[List[int]] = []
                confs_all: List[float] = []
                labels_all: List[str] = []

                # detections: [1,1,N,7] => [img_id, class_id, conf, x1,y1,x2,y2]
                for i in range(detections.shape[2]):
                    conf = float(detections[0, 0, i, 2])
                    conf_max = max(conf_max, conf)
                    if conf < OBJ_CONF_THRESH:
                        continue
                    idx = int(detections[0, 0, i, 1])
                    if idx < 0 or idx >= len(OBJ_CLASSES):
                        continue
                    label = OBJ_CLASSES[idx]
                    if label != "person" and label not in ANIMAL_CLASSES:
                        continue
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    x1, y1, x2, y2 = box.astype("int")
                    x, y = max(0, x1), max(0, y1)
                    rw, rh = max(0, x2 - x), max(0, y2 - y)
                    if rw * rh <= 0: continue
                    boxes_all.append([int(x), int(y), int(rw), int(rh)])
                    confs_all.append(conf)
                    labels_all.append(label)

                keep = self._nms(boxes_all, confs_all)
                for k in keep:
                    out_objects.append({
                        "label": labels_all[k],
                        "conf": float(confs_all[k]),
                        "box": [int(v) for v in boxes_all[k]]
                    })

                out_objects.sort(key=lambda o: o["conf"], reverse=True)
                out_objects = out_objects[:15]

            with self._lock:
                self._last_conf_max = conf_max
                self._last = {
                    "ok": bool(self.ok),
                    "backend": self.backend,
                    "fps_obj": round(self._fps, 2),
                    "objects": out_objects,
                    "ts": int(time.time()*1000),
                    "proto": self.proto_path,
                    "weights": self.weights_path,
                    "conf_max": round(conf_max, 3),
                }

            self._frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._fps = self._frames / (now - self._last_fps_tick)
                self._frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(max(0.0, min_interval - elapsed))

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber)
objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status()
    s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    if res.get("ts", 0) and (int(time.time() * 1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        res["objects"] = objects_det.get()
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    arr = np.frombuffer(jpeg, dtype=np.uint8)
    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[..., 2])) / 255.0
    score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {
        "ok": True, "isFire": is_fire,
        "score": round(float(score_raw), 3),
        "score_raw": round(float(score_raw), 3),
        "score_ema": round(float(score_raw), 3),
        "boxes": [], "ts": int(time.time() * 1000), "fallback": True,
        "objects": objects_det.get()
    }

@app.get("/objects")
def objects(conf: float = Query(None, description="override confidence threshold (0..1)")):
    global OBJ_CONF_THRESH
    if conf is not None:
        # permite ajustar on-the-fly sem reiniciar
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/debug_models")
def debug_models():
    o = objects_det.get()
    return {
        "ok": True,
        "fire_model": "heuristic-balanced",
        "objects_backend": o.get("backend", "mobilenet-ssd"),
        "objects_ok": o.get("ok", False),
        "fps_obj": o.get("fps_obj", 0.0),
        "num_objects": len(o.get("objects", [])),
        "proto": o.get("proto"),
        "weights": o.get("weights"),
        "conf_max": o.get("conf_max"),
        "error": o.get("error"),
        "conf_thresh": OBJ_CONF_THRESH,
        "nms_thresh": OBJ_NMS_THRESH,
    }




Teste r√°pido (para achar a causa)




Reinicie:




uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload





Abra no navegador (no PC do servidor):






http://SEU_PC:8000/debug_models

Confira:



objects_ok: true


proto aponta para um dos candidatos (ex.: ./models/deploy.prototxt ou ...MobileNetSSD_deploy.prototxt)


weights aponta para mobilenet_iter_73000.caffemodel ou MobileNetSSD_deploy.caffemodel






http://SEU_PC:8000/objects

Fique na frente da c√¢mera por 2‚Äì3s e veja conf_max subir (ex.: 0.6, 0.8), e aparecer items em objects.






Se ainda vier vazio:






Tente baixar o limiar no voo:

http://SEU_PC:8000/objects?conf=0.15


Recarregue /objects.

Se ent√£o aparecer, ficou claro que era threshold alto para a sua cena.

Depois fixe o valor que funcionar melhor.






Se objects_ok: false ou error: load failed:






√â par de arquivos incompat√≠vel. Use deploy.prototxt do mesmo repo do mobilenet_iter_73000.caffemodel (o que voc√™ clonou).


Atualize OpenCV: pip install --upgrade opencv-python.





No app (C√¢mera)


Com o servidor ok (objects preenchido), a tela que te passei j√° mostra:




üî• fogo (como antes)


üë§ Pessoas: N


üêæ Animais: M




Se /objects mostrar itens mas o app n√£o contar, me manda um pequeno JSON retornado por /detect (s√≥ as primeiras linhas) para eu ajustar o caminho exato ‚Äî mas j√° deixei j.objects.objects (estrutura que sai do servidor acima).


Vamos ver o que aparece no /debug_models (principalmente proto, weights, conf_max) e se baixar conf faz os objetos surgirem.




























































Vamos direto ao ponto: o servidor est√° ok, mas a tela C√¢mera n√£o estava exibindo o feedback de pessoas/animais que o endpoint j√° envia. Abaixo te passo:




como testar o servidor rapidinho (para confirmar que ele est√° detectando),


o arquivo completo CameraScreen.tsx com as mudan√ßas para mostrar contagem est√°vel de pessoas e animais quando voc√™ clica em Detectar (sem depender de novas libs nem desenhar caixas).





1) Teste r√°pido do servidor (confirma se est√° detectando)


No PC do servidor, com a c√¢mera apontando para algu√©m/animal:






Abra http://SEU_PC:8000/debug_models

‚Üí Deve ter: "objects_backend":"mobilenet-ssd", "objects_ok": true.






Abra http://SEU_PC:8000/objects

‚Üí Deve aparecer algo assim quando h√° algu√©m no quadro:


{
  "ok": true,
  "backend": "mobilenet-ssd",
  "objects": [
    {"label":"person","conf":0.82,"box":[...]}
  ]
}







Se /objects trouxer lista vazia mesmo com pessoa no quadro, me diga que ajusto os thresholds; mas normalmente aparece.



2) Substitua sua tela por ESTE CameraScreen.tsx (COMPLETO)


Coloque em:

HydroBotApp2/src/screens/CameraScreen.tsx




O que muda: enquanto Detectar estiver ativo, o app consulta /detect ~5 Hz e mostra dois badges com contagem de üë§ Pessoas e üêæ Animais. N√£o precisa de bibliotecas novas. O v√≠deo continua com STREAM (r√°pido) ‚â•20 fps ou SNAPSHOT (fallback), como voc√™ j√° tinha.




// HydrobotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet, PanResponder,
  GestureResponderEvent, PanResponderGestureState, Image, Animated,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg: "#000000", card: "#0d0d0d", border: "#1a1a1a", red: "#E53B2F", white: "#ffffff" };

/* ============================
   A) VISUAL 1 ‚Äî STREAM (‚â•20fps)
   ============================ */
function LiveMJPEG({ ip }: { ip: string }) {
  const html = `
    <html><head><meta name="viewport" content="width=device-width, initial-scale=1">
      <style>
        html,body{margin:0;padding:0;background:#000;height:100%;}
        .wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;background:#000;}
        img{max-width:100%;max-height:100%;object-fit:contain;background:#000;}
      </style>
    </head>
    <body>
      <div class="wrap">
        <img src="http://${ip}:81/stream" />
      </div>
    </body></html>
  `;
  return (
    <WebView
      originWhitelist={["*"]}
      source={{ html }}
      javaScriptEnabled
      allowsInlineMediaPlayback
      mediaPlaybackRequiresUserAction={false}
      automaticallyAdjustContentInsets={false}
      style={{ flex: 1, backgroundColor: "black" }}
    />
  );
}

/* ==========================================
   B) VISUAL 2 ‚Äî SNAPSHOT com crossfade (fallback)
   ========================================== */
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: () => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {currentUri ? (
        <Image source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      ) : null}

      {showNext ? (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown();
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      ) : null}
    </View>
  );
}

/* ============================
   TEXTOS
   ============================ */
const textsByLang = {
  pt: {
    espIp: "ESP IP:", test: "Testar", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "BOMBA ON", pumpOff: "BOMBA OFF", server: "Servidor:",
    detect: "Detectar", detecting: "Detectando", saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi e IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s:number)=>`üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`, fireOff: (s:number)=>`Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Evento salvo em ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vis√£o:",
    stream: "STREAM (r√°pido)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`üë§ Pessoas: ${n}`,
    animals: (n:number)=>`üêæ Animais: ${n}`,
  },
  en: {
    espIp: "ESP IP:", test: "Test", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "PUMP ON", pumpOff: "PUMP OFF", server: "Server:",
    detect: "Detect", detecting: "Detecting", saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s:number)=>`üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`, fireOff: (s:number)=>`No fire ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Event saved at ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "View:",
    stream: "STREAM (fast)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`üë§ People: ${n}`,
    animals: (n:number)=>`üêæ Animals: ${n}`,
  },
  es: {
    espIp: "ESP IP:", test: "Probar", ledOn: "LED ENC.", ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.", pumpOff: "BOMBA APAG.", server: "Servidor:",
    detect: "Detectar", detecting: "Detectando", saving: "Guardando...",
    statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s:number)=>`üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`, fireOff: (s:number)=>`Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Evento guardado a las ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vista:",
    stream: "STREAM (r√°pido)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`üë§ Personas: ${n}`,
    animals: (n:number)=>`üêæ Animales: ${n}`,
  },
};

const DEFAULT_IP = "192.168.4.1";
const DEFAULT_SERVER = "http://192.168.4.2:8000";

type ObjDet = { label: string; conf: number; box: [number, number, number, number] };

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conex√µes
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState("‚Äî");
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detec√ß√£o
  const [detectOn, setDetectOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);

  // pessoas/animais (feedback visual)
  const [peopleCount, setPeopleCount] = useState(0);
  const [animalCount, setAnimalCount] = useState(0);

  // registro autom√°tico
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // modo de visualiza√ß√£o
  const [useStream, setUseStream] = useState(true);

  // v√≠deo (snapshot double-buffer)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // URLs do ESP
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl, { method: "GET" });
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(`OK ‚Ä¢ ip:${j.ip} ‚Ä¢ mode:${j.mode} ‚Ä¢ led:${j.led ? "on" : "off"} ‚Ä¢ pump:${j.pump ? "on" : "off"}`);
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() { try { const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t); } catch { setStatusText(T.statusFail); } }
  async function togglePump() { try { const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); } catch { setStatusText(T.statusFail); } }

  useEffect(() => { pingStatus(); const id = setInterval(pingStatus, 5000); return () => clearInterval(id); }, [statusUrl]);

  /* ===== V√≠deo via snapshots ‚Äî ~25fps (fallback) ===== */
  useEffect(() => {
    if (useStream) return;
    let stop = false;
    const FPS_INTERVAL = 40;
    setCurrentFrameUri(`${server.replace(/\/+$/, "")}/snapshot?ts=${Date.now()}`);
    const tick = () => {
      if (stop) return;
      if (!loadingNextRef.current) {
        const url = `${server.replace(/\/+$/, "")}/snapshot?ts=${Date.now()}`;
        setNextFrameUri(url);
      }
      setTimeout(tick, FPS_INTERVAL);
    };
    tick();
    return () => { stop = true; };
  }, [server, useStream]);

  function onNextLoadStart() { loadingNextRef.current = true; }
  function onNextShown() {
    if (nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== DETECT LOOP ===== */
  useEffect(() => {
    if (!detectOn) { setPeopleCount(0); setAnimalCount(0); return; }
    let stop = false;
    const loop = async () => {
      try {
        const r = await fetch(`${server.replace(/\/+$/, "")}/detect`, { method: "GET" });
        const j = await r.json();
        if (!stop && j && j.ok) {
          // fogo
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          // pessoas/animais vindos do servidor
          const objsRoot = (j.objects && j.objects.objects) ? j.objects.objects : [];
          const people = (objsRoot as ObjDet[]).filter(o => o.label === "person").length;
          const animals = (objsRoot as ObjDet[]).filter(o => o.label !== "person").length;

          setPeopleCount(people);
          setAnimalCount(animals);
        }
      } catch {
        if (!stop) {
          setIsFire(false); setFireScore(0);
          setPeopleCount(0); setAnimalCount(0);
        }
      } finally {
        if (!stop) setTimeout(loop, 120); // ~8‚Äì9 Hz de estado (leve)
      }
    };
    loop();
    return () => { stop = true; };
  }, [detectOn, server]);

  /* ===== Registro autom√°tico ===== */
  useEffect(() => {
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;
    if (detectOn && rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [detectOn, isFire, server, saving, T]);

  /* ===== Joystick ===== */
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS, ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny); if (len > 1) { nx /= len; ny /= len; }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
      onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    })
  ).current;

  const knobLeft = joy.x * RADIUS, knobTop = -joy.y * RADIUS;

  return (
    <View style={styles.container}>
      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor IA + Detectar + Modo de Vis√£o */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={setServer}
          placeholder={T.placeholderServer}
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Pressable onPress={() => setDetectOn((v) => !v)} style={[styles.btn, detectOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{detectOn ? (saving ? T.saving : T.detecting) : T.detect}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
      </View>

      {/* Seletor de vis√£o */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.view}</Text>
        <Pressable onPress={() => setUseStream(true)}  style={[styles.btn, useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.stream}</Text>
        </Pressable>
        <Pressable onPress={() => setUseStream(false)} style={[styles.btn, !useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.snapshot}</Text>
        </Pressable>
      </View>

      {/* Banners de estado */}
      {detectOn && (
        <>
          <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
            <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
          </View>

          {/* NOVO: badges de pessoas / animais */}
          <View style={styles.badgesRow}>
            <View style={[styles.badge, { backgroundColor: "#1b2a4b" }]}>
              <Text style={styles.badgeTxt}>{T.people(peopleCount)}</Text>
            </View>
            <View style={[styles.badge, { backgroundColor: "#2b3a1b" }]}>
              <Text style={styles.badgeTxt}>{T.animals(animalCount)}</Text>
            </View>
          </View>
        </>
      )}

      {/* V√≠deo (STREAM r√°pido OU SNAPSHOT fallback) */}
      <View style={{ flex: 1 }}>
        {useStream ? (
          <LiveMJPEG ip={ip} />
        ) : (
          <CrossfadeImage
            currentUri={currentFrameUri}
            nextUri={nextFrameUri}
            onNextLoadStart={onNextLoadStart}
            onNextShown={onNextShown}
          />
        )}
      </View>

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: RADIUS * 2 + 24, height: RADIUS * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: RADIUS * 2, height: RADIUS * 2, borderRadius: RADIUS }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: KNOB_R * 2, height: KNOB_R * 2, borderRadius: KNOB_R,
                transform: [{ translateX: knobLeft }, { translateY: knobTop }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)}   y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: PALETTE.bg,
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: "#1e2a4d",
    minWidth: 110,
  },
  btn: {
    backgroundColor: "#2b48ff",
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1730",
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  // NOVO: badges de pessoas/animais
  badgesRow: {
    flexDirection: "row",
    gap: 8,
    paddingHorizontal: 12,
    paddingVertical: 6,
    backgroundColor: "#0b0f1e",
  },
  badge: {
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
  },
  badgeTxt: { color: "white", fontWeight: "700" },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(43,72,255,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});




Checklist r√°pido




Servidor rodando (/debug_models com objects_ok: true).


App: ‚ÄúServidor‚Äù = http://SEU_PC:8000.


C√¢mera ‚Üí bot√£o Detectar.


Veja os badges atualizando: üë§ Pessoas: N e üêæ Animais: M.




Se /objects mostra itens, mas o app ainda n√£o conta, me manda um exemplo de JSON retornado por /detect (primeiras linhas) para eu alinhar o path exato (j.objects.objects).























































(.venv) PS D:\loud2025\hydrobot-server> uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload   
INFO:     Will watch for changes in these directories: ['D:\\loud2025\\hydrobot-server']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [17572] using WatchFiles
Process SpawnProcess-1:
Traceback (most recent call last):
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\process.py", line 313, in _bootstrap
    self.run()
    ~~~~~~~~^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
    ~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 65, in run
    return asyncio.run(self.serve(sockets=sockets))
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run 
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run 
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 725, in 
run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 69, in serve
    await self._serve(sockets)
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 76, in _serve
    config.load()
    ~~~~~~~~~~~^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\config.py", line 434, in load
    self.loaded_app = import_from_string(self.app)
                      ~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py", line 88, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 1022, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1160, in get_code
  File "<frozen importlib._bootstrap_external>", line 1090, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "D:\loud2025\hydrobot-server\server_heuristic.py", line 259
    self._thread = threading.Thread(target=self._run, daemon=True)
IndentationError: unexpected indent
