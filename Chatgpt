
// ====== HydroBot – Driver, Modos (APP/AUTO) e Calibração Inteligente (versão refatorada) ======
#include <Arduino.h>

/* ========================== CONFIGURAÇÃO GERAL ========================== */
// Ative 1 se for usar o servo. Se 1, o LED será deslocado para não conflitar com o pino do servo.
#define HAVE_SERVO 0

/* ---------------- PINAGEM ---------------- */
#define IN1 8
#define IN2 9
#define IN3 10
#define IN4 11
#define BOMBA_PIN 13

#if HAVE_SERVO
  #include <Servo.h>
  Servo servoMangueira;
  #define SERVO_PIN     12
  #define SERVO_ESQ     45
  #define SERVO_CENTRO 100
  #define SERVO_DIR     135
  #define LED_VERMELHO_PIN 3   // evita conflito com SERVO_PIN
#else
  #define LED_VERMELHO_PIN 12
#endif

#define BOTAO 7
#define SENSOR_FOGO_ESQ_D 4
#define SENSOR_FOGO_MEIO_D 5
#define SENSOR_FOGO_DIR_D 6

#define SENSOR_FOGO_ESQ  A2
#define SENSOR_FOGO_MEIO A1
#define SENSOR_FOGO_DIR  A0
#define NIVEL_AGUA_PIN   A3

/* ========================== TIPOS E ESTADOS ========================== */
enum Modo       : uint8_t { MODO_APP = 0, MODO_AUTO = 1 };
enum Dir        : uint8_t { DIR_STOP=0, DIR_FWD, DIR_BACK, DIR_LEFT, DIR_RIGHT };
enum AutoState  : uint8_t { AUTO_IDLE=0, AUTO_ATTACK_FWD, AUTO_ATTACK_BACK, AUTO_PATROL };

struct FireSample {
  bool digE, digM, digD;     // sensores digitais (LOW = fogo)
  int  aE, aM, aD;           // analógicos
  int  dE, dM, dD;           // base - atual (delta)
  bool fogo;                 // houve fogo?
  int  side;                 // -1 esq, 0 meio, +1 dir
};

struct State {
  Modo modo = MODO_APP;
  bool pumpOn = false;

  // movimento
  Dir currentDir = DIR_STOP;
  bool motionActive = false;
  unsigned long motionEndMs = 0;
  unsigned long lastMoveCmdAt = 0;
  uint8_t baseSpeed = 70;

  // botão (manual sob demanda + troca de modo)
  bool ultimoEstadoBotao = HIGH;
  unsigned long lastDebounce = 0;

  // calibração e EMA (somente no AUTO)
  int baseEsq = 0, baseMeio = 0, baseDir = 0;
  bool sistemaCalibrado = false;
  unsigned long ultimaRecalibracao = 0;

  // auto
  AutoState autoState = AUTO_IDLE;
  unsigned long autoStateUntil = 0;
  int patrolPhase = 0;

  // água
  uint8_t nivelAguaPct = 0;

  // LED água (digital/blink)
  unsigned long ledToggleAt = 0;
  bool ledBlinkState = false;
} G;

/* ========================== CONSTANTES ========================== */
static const uint16_t TEMPO_CALIBRACAO_MS   = 3000;
static const int      DIF_FOGO              = 150;
static const int      SALTO_LUZ_RECALIB     = 200;
static const uint32_t PER_RECALIB_MS        = 30000;
static const uint8_t  EMA_ALPHA_NUM         = 1;
static const uint8_t  EMA_ALPHA_DEN         = 16;

static const uint16_t BTN_DEBOUNCE_MS       = 35;
static const uint16_t MANUAL_BTN_HOLD_MS    = 40;   // leitura sob demanda enquanto segurado

/* ========================== PROTÓTIPOS ========================== */
void setupHardware();
FireSample readSensors();
void updateMotors(Dir d);
void setMotion(Dir d, uint16_t ms);
void pumpWrite(bool on);
uint8_t waterPercent();
void updateWaterLED(uint8_t pct);
void emitStatus();

void handleAutoMode();
void handleManualMode();
void autoCalibrateInitial();
void emaBasesSemFogo(int aE, int aM, int aD);
bool precisaRecalibrarPorLuz(int aE, int aM, int aD);
void autoAimBySide(int side);
void autoPatrolStep();

void handleModeButtonToggle();
void handleUARTLine(const String& s);

/* ========================== IMPLEMENTAÇÃO ========================== */
// --------- Motores ---------
void motorsStop(){ digitalWrite(IN1,LOW);digitalWrite(IN2,LOW);digitalWrite(IN3,LOW);digitalWrite(IN4,LOW); G.currentDir=DIR_STOP; }
void motorsFwd(){  digitalWrite(IN1,HIGH);digitalWrite(IN2,LOW);digitalWrite(IN3,HIGH);digitalWrite(IN4,LOW); G.currentDir=DIR_FWD; }
void motorsBack(){ digitalWrite(IN1,LOW);digitalWrite(IN2,HIGH);digitalWrite(IN3,LOW);digitalWrite(IN4,HIGH); G.currentDir=DIR_BACK; }
void motorsLeftTurn(){  digitalWrite(IN1,LOW);digitalWrite(IN2,HIGH);digitalWrite(IN3,HIGH);digitalWrite(IN4,LOW); G.currentDir=DIR_LEFT; }
void motorsRightTurn(){ digitalWrite(IN1,HIGH);digitalWrite(IN2,LOW);digitalWrite(IN3,LOW);digitalWrite(IN4,HIGH); G.currentDir=DIR_RIGHT; }

void updateMotors(Dir d){
  switch(d){
    case DIR_FWD: motorsFwd(); break;
    case DIR_BACK: motorsBack(); break;
    case DIR_LEFT: motorsLeftTurn(); break;
    case DIR_RIGHT: motorsRightTurn(); break;
    default: motorsStop(); break;
  }
}

void setMotion(Dir d, uint16_t ms){
  if (ms==0 || d==DIR_STOP){ motorsStop(); G.motionActive=false; return; }
  updateMotors(d);
  G.motionActive = true;
  G.motionEndMs = millis() + (unsigned long)ms;
  G.lastMoveCmdAt = millis();
}

// --------- Bomba e Água ---------
void pumpWrite(bool on){
  G.pumpOn = on;
  digitalWrite(BOMBA_PIN, on?HIGH:LOW);
}

uint8_t waterPercent(){
  int raw = analogRead(NIVEL_AGUA_PIN);
  int pct = map(raw,0,1023,0,100);
  pct = constrain(pct,0,100);
  return (uint8_t)pct;
}

// LED de água – DIGITAL (OFF/ON/BLINK)
void updateWaterLED(uint8_t pct){
  if (pct > 50){
    digitalWrite(LED_VERMELHO_PIN, LOW); // apagado
    return;
  }
  if (pct > 15){
    digitalWrite(LED_VERMELHO_PIN, HIGH); // ligado fixo
    return;
  }
  // < 15%: pisca rápido
  if (millis() - G.ledToggleAt > 300){
    G.ledToggleAt = millis();
    G.ledBlinkState = !G.ledBlinkState;
    digitalWrite(LED_VERMELHO_PIN, G.ledBlinkState ? HIGH : LOW);
  }
}

// --------- Status ---------
void emitStatus(){
  int ax=analogRead(SENSOR_FOGO_ESQ), am=analogRead(SENSOR_FOGO_MEIO), ad=analogRead(SENSOR_FOGO_DIR);
  Serial.print(F("STAT:ax="));Serial.print(ax);
  Serial.print(F(":am="));Serial.print(am);
  Serial.print(F(":ad="));Serial.print(ad);
  Serial.print(F(":water="));Serial.print(G.nivelAguaPct);
  Serial.print(F(":pump="));Serial.print(G.pumpOn?1:0);
  Serial.print(F(":mode="));Serial.print((int)G.modo);
  Serial.print(F(":auto="));Serial.println((int)G.autoState);
}

/* ========================== SENSORES E CALIBRAÇÃO ========================== */
void autoCalibrateInitial(){
  unsigned long t0=millis(); long sE=0,sM=0,sD=0; int n=0;
  while(millis()-t0<TEMPO_CALIBRACAO_MS){
    sE += analogRead(SENSOR_FOGO_ESQ);
    sM += analogRead(SENSOR_FOGO_MEIO);
    sD += analogRead(SENSOR_FOGO_DIR);
    n++; delay(50);
  }
  if (n==0) n=1;
  G.baseEsq  = sE/n;
  G.baseMeio = sM/n;
  G.baseDir  = sD/n;
  G.sistemaCalibrado = true;
  Serial.print(F("CALIB:E="));Serial.print(G.baseEsq);
  Serial.print(F(" M="));Serial.print(G.baseMeio);
  Serial.print(F(" D="));Serial.println(G.baseDir);
}

void emaBasesSemFogo(int aE,int aM,int aD){
  G.baseEsq  = ((EMA_ALPHA_DEN-EMA_ALPHA_NUM)*G.baseEsq  + EMA_ALPHA_NUM*aE)/EMA_ALPHA_DEN;
  G.baseMeio = ((EMA_ALPHA_DEN-EMA_ALPHA_NUM)*G.baseMeio + EMA_ALPHA_NUM*aM)/EMA_ALPHA_DEN;
  G.baseDir  = ((EMA_ALPHA_DEN-EMA_ALPHA_NUM)*G.baseDir  + EMA_ALPHA_NUM*aD)/EMA_ALPHA_DEN;
}

bool precisaRecalibrarPorLuz(int aE,int aM,int aD){
  return (abs(aE-G.baseEsq)>SALTO_LUZ_RECALIB) ||
         (abs(aM-G.baseMeio)>SALTO_LUZ_RECALIB) ||
         (abs(aD-G.baseDir)>SALTO_LUZ_RECALIB);
}

FireSample readSensors(){
  FireSample s;
  s.digE=(digitalRead(SENSOR_FOGO_ESQ_D)==LOW);
  s.digM=(digitalRead(SENSOR_FOGO_MEIO_D)==LOW);
  s.digD=(digitalRead(SENSOR_FOGO_DIR_D)==LOW);
  s.aE=analogRead(SENSOR_FOGO_ESQ);
  s.aM=analogRead(SENSOR_FOGO_MEIO);
  s.aD=analogRead(SENSOR_FOGO_DIR);
  s.dE=G.baseEsq - s.aE; s.dM=G.baseMeio - s.aM; s.dD=G.baseDir - s.aD;
  bool fogoAnal=(s.dE>DIF_FOGO)||(s.dM>DIF_FOGO)||(s.dD>DIF_FOGO);
  bool fogoDig =(s.digE||s.digM||s.digD);
  s.fogo = fogoAnal || fogoDig;
  int md=s.dM; s.side=0; if(s.dE>md){md=s.dE; s.side=-1;} if(s.dD>md){md=s.dD; s.side=+1;}
  return s;
}

/* ========================== AUTO MODE ========================== */
void autoAimBySide(int side){
#if HAVE_SERVO
  int tgt = (side<0?SERVO_DIR:(side>0?SERVO_ESQ:SERVO_CENTRO));
  servoMangueira.write(tgt);
#else
  (void)side;
#endif
}

void autoPatrolStep(){
  switch(G.patrolPhase % 4){
    case 0: setMotion(DIR_FWD,250);  break;
    case 1: setMotion(DIR_LEFT,220); break;
    case 2: setMotion(DIR_FWD,250);  break;
    case 3: setMotion(DIR_RIGHT,220);break;
  }
  G.patrolPhase++;
}

void handleAutoMode(){
  // calibração inicial e periódica apenas no AUTO
  if (!G.sistemaCalibrado){ autoCalibrateInitial(); G.ultimaRecalibracao=millis(); return; }

  FireSample s = readSensors();

  // água + LED
  G.nivelAguaPct = waterPercent();
  updateWaterLED(G.nivelAguaPct);
  if (G.nivelAguaPct<10 && G.pumpOn) pumpWrite(false);

  // recalibra por salto de luz ou período
  if ((millis()-G.ultimaRecalibracao>PER_RECALIB_MS) || precisaRecalibrarPorLuz(s.aE,s.aM,s.aD)){
    Serial.println(F("AUTO:Recalibrando..."));
    autoCalibrateInitial(); G.ultimaRecalibracao=millis(); return;
  }

  if (!s.fogo){
    if (G.pumpOn) pumpWrite(false);
#if HAVE_SERVO
    servoMangueira.write(SERVO_CENTRO);
#endif
    if ((long)(millis()-G.autoStateUntil)>=0){
      G.autoState = AUTO_PATROL; G.autoStateUntil=millis()+400; autoPatrolStep();
    }
    // EMA só sem fogo
    emaBasesSemFogo(s.aE,s.aM,s.aD);
    return;
  }

  // Combate
  autoAimBySide(s.side);
  if (G.nivelAguaPct>10) pumpWrite(true); else pumpWrite(false);

  if (G.autoState==AUTO_IDLE || G.autoState==AUTO_PATROL || (long)(millis()-G.autoStateUntil)>=0){
    static uint8_t forwardStrikes=0;
    if (G.autoState!=AUTO_ATTACK_BACK){
      G.autoState=AUTO_ATTACK_FWD; G.autoStateUntil=millis()+500;
      if (s.side<0) setMotion(DIR_LEFT,160);
      else if (s.side>0) setMotion(DIR_RIGHT,160);
      else setMotion(DIR_FWD,220);
      forwardStrikes++;
      if (forwardStrikes>=3){
        G.autoState=AUTO_ATTACK_BACK; G.autoStateUntil=millis()+600; setMotion(DIR_BACK,280); forwardStrikes=0;
      }
    } else {
      G.autoState=AUTO_ATTACK_FWD; G.autoStateUntil=millis()+500; setMotion(DIR_FWD,220);
    }
  }
}

/* ========================== MANUAL MODE (sob demanda) ========================== */
void handleManualMode(){
  // Em manual, **nada automático**: sem calibração, sem EMA, sem servo automático.
  // LED de água ainda informa nível (útil sempre).
  G.nivelAguaPct = waterPercent();
  updateWaterLED(G.nivelAguaPct);
  if (G.nivelAguaPct<10 && G.pumpOn) pumpWrite(false);

  // Leitura sob demanda: enquanto o botão estiver pressionado
  static unsigned long btnPressStart = 0;
  bool btnPressed = (digitalRead(BOTAO) == LOW);

  if (btnPressed){
    if (btnPressStart==0) btnPressStart = millis();
    if (millis() - btnPressStart >= MANUAL_BTN_HOLD_MS){
      FireSample s = readSensors(); // usa bases atuais (não recalibra aqui)
      if (s.fogo){
        if (G.nivelAguaPct>10) pumpWrite(true); else pumpWrite(false);
        Serial.println(F("MANUAL:FOGO"));
      } else {
        pumpWrite(false);
        Serial.println(F("MANUAL:SEM_FOGO"));
      }
    }
  } else {
    btnPressStart = 0;
    // Soltou → bomba desliga (previsível)
    pumpWrite(false);
  }
}

/* ========================== ENTRADA (BOTÃO/MODO) ========================== */
void handleModeButtonToggle(){
  bool leitura = digitalRead(BOTAO);
  if (leitura != G.ultimoEstadoBotao){
    G.lastDebounce = millis();
    G.ultimoEstadoBotao = leitura;
  }
  if ((millis()-G.lastDebounce) > BTN_DEBOUNCE_MS){
    static bool prev = HIGH;
    // Toggle no flanco de descida
    if (prev==HIGH && leitura==LOW){
      G.modo = (G.modo==MODO_APP) ? MODO_AUTO : MODO_APP;

      // Ao trocar modo: zera estados para previsibilidade
      motorsStop(); pumpWrite(false);
#if HAVE_SERVO
      servoMangueira.write(SERVO_CENTRO);
#endif
      G.autoState = AUTO_IDLE;

      Serial.print(F("MODE:")); Serial.println(G.modo==MODO_APP?F("APP"):F("AUTO"));
    }
    prev = leitura;
  }
}

/* ========================== UART / PROTOCOLO ========================== */
void handleMoveCmd(const String&cmd){
  uint16_t ms=200; int pms=cmd.indexOf("ms="); if(pms>=0) ms=(uint16_t)cmd.substring(pms+3).toInt();
  ms = constrain(ms,80,700);
  if      (cmd.indexOf("FWD")>=0)   setMotion(DIR_FWD,ms);
  else if (cmd.indexOf("BACK")>=0)  setMotion(DIR_BACK,ms);
  else if (cmd.indexOf("LEFT")>=0)  setMotion(DIR_LEFT,ms);
  else if (cmd.indexOf("RIGHT")>=0) setMotion(DIR_RIGHT,ms);
  else if (cmd.indexOf("STOP")>=0)  setMotion(DIR_STOP,0);
}

void handleUARTLine(const String& s){
  // Sempre disponíveis:
  if (s.startsWith("REQ:STATUS")){ emitStatus(); return; }
  if (s.startsWith("SET:SPEED:")){ int v=s.substring(10).toInt(); G.baseSpeed=(uint8_t)constrain(v,0,100); Serial.println(F("OK:SPEED")); return; }
  if (s.startsWith("SET:LED:"))  { int v=s.substring(8).toInt(); digitalWrite(LED_VERMELHO_PIN, v>0?HIGH:LOW); Serial.println(F("OK:LED")); return; }

  // Manual: aceita comandos de direção e bomba
  if (G.modo == MODO_APP){
    if (s.indexOf("CMD:PUMP:")>=0){ bool on=s.endsWith("1"); if(on && waterPercent()<=15){ pumpWrite(false); Serial.println(F("WARN:NO_WATER")); } else { pumpWrite(on); Serial.println(on?F("OK:PUMP_ON"):F("OK:PUMP_OFF")); } return; }
    if (s.startsWith("CMD:")){ handleMoveCmd(s); return; }
    if (s.startsWith("CMD:CALIB")){ Serial.println(F("IGN:CALIB_MANUAL")); return; } // sem calib automática no manual
  } else {
    // No AUTO, permitir solicitar calibração explicitamente
    if (s.startsWith("CMD:CALIB")){ G.sistemaCalibrado=false; Serial.println(F("OK:CALIB_REQUEST")); return; }
    // Evita comandos de movimento ditando o AUTO; ainda assim STOP é permitido para segurança
    if (s.indexOf("CMD:STOP")>=0){ setMotion(DIR_STOP,0); Serial.println(F("OK:STOP")); return; }
    if (s.indexOf("CMD:PUMP:0")>=0){ pumpWrite(false); Serial.println(F("OK:PUMP_OFF")); return; }
  }

  Serial.println(F("ERR:UNKNOWN"));
}

/* ========================== SETUP / LOOP ========================== */
void setupHardware(){
  Serial.begin(115200);

  pinMode(IN1,OUTPUT); pinMode(IN2,OUTPUT); pinMode(IN3,OUTPUT); pinMode(IN4,OUTPUT);
  pinMode(BOMBA_PIN,OUTPUT); pumpWrite(false);
  pinMode(LED_VERMELHO_PIN,OUTPUT); digitalWrite(LED_VERMELHO_PIN,LOW);

  pinMode(BOTAO,INPUT_PULLUP);

  pinMode(SENSOR_FOGO_ESQ_D,INPUT);
  pinMode(SENSOR_FOGO_MEIO_D,INPUT);
  pinMode(SENSOR_FOGO_DIR_D,INPUT);

#if HAVE_SERVO
  servoMangueira.attach(SERVO_PIN);
  servoMangueira.write(SERVO_CENTRO);
#endif

  motorsStop();
  Serial.println(F("ARDUINO_READY"));
}

void setup(){
  setupHardware();
  // Calibração inicial somente se iniciar já em AUTO.
  if (G.modo == MODO_AUTO){
    autoCalibrateInitial();
    G.ultimaRecalibracao = millis();
  }
}

void loop(){
  // watchdog de movimento
  if (G.motionActive && (long)(millis()-G.motionEndMs)>=0){ motorsStop(); G.motionActive=false; }
  if ((millis()-G.lastMoveCmdAt)>1000 && G.currentDir!=DIR_STOP){ motorsStop(); G.motionActive=false; }

  // troca de modo por botão (flanco)
  handleModeButtonToggle();

  // processar UART
  while(Serial.available()){
    static String line;
    char c=Serial.read();
    if(c=='\n'||c=='\r'){
      if(line.length()>0){ String s=line; line=""; s.trim(); handleUARTLine(s); }
    } else {
      line += c; if(line.length()>240) line.remove(0);
    }
  }

  // modos
  if (G.modo == MODO_APP){
    handleManualMode();     // somente leitura sob demanda (botão)
  } else {
    handleAutoMode();       // toda lógica automática e calib/EMA vivem aqui
  }
}






































Perfeito—vou adaptar apenas o necessário para casar com o seu firmware atual (STA, endpoints /status, /snapshot, /stream, POST /uart|/led|/restart, mDNS hydrobot.local). Abaixo vão dois arquivos completos:



1) server_heuristic.py (FastAPI)




Consome direto http://<ESP_IP>/stream do seu firmware.


Mantém um leitor MJPEG em thread com backpressure (sempre guarda só o último frame).


Expõe:



GET /healthz → estado do stream.


GET /frame.jpg → último JPEG (para apps que fazem “pull”).


GET /stream → re-stream MJPEG (app pode usar via WebView).


GET /esp/status → proxy do /status do ESP.


POST /esp/uart?cmd=..., POST /esp/led?on=0|1, POST /esp/restart → proxys para o seu firmware.


GET /ui/stream?mode=server|direct → HTML simples (útil para testar em browser).






CORS liberado.


Sem mudar o nome do arquivo.




# server_heuristic.py
# HydroBot - Proxy/Heurística para ESP32-CAM em STA
# - Conecta no ESP em /stream (MJPEG) e mantém o último frame em memória
# - Reexpõe /stream (re-stream) e /frame.jpg (último frame)
# - Faz proxy dos comandos UART/LED/Restart e do /status do ESP
#
# Rodar:
#   uvicorn server_heuristic:app --host 0.0.0.0 --port 8000
#
# Ajuste ESP_HOST abaixo (pode usar mDNS "hydrobot.local" se resolver na sua rede)

import io
import time
import threading
from typing import Optional, Tuple

import requests
from fastapi import FastAPI, Response, Request
from fastapi.middleware.cors import CORSMiddleware
from starlette.background import BackgroundTask

# ========= CONFIG =========
ESP_HOST = "hydrobot.local"        # ou "192.168.0.50" se IP fixo
ESP_BASE = f"http://{ESP_HOST}"
ESP_STREAM = f"{ESP_BASE}/stream"
ESP_STATUS = f"{ESP_BASE}/status"
ESP_SNAPSHOT = f"{ESP_BASE}/snapshot"
ESP_UART = f"{ESP_BASE}/uart"
ESP_LED = f"{ESP_BASE}/led"
ESP_RESTART = f"{ESP_BASE}/restart"

CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
REQUEST_HEADERS = {"Connection": "keep-alive", "User-Agent": "HydroBot-Server/1.0"}
MAX_FRAME_AGE_MS = 5000

# ========= APP / CORS =========
app = FastAPI(title="HydroBot Server (STA)")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"]
)

# ========= STATE =========
_last_jpeg: Optional[bytes] = None
_last_jpeg_ts_ms: int = 0
_stream_ok: bool = False
_stop_reader = False

def _now_ms() -> int:
    return int(time.time() * 1000)

def _parse_mjpeg_and_store(resp: requests.Response):
    global _last_jpeg, _last_jpeg_ts_ms, _stream_ok

    # Tenta ler o boundary do cabeçalho
    ctype = resp.headers.get("Content-Type", "")
    boundary = None
    if "multipart/x-mixed-replace" in ctype:
        # Ex.: multipart/x-mixed-replace;boundary=frame
        parts = ctype.split("boundary=")
        if len(parts) == 2:
            boundary = parts[1].strip()
    if not boundary:
        boundary = "frame"  # fallback, seu firmware usa "frame"

    delimiter = ("--" + boundary).encode()

    buf = b""
    for chunk in resp.iter_content(chunk_size=4096):
        if _stop_reader:
            break
        if not chunk:
            continue
        buf += chunk

        # Procura delimitadores
        while True:
            start = buf.find(delimiter)
            if start < 0:
                break
            # corta o prefixo antes do delimiter
            buf = buf[start + len(delimiter):]

            # Agora esperamos os headers dessa parte até \r\n\r\n
            head_end = buf.find(b"\r\n\r\n")
            if head_end < 0:
                # ainda não temos todos os headers; precisa de mais dados
                break

            headers_blob = buf[:head_end].decode(errors="ignore")
            buf = buf[head_end + 4:]  # avança além do \r\n\r\n

            # Descobre o tamanho via Content-Length (se existir)
            content_length = None
            for line in headers_blob.split("\r\n"):
                if line.lower().startswith("content-length:"):
                    try:
                        content_length = int(line.split(":")[1].strip())
                    except:
                        content_length = None

            if content_length is not None:
                # Espera exatamente content_length bytes para o JPEG
                if len(buf) < content_length:
                    # esperar mais dados
                    break
                jpg = buf[:content_length]
                buf = buf[content_length:]
            else:
                # Sem Content-Length, tenta achar próximo delimiter
                next_delim = buf.find(delimiter)
                if next_delim < 0:
                    # não chegou ainda a próxima parte
                    break
                jpg = buf[:next_delim]
                buf = buf[next_delim:]

            # Guarda o frame
            _last_jpeg = bytes(jpg)
            _last_jpeg_ts_ms = _now_ms()
            _stream_ok = True

def _reader_thread():
    global _stream_ok
    while not _stop_reader:
        try:
            _stream_ok = False
            with requests.get(ESP_STREAM, stream=True,
                              headers=REQUEST_HEADERS,
                              timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                if r.status_code == 200:
                    _parse_mjpeg_and_store(r)
                else:
                    _stream_ok = False
                    time.sleep(1.0)
        except Exception:
            _stream_ok = False
            time.sleep(1.0)

_reader_started = False
_reader_lock = threading.Lock()

def ensure_reader_started():
    global _reader_started
    with _reader_lock:
        if not _reader_started:
            t = threading.Thread(target=_reader_thread, daemon=True)
            t.start()
            _reader_started = True

# ========= ROUTES =========

@app.on_event("startup")
def _startup():
    ensure_reader_started()

@app.get("/healthz")
def healthz():
    age = _now_ms() - _last_jpeg_ts_ms if _last_jpeg_ts_ms else None
    return {
        "stream_ok": _stream_ok,
        "has_frame": _last_jpeg is not None,
        "frame_age_ms": age
    }

@app.get("/frame.jpg")
def frame_jpg():
    if _last_jpeg and (_now_ms() - _last_jpeg_ts_ms) <= MAX_FRAME_AGE_MS:
        return Response(content=_last_jpeg, media_type="image/jpeg")
    return Response(content=b"", media_type="image/jpeg", status_code=503)

@app.get("/stream")
def stream_proxy():
    """
    Re-stream do último frame em MJPEG (server-side).
    Útil para clientes que querem uma URL estável mesmo se o ESP reiniciar.
    """
    def gen():
        boundary = b"--frame"
        yield b"HTTP/1.1 200 OK\r\n"
        yield b"Content-Type: multipart/x-mixed-replace; boundary=frame\r\n"
        yield b"Cache-Control: no-cache\r\n\r\n"

        while True:
            if _last_jpeg:
                part = (
                    b"--frame\r\n"
                    b"Content-Type: image/jpeg\r\n"
                    b"Content-Length: " + str(len(_last_jpeg)).encode() + b"\r\n\r\n" +
                    _last_jpeg + b"\r\n"
                )
                yield part
            time.sleep(0.04)  # ~25 FPS alvo (controlado pelo ESP de toda forma)

    return Response(content=gen(), media_type="multipart/x-mixed-replace; boundary=frame")

@app.get("/esp/status")
def esp_status():
    try:
        r = requests.get(ESP_STATUS, headers=REQUEST_HEADERS, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT))
        return Response(content=r.content, media_type=r.headers.get("Content-Type", "application/json"),
                        status_code=r.status_code)
    except Exception as e:
        return {"error": str(e)}

@app.post("/esp/uart")
def esp_uart(cmd: str):
    try:
        r = requests.post(ESP_UART, params={"cmd": cmd}, headers=REQUEST_HEADERS,
                          timeout=(CONNECT_TIMEOUT, READ_TIMEOUT))
        return Response(content=r.content, media_type=r.headers.get("Content-Type", "application/json"),
                        status_code=r.status_code)
    except Exception as e:
        return {"error": str(e)}

@app.post("/esp/led")
def esp_led(on: int):
    try:
        r = requests.post(ESP_LED, params={"on": on}, headers=REQUEST_HEADERS,
                          timeout=(CONNECT_TIMEOUT, READ_TIMEOUT))
        return Response(content=r.content, media_type=r.headers.get("Content-Type", "application/json"),
                        status_code=r.status_code)
    except Exception as e:
        return {"error": str(e)}

@app.post("/esp/restart")
def esp_restart():
    try:
        r = requests.post(ESP_RESTART, headers=REQUEST_HEADERS,
                          timeout=(CONNECT_TIMEOUT, READ_TIMEOUT))
        return Response(content=r.content, media_type=r.headers.get("Content-Type", "application/json"),
                        status_code=r.status_code)
    except Exception as e:
        return {"error": str(e)}

@app.get("/ui/stream")
def ui_stream(mode: str = "server"):
    """
    Página simples p/ testar stream no navegador:
      - mode=server -> usa /stream deste servidor
      - mode=direct -> usa /stream direto do ESP
    """
    src = "/stream" if mode == "server" else ESP_STREAM
    html = f"""
<!doctype html><html><head>
<meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>HydroBot Stream</title>
<style>
body{{background:#0b0b0f;color:#e5e7eb;margin:0;font-family:system-ui}}
.top{{padding:12px;background:#121218;position:sticky;top:0;display:flex;gap:8px;align-items:center}}
a.button{{padding:8px 12px;background:#e6403a;color:#fff;text-decoration:none;border-radius:8px}}
.container{{display:flex;justify-content:center;align-items:center;padding:12px}}
img{{max-width:100vw;max-height:80vh;display:block}}
small{{opacity:.7}}
</style></head>
<body>
<div class="top">
  <a class="button" href="/ui/stream?mode=server">Server Stream</a>
  <a class="button" href="/ui/stream?mode=direct">Direct ESP</a>
  <small>ESP: <code>{ESP_BASE}</code> | modo: <b>{mode}</b></small>
</div>
<div class="container">
  <img src="{src}" alt="stream"/>
</div>
</body></html>
    """.strip()
    return Response(content=html, media_type="text/html")




2) HydroBotApp2/src/screens/CameraScreen.tsx (React Native)




Mantém o visual que você já vinha usando (paleta, textos), e adiciona um seletor “Fonte de vídeo”:



Direto do ESP (http://hydrobot.local/stream) — aproveita o seu endpoint novo.


Via servidor (http://<server>:8000/stream) — útil se você preferir o re-stream do FastAPI.






Como o <Image> do React Native não toca MJPEG, uso um WebView leve com um HTML inline só com <img src="...">.


Inclui teste de /status do ESP, botões de LED ON/OFF e envio de UART (ex: CMD:FWD:ms=400:spd=70), casando com seus POSTs.


Não depende do seu servidor para funcionar “direto” com o ESP.




// HydroBotApp2/src/screens/CameraScreen.tsx
import React, { useMemo, useRef, useState } from "react";
import { View, Text, TextInput, Pressable, StyleSheet, Platform, KeyboardAvoidingView, ScrollView } from "react-native";
import { WebView } from "react-native-webview";

const PALETTE = { bg: "#0b0b0f", card: "#121218", border: "#25273a", accent: "#e6403a", text: "#e5e7eb" };

type SourceMode = "direct" | "server";

export default function CameraScreen() {
  // IP/host do ESP (mDNS por padrão) e do servidor FastAPI
  const [espHost, setEspHost] = useState<string>("hydrobot.local"); // ou "192.168.0.50"
  const [serverHost, setServerHost] = useState<string>("192.168.0.100:8000"); // ajuste se precisar
  const [mode, setMode] = useState<SourceMode>("direct");

  const [statusText, setStatusText] = useState<string>("");

  const streamURL = useMemo(() => {
    if (mode === "server") {
      return `http://${serverHost}/stream`;
    }
    return `http://${espHost}/stream`;
  }, [mode, espHost, serverHost]);

  const html = useMemo(() => {
    // HTML mínimo para exibir MJPEG de forma robusta
    // Mantemos fundo/estilo parecidos com o app
    const escapedSrc = streamURL.replace(/"/g, "&quot;");
    return `
<!doctype html><html><head>
<meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/>
<style>
  html,body{margin:0;padding:0;background:#0b0b0f;color:#e5e7eb;height:100%;}
  .wrap{display:flex;align-items:center;justify-content:center;height:100%;}
  img{max-width:100vw;max-height:100vh;display:block}
</style>
</head>
<body>
<div class="wrap">
  <img id="m" src="${escapedSrc}" alt="stream"/>
</div>
</body></html>
    `.trim();
  }, [streamURL]);

  async function testStatus() {
    try {
      const url = `http://${espHost}/status`;
      const res = await fetch(url, { method: "GET" });
      const txt = await res.text();
      setStatusText(`OK ${res.status}: ${txt}`);
    } catch (e: any) {
      setStatusText(`ERRO: ${String(e?.message || e)}`);
    }
  }

  async function led(on: boolean) {
    try {
      const url = `http://${espHost}/led?on=${on ? 1 : 0}`;
      const res = await fetch(url, { method: "POST" });
      const txt = await res.text();
      setStatusText(`LED ${on ? "ON" : "OFF"} => ${res.status}: ${txt}`);
    } catch (e: any) {
      setStatusText(`ERRO LED: ${String(e?.message || e)}`);
    }
  }

  const [uartCmd, setUartCmd] = useState<string>("CMD:FWD:ms=400:spd=70");

  async function sendUART() {
    try {
      // Garante \n do lado do ESP (ele adiciona se faltar, mas mantemos simples)
      const url = `http://${espHost}/uart?cmd=${encodeURIComponent(uartCmd)}`;
      const res = await fetch(url, { method: "POST" });
      const txt = await res.text();
      setStatusText(`UART => ${res.status}: ${txt}`);
    } catch (e: any) {
      setStatusText(`ERRO UART: ${String(e?.message || e)}`);
    }
  }

  return (
    <KeyboardAvoidingView style={{ flex: 1, backgroundColor: PALETTE.bg }} behavior={Platform.OS === "ios" ? "padding" : undefined}>
      <View style={styles.header}>
        <Text style={styles.title}>HydroBot — Câmera</Text>
        <Text style={styles.subtitle}>Monitoramento (ESP STA)</Text>
      </View>

      <View style={styles.row}>
        <Text style={styles.label}>ESP host:</Text>
        <TextInput
          style={styles.input}
          value={espHost}
          onChangeText={setEspHost}
          autoCapitalize="none"
          autoCorrect={false}
          placeholder="hydrobot.local ou 192.168.0.50"
          placeholderTextColor="#6b7280"
        />
      </View>

      <View style={styles.row}>
        <Text style={styles.label}>Servidor:</Text>
        <TextInput
          style={styles.input}
          value={serverHost}
          onChangeText={setServerHost}
          autoCapitalize="none"
          autoCorrect={false}
          placeholder="IP:porta (ex: 192.168.0.100:8000)"
          placeholderTextColor="#6b7280"
        />
      </View>

      <View style={[styles.row, { justifyContent: "space-between" }]}>
        <View style={styles.modeGroup}>
          <Pressable style={[styles.modeBtn, mode === "direct" && styles.modeBtnActive]} onPress={() => setMode("direct")}>
            <Text style={styles.modeText}>Direto ESP</Text>
          </Pressable>
          <Pressable style={[styles.modeBtn, mode === "server" && styles.modeBtnActive]} onPress={() => setMode("server")}>
            <Text style={styles.modeText}>Via Servidor</Text>
          </Pressable>
        </View>

        <Pressable style={styles.testBtn} onPress={testStatus}>
          <Text style={styles.btnText}>Testar /status</Text>
        </Pressable>
      </View>

      {/* VIEW DO VÍDEO (via WebView com <img src="...">) */}
      <View style={styles.viewer}>
        <WebView originWhitelist={["*"]} source={{ html }} allowsInlineMediaPlayback />
      </View>

      <ScrollView style={styles.controls} contentContainerStyle={{ paddingBottom: 24 }}>
        <View style={styles.btnRow}>
          <Pressable style={styles.actionBtn} onPress={() => led(true)}>
            <Text style={styles.btnText}>LED ON</Text>
          </Pressable>
          <Pressable style={styles.actionBtn} onPress={() => led(false)}>
            <Text style={styles.btnText}>LED OFF</Text>
          </Pressable>
        </View>

        <View style={styles.row}>
          <Text style={styles.label}>UART:</Text>
          <TextInput
            style={styles.input}
            value={uartCmd}
            onChangeText={setUartCmd}
            autoCapitalize="characters"
            autoCorrect={false}
            placeholder="ex: CMD:FWD:ms=400:spd=70"
            placeholderTextColor="#6b7280"
          />
        </View>
        <Pressable style={styles.actionBtn} onPress={sendUART}>
          <Text style={styles.btnText}>Enviar UART</Text>
        </Pressable>

        {!!statusText && (
          <View style={styles.statusBox}>
            <Text style={styles.statusText}>{statusText}</Text>
          </View>
        )}
      </ScrollView>
    </KeyboardAvoidingView>
  );
}

const styles = StyleSheet.create({
  header: { padding: 16, paddingBottom: 8 },
  title: { color: PALETTE.text, fontSize: 18, fontWeight: "700" },
  subtitle: { color: "#9ca3af", marginTop: 2 },
  row: { flexDirection: "row", alignItems: "center", paddingHorizontal: 16, gap: 8, marginTop: 8 },
  label: { color: "#9ca3af", width: 84 },
  input: { flex: 1, backgroundColor: PALETTE.card, borderColor: PALETTE.border, borderWidth: 1, borderRadius: 10, color: PALETTE.text, paddingHorizontal: 12, height: 40 },
  modeGroup: { flexDirection: "row", gap: 8 },
  modeBtn: { paddingHorizontal: 12, paddingVertical: 8, borderRadius: 10, backgroundColor: PALETTE.card, borderWidth: 1, borderColor: PALETTE.border },
  modeBtnActive: { backgroundColor: PALETTE.accent, borderColor: PALETTE.accent },
  modeText: { color: "#fff" },
  testBtn: { backgroundColor: PALETTE.accent, paddingHorizontal: 12, paddingVertical: 8, borderRadius: 10 },
  btnText: { color: "#fff", fontWeight: "600" },
  viewer: { height: 280, margin: 16, borderRadius: 12, overflow: "hidden", borderColor: PALETTE.border, borderWidth: 1, backgroundColor: "#000" },
  controls: { flex: 1, paddingHorizontal: 16 },
  btnRow: { flexDirection: "row", gap: 10, marginTop: 8 },
  actionBtn: { backgroundColor: PALETTE.accent, paddingHorizontal: 14, paddingVertical: 10, borderRadius: 10, alignItems: "center", justifyContent: "center" },
  statusBox: { marginTop: 12, backgroundColor: PALETTE.card, borderRadius: 10, borderWidth: 1, borderColor: PALETTE.border, padding: 12 },
  statusText: { color: "#e5e7eb", fontSize: 12 },
});




Como usar / validar rápido




ESP ligado no roteador

Acesse no navegador do celular/PC:






http://hydrobot.local/


http://hydrobot.local/stream


http://hydrobot.local/snapshot

Se não resolver mDNS, use o IP (ex.: http://192.168.0.50/stream).






Servidor FastAPI






Inicie: uvicorn server_heuristic:app --host 0.0.0.0 --port 8000


Teste no navegador:



http://<server>:8000/ui/stream?mode=server (re-stream)


http://<server>:8000/ui/stream?mode=direct (direto do ESP)


http://<server>:8000/healthz e http://<server>:8000/frame.jpg










App (CameraScreen)






Em “ESP host” deixe hydrobot.local (ou o IP).


Em “Servidor” defina IP:porta do FastAPI se for usar “Via Servidor”.


Toque Direto ESP (ou Via Servidor) conforme preferir.


Use Testar /status para validar a comunicação.


LED/ UART já casam com seus POST atuais do firmware.





Por que isso resolve seus sintomas anteriores?




Reboot ao “olhar longe”: manter /stream + fb_count=2 e consumir via WebView <img> evita estourar RAM do app. O servidor, se usado, faz re-stream e aplica “backpressure” guardando apenas o último frame, reduzindo risco de travas quando a cena tem muitos detalhes.


“No live frame”: o endpoint /frame.jpg sempre devolve o último frame válido em JPEG (útil como fallback).


CORS e POSTs: tudo alinhado ao seu firmware atual—sem endpoints inventados.




Se quiser, depois posso incluir um fallback por snapshot (pull 5–10 FPS) no mesmo WebView, mas quis manter enxuto e fiel à sua lógica atual.


















































/*
  HydroBot - ESP32-CAM em modo STA (roteador externo)
  - Endpoints:
      GET  /              -> página info rápida
      GET  /status        -> JSON (uptime, RSSI, heap, ip, último STATUS do Arduino)
      GET  /snapshot      -> JPEG único
      GET  /stream        -> MJPEG stream
      POST /uart?cmd=...  -> envia comando na UART para o Arduino (ex: CMD:FWD:ms=400:spd=70)
      POST /led?on=0|1    -> liga/desliga flash (GPIO 4)
      POST /restart       -> reinicia ESP
  - mDNS: http://hydrobot.local
  - CORS: Access-Control-Allow-Origin: *
  - UART: Serial2 (pinos configuráveis abaixo). ESP requisita "REQ:STATUS\n" periodicamente e armazena última linha "STAT:...".
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_timer.h"
#include "img_converters.h"
#include "esp_camera.h"
#include "fb_gfx.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"

// ====== CONFIG ======
const char* WIFI_SSID   = "HydroBot";
const char* WIFI_PASS   = "loud2025emibr";

// (Opcional) IP fixo – deixe comentado se preferir DHCP
//#define USE_STATIC_IP
IPAddress local_IP(192,168,0,50);
IPAddress gateway(192,168,0,1);
IPAddress subnet(255,255,255,0);
IPAddress dns1(8,8,8,8);
IPAddress dns2(1,1,1,1);

// mDNS
const char* MDNS_NAME = "hydrobot"; // http://hydrobot.local

// UART com Arduino (ajuste conforme seu fio)
// Recomenda-se ESP32-CAM: RX=15, TX=14 (costuma estar disponível nesse módulo)
#define UART_RX_PIN 15
#define UART_TX_PIN 14
#define UART_BAUD   115200

// Requisição periódica ao Arduino
#define STATUS_POLL_MS  1000

// Camera: selecione pinos do modelo AI Thinker
#define CAMERA_MODEL_AI_THINKER
#include "camera_pins.h"

// ====== FIM CONFIG ======

// Servidor HTTP
WebServer server(80);

// Buffer do último STATUS do Arduino
String lastStatusLine = "";

// Controle de LED do flash (AI Thinker usa GPIO 4 pra lâmpada)
static const int FLASH_PIN = 4;

// Controle de stream
static const char* STREAM_BOUNDARY = "frame";
static const char* STREAM_CONTENT_TYPE = "multipart/x-mixed-replace;boundary=" "frame";
static const int STREAM_QUALITY = 12;   // 10..20 (mais baixo = melhor qualidade, porém mais pesado)
static const bool STREAM_HFLIP = false; // espelhar horizontal
static const bool STREAM_VFLIP = false; // espelhar vertical

// Watchdog / reconexão
unsigned long lastWiFiCheck = 0;
unsigned long lastStatusPoll = 0;

// ---------- Util ----------
void addCORS() {
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}
void handleOptions() {
  addCORS();
  server.send(204);
}

// ---------- UART ----------
void initUART() {
  Serial2.begin(UART_BAUD, SERIAL_8N1, UART_RX_PIN, UART_TX_PIN);
}
void pollArduinoStatus() {
  static String rxBuf;
  // Solicita status
  Serial2.print("REQ:STATUS\n");
  // Lê o que chegou desde a última chamada
  while (Serial2.available()) {
    char c = (char)Serial2.read();
    if (c == '\n' || c == '\r') {
      if (rxBuf.length() > 0) {
        // Guarda última linha completa
        if (rxBuf.startsWith("STAT:")) {
          lastStatusLine = rxBuf;
        }
        rxBuf = "";
      }
    } else {
      rxBuf += c;
    }
  }
}

// ---------- Câmera ----------
bool initCamera() {
  // Evitar brownout reset
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);

  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer   = LEDC_TIMER_0;
  config.pin_d0       = Y2_GPIO_NUM;
  config.pin_d1       = Y3_GPIO_NUM;
  config.pin_d2       = Y4_GPIO_NUM;
  config.pin_d3       = Y5_GPIO_NUM;
  config.pin_d4       = Y6_GPIO_NUM;
  config.pin_d5       = Y7_GPIO_NUM;
  config.pin_d6       = Y8_GPIO_NUM;
  config.pin_d7       = Y9_GPIO_NUM;
  config.pin_xclk     = XCLK_GPIO_NUM;
  config.pin_pclk     = PCLK_GPIO_NUM;
  config.pin_vsync    = VSYNC_GPIO_NUM;
  config.pin_href     = HREF_GPIO_NUM;
  config.pin_sscb_sda = SIOD_GPIO_NUM;
  config.pin_sscb_scl = SIOC_GPIO_NUM;
  config.pin_pwdn     = PWDN_GPIO_NUM;
  config.pin_reset    = RESET_GPIO_NUM;
  config.xclk_freq_hz = 20000000;
  config.pixel_format = PIXFORMAT_JPEG;

  // Resoluções: FRAMESIZE_QQVGA .. UXGA
  config.frame_size   = FRAMESIZE_VGA;
  config.jpeg_quality = 12;     // 10..20 (10 melhor)
  config.fb_count     = 2;

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    return false;
  }

  // Efeitos básicos
  sensor_t * s = esp_camera_sensor_get();
  s->set_vflip(s, STREAM_VFLIP);
  s->set_hmirror(s, STREAM_HFLIP);

  return true;
}

// ---------- Handlers HTTP ----------
void handleRoot() {
  addCORS();
  String html = "<!doctype html><html><head><meta charset='utf-8'/>"
                "<meta name='viewport' content='width=device-width,initial-scale=1'/>"
                "<title>HydroBot ESP32-CAM</title>"
                "<style>body{font-family:system-ui;background:#0b0b0f;color:#e5e7eb;padding:16px}"
                "a,button{background:#e6403a;color:#fff;padding:8px 12px;border:none;border-radius:8px;text-decoration:none;margin-right:8px}"
                "code{background:#121218;padding:2px 6px;border-radius:6px}</style></head><body>";
  html += "<h2>HydroBot ESP32-CAM (STA)</h2>";
  html += "<p>IP: <code>" + WiFi.localIP().toString() + "</code> | RSSI: <code>" + String(WiFi.RSSI()) + " dBm</code></p>";
  html += "<p><a href='/snapshot'>/snapshot</a> <a href='/stream'>/stream</a> <a href='/status'>/status</a></p>";
  html += "<p>mDNS: <code>http://" + String(MDNS_NAME) + ".local</code></p>";
  html += "<p>Último STATUS Arduino: <code>" + (lastStatusLine.length() ? lastStatusLine : "(ainda não)") + "</code></p>";
  html += "</body></html>";
  server.send(200, "text/html", html);
}

void handleStatus() {
  addCORS();
  // Monta JSON simples
  String json = "{";
  json += "\"ip\":\"" + WiFi.localIP().toString() + "\",";
  json += "\"rssi\":" + String(WiFi.RSSI()) + ",";
  json += "\"heap\":" + String(ESP.getFreeHeap()) + ",";
  json += "\"uptime_ms\":" + String(millis()) + ",";
  // Se quiser, parse do lastStatusLine -> chave:valor
  json += "\"arduino_status\":\"" + lastStatusLine + "\"";
  json += "}";
  server.send(200, "application/json", json);
}

void handleSnapshot() {
  addCORS();
  camera_fb_t * fb = esp_camera_fb_get();
  if (!fb) {
    server.send(503, "text/plain", "Camera capture failed");
    return;
  }
  server.sendHeader("Content-Type", "image/jpeg");
  server.sendHeader("Content-Disposition", "inline; filename=capture.jpg");
  server.send_P(200, "image/jpeg", (const char*)fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

void handleStream() {
  WiFiClient client = server.client();
  // Cabeçalhos do stream
  client.println("HTTP/1.1 200 OK");
  client.println("Content-Type: " + String(STREAM_CONTENT_TYPE));
  client.println("Access-Control-Allow-Origin: *");
  client.println();

  while (client.connected()) {
    camera_fb_t * fb = esp_camera_fb_get();
    if (!fb) break;

    client.println("--" + String(STREAM_BOUNDARY));
    client.println("Content-Type: image/jpeg");
    client.println("Content-Length: " + String(fb->len));
    client.println();
    client.write(fb->buf, fb->len);
    client.println();
    esp_camera_fb_return(fb);

    // Pequena folga
    delay(10);
  }
}

void handleUART() {
  addCORS();
  if (server.method() == HTTP_OPTIONS) { handleOptions(); return; }
  String cmd = server.arg("cmd");
  if (!cmd.length()) {
    server.send(400, "application/json", "{\"error\":\"use /uart?cmd=...\"}");
    return;
  }
  // Garante terminador de linha
  if (!cmd.endsWith("\n")) cmd += "\n";
  Serial2.print(cmd);
  server.send(200, "application/json", "{\"ok\":true}");
}

void handleLED() {
  addCORS();
  if (server.method() == HTTP_OPTIONS) { handleOptions(); return; }
  int on = server.arg("on").toInt();
  digitalWrite(FLASH_PIN, on ? HIGH : LOW);
  server.send(200, "application/json", String("{\"on\":") + (on? "true":"false") + "}");
}

void handleRestart() {
  addCORS();
  server.send(200, "application/json", "{\"restarting\":true}");
  delay(300);
  ESP.restart();
}

// ---------- Wi-Fi ----------
void connectWiFi() {
#ifdef USE_STATIC_IP
  WiFi.config(local_IP, gateway, subnet, dns1, dns2);
#endif
  WiFi.mode(WIFI_STA);
  WiFi.begin(WIFI_SSID, WIFI_PASS);

  unsigned long t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 15000) {
    delay(250);
  }
}

void setupServer() {
  // Rotas
  server.on("/", HTTP_GET, handleRoot);
  server.on("/status", HTTP_GET, handleStatus);
  server.on("/snapshot", HTTP_GET, handleSnapshot);
  server.on("/stream", HTTP_GET, handleStream);
  server.on("/uart", HTTP_POST, handleUART);
  server.on("/led", HTTP_POST, handleLED);
  server.on("/restart", HTTP_POST, handleRestart);

  // CORS preflight
  server.onNotFound([](){
    addCORS();
    server.send(404, "application/json", "{\"error\":\"not found\"}");
  });
  server.on("/uart", HTTP_OPTIONS, handleOptions);
  server.on("/led", HTTP_OPTIONS, handleOptions);
  server.on("/restart", HTTP_OPTIONS, handleOptions);

  server.begin();
}

// ---------- setup / loop ----------
void setup() {
  // Logs seriais (opcional). Evite compartilhar TX0/RX0 com Arduino se usar USB.
  Serial.begin(115200);
  delay(200);

  pinMode(FLASH_PIN, OUTPUT);
  digitalWrite(FLASH_PIN, LOW);

  // UART secundária com Arduino
  initUART();

  // Câmera
  if (!initCamera()) {
    // Tente outra vez
    delay(1000);
    initCamera();
  }

  // Wi-Fi
  connectWiFi();

  // mDNS
  if (WiFi.status() == WL_CONNECTED) {
    if (MDNS.begin(MDNS_NAME)) {
      MDNS.addService("http", "tcp", 80);
    }
  }

  // HTTP
  setupServer();
}

void loop() {
  server.handleClient();

  // Watch Wi-Fi & reconectar
  if (millis() - lastWiFiCheck > 3000) {
    lastWiFiCheck = millis();
    if (WiFi.status() != WL_CONNECTED) {
      connectWiFi();
    }
  }

  // Poll do STATUS no Arduino
  if (millis() - lastStatusPoll > STATUS_POLL_MS) {
    lastStatusPoll = millis();
    pollArduinoStatus();
  }
}

























/*
  HydroBot - ESP32-CAM em modo STA (roteador externo)
  - Endpoints:
      GET  /              -> página info rápida
      GET  /status        -> JSON (uptime, RSSI, heap, ip, último STATUS do Arduino)
      GET  /snapshot      -> JPEG único
      GET  /stream        -> MJPEG stream
      POST /uart?cmd=...  -> envia comando na UART para o Arduino (ex: CMD:FWD:ms=400:spd=70)
      POST /led?on=0|1    -> liga/desliga flash (GPIO 4)
      POST /restart       -> reinicia ESP
  - mDNS: http://hydrobot.local
  - CORS: Access-Control-Allow-Origin: *
  - UART: Serial2 (pinos configuráveis abaixo). ESP requisita "REQ:STATUS\n" periodicamente e armazena última linha "STAT:...".
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_timer.h"
#include "img_converters.h"
#include "esp_camera.h"
#include "fb_gfx.h"
#include "soc/soc.h"
#include "soc/rtc_cntl_reg.h"

// ====== CONFIG ======
const char* WIFI_SSID   = "SEU_SSID_AQUI";
const char* WIFI_PASS   = "SUA_SENHA_AQUI";

// (Opcional) IP fixo – deixe comentado se preferir DHCP
//#define USE_STATIC_IP
IPAddress local_IP(192,168,0,50);
IPAddress gateway(192,168,0,1);
IPAddress subnet(255,255,255,0);
IPAddress dns1(8,8,8,8);
IPAddress dns2(1,1,1,1);

// mDNS
const char* MDNS_NAME = "hydrobot"; // http://hydrobot.local

// UART com Arduino (ajuste conforme seu fio)
// Recomenda-se ESP32-CAM: RX=15, TX=14 (costuma estar disponível nesse módulo)
#define UART_RX_PIN 15
#define UART_TX_PIN 14
#define UART_BAUD   115200

// Requisição periódica ao Arduino
#define STATUS_POLL_MS  1000

// Camera: selecione pinos do modelo AI Thinker
#define CAMERA_MODEL_AI_THINKER
#include "camera_pins.h"

// ====== FIM CONFIG ======

// Servidor HTTP
WebServer server(80);

// Buffer do último STATUS do Arduino
String lastStatusLine = "";

// Controle de LED do flash (AI Thinker usa GPIO 4 pra lâmpada)
static const int FLASH_PIN = 4;

// Controle de stream
static const char* STREAM_BOUNDARY = "frame";
static const char* STREAM_CONTENT_TYPE = "multipart/x-mixed-replace;boundary=" "frame";
static const int STREAM_QUALITY = 12;   // 10..20 (mais baixo = melhor qualidade, porém mais pesado)
static const bool STREAM_HFLIP = false; // espelhar horizontal
static const bool STREAM_VFLIP = false; // espelhar vertical

// Watchdog / reconexão
unsigned long lastWiFiCheck = 0;
unsigned long lastStatusPoll = 0;

// ---------- Util ----------
void addCORS() {
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}
void handleOptions() {
  addCORS();
  server.send(204);
}

// ---------- UART ----------
void initUART() {
  Serial2.begin(UART_BAUD, SERIAL_8N1, UART_RX_PIN, UART_TX_PIN);
}
void pollArduinoStatus() {
  static String rxBuf;
  // Solicita status
  Serial2.print("REQ:STATUS\n");
  // Lê o que chegou desde a última chamada
  while (Serial2.available()) {
    char c = (char)Serial2.read();
    if (c == '\n' || c == '\r') {
      if (rxBuf.length() > 0) {
        // Guarda última linha completa
        if (rxBuf.startsWith("STAT:")) {
          lastStatusLine = rxBuf;
        }
        rxBuf = "";
      }
    } else {
      rxBuf += c;
    }
  }
}

// ---------- Câmera ----------
bool initCamera() {
  // Evitar brownout reset
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0);

  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer   = LEDC_TIMER_0;
  config.pin_d0       = Y2_GPIO_NUM;
  config.pin_d1       = Y3_GPIO_NUM;
  config.pin_d2       = Y4_GPIO_NUM;
  config.pin_d3       = Y5_GPIO_NUM;
  config.pin_d4       = Y6_GPIO_NUM;
  config.pin_d5       = Y7_GPIO_NUM;
  config.pin_d6       = Y8_GPIO_NUM;
  config.pin_d7       = Y9_GPIO_NUM;
  config.pin_xclk     = XCLK_GPIO_NUM;
  config.pin_pclk     = PCLK_GPIO_NUM;
  config.pin_vsync    = VSYNC_GPIO_NUM;
  config.pin_href     = HREF_GPIO_NUM;
  config.pin_sscb_sda = SIOD_GPIO_NUM;
  config.pin_sscb_scl = SIOC_GPIO_NUM;
  config.pin_pwdn     = PWDN_GPIO_NUM;
  config.pin_reset    = RESET_GPIO_NUM;
  config.xclk_freq_hz = 20000000;
  config.pixel_format = PIXFORMAT_JPEG;

  // Resoluções: FRAMESIZE_QQVGA .. UXGA
  config.frame_size   = FRAMESIZE_VGA;
  config.jpeg_quality = 12;     // 10..20 (10 melhor)
  config.fb_count     = 2;

  esp_err_t err = esp_camera_init(&config);
  if (err != ESP_OK) {
    return false;
  }

  // Efeitos básicos
  sensor_t * s = esp_camera_sensor_get();
  s->set_vflip(s, STREAM_VFLIP);
  s->set_hmirror(s, STREAM_HFLIP);

  return true;
}

// ---------- Handlers HTTP ----------
void handleRoot() {
  addCORS();
  String html = "<!doctype html><html><head><meta charset='utf-8'/>"
                "<meta name='viewport' content='width=device-width,initial-scale=1'/>"
                "<title>HydroBot ESP32-CAM</title>"
                "<style>body{font-family:system-ui;background:#0b0b0f;color:#e5e7eb;padding:16px}"
                "a,button{background:#e6403a;color:#fff;padding:8px 12px;border:none;border-radius:8px;text-decoration:none;margin-right:8px}"
                "code{background:#121218;padding:2px 6px;border-radius:6px}</style></head><body>";
  html += "<h2>HydroBot ESP32-CAM (STA)</h2>";
  html += "<p>IP: <code>" + WiFi.localIP().toString() + "</code> | RSSI: <code>" + String(WiFi.RSSI()) + " dBm</code></p>";
  html += "<p><a href='/snapshot'>/snapshot</a> <a href='/stream'>/stream</a> <a href='/status'>/status</a></p>";
  html += "<p>mDNS: <code>http://" + String(MDNS_NAME) + ".local</code></p>";
  html += "<p>Último STATUS Arduino: <code>" + (lastStatusLine.length() ? lastStatusLine : "(ainda não)") + "</code></p>";
  html += "</body></html>";
  server.send(200, "text/html", html);
}

void handleStatus() {
  addCORS();
  // Monta JSON simples
  String json = "{";
  json += "\"ip\":\"" + WiFi.localIP().toString() + "\",";
  json += "\"rssi\":" + String(WiFi.RSSI()) + ",";
  json += "\"heap\":" + String(ESP.getFreeHeap()) + ",";
  json += "\"uptime_ms\":" + String(millis()) + ",";
  // Se quiser, parse do lastStatusLine -> chave:valor
  json += "\"arduino_status\":\"" + lastStatusLine + "\"";
  json += "}";
  server.send(200, "application/json", json);
}

void handleSnapshot() {
  addCORS();
  camera_fb_t * fb = esp_camera_fb_get();
  if (!fb) {
    server.send(503, "text/plain", "Camera capture failed");
    return;
  }
  server.sendHeader("Content-Type", "image/jpeg");
  server.sendHeader("Content-Disposition", "inline; filename=capture.jpg");
  server.send_P(200, "image/jpeg", (const char*)fb->buf, fb->len);
  esp_camera_fb_return(fb);
}

void handleStream() {
  WiFiClient client = server.client();
  // Cabeçalhos do stream
  client.println("HTTP/1.1 200 OK");
  client.println("Content-Type: " + String(STREAM_CONTENT_TYPE));
  client.println("Access-Control-Allow-Origin: *");
  client.println();

  while (client.connected()) {
    camera_fb_t * fb = esp_camera_fb_get();
    if (!fb) break;

    client.println("--" + String(STREAM_BOUNDARY));
    client.println("Content-Type: image/jpeg");
    client.println("Content-Length: " + String(fb->len));
    client.println();
    client.write(fb->buf, fb->len);
    client.println();
    esp_camera_fb_return(fb);

    // Pequena folga
    delay(10);
  }
}

void handleUART() {
  addCORS();
  if (server.method() == HTTP_OPTIONS) { handleOptions(); return; }
  String cmd = server.arg("cmd");
  if (!cmd.length()) {
    server.send(400, "application/json", "{\"error\":\"use /uart?cmd=...\"}");
    return;
  }
  // Garante terminador de linha
  if (!cmd.endsWith("\n")) cmd += "\n";
  Serial2.print(cmd);
  server.send(200, "application/json", "{\"ok\":true}");
}

void handleLED() {
  addCORS();
  if (server.method() == HTTP_OPTIONS) { handleOptions(); return; }
  int on = server.arg("on").toInt();
  digitalWrite(FLASH_PIN, on ? HIGH : LOW);
  server.send(200, "application/json", String("{\"on\":") + (on? "true":"false") + "}");
}

void handleRestart() {
  addCORS();
  server.send(200, "application/json", "{\"restarting\":true}");
  delay(300);
  ESP.restart();
}

// ---------- Wi-Fi ----------
void connectWiFi() {
#ifdef USE_STATIC_IP
  WiFi.config(local_IP, gateway, subnet, dns1, dns2);
#endif
  WiFi.mode(WIFI_STA);
  WiFi.begin(WIFI_SSID, WIFI_PASS);

  unsigned long t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 15000) {
    delay(250);
  }
}

void setupServer() {
  // Rotas
  server.on("/", HTTP_GET, handleRoot);
  server.on("/status", HTTP_GET, handleStatus);
  server.on("/snapshot", HTTP_GET, handleSnapshot);
  server.on("/stream", HTTP_GET, handleStream);
  server.on("/uart", HTTP_POST, handleUART);
  server.on("/led", HTTP_POST, handleLED);
  server.on("/restart", HTTP_POST, handleRestart);

  // CORS preflight
  server.onNotFound([](){
    addCORS();
    server.send(404, "application/json", "{\"error\":\"not found\"}");
  });
  server.on("/uart", HTTP_OPTIONS, handleOptions);
  server.on("/led", HTTP_OPTIONS, handleOptions);
  server.on("/restart", HTTP_OPTIONS, handleOptions);

  server.begin();
}

// ---------- setup / loop ----------
void setup() {
  // Logs seriais (opcional). Evite compartilhar TX0/RX0 com Arduino se usar USB.
  Serial.begin(115200);
  delay(200);

  pinMode(FLASH_PIN, OUTPUT);
  digitalWrite(FLASH_PIN, LOW);

  // UART secundária com Arduino
  initUART();

  // Câmera
  if (!initCamera()) {
    // Tente outra vez
    delay(1000);
    initCamera();
  }

  // Wi-Fi
  connectWiFi();

  // mDNS
  if (WiFi.status() == WL_CONNECTED) {
    if (MDNS.begin(MDNS_NAME)) {
      MDNS.addService("http", "tcp", 80);
    }
  }

  // HTTP
  setupServer();
}

void loop() {
  server.handleClient();

  // Watch Wi-Fi & reconectar
  if (millis() - lastWiFiCheck > 3000) {
    lastWiFiCheck = millis();
    if (WiFi.status() != WL_CONNECTED) {
      connectWiFi();
    }
  }

  // Poll do STATUS no Arduino
  if (millis() - lastStatusPoll > STATUS_POLL_MS) {
    lastStatusPoll = millis();
    pollArduinoStatus();
  }
}


























































/* ESP32-CAM (AI Thinker) — CÂMERA APENAS (robusto)
   - Wi-Fi STA
   - xclk 8 MHz, FRAMESIZE_QQVGA (160x120), jpeg_quality 32, fb_count 1
   - Endpoints:
       /snapshot  -> JPEG único (Connection: close)
       /stream    -> MJPEG (multipart/x-mixed-replace)
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"

// ---------- CONFIG WI-FI ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- WEB ----------
WebServer server(80);

// ---------- PINAGEM AI Thinker ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- PERFIL DE CÂMERA ----------
static framesize_t   CAM_SIZE   = FRAMESIZE_QQVGA; // suba p/ QVGA após estabilizar
static int           CAM_QLTY   = 32;              // maior = mais compressão (menos bytes)
static const size_t  MAX_JPEG   = 80 * 1024;       // descarta frames muito grandes (proteção)

// ---------- CORS util ----------
static void sendCORS() {
  server.sendHeader("Access-Control-Allow-Origin", "*");
  server.sendHeader("Access-Control-Allow-Methods", "GET,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers", "Content-Type");
}
static void handle_options() { sendCORS(); server.send(204); }

// ---------- INIT WI-FI ----------
static void wifi_begin() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.setTxPower(WIFI_POWER_13dBm); // menos EMI no barramento da câmera
  WiFi.begin(WIFI_SSID, WIFI_PASS);

  uint32_t t0 = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - t0 < 20000) {
    delay(200);
  }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http", "tcp", 80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- INIT CÂMERA ----------
static bool camera_begin() {
  camera_config_t cfg = {};
  cfg.ledc_channel = LEDC_CHANNEL_0;
  cfg.ledc_timer   = LEDC_TIMER_0;
  cfg.pin_d0 = Y2_GPIO_NUM;  cfg.pin_d1 = Y3_GPIO_NUM;  cfg.pin_d2 = Y4_GPIO_NUM;  cfg.pin_d3 = Y5_GPIO_NUM;
  cfg.pin_d4 = Y6_GPIO_NUM;  cfg.pin_d5 = Y7_GPIO_NUM;  cfg.pin_d6 = Y8_GPIO_NUM;  cfg.pin_d7 = Y9_GPIO_NUM;
  cfg.pin_xclk = XCLK_GPIO_NUM;  cfg.pin_pclk = PCLK_GPIO_NUM;  cfg.pin_vsync = VSYNC_GPIO_NUM;  cfg.pin_href = HREF_GPIO_NUM;
  cfg.pin_sccb_sda = SIOD_GPIO_NUM;  cfg.pin_sccb_scl = SIOC_GPIO_NUM;  cfg.pin_pwdn = PWDN_GPIO_NUM;  cfg.pin_reset = RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 8000000;              // 8 MHz reduz pressão no DMA
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = CAM_SIZE;
  cfg.jpeg_quality = CAM_QLTY;             // 10 melhor/maior; 63 pior/menor (aqui mais compressão)
  cfg.fb_count     = 1;                    // 1 buffer evita fila estourar
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;   // dropa frames velhos

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) {
    Serial.printf("CAMERA_INIT_ERR 0x%x\n", err);
    return false;
  }

  sensor_t* s = esp_camera_sensor_get();
  if (s && s->id.PID == OV3660_PID) {
    s->set_vflip(s, 1);
    s->set_saturation(s, -1);
  }
  if (s) {
    s->set_framesize  (s, CAM_SIZE);
    s->set_quality    (s, CAM_QLTY);
    s->set_exposure_ctrl(s, 1);
    s->set_gain_ctrl    (s, 1);
    s->set_whitebal     (s, 1);
    s->set_awb_gain     (s, 1);
    // aliviar ISP:
    s->set_lenc(s, 0);
    s->set_bpc (s, 0);
    s->set_wpc (s, 0);
    s->set_dcw (s, 1);
  }

  return true;
}

// ---------- /snapshot ----------
static void handle_snapshot() {
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.sendHeader("Connection","close");

  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) { server.send(503, "text/plain", "no frame\n"); return; }

  if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > MAX_JPEG) {
    esp_camera_fb_return(fb);
    server.send(503, "text/plain", "bad frame\n");
    return;
  }

  server.setContentLength(fb->len);
  server.send(200, "image/jpeg", "");
  WiFiClient c = server.client();

  size_t sent = 0;
  while (sent < fb->len) {
    int n = c.write(fb->buf + sent, fb->len - sent);
    if (n <= 0) break;
    sent += n;
    delay(0); // yield
  }

  esp_camera_fb_return(fb);
}

// ---------- /stream (MJPEG) ----------
static const char* BOUNDARY = "frame";
static void handle_stream() {
  WiFiClient client = server.client();
  sendCORS();
  String hdr = 
    "HTTP/1.1 200 OK\r\n"
    "Content-Type: multipart/x-mixed-replace; boundary=" + String(BOUNDARY) + "\r\n"
    "Cache-Control: no-store, no-cache, must-revalidate, max-age=0\r\n"
    "Pragma: no-cache\r\n"
    "Connection: close\r\n\r\n";
  client.print(hdr);

  // loop até cliente fechar
  while (client.connected()) {
    camera_fb_t* fb = esp_camera_fb_get();
    if (!fb) { delay(10); continue; }

    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > MAX_JPEG) {
      esp_camera_fb_return(fb);
      delay(2);
      continue;
    }

    client.print("--"); client.print(BOUNDARY); client.print("\r\n");
    client.print("Content-Type: image/jpeg\r\n");
    client.print("Content-Length: "); client.print(fb->len); client.print("\r\n\r\n");

    size_t sent = 0;
    while (sent < fb->len) {
      int n = client.write(fb->buf + sent, fb->len - sent);
      if (n <= 0) { break; }
      sent += n;
      delay(0);
    }
    client.print("\r\n");

    esp_camera_fb_return(fb);

    // pequeno cap (≈4 fps) para aliviar DMA e Wi-Fi
    delay(250);
  }
}

// ---------- SETUP / LOOP ----------
void setup() {
  Serial.begin(115200);
  delay(50);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  wifi_begin();

  if (!camera_begin()) {
    delay(400);
    // último fallback: mais compressão
    CAM_QLTY = 36;
    camera_begin();
  }

  server.on("/snapshot", HTTP_GET, handle_snapshot);
  server.on("/stream",   HTTP_GET, handle_stream);

  server.on("/",         HTTP_OPTIONS, handle_options);
  server.on("/snapshot", HTTP_OPTIONS, handle_options);
  server.on("/stream",   HTTP_OPTIONS, handle_options);

  server.onNotFound([](){
    sendCORS();
    server.send(404, "text/plain", "NF\n");
  });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}





































/*  ESP32-CAM (AI Thinker) — Perfil anti-DMA overflow (rev B)
    - xclk 8 MHz
    - QQVGA (160x120) + jpeg_quality 30 (mais compressão)
    - fb_count 1 (sem fila pro DMA estourar)
    - /snapshot = último frame do cache (Connection: close)
    - Task da câmera no Core 1 (Wi-Fi no Core 0)
    - Reinit após falhas
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"
#include <math.h>

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer fixo do último frame ----------
static uint8_t* g_buf = nullptr;     // PSRAM buffer fixo
static size_t   g_cap = 0;           // capacidade total (bytes)
static size_t   g_len = 0;           // bytes válidos do último frame
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;
static uint32_t g_fail_streak = 0;

// ---------- Estado de captura (perfil conservador) ----------
static sensor_t*   g_sensor  = nullptr;
static framesize_t g_fs      = FRAMESIZE_QQVGA; // 160x120
static int         g_quality = 30;              // mais compressão -> menos bytes

// ---------- Limites práticos ----------
static const size_t   HARD_DROP_BYTES  = 80*1024;   // dropa frames > 80KB
static const uint32_t MIN_INTERVAL_MS  = 260;       // ~3.8 fps (cap mais folgado)
static const uint32_t REINIT_STREAK    = 6;         // reinit após 6 falhas seguidas

// ---------- Utils ----------
static inline uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
static void handle_options(){ sendCORS(); server.send(204); }

// ---------- Wi-Fi ----------
static void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  // Dormir ligado pode ajudar RF; mas aqui evitamos latência:
  WiFi.setSleep(false);
  // Reduz potência p/ diminuir EMI nos sinais da câmera:
  WiFi.setTxPower(WIFI_POWER_13dBm);
  WiFi.begin(WIFI_SSID, WIFI_PASS);

  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) { delay(200); }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 8000000;               // 8 MHz -> alivia o DMA
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;                    // QQVGA (pode subir depois)
  cfg.jpeg_quality = quality;               // 10 melhor, 63 pior (aqui mais compressão)
  cfg.fb_count     = 1;                     // *** 1 buffer: evita fila/overflow do DMA
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;    // pega o mais novo (dropa se atrasar)

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);
    g_sensor->set_gain_ctrl(g_sensor, 1);
    g_sensor->set_whitebal(g_sensor, 1);
    g_sensor->set_awb_gain(g_sensor, 1);
    // Reduzir carga do ISP ajuda:
    g_sensor->set_lenc(g_sensor, 0);   // lens correction off
    g_sensor->set_bpc(g_sensor, 0);    // bad pixel cancel off
    g_sensor->set_wpc(g_sensor, 0);    // white pixel cancel off
    g_sensor->set_dcw(g_sensor, 1);    // downsize enable
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

// ---------- Handlers ----------
static void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"snapshot-buffer-fixo\","
             "\"hasFrame\":" + String((g_len>0 && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QQVGA?"QQVGA":"QVGA") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

static void handle_snapshot(){
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.sendHeader("Connection","close");

  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_buf && g_len>0);
  size_t len = g_len;
  // Fazemos uma cópia local para reduzir tempo segurando o mutex
  static uint8_t* tmp = nullptr; static size_t tmpcap = 0;
  if (ok) {
    if (tmpcap < len) {
      if (tmp) { heap_caps_free(tmp); tmp = nullptr; tmpcap = 0; }
      tmp = (uint8_t*) heap_caps_malloc(len, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
      if (tmp) tmpcap = len;
      else ok = false;
    }
    if (ok) memcpy(tmp, g_buf, len);
  }
  xSemaphoreGive(g_lock);

  if(!ok){ server.send(503,"text/plain","no frame\n"); return; }

  server.setContentLength(len);
  server.send(200,"image/jpeg","");
  WiFiClient c = server.client();
  // Envia do buffer temporário (sem segurar mutex, evitando travar a captura)
  size_t written = 0;
  while (written < len) {
    int n = c.write(tmp + written, len - written);
    if (n <= 0) break;
    written += n;
    delay(0); // yield ao Wi-Fi
  }
}

static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
static void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

static void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

static void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(fminf(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- Task de captura contínua ----------
static void cam_task(void*){
  g_cap_tick = now_ms();
  for(;;){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= REINIT_STREAK){
        Serial.println("CAM_REINIT");
        esp_camera_deinit();
        delay(180);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(14));
      continue;
    }
    g_fail_streak = 0;

    // Dropa tudo que possa estourar DMA/PSRAM
    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > HARD_DROP_BYTES) {
      esp_camera_fb_return(fb);
      // pequeno respiro
      vTaskDelay(pdMS_TO_TICKS(2));
      continue;
    }

    // Copiamos MUITO rápido e já liberamos o fb pro driver
    xSemaphoreTake(g_lock, portMAX_DELAY);
    if (g_buf && fb->len <= g_cap) {
      memcpy(g_buf, fb->buf, fb->len);
      g_len = fb->len;
      g_ts_ms = now_ms();
    }
    xSemaphoreGive(g_lock);
    esp_camera_fb_return(fb);

    // FPS meter
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // Cap de FPS bem folgado p/ driver nunca acumular
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
    taskYIELD();
  }
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(60);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  g_lock = xSemaphoreCreateMutex();

  // Aloca buffer fixo em PSRAM (tenta 128KB → 96KB → 64KB)
  g_cap = 128*1024;
  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  if(!g_buf){ g_cap = 96*1024;  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); }
  if(!g_buf){ g_cap = 64*1024;  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); }

  wifi_begin_dhcp();

  // Inicializa câmera (perfil anti-overflow)
  if(!camera_begin(g_fs, g_quality)){
    delay(300);
    camera_begin(FRAMESIZE_QQVGA, g_quality+4); // fallback extra (mais compressão)
  }

  // *** Agora no Core 1 (Arduino loop), Wi-Fi fica no Core 0 ***
  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 2, nullptr, 1);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}
























/*  ESP32-CAM (AI Thinker) — Perfil “anti-DMA overflow”
    - xclk 8 MHz
    - QQVGA (160x120) + jpeg_quality 26
    - fb_count 2 (duplo buffer)
    - /snapshot = último frame do cache (Content-Length + Connection: close)
    - Reinit após falhas
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer fixo do último frame ----------
static uint8_t* g_buf = nullptr;     // PSRAM buffer fixo
static size_t   g_cap = 0;           // capacidade total (bytes)
static size_t   g_len = 0;           // bytes válidos do último frame
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;
static uint32_t g_fail_streak = 0;

// ---------- Estado de captura (perfil conservador) ----------
static sensor_t*   g_sensor  = nullptr;
static framesize_t g_fs      = FRAMESIZE_QQVGA; // 160x120 (suba p/ QVGA após estabilizar)
static int         g_quality = 26;              // maior = mais compressão (arquivos menores)

// ---------- Limites práticos ----------
static const size_t   HARD_DROP_BYTES  = 140*1024; // nunca guardar frames > 140KB
static const uint32_t MIN_INTERVAL_MS  = 220;      // ~4–5 fps cap
static const uint32_t REINIT_STREAK    = 6;        // reinit após 6 falhas seguidas

// ---------- Utils ----------
static inline uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
static void handle_options(){ sendCORS(); server.send(204); }

// ---------- Wi-Fi ----------
static void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) { delay(200); }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 8000000;               // 8 MHz -> alivia o DMA
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;                    // QQVGA (depois suba p/ QVGA)
  cfg.jpeg_quality = quality;               // 10 melhor, 63 pior
  cfg.fb_count     = 2;                     // duplo buffer ajuda o pipeline
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;    // o mais novo (dropa se atrasar)

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);
    g_sensor->set_gain_ctrl(g_sensor, 1);
    g_sensor->set_whitebal(g_sensor, 1);
    g_sensor->set_awb_gain(g_sensor, 1);
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

// ---------- Handlers ----------
static void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"snapshot-buffer-fixo\","
             "\"hasFrame\":" + String((g_len>0 && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QQVGA?"QQVGA":"QVGA") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

static void handle_snapshot(){
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.sendHeader("Connection","close");

  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_buf && g_len>0);
  size_t len = g_len;
  xSemaphoreGive(g_lock);

  if(!ok){ server.send(503,"text/plain","no frame\n"); return; }

  server.setContentLength(len);
  server.send(200,"image/jpeg","");
  WiFiClient c = server.client();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  c.write(g_buf, len);
  xSemaphoreGive(g_lock);
}

static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
static void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

static void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

static void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- Task de captura contínua ----------
static void cam_task(void*){
  g_cap_tick = now_ms();
  for(;;){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= REINIT_STREAK){
        Serial.println("CAM_REINIT");
        esp_camera_deinit();
        delay(180);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(14));
      continue;
    }
    g_fail_streak = 0;

    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > HARD_DROP_BYTES) {
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      continue;
    }

    xSemaphoreTake(g_lock, portMAX_DELAY);
    if (g_buf && fb->len <= g_cap) {
      memcpy(g_buf, fb->buf, fb->len);
      g_len = fb->len;
      g_ts_ms = now_ms();
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(60);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  g_lock = xSemaphoreCreateMutex();

  // Aloca buffer fixo em PSRAM (tenta 160KB → 128KB → 96KB)
  g_cap = 160*1024;
  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  if(!g_buf){ g_cap = 128*1024; g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); }
  if(!g_buf){ g_cap = 96*1024;  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); }

  wifi_begin_dhcp();

  // Inicializa câmera (perfil anti-overflow)
  if(!camera_begin(g_fs, g_quality)){
    delay(300);
    camera_begin(FRAMESIZE_QQVGA, g_quality+2); // fallback extra
  }

  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}


























































/*  ESP32-CAM (AI Thinker) — Snapshot estável p/ app atual
    - Clock da câmera: 10 MHz (evita DMA overflow em módulos sensíveis)
    - QVGA + jpeg_quality=20 (arquivos menores, ~20–40 KB)
    - Buffer fixo em PSRAM p/ último frame (sem malloc/free por frame)
    - /snapshot devolve sempre o último frame (Content-Length + Connection: close)
    - Reinit após falhas seguidas
    Endpoints: /status, /snapshot, /uart?line=, /pump?on=0|1, /joystick?x=&y=
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer fixo do último frame ----------
static uint8_t* g_buf = nullptr;     // PSRAM buffer fixo
static size_t   g_cap = 0;           // capacidade total (bytes)
static size_t   g_len = 0;           // bytes válidos do último frame
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;
static uint32_t g_fail_streak = 0;

// ---------- Estado de captura ----------
static sensor_t*   g_sensor  = nullptr;
static framesize_t g_fs      = FRAMESIZE_QVGA; // 320x240 (troque p/ FRAMESIZE_QQVGA se precisar)
static int         g_quality = 20;             // maior = mais compressão (arquivos menores)

// ---------- Limites práticos ----------
static const size_t   HARD_DROP_BYTES  = 140*1024; // nunca guardar frames > 140KB
static const uint32_t MIN_INTERVAL_MS  = 160;      // ~6 fps cap (ajuda estabilidade)
static const uint32_t REINIT_STREAK    = 6;        // reinit após 6 falhas seguidas

// ---------- Utils ----------
static inline uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
static void handle_options(){ sendCORS(); server.send(204); }

// ---------- Wi-Fi ----------
static void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);        // potência máxima
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) { delay(200); }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 10000000;              // 10 MHz -> evita DMA overflow
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;                    // QVGA (ou QQVGA se precisar)
  cfg.jpeg_quality = quality;               // 10 melhor, 63 pior (20 é leve)
  cfg.fb_count     = 1;                     // 1 buffer => menos fragmentação PSRAM
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;    // sempre o mais novo

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);
    g_sensor->set_gain_ctrl(g_sensor, 1);
    g_sensor->set_whitebal(g_sensor, 1);
    g_sensor->set_awb_gain(g_sensor, 1);
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

// ---------- Handlers ----------
static void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"snapshot-buffer-fixo\","
             "\"hasFrame\":" + String((g_len>0 && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QVGA?"QVGA":"QQVGA") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

static void handle_snapshot(){
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.sendHeader("Connection","close");      // evita keep-alive pendurado

  // snapshot do cache (sem tocar na câmera)
  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_buf && g_len>0);
  size_t len = g_len;
  xSemaphoreGive(g_lock);

  if(!ok){ server.send(503,"text/plain","no frame\n"); return; }

  server.setContentLength(len);
  server.send(200,"image/jpeg","");  // só cabeçalhos
  WiFiClient c = server.client();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  c.write(g_buf, len);               // envia corpo
  xSemaphoreGive(g_lock);
}

static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
static void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

static void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

static void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Compat: eco GET "cru" na serial
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Comando discreto redundante
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- Task de captura contínua ----------
static void cam_task(void*){
  g_cap_tick = now_ms();
  for(;;){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= REINIT_STREAK){
        Serial.println("CAM_REINIT");
        esp_camera_deinit();
        delay(150);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(12));
      continue;
    }
    g_fail_streak = 0;

    // Proteção: descarta frames absurdos
    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > HARD_DROP_BYTES) {
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      continue;
    }

    // Copia se couber no buffer fixo
    xSemaphoreTake(g_lock, portMAX_DELAY);
    if (g_buf && fb->len <= g_cap) {
      memcpy(g_buf, fb->buf, fb->len);
      g_len = fb->len;
      g_ts_ms = now_ms();
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // Limite de taxa (alivia DMA/rádio/PSRAM)
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(60);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout (módulos sensíveis)

  g_lock = xSemaphoreCreateMutex();

  // Aloca buffer fixo em PSRAM (tenta 160KB → 128KB → 96KB)
  g_cap = 160*1024;
  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  if(!g_buf){ g_cap = 128*1024; g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); }
  if(!g_buf){ g_cap = 96*1024;  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT); }

  wifi_begin_dhcp();

  // Inicializa câmera (se seu módulo continuar com overflow, troque p/ QQVGA)
  if(!camera_begin(FRAMESIZE_QVGA, g_quality)){
    delay(300);
    camera_begin(FRAMESIZE_QVGA, g_quality+2); // leve ajuste
  }

  // Task de captura (core 0), HTTP no core padrão
  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}
















































/*  ESP32-CAM (AI Thinker) — Snapshot estável para app/server atuais
    Mudanças mínimas:
      - Buffer fixo em PSRAM (g_buf/g_cap) → sem malloc/free por frame
      - /snapshot retorna SEMPRE o último frame pronto (Content-Length + Connection: close)
      - Captura contínua com fb_count=1, GRAB_LATEST; reinit se falhar em sequência
    Endpoints:
      /status, /snapshot, /uart?line=, /pump?on=0|1, /joystick?x=&y=
    Rede: STA DHCP + mDNS http://hydrobot-esp.local
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer fixo do último frame ----------
static uint8_t* g_buf = nullptr;     // PSRAM buffer fixo
static size_t   g_cap = 0;           // capacidade total (bytes)
static size_t   g_len = 0;           // bytes válidos do último frame
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;
static uint32_t g_fail_streak = 0;

// ---------- Estado de captura ----------
static sensor_t* g_sensor = nullptr;
static framesize_t g_fs   = FRAMESIZE_QVGA; // 320x240
static int g_quality      = 16;             // 10 melhor, 63 pior

// ---------- Limites práticos ----------
static const size_t HARD_DROP_BYTES  = 140*1024; // nunca guardar frames > 140KB
static const uint32_t MIN_INTERVAL_MS = 150;     // ~6-7 fps cap
static const uint32_t REINIT_STREAK   = 6;       // reinit após 6 falhas seguidas

// ---------- Utils ----------
static inline uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }

static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
static void handle_options(){ sendCORS(); server.send(204); }

// ---------- Wi-Fi ----------
static void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) { delay(200); }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 20000000;             // 20 MHz estável
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;
  cfg.jpeg_quality = quality;              // (menor = melhor)
  cfg.fb_count     = 1;                    // 1 buffer => menos fragmentação PSRAM
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;   // sempre o mais novo

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);
    g_sensor->set_gain_ctrl(g_sensor, 1);
    g_sensor->set_whitebal(g_sensor, 1);
    g_sensor->set_awb_gain(g_sensor, 1);
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

// ---------- Handlers ----------
static void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"snapshot-buffer-fixo\","
             "\"hasFrame\":" + String((g_len>0 && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QVGA?"QVGA":"?") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

static void handle_snapshot(){
  sendCORS();
  server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
  server.sendHeader("Pragma","no-cache");
  server.sendHeader("Expires","0");
  server.sendHeader("Connection","close");           // evita keep-alive pendurado em alguns clientes

  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_buf && g_len>0);
  size_t len = g_len;
  xSemaphoreGive(g_lock);

  if(!ok){
    server.send(503,"text/plain","no frame\n");
    return;
  }

  // Envia cabeçalho com Content-Length e o corpo bruto
  server.setContentLength(len);
  server.send(200,"image/jpeg","");  // envia apenas headers
  WiFiClient c = server.client();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  c.write(g_buf, len);
  xSemaphoreGive(g_lock);
}

static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
static void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

static void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

static void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Compat: encaminha GET "cru" pela UART
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Comando discreto redundante
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- Task de captura contínua ----------
static void cam_task(void*){
  g_cap_tick = now_ms();
  for(;;){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= REINIT_STREAK){
        Serial.println("CAM_REINIT");
        esp_camera_deinit();
        delay(120);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(10));
      continue;
    }
    g_fail_streak = 0;

    // Proteção: descarta frames absurdos
    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > HARD_DROP_BYTES) {
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      continue;
    }

    // Copia somente se couber no buffer fixo
    xSemaphoreTake(g_lock, portMAX_DELAY);
    if (g_buf && fb->len <= g_cap) {
      memcpy(g_buf, fb->buf, fb->len);
      g_len = fb->len;
      g_ts_ms = now_ms();
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // Limite de taxa
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(50);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  g_lock = xSemaphoreCreateMutex();

  // Aloca buffer fixo em PSRAM (tenta 160KB → 128KB → 96KB)
  g_cap = 160*1024;
  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  if(!g_buf){
    g_cap = 128*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }
  if(!g_buf){
    g_cap = 96*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }

  wifi_begin_dhcp();

  // Inicializa câmera
  if(!camera_begin(FRAMESIZE_QVGA, 16)){
    delay(300);
    camera_begin(FRAMESIZE_QVGA, 18); // leve ajuste se a primeira falhar
  }

  // Task de captura (core 0), loop HTTP roda no core padrão
  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}




































































Perfeito — vou manter toda a sua lógica e só aplicar o mínimo para garantir que o vídeo apareça:






No server:




/snapshot passa a devolver somente o último frame em cache (sem chamar o ESP a cada requisição).


Adicionei /frame.jpg (mesmo conteúdo do /snapshot) — alguns dispositivos carregam melhor quando há extensão.








Na CameraScreen.tsx:




Mantive tudo.


Só acrescentei um fallback discreto: se falhar algumas vezes no /snapshot, ele tenta o /frame.jpg automaticamente.


Não alterei joystick, bomba, textos, nem estrutura.








Abaixo estão os dois arquivos completos.



server_heuristic.py (apenas ajustes pontuais em /snapshot + alias /frame.jpg)


# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot (robusto)
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 15.0
POLL_FPS_TARGET = 8.0                              # ~8 fps estável
MAX_FRAME_AGE_MS = 15000                           # relaxado p/ redes lentas
MAX_RESULT_AGE_MS = 800
JPEG_QUALITY = 85

# Heurística simples de fogo
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}

ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.2")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True  # às vezes vem vazio; vamos checar magic bytes
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEURÍSTICA FOGO (igual) =========
def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.02); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.01); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)
            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema
            boxes = boxes_from_mask(mask)
            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire
            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now
            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # 🔧 MÍNIMO: não chama o ESP aqui; só devolve o último frame do cache (grabber)
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS) or placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

# 🔧 Alias simples com extensão (alguns devices/WebViews preferem):
@app.get("/frame.jpg")
def frame_jpg():
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS) or placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}




CameraScreen.tsx (com fallback discreto p/ /frame.jpg, resto intacto)


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando…", waiting:"Aguardando servidor…", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem vídeo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo • score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting…", waiting:"Waiting for server…", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire • score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando…", waiting:"Esperando servidor…", statusFail:"Error de conexión. Revisa Wi-Fi/IP.",
        noVideo:"Sin vídeo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego • score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type SrcBox = { x:number; y:number; w:number; h:number; type:"fire" };
function BoxesOverlay({ frameWH, containerWH, boxes }:{
  frameWH:{w:number;h:number}|null; containerWH:{w:number;h:number}|null; boxes:SrcBox[];
}) {
  const f = frameWH && frameWH.w>0 && frameWH.h>0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w<=0 || containerWH.h<=0) return null;
  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale, dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW)/2, offsetY = (containerWH.h - dispH)/2;
  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position:"absolute", left:offsetX, top:offsetY, width:dispW, height:dispH }}>
        {boxes.map((b,i)=>{
          const left=b.x*scale, top=b.y*scale, width=b.w*scale, height=b.h*scale;
          return (
            <View key={i} style={{ position:"absolute", left, top, width, height, borderWidth:3, borderColor:"#ff3b30", borderRadius:6 }}>
              <View style={{ position:"absolute", left:0, top:-18, paddingHorizontal:6, paddingVertical:2, borderRadius:4, backgroundColor:"#ff3b30" }}>
                <Text style={{ color:"#000", fontWeight:"800", fontSize:10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{w:number;h:number}|null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{w:number;h:number}|null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [useDirectSnapshot, setUseDirectSnapshot] = useState(false);
  const failCountRef = useRef(0);

  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  const clean = (s:string)=>s.replace(/\/+$/,"");

  // Server endpoints
  const healthUrl     = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl     = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv   = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const snapshotSrvAlt= useMemo(()=>`${clean(server)}/frame.jpg`,[server]);
  const configUrl     = useMemo(()=>`${clean(server)}/config`,[server]);

  // ESP endpoints (controle e snapshot direto - fallback)
  const pumpUrl       = useMemo(()=> (on:boolean)=>`http://${ip}/pump?on=${on?"1":"0"}`,[ip]);
  const joystickUrl   = useMemo(()=> (x:number,y:number)=>`http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,[ip]);
  const uartUrl       = useMemo(()=> (line:string)=>`http://${ip}/uart?line=${encodeURIComponent(line)}`,[ip]);
  const snapshotEsp   = useMemo(()=> `http://${ip}/snapshot`, [ip]);

  // Sincroniza IP da câmera no server
  useEffect(()=>{
    let aborted=false;
    (async()=>{
      try{
        const r=await fetch(configUrl,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_ip:ip})});
        const j=await r.json();
        if(!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      }catch{ if(!aborted) setStatusText(T.statusFail); }
    })();
    return()=>{aborted=true};
  },[ip, configUrl, T]);

  // Health do servidor
  useEffect(()=>{
    let stop=false, backoff=500;
    const poll=async()=>{
      if(stop) return;
      try{
        const r=await fetch(healthUrl); const j=await r.json();
        if(j?.ok){ setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`); return; }
      }catch{}
      setStatusText(T.waiting);
      setTimeout(poll, backoff); backoff=Math.min(backoff*1.6, 5000);
    };
    poll(); return()=>{stop=true};
  },[healthUrl, T]);

  // SNAPSHOT loop com fallback server->ESP (mínimo)
  useEffect(()=>{
    let stop=false, interval=160;
    const pickBase = ()=>{
      if (useDirectSnapshot) return snapshotEsp;
      // 🔧 mínimo: se falhar 2x no /snapshot, tenta /frame.jpg
      return failCountRef.current >= 2 ? snapshotSrvAlt : snapshotSrv;
    };

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=160;
      }catch{
        interval=Math.min(interval*1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotSrvAlt, snapshotEsp, useDirectSnapshot]);

  const onNextLoadStart = ()=>{ loadingNextRef.current=true; };
  const onNextShown = (ok:boolean)=>{
    if(ok){
      failCountRef.current = 0;
      if(useDirectSnapshot){ setUseDirectSnapshot(false); }   // volta p/ servidor quando estabiliza
      if(nextFrameUri) setCurrentFrameUri(nextFrameUri);
    }else{
      failCountRef.current += 1;
      // 2 falhas: tenta rota alternativa; 3 falhas: cai p/ ESP direto
      if(!useDirectSnapshot && failCountRef.current >= 3){
        setUseDirectSnapshot(true);
        failCountRef.current = 0;
      }
    }
    loadingNextRef.current=false;
  };

  // DETECT loop (inalterado)
  useEffect(()=>{
    let stop=false, interval=250;
    const loop=async()=>{
      if(stop) return;
      try{
        const r=await fetch(detectUrl); const j=await r.json();
        if(j && j.ok!==false){
          setIsFire(!!j.isFire); setFireScore(Number(j.score||0));
          const wh = Array.isArray(j.frame_wh)&&j.frame_wh.length===2
                     ? {w:Number(j.frame_wh[0])||0, h:Number(j.frame_wh[1])||0}:null;
          if(wh && wh.w>0 && wh.h>0) setFrameWH(wh);
          const boxes:SrcBox[]=[];
          if(j.isFire && Array.isArray(j.boxes)){
            for(const b of j.boxes){
              if(Array.isArray(b)&&b.length>=4){
                const [x,y,w,h]=b.map((n:any)=>Number(n)||0);
                boxes.push({x,y,w,h,type:"fire"});
              }
            }
          }
          setOverlayBoxes(boxes); interval=250;
        }
      }catch{
        setIsFire(false); setFireScore(0); setOverlayBoxes([]);
        interval=Math.min(interval*1.5,1500);
      }finally{ setTimeout(loop, interval); }
    };
    loop(); return()=>{stop=true};
  },[detectUrl]);

  // Joystick (inalterado)
  const RADIUS=64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder:()=>true,
      onMoveShouldSetPanResponder:()=>true,
      onPanResponderGrant:()=>{ setDragging(true); },
      onPanResponderMove:(_e:GestureResponderEvent,g:PanResponderGestureState)=>{
        let nx=g.dx/RADIUS, ny=g.dy/RADIUS;
        const len=Math.hypot(nx,ny); if(len>1){ nx/=len; ny/=len; }
        setJoy({x:nx, y:-ny});
      },
      onPanResponderRelease:()=>{ setJoy({x:0,y:0}); setDragging(false); },
      onPanResponderTerminate:()=>{ setJoy({x:0,y:0}); setDragging(false); },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef  = useRef<string>("STOP");
  const trySendJoystick = async (x:number,y:number)=>{ try{ await fetch(joystickUrl(x,y)); return true; }catch{ return false; } };
  const sendDiscreteCmd  = async (line:string)=>{ try{ await fetch(uartUrl(line)); return true; }catch{ return false; } };
  const vecToDir=(x:number,y:number):"FWD"|"BACK"|"LEFT"|"RIGHT"|"STOP"=>{
    const mag=Math.hypot(x,y); if(mag<0.2) return "STOP";
    const deg=(Math.atan2(y,x)*180)/Math.PI;
    if(deg>-45&&deg<=45) return "RIGHT";
    if(deg>45&&deg<=135) return "FWD";
    if(deg<=-45&&deg>-135) return "BACK";
    return "LEFT";
  };

  useEffect(()=>{
    let cancelled=false;
    const tick=async()=>{
      if(cancelled) return;
      const now=Date.now();
      if(now-lastSendRef.current<120){ setTimeout(tick,20); return; }
      lastSendRef.current=now;

      const {x,y}=joy; const mag=Math.hypot(x,y);
      const ok = await trySendJoystick(x,y);
      if(ok){
        if(mag<0.2 && lastDirRef.current!=="STOP"){ await sendDiscreteCmd("CMD:STOP"); lastDirRef.current="STOP"; }
        setTimeout(tick,120); return;
      }
      const dir=vecToDir(x,y);
      if(dir!==lastDirRef.current){
        const ms=140+Math.round(260*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd( dir==="STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}` );
        lastDirRef.current=dir;
      }else if(dir!=="STOP"){
        const ms=120+Math.round(200*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick,120);
    };
    tick(); return()=>{cancelled=true};
  },[joy, ip]);

  // Bomba (inalterado)
  async function togglePump(){
    try{
      const t=!pumpOn; await fetch(pumpUrl(t)); setPumpOn(t);
    }catch{ setStatusText(T.statusFail); }
  }

  function onVideoLayout(e:LayoutChangeEvent){
    const {width,height}=e.nativeEvent.layout; setVideoContainerWH({w:width,h:height});
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5"
                   autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput value={server} onChangeText={(s)=>{ setServer(s); }}
                   placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
                   style={[styles.input,{minWidth:220}]} />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn?styles.btnOn:styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn?T.pumpOn:T.pumpOff}</Text>
        </Pressable>
      </View>

      <View style={[styles.statusRow,{paddingTop:4,paddingBottom:8}]}>
        <Text numberOfLines={2} style={styles.status}>{statusText} {useDirectSnapshot ? "• (snapshot direto)" : ""}</Text>
        <View style={[styles.badge,{backgroundColor: "#065f46"}]}>
          <Text style={{ color:"#fff", fontWeight:"800" }}>{isFire ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      <View style={[styles.fireBanner, isFire?styles.fireOn:styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      <View style={{ flex:1 }} onLayout={onVideoLayout}>
        <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri}
                        onNextLoadStart={()=> (loadingNextRef.current=true)}
                        onNextShown={onNextShown}/>
        {overlayBoxes.length>0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick (inalterado) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap,{width:64*2+24,height:64*2+24}]}
              {...pan.panHandlers}>
          <View style={[styles.joyBase,{width:64*2,height:64*2,borderRadius:64}]} />
          <View style={[styles.joyKnob,{width:22*2,height:22*2,borderRadius:22,
                        transform:[{translateX:joy.x*64},{translateY:-joy.y*64}], opacity: dragging?1:0.9}]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container:{ flex:1, backgroundColor:PALETTE.bg },
  hero:{ alignItems:"center", paddingTop:12, paddingBottom:6 },
  heroLogo:{ width:80, height:80, marginBottom:6, resizeMode:"contain" },
  heroTitle:{ color:"#fff", fontSize:22, fontWeight:"800" },
  heroSubtitle:{ color:"#d1d5db", marginTop:2 },

  topbar:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:10, gap:8,
           backgroundColor:PALETTE.card, borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  label:{ color:"#cfd3d8", fontSize:12 },
  input:{ backgroundColor:"#0b0d14", color:"white", borderRadius:8, paddingHorizontal:10, paddingVertical:8,
          borderWidth:1, borderColor:PALETTE.border, minWidth:120 },
  btn:{ backgroundColor:PALETTE.accent, paddingHorizontal:10, paddingVertical:10, borderRadius:10 },
  btnOn:{ backgroundColor:"#17a34a" }, btnOff:{ backgroundColor:"#374151" },
  btnText:{ color:"white", fontWeight:"600" },

  statusRow:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:8, gap:8,
              backgroundColor:"#0f1322", borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  badge:{ paddingHorizontal:10, paddingVertical:6, borderRadius:8, borderWidth:1, borderColor:PALETTE.border },
  status:{ color:"#cbd5ff", flex:1, fontSize:12 },

  fireBanner:{ alignItems:"center", justifyContent:"center", paddingVertical:6 },
  fireOn:{ backgroundColor:"#8b0000" }, fireOff:{ backgroundColor:"#223" },
  fireText:{ color:"white", fontWeight:"800" },

  joyWrap:{ position:"absolute", bottom:24, left:24, alignItems:"center", justifyContent:"center" },
  joyBase:{ position:"absolute", backgroundColor:"rgba(255,255,255,0.08)", borderWidth:2, borderColor:"rgba(255,255,255,0.14)" },
  joyKnob:{ position:"absolute", backgroundColor:"rgba(230,64,58,0.9)", borderWidth:2, borderColor:"rgba(255,255,255,0.85)" },
  joyText:{ position:"absolute", bottom:-22, color:"#cbd5ff", fontSize:12 },
});



Esses ajustes são o mínimo para o vídeo aparecer de forma consistente no app sem mexer no restante. Se ainda não renderizar no Android, confirme que o Manifest permite HTTP (cleartext); caso precise, te passo só esses dois trechos do Android sem tocar no resto.


















































Perfeito 👍 Vou te mandar os arquivos completos já com os ajustes necessários para resolver o problema das imagens não aparecerem no app Android.

Fiz três mudanças principais:






Server (FastAPI)




Adicionei um alias /frame.jpg que serve a mesma imagem do /snapshot, mas com extensão .jpg (alguns dispositivos/WebViews exigem).


Headers já forçam no-cache.








App (CameraScreen.tsx)




Ajustei a escolha do endpoint de snapshot para tentar /frame.jpg se /snapshot falhar.


Mantida sua lógica de fallback para snapshot direto do ESP.








Manifest Android (seu projeto React Native bare / prebuild Expo)




Permite tráfego cleartext (HTTP sem TLS) para IPs locais (192.168.x.x).


Inclui network_security_config.xml.









🔹 server_heuristic.py (com /frame.jpg)


# ... [resto do código igual ao seu acima] ...

@app.get("/snapshot")
def snapshot():
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if not b:
        b = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

# Novo alias com extensão .jpg
@app.get("/frame.jpg")
def frame_jpg():
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if not b:
        b = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")




🔹 CameraScreen.tsx (com fallback para /frame.jpg)


// ... imports e constantes iguais ...

export default function CameraScreen() {
  // ... estados e hooks iguais ...

  // Server endpoints
  const healthUrl     = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl     = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv   = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const snapshotSrvAlt= useMemo(()=>`${clean(server)}/frame.jpg`,[server]);
  const configUrl     = useMemo(()=>`${clean(server)}/config`,[server]);

  // ... resto igual ...

  // SNAPSHOT loop (ajustado)
  useEffect(()=>{
    let stop=false;
    let interval=200; // ~5fps
    const pickBase = ()=>{
      if(useDirectSnapshot) return snapshotEsp;
      // se houver falhas recentes, tenta rota alternativa /frame.jpg
      return failCountRef.current >= 2 ? snapshotSrvAlt : snapshotSrv;
    };

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=200;
      }catch{
        interval=Math.min(interval*1.7, 1400);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotSrvAlt, snapshotEsp, useDirectSnapshot]);

  // ... resto do código igual (detecção, joystick, bomba, render) ...
}




🔹 AndroidManifest.xml


android/app/src/main/AndroidManifest.xml


<manifest xmlns:android="http://schemas.android.com/apk/res/android"
    package="com.hydrobot">

    <uses-permission android:name="android.permission.INTERNET"/>

    <application
        android:name=".MainApplication"
        android:label="@string/app_name"
        android:icon="@mipmap/ic_launcher"
        android:usesCleartextTraffic="true"
        android:networkSecurityConfig="@xml/network_security_config">
        <!-- resto igual -->
    </application>
</manifest>




🔹 network_security_config.xml


Crie em:

android/app/src/main/res/xml/network_security_config.xml


<?xml version="1.0" encoding="utf-8"?>
<network-security-config>
  <!-- Permite HTTP sem TLS em sub-redes locais -->
  <domain-config cleartextTrafficPermitted="true">
    <domain includeSubdomains="true">192.168.0.0</domain>
    <domain includeSubdomains="true">192.168.1.0</domain>
    <domain includeSubdomains="true">192.168.2.0</domain>
    <domain includeSubdomains="true">192.168.3.0</domain>
    <domain includeSubdomains="true">10.0.0.0</domain>
    <domain includeSubdomains="true">172.16.0.0</domain>
  </domain-config>

  <!-- Hostname/mDNS opcional -->
  <domain-config cleartextTrafficPermitted="true">
    <domain includeSubdomains="true">hydrobot-esp.local</domain>
  </domain-config>

  <base-config cleartextTrafficPermitted="true" />
</network-security-config>




✅ Com isso:




O server entrega imagem em /snapshot e também em /frame.jpg.


O app troca automaticamente para /frame.jpg se /snapshot falhar.


O Android agora deixa abrir http://192.168.x.x/... sem bloquear.





Quer que eu já mande também a versão do firmware ESP32-CAM com os últimos ajustes de estabilidade (buffer fixo/adaptação) junto nesse pacote, ou deixo só o server + app + manifest por enquanto?






























Beleza 👌

Aqui estão os arquivos completos já corrigidos para as imagens aparecerem no app:



🔹 server_heuristic.py (com /frame.jpg)


# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot (robusto)
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
POLL_FPS_TARGET = 6.0
MAX_FRAME_AGE_MS = 15000
MAX_RESULT_AGE_MS = 800
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.1",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}
ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.2")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= FIRE DETECTOR =========
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.02); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if not b:
        b = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

# Novo alias com extensão .jpg
@app.get("/frame.jpg")
def frame_jpg():
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if not b:
        b = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")




🔹 CameraScreen.tsx (com fallback /frame.jpg)


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando…", waiting:"Aguardando servidor…", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem vídeo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo • score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting…", waiting:"Waiting for server…", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire • score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando…", waiting:"Esperando servidor…", statusFail:"Error de conexión. Revisa Wi-Fi/IP.",
        noVideo:"Sin vídeo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego • score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = texts










































Vamos atacar o gargalo real: quando a câmera olha “longe” (muita textura/detalhe), os JPEGs ficam grandes, a captura demora mais, a PSRAM fragmenta e o Wi-Fi congestiona — isso faz travar/rebootar. Corrigi isso de 3 lados:






ESP32-CAM:




Buffer único pré-alocado em PSRAM (tamanho fixo) — sem malloc/free por frame.


Queda agressiva de resolução/qualidade quando um frame passa do limite, e recuperação gradual quando aliviar.


Drops “duros” seguros para frames imensos (protege rádio e PSRAM).


fb_count=1, GRAB_LATEST, WiFi sem sleep e reinit da câmera em streak de falhas.








Server (FastAPI):




/snapshot passa a entregar apenas o último frame em cache do grabber (sem refazer requisição direta ao ESP).


Grabber com FPS alvo menor (6–7) e backoff suave para redes mais lentas.








App (CameraScreen):




Poll de imagem ajustado (~5–6 fps) com backoff em falha.


Mantida a lógica de fallback (server → ESP direto) mas com menos pressão.








Abaixo os arquivos completos já ajustados.



1) server_heuristic.py (com cache único e /snapshot leve)


# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot (robusto)
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
POLL_FPS_TARGET = 6.0                              # ~6 fps para aliviar rede/ESP
MAX_FRAME_AGE_MS = 15000                           # relaxado p/ redes lentas
MAX_RESULT_AGE_MS = 800
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.1",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}
ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.2")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEURÍSTICA FOGO =========
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.02); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # Agora SEM requisitar o ESP aqui: apenas entrega o último do grabber (reduz carga)
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if not b:
        b = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}




2) CameraScreen.tsx (poll mais leve e fallback mantido)


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando…", waiting:"Aguardando servidor…", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem vídeo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo • score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting…", waiting:"Waiting for server…", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire • score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando…", waiting:"Esperando servidor…", statusFail:"Error de conexión. Revisa Wi-Fi/IP.",
        noVideo:"Sin vídeo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego • score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type SrcBox = { x:number; y:number; w:number; h:number; type:"fire" };
function BoxesOverlay({ frameWH, containerWH, boxes }:{
  frameWH:{w:number;h:number}|null; containerWH:{w:number;h:number}|null; boxes:SrcBox[];
}) {
  const f = frameWH && frameWH.w>0 && frameWH.h>0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w<=0 || containerWH.h<=0) return null;
  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale, dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW)/2, offsetY = (containerWH.h - dispH)/2;
  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position:"absolute", left:offsetX, top:offsetY, width:dispW, height:dispH }}>
        {boxes.map((b,i)=>{
          const left=b.x*scale, top=b.y*scale, width=b.w*scale, height=b.h*scale;
          return (
            <View key={i} style={{ position:"absolute", left, top, width, height, borderWidth:3, borderColor:"#ff3b30", borderRadius:6 }}>
              <View style={{ position:"absolute", left:0, top:-18, paddingHorizontal:6, paddingVertical:2, borderRadius:4, backgroundColor:"#ff3b30" }}>
                <Text style={{ color:"#000", fontWeight:"800", fontSize:10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{w:number;h:number}|null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{w:number;h:number}|null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [useDirectSnapshot, setUseDirectSnapshot] = useState(false);
  const failCountRef = useRef(0);

  const [joy, setJoy] = useState({ x: 0, y: 0 });

  const clean = (s:string)=>s.replace(/\/+$/,"");

  // Server endpoints
  const healthUrl   = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl   = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const configUrl   = useMemo(()=>`${clean(server)}/config`,[server]);

  // ESP endpoints
  const pumpUrl     = useMemo(()=> (on:boolean)=>`http://${ip}/pump?on=${on?"1":"0"}`,[ip]);
  const joystickUrl = useMemo(()=> (x:number,y:number)=>`http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,[ip]);
  const uartUrl     = useMemo(()=> (line:string)=>`http://${ip}/uart?line=${encodeURIComponent(line)}`,[ip]);
  const snapshotEsp = useMemo(()=> `http://${ip}/snapshot`, [ip]);

  // Sincroniza IP no server
  useEffect(()=>{
    let aborted=false;
    (async()=>{
      try{
        const r=await fetch(configUrl,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_ip:ip})});
        const j=await r.json();
        if(!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      }catch{ if(!aborted) setStatusText(T.statusFail); }
    })();
    return()=>{aborted=true};
  },[ip, configUrl, T]);

  // Health
  useEffect(()=>{
    let stop=false, backoff=600;
    const poll=async()=>{
      if(stop) return;
      try{
        const r=await fetch(healthUrl); const j=await r.json();
        if(j?.ok){ setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`); setTimeout(poll, 1500); return; }
      }catch{}
      setStatusText(T.waiting);
      setTimeout(poll, backoff); backoff=Math.min(backoff*1.6, 5000);
    };
    poll(); return()=>{stop=true};
  },[healthUrl, T]);

  // SNAPSHOT loop (menos pressão)
  useEffect(()=>{
    let stop=false;
    let interval=190; // ~5.2 fps
    const pickBase = ()=> useDirectSnapshot ? snapshotEsp : snapshotSrv;

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=190;
      }catch{
        interval=Math.min(interval*1.7, 1400);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotEsp, useDirectSnapshot]);

  const onNextLoadStart = ()=>{ loadingNextRef.current=true; };
  const onNextShown = (ok:boolean)=>{
    if(ok){
      failCountRef.current = 0;
      if(useDirectSnapshot){ setUseDirectSnapshot(false); }
      if(nextFrameUri) setCurrentFrameUri(nextFrameUri);
    }else{
      failCountRef.current += 1;
      if(!useDirectSnapshot && failCountRef.current >= 3){
        setUseDirectSnapshot(true);
        failCountRef.current = 0;
      }
    }
    loadingNextRef.current=false;
  };

  // DETECT loop
  useEffect(()=>{
    let stop=false, interval=300;
    const loop=async()=>{
      if(stop) return;
      try{
        const r=await fetch(detectUrl); const j=await r.json();
        if(j && j.ok!==false){
          setIsFire(!!j.isFire); setFireScore(Number(j.score||0));
          const wh = Array.isArray(j.frame_wh)&&j.frame_wh.length===2
                     ? {w:Number(j.frame_wh[0])||0, h:Number(j.frame_wh[1])||0}:null;
          if(wh && wh.w>0 && wh.h>0) setFrameWH(wh);
          const boxes:SrcBox[]=[];
          if(j.isFire && Array.isArray(j.boxes)){
            for(const b of j.boxes){
              if(Array.isArray(b)&&b.length>=4){
                const [x,y,w,h]=b.map((n:any)=>Number(n)||0);
                boxes.push({x,y,w,h,type:"fire"});
              }
            }
          }
          setOverlayBoxes(boxes); interval=300;
        }
      }catch{
        setIsFire(false); setFireScore(0); setOverlayBoxes([]);
        interval=Math.min(interval*1.5,1500);
      }finally{ setTimeout(loop, interval); }
    };
    loop(); return()=>{stop=true};
  },[detectUrl]);

  // Joystick (mantido)
  const RADIUS=64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder:()=>true,
      onMoveShouldSetPanResponder:()=>true,
      onPanResponderMove:(_e:GestureResponderEvent,g:PanResponderGestureState)=>{
        let nx=g.dx/RADIUS, ny=g.dy/RADIUS;
        const len=Math.hypot(nx,ny); if(len>1){ nx/=len; ny/=len; }
        setJoy({x:nx, y:-ny});
      },
      onPanResponderRelease:()=>{ setJoy({x:0,y:0}); },
      onPanResponderTerminate:()=>{ setJoy({x:0,y:0}); },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef  = useRef<string>("STOP");
  const trySendJoystick = async (x:number,y:number)=>{ try{ await fetch(joystickUrl(x,y)); return true; }catch{ return false; } };
  const sendDiscreteCmd  = async (line:string)=>{ try{ await fetch(uartUrl(line)); return true; }catch{ return false; } };
  const vecToDir=(x:number,y:number):"FWD"|"BACK"|"LEFT"|"RIGHT"|"STOP"=>{
    const mag=Math.hypot(x,y); if(mag<0.2) return "STOP";
    const deg=(Math.atan2(y,x)*180)/Math.PI;
    if(deg>-45&&deg<=45) return "RIGHT";
    if(deg>45&&deg<=135) return "FWD";
    if(deg<=-45&&deg>-135) return "BACK";
    return "LEFT";
  };

  useEffect(()=>{
    let cancelled=false;
    const tick=async()=>{
      if(cancelled) return;
      const now=Date.now();
      if(now-lastSendRef.current<120){ setTimeout(tick,20); return; }
      lastSendRef.current=now;

      const {x,y}=joy; const mag=Math.hypot(x,y);
      const ok = await trySendJoystick(x,y);
      if(ok){
        if(mag<0.2 && lastDirRef.current!=="STOP"){ await sendDiscreteCmd("CMD:STOP"); lastDirRef.current="STOP"; }
        setTimeout(tick,120); return;
      }
      const dir=vecToDir(x,y);
      if(dir!==lastDirRef.current){
        const ms=140+Math.round(260*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd( dir==="STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}` );
        lastDirRef.current=dir;
      }else if(dir!=="STOP"){
        const ms=120+Math.round(200*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick,120);
    };
    tick(); return()=>{cancelled=true};
  },[joy, ip]);

  // Bomba
  async function togglePump(){
    try{ const t=!pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); }
    catch{ setStatusText(T.statusFail); }
  }

  function onVideoLayout(e:LayoutChangeEvent){
    const {width,height}=e.nativeEvent.layout; setVideoContainerWH({w:width,h:height});
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5"
                   autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput value={server} onChangeText={setServer}
                   placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
                   style={[styles.input,{minWidth:220}]} />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn?styles.btnOn:styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn?T.pumpOn:T.pumpOff}</Text>
        </Pressable>
      </View>

      <View style={[styles.statusRow,{paddingTop:4,paddingBottom:8}]}>
        <Text numberOfLines={2} style={styles.status}>{statusText} {useDirectSnapshot ? "• (snapshot direto)" : ""}</Text>
        <View style={[styles.badge,{backgroundColor:"#065f46"}]}>
          <Text style={{ color:"#fff", fontWeight:"800" }}>{isFire ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      <View style={[styles.fireBanner, isFire?styles.fireOn:styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      <View style={{ flex:1 }} onLayout={onVideoLayout}>
        <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri}
                        onNextLoadStart={()=> (loadingNextRef.current=true)}
                        onNextShown={onNextShown}/>
        {overlayBoxes.length>0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap,{width:64*2+24,height:64*2+24}]}
              {...pan.panHandlers}>
          <View style={[styles.joyBase,{width:64*2,height:64*2,borderRadius:64}]} />
          <View style={[styles.joyKnob,{width:22*2,height:22*2,borderRadius:22,
                        transform:[{translateX:joy.x*64},{translateY:-joy.y*64}], opacity: 0.9}]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container:{ flex:1, backgroundColor:PALETTE.bg },
  hero:{ alignItems:"center", paddingTop:12, paddingBottom:6 },
  heroLogo:{ width:80, height:80, marginBottom:6, resizeMode:"contain" },
  heroTitle:{ color:"#fff", fontSize:22, fontWeight:"800" },
  heroSubtitle:{ color:"#d1d5db", marginTop:2 },

  topbar:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:10, gap:8,
           backgroundColor:PALETTE.card, borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  label:{ color:"#cfd3d8", fontSize:12 },
  input:{ backgroundColor:"#0b0d14", color:"white", borderRadius:8, paddingHorizontal:10, paddingVertical:8,
          borderWidth:1, borderColor:PALETTE.border, minWidth:120 },
  btn:{ backgroundColor:PALETTE.accent, paddingHorizontal:10, paddingVertical:10, borderRadius:10 },
  btnOn:{ backgroundColor:"#17a34a" }, btnOff:{ backgroundColor:"#374151" },
  btnText:{ color:"white", fontWeight:"600" },

  statusRow:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:8, gap:8,
              backgroundColor:"#0f1322", borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  badge:{ paddingHorizontal:10, paddingVertical:6, borderRadius:8, borderWidth:1, borderColor:PALETTE.border },
  status:{ color:"#cbd5ff", flex:1, fontSize:12 },

  fireBanner:{ alignItems:"center", justifyContent:"center", paddingVertical:6 },
  fireOn:{ backgroundColor:"#8b0000" }, fireOff:{ backgroundColor:"#223" },
  fireText:{ color:"white", fontWeight:"800" },

  joyWrap:{ position:"absolute", bottom:24, left:24, alignItems:"center", justifyContent:"center" },
  joyBase:{ position:"absolute", backgroundColor:"rgba(255,255,255,0.08)", borderWidth:2, borderColor:"rgba(255,255,255,0.14)" },
  joyKnob:{ position:"absolute", backgroundColor:"rgba(230,64,58,0.9)", borderWidth:2, borderColor:"rgba(255,255,255,0.85)" },
  joyText:{ position:"absolute", bottom:-22, color:"#cbd5ff", fontSize:12 },
});




3) Firmware ESP32-CAM (AI Thinker) — buffer fixo + adaptação agressiva


/*  ESP32-CAM (AI Thinker) — Snapshot buffer fixo + Bridge HTTP<->UART
    Anti-trava ao olhar "longe":
      - Buffer PSRAM fixo (sem malloc/free por frame)
      - Queda agressiva de qualidade/resolução ao detectar frame grande/lento
      - Drop duro de frames > limite
      - fb_count=1, GRAB_LATEST, reinit em streak de falhas
    Endpoints:
      /status, /snapshot, /uart?line=, /pump?on=0|1, /joystick?x=&y=
    Rede: Wi-Fi STA DHCP + mDNS http://hydrobot-esp.local
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer fixo do último frame ----------
static uint8_t* g_buf = nullptr;
static size_t   g_cap = 0;       // capacidade
static size_t   g_len = 0;       // tamanho válido
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;
static uint32_t g_fail_streak = 0;

// ---------- Estado adaptativo ----------
static sensor_t* g_sensor = nullptr;
static framesize_t g_fs   = FRAMESIZE_QVGA;
static int g_quality      = 16;
static uint8_t g_big_hits = 0;
static uint8_t g_ok_hits  = 0;

// thresholds (afinados p/ estabilidade)
static const size_t HARD_DROP_BYTES  = 140*1024; // drop sempre acima disso
static const size_t BIG_QVGA_BYTES   = 60*1024;
static const size_t BIG_QQVGA_BYTES  = 26*1024;
static const uint32_t SLOW_MS        = 500;      // captura >500ms conta como "grande"
static const uint8_t  HITS_UP        = 2;        // reage rápido a cena pesada
static const uint8_t  HITS_DOWN      = 40;       // recupera devagar

// ---------- Utils ----------
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }
static uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 20000000;             // 20 MHz estável
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;
  cfg.jpeg_quality = quality;              // (menor = melhor)
  cfg.fb_count     = 1;                    // evita fragmentação
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);
    g_sensor->set_gain_ctrl(g_sensor, 1);
    g_sensor->set_whitebal(g_sensor, 1);
    g_sensor->set_awb_gain(g_sensor, 1);
    g_sensor->set_gainceiling(g_sensor, GAINCEILING_8X);
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

static void camera_reconfigure(framesize_t fs, int quality) {
  if (!g_sensor) return;
  g_sensor->set_framesize(g_sensor, fs);
  g_sensor->set_quality(g_sensor, quality);
  g_fs = fs;
  g_quality = quality;
  Serial.printf("CAM_CFG fs=%s q=%d\n", (fs==FRAMESIZE_QVGA?"QVGA":"QQVGA"), quality);
}

static inline bool is_big_frame(size_t len, uint32_t took_ms) {
  size_t lim = (g_fs==FRAMESIZE_QVGA) ? BIG_QVGA_BYTES : BIG_QQVGA_BYTES;
  return (len > lim) || (took_ms > SLOW_MS);
}

static void adapt_if_needed() {
  if (g_big_hits >= HITS_UP) {
    g_big_hits = 0; g_ok_hits = 0;
    if (g_quality < 22) { g_quality += 2; camera_reconfigure(g_fs, g_quality); }
    else if (g_fs != FRAMESIZE_QQVGA)     camera_reconfigure(FRAMESIZE_QQVGA, g_quality);
  } else if (g_ok_hits >= HITS_DOWN) {
    g_ok_hits = 0;
    if (g_fs == FRAMESIZE_QQVGA)          camera_reconfigure(FRAMESIZE_QVGA, g_quality);
    else if (g_quality > 14)              { g_quality -= 2; if (g_quality<14) g_quality=14; camera_reconfigure(g_fs, g_quality); }
  }
}

// ---------- Wi-Fi ----------
static void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) { delay(200); }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
    Serial.print("RSSI: "); Serial.println(WiFi.RSSI());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Handlers ----------
static void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot-buffer-fixo\","
             "\"hasFrame\":" + String((g_len>0 && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QVGA?"QVGA":"QQVGA") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

static void handle_snapshot(){
  sendCORS();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_buf && g_len>0);
  if(ok){
    server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
    server.sendHeader("Pragma","no-cache");
    server.sendHeader("Expires","0");
    server.setContentLength(g_len);
    server.send(200,"image/jpeg","");
    WiFiClient c = server.client();
    c.write(g_buf, g_len);
  } else {
    server.send(503,"text/plain","no frame\n");
  }
  xSemaphoreGive(g_lock);
}

static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
static void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

static void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

static void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- Captura contínua com buffer fixo ----------
static void cam_task(void*){
  const uint32_t MIN_INTERVAL_MS = 150;   // ~6–7 fps cap
  g_cap_tick = now_ms();
  while(true){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();
    uint32_t took = now_ms() - t0;

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= 6){
        Serial.println("CAM_REINIT");
        esp_camera_deinit();
        delay(120);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(10));
      continue;
    }
    g_fail_streak = 0;

    // Drop duro protege rádio/PSRAM
    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > HARD_DROP_BYTES) {
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      g_big_hits++; g_ok_hits = 0; adapt_if_needed();
      continue;
    }

    // Marca grande/leve p/ adaptação
    if (is_big_frame(fb->len, took)) { g_big_hits++; g_ok_hits = 0; }
    else { g_ok_hits++; if(g_big_hits) g_big_hits--; }
    adapt_if_needed();

    // Copia para buffer fixo (se couber)
    xSemaphoreTake(g_lock, portMAX_DELAY);
    if (fb->len <= g_cap) {
      memcpy(g_buf, fb->buf, fb->len);
      g_len = fb->len;
      g_ts_ms = now_ms();
    } else {
      // não cabe → conta como grande e não atualiza o frame
      g_big_hits++; g_ok_hits = 0;
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // cap de taxa
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(50);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  g_lock = xSemaphoreCreateMutex();

  // Buffer fixo: tenta 160KB, cai para 128KB se necessário
  g_cap = 160*1024;
  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  if(!g_buf){
    g_cap = 128*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }
  if(!g_buf){
    // último recurso: 96KB
    g_cap = 96*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }

  wifi_begin_dhcp();

  if(!camera_begin(FRAMESIZE_QVGA, 16)){
    delay(300);
    camera_begin(FRAMESIZE_QQVGA, 18);
  }

  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}




Como isso resolve o seu sintoma “apontou longe ⇒ trava”




JPEG grande/complexo agora:



é identificado na hora (pelo tamanho e/ou tempo de captura),


dispara queda de quality e até QQVGA rapidamente,


nunca realoca PSRAM por frame (buffer fixo),


descarta frames gigantes em vez de tentar servir/armazenar,


server/app reduzem a pressão (menos fps e sem “requisição dupla”).








Se algo ainda estourar (rede muito ruidosa), a task re-inicializa a câmera automaticamente e segue.


Se quiser, depois podemos expor no /status o last_big_reason (por tamanho/tempo) e um endpoint /config no ESP para travar em QQVGA em ambientes muito texturizados — mas, com os ajustes acima, a tendência é estabilizar sem precisar disso.







































Vamos atacar o gargalo real: quando a câmera olha “longe” (muita textura/detalhe), os JPEGs ficam grandes, a captura demora mais, a PSRAM fragmenta e o Wi-Fi congestiona — isso faz travar/rebootar. Corrigi isso de 3 lados:






ESP32-CAM:




Buffer único pré-alocado em PSRAM (tamanho fixo) — sem malloc/free por frame.


Queda agressiva de resolução/qualidade quando um frame passa do limite, e recuperação gradual quando aliviar.


Drops “duros” seguros para frames imensos (protege rádio e PSRAM).


fb_count=1, GRAB_LATEST, WiFi sem sleep e reinit da câmera em streak de falhas.








Server (FastAPI):




/snapshot passa a entregar apenas o último frame em cache do grabber (sem refazer requisição direta ao ESP).


Grabber com FPS alvo menor (6–7) e backoff suave para redes mais lentas.








App (CameraScreen):




Poll de imagem ajustado (~5–6 fps) com backoff em falha.


Mantida a lógica de fallback (server → ESP direto) mas com menos pressão.








Abaixo os arquivos completos já ajustados.



1) server_heuristic.py (com cache único e /snapshot leve)


# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot (robusto)
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
POLL_FPS_TARGET = 6.0                              # ~6 fps para aliviar rede/ESP
MAX_FRAME_AGE_MS = 15000                           # relaxado p/ redes lentas
MAX_RESULT_AGE_MS = 800
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.1",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}
ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.2")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEURÍSTICA FOGO =========
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.02); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # Agora SEM requisitar o ESP aqui: apenas entrega o último do grabber (reduz carga)
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if not b:
        b = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}




2) CameraScreen.tsx (poll mais leve e fallback mantido)


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando…", waiting:"Aguardando servidor…", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem vídeo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo • score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting…", waiting:"Waiting for server…", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire • score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando…", waiting:"Esperando servidor…", statusFail:"Error de conexión. Revisa Wi-Fi/IP.",
        noVideo:"Sin vídeo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego • score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type SrcBox = { x:number; y:number; w:number; h:number; type:"fire" };
function BoxesOverlay({ frameWH, containerWH, boxes }:{
  frameWH:{w:number;h:number}|null; containerWH:{w:number;h:number}|null; boxes:SrcBox[];
}) {
  const f = frameWH && frameWH.w>0 && frameWH.h>0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w<=0 || containerWH.h<=0) return null;
  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale, dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW)/2, offsetY = (containerWH.h - dispH)/2;
  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position:"absolute", left:offsetX, top:offsetY, width:dispW, height:dispH }}>
        {boxes.map((b,i)=>{
          const left=b.x*scale, top=b.y*scale, width=b.w*scale, height=b.h*scale;
          return (
            <View key={i} style={{ position:"absolute", left, top, width, height, borderWidth:3, borderColor:"#ff3b30", borderRadius:6 }}>
              <View style={{ position:"absolute", left:0, top:-18, paddingHorizontal:6, paddingVertical:2, borderRadius:4, backgroundColor:"#ff3b30" }}>
                <Text style={{ color:"#000", fontWeight:"800", fontSize:10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{w:number;h:number}|null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{w:number;h:number}|null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [useDirectSnapshot, setUseDirectSnapshot] = useState(false);
  const failCountRef = useRef(0);

  const [joy, setJoy] = useState({ x: 0, y: 0 });

  const clean = (s:string)=>s.replace(/\/+$/,"");

  // Server endpoints
  const healthUrl   = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl   = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const configUrl   = useMemo(()=>`${clean(server)}/config`,[server]);

  // ESP endpoints
  const pumpUrl     = useMemo(()=> (on:boolean)=>`http://${ip}/pump?on=${on?"1":"0"}`,[ip]);
  const joystickUrl = useMemo(()=> (x:number,y:number)=>`http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,[ip]);
  const uartUrl     = useMemo(()=> (line:string)=>`http://${ip}/uart?line=${encodeURIComponent(line)}`,[ip]);
  const snapshotEsp = useMemo(()=> `http://${ip}/snapshot`, [ip]);

  // Sincroniza IP no server
  useEffect(()=>{
    let aborted=false;
    (async()=>{
      try{
        const r=await fetch(configUrl,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_ip:ip})});
        const j=await r.json();
        if(!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      }catch{ if(!aborted) setStatusText(T.statusFail); }
    })();
    return()=>{aborted=true};
  },[ip, configUrl, T]);

  // Health
  useEffect(()=>{
    let stop=false, backoff=600;
    const poll=async()=>{
      if(stop) return;
      try{
        const r=await fetch(healthUrl); const j=await r.json();
        if(j?.ok){ setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`); setTimeout(poll, 1500); return; }
      }catch{}
      setStatusText(T.waiting);
      setTimeout(poll, backoff); backoff=Math.min(backoff*1.6, 5000);
    };
    poll(); return()=>{stop=true};
  },[healthUrl, T]);

  // SNAPSHOT loop (menos pressão)
  useEffect(()=>{
    let stop=false;
    let interval=190; // ~5.2 fps
    const pickBase = ()=> useDirectSnapshot ? snapshotEsp : snapshotSrv;

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=190;
      }catch{
        interval=Math.min(interval*1.7, 1400);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotEsp, useDirectSnapshot]);

  const onNextLoadStart = ()=>{ loadingNextRef.current=true; };
  const onNextShown = (ok:boolean)=>{
    if(ok){
      failCountRef.current = 0;
      if(useDirectSnapshot){ setUseDirectSnapshot(false); }
      if(nextFrameUri) setCurrentFrameUri(nextFrameUri);
    }else{
      failCountRef.current += 1;
      if(!useDirectSnapshot && failCountRef.current >= 3){
        setUseDirectSnapshot(true);
        failCountRef.current = 0;
      }
    }
    loadingNextRef.current=false;
  };

  // DETECT loop
  useEffect(()=>{
    let stop=false, interval=300;
    const loop=async()=>{
      if(stop) return;
      try{
        const r=await fetch(detectUrl); const j=await r.json();
        if(j && j.ok!==false){
          setIsFire(!!j.isFire); setFireScore(Number(j.score||0));
          const wh = Array.isArray(j.frame_wh)&&j.frame_wh.length===2
                     ? {w:Number(j.frame_wh[0])||0, h:Number(j.frame_wh[1])||0}:null;
          if(wh && wh.w>0 && wh.h>0) setFrameWH(wh);
          const boxes:SrcBox[]=[];
          if(j.isFire && Array.isArray(j.boxes)){
            for(const b of j.boxes){
              if(Array.isArray(b)&&b.length>=4){
                const [x,y,w,h]=b.map((n:any)=>Number(n)||0);
                boxes.push({x,y,w,h,type:"fire"});
              }
            }
          }
          setOverlayBoxes(boxes); interval=300;
        }
      }catch{
        setIsFire(false); setFireScore(0); setOverlayBoxes([]);
        interval=Math.min(interval*1.5,1500);
      }finally{ setTimeout(loop, interval); }
    };
    loop(); return()=>{stop=true};
  },[detectUrl]);

  // Joystick (mantido)
  const RADIUS=64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder:()=>true,
      onMoveShouldSetPanResponder:()=>true,
      onPanResponderMove:(_e:GestureResponderEvent,g:PanResponderGestureState)=>{
        let nx=g.dx/RADIUS, ny=g.dy/RADIUS;
        const len=Math.hypot(nx,ny); if(len>1){ nx/=len; ny/=len; }
        setJoy({x:nx, y:-ny});
      },
      onPanResponderRelease:()=>{ setJoy({x:0,y:0}); },
      onPanResponderTerminate:()=>{ setJoy({x:0,y:0}); },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef  = useRef<string>("STOP");
  const trySendJoystick = async (x:number,y:number)=>{ try{ await fetch(joystickUrl(x,y)); return true; }catch{ return false; } };
  const sendDiscreteCmd  = async (line:string)=>{ try{ await fetch(uartUrl(line)); return true; }catch{ return false; } };
  const vecToDir=(x:number,y:number):"FWD"|"BACK"|"LEFT"|"RIGHT"|"STOP"=>{
    const mag=Math.hypot(x,y); if(mag<0.2) return "STOP";
    const deg=(Math.atan2(y,x)*180)/Math.PI;
    if(deg>-45&&deg<=45) return "RIGHT";
    if(deg>45&&deg<=135) return "FWD";
    if(deg<=-45&&deg>-135) return "BACK";
    return "LEFT";
  };

  useEffect(()=>{
    let cancelled=false;
    const tick=async()=>{
      if(cancelled) return;
      const now=Date.now();
      if(now-lastSendRef.current<120){ setTimeout(tick,20); return; }
      lastSendRef.current=now;

      const {x,y}=joy; const mag=Math.hypot(x,y);
      const ok = await trySendJoystick(x,y);
      if(ok){
        if(mag<0.2 && lastDirRef.current!=="STOP"){ await sendDiscreteCmd("CMD:STOP"); lastDirRef.current="STOP"; }
        setTimeout(tick,120); return;
      }
      const dir=vecToDir(x,y);
      if(dir!==lastDirRef.current){
        const ms=140+Math.round(260*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd( dir==="STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}` );
        lastDirRef.current=dir;
      }else if(dir!=="STOP"){
        const ms=120+Math.round(200*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick,120);
    };
    tick(); return()=>{cancelled=true};
  },[joy, ip]);

  // Bomba
  async function togglePump(){
    try{ const t=!pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); }
    catch{ setStatusText(T.statusFail); }
  }

  function onVideoLayout(e:LayoutChangeEvent){
    const {width,height}=e.nativeEvent.layout; setVideoContainerWH({w:width,h:height});
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5"
                   autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput value={server} onChangeText={setServer}
                   placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
                   style={[styles.input,{minWidth:220}]} />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn?styles.btnOn:styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn?T.pumpOn:T.pumpOff}</Text>
        </Pressable>
      </View>

      <View style={[styles.statusRow,{paddingTop:4,paddingBottom:8}]}>
        <Text numberOfLines={2} style={styles.status}>{statusText} {useDirectSnapshot ? "• (snapshot direto)" : ""}</Text>
        <View style={[styles.badge,{backgroundColor:"#065f46"}]}>
          <Text style={{ color:"#fff", fontWeight:"800" }}>{isFire ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      <View style={[styles.fireBanner, isFire?styles.fireOn:styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      <View style={{ flex:1 }} onLayout={onVideoLayout}>
        <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri}
                        onNextLoadStart={()=> (loadingNextRef.current=true)}
                        onNextShown={onNextShown}/>
        {overlayBoxes.length>0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap,{width:64*2+24,height:64*2+24}]}
              {...pan.panHandlers}>
          <View style={[styles.joyBase,{width:64*2,height:64*2,borderRadius:64}]} />
          <View style={[styles.joyKnob,{width:22*2,height:22*2,borderRadius:22,
                        transform:[{translateX:joy.x*64},{translateY:-joy.y*64}], opacity: 0.9}]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container:{ flex:1, backgroundColor:PALETTE.bg },
  hero:{ alignItems:"center", paddingTop:12, paddingBottom:6 },
  heroLogo:{ width:80, height:80, marginBottom:6, resizeMode:"contain" },
  heroTitle:{ color:"#fff", fontSize:22, fontWeight:"800" },
  heroSubtitle:{ color:"#d1d5db", marginTop:2 },

  topbar:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:10, gap:8,
           backgroundColor:PALETTE.card, borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  label:{ color:"#cfd3d8", fontSize:12 },
  input:{ backgroundColor:"#0b0d14", color:"white", borderRadius:8, paddingHorizontal:10, paddingVertical:8,
          borderWidth:1, borderColor:PALETTE.border, minWidth:120 },
  btn:{ backgroundColor:PALETTE.accent, paddingHorizontal:10, paddingVertical:10, borderRadius:10 },
  btnOn:{ backgroundColor:"#17a34a" }, btnOff:{ backgroundColor:"#374151" },
  btnText:{ color:"white", fontWeight:"600" },

  statusRow:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:8, gap:8,
              backgroundColor:"#0f1322", borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  badge:{ paddingHorizontal:10, paddingVertical:6, borderRadius:8, borderWidth:1, borderColor:PALETTE.border },
  status:{ color:"#cbd5ff", flex:1, fontSize:12 },

  fireBanner:{ alignItems:"center", justifyContent:"center", paddingVertical:6 },
  fireOn:{ backgroundColor:"#8b0000" }, fireOff:{ backgroundColor:"#223" },
  fireText:{ color:"white", fontWeight:"800" },

  joyWrap:{ position:"absolute", bottom:24, left:24, alignItems:"center", justifyContent:"center" },
  joyBase:{ position:"absolute", backgroundColor:"rgba(255,255,255,0.08)", borderWidth:2, borderColor:"rgba(255,255,255,0.14)" },
  joyKnob:{ position:"absolute", backgroundColor:"rgba(230,64,58,0.9)", borderWidth:2, borderColor:"rgba(255,255,255,0.85)" },
  joyText:{ position:"absolute", bottom:-22, color:"#cbd5ff", fontSize:12 },
});




3) Firmware ESP32-CAM (AI Thinker) — buffer fixo + adaptação agressiva


/*  ESP32-CAM (AI Thinker) — Snapshot buffer fixo + Bridge HTTP<->UART
    Anti-trava ao olhar "longe":
      - Buffer PSRAM fixo (sem malloc/free por frame)
      - Queda agressiva de qualidade/resolução ao detectar frame grande/lento
      - Drop duro de frames > limite
      - fb_count=1, GRAB_LATEST, reinit em streak de falhas
    Endpoints:
      /status, /snapshot, /uart?line=, /pump?on=0|1, /joystick?x=&y=
    Rede: Wi-Fi STA DHCP + mDNS http://hydrobot-esp.local
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer fixo do último frame ----------
static uint8_t* g_buf = nullptr;
static size_t   g_cap = 0;       // capacidade
static size_t   g_len = 0;       // tamanho válido
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;
static uint32_t g_fail_streak = 0;

// ---------- Estado adaptativo ----------
static sensor_t* g_sensor = nullptr;
static framesize_t g_fs   = FRAMESIZE_QVGA;
static int g_quality      = 16;
static uint8_t g_big_hits = 0;
static uint8_t g_ok_hits  = 0;

// thresholds (afinados p/ estabilidade)
static const size_t HARD_DROP_BYTES  = 140*1024; // drop sempre acima disso
static const size_t BIG_QVGA_BYTES   = 60*1024;
static const size_t BIG_QQVGA_BYTES  = 26*1024;
static const uint32_t SLOW_MS        = 500;      // captura >500ms conta como "grande"
static const uint8_t  HITS_UP        = 2;        // reage rápido a cena pesada
static const uint8_t  HITS_DOWN      = 40;       // recupera devagar

// ---------- Utils ----------
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }
static uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 20000000;             // 20 MHz estável
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;
  cfg.jpeg_quality = quality;              // (menor = melhor)
  cfg.fb_count     = 1;                    // evita fragmentação
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);
    g_sensor->set_gain_ctrl(g_sensor, 1);
    g_sensor->set_whitebal(g_sensor, 1);
    g_sensor->set_awb_gain(g_sensor, 1);
    g_sensor->set_gainceiling(g_sensor, GAINCEILING_8X);
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

static void camera_reconfigure(framesize_t fs, int quality) {
  if (!g_sensor) return;
  g_sensor->set_framesize(g_sensor, fs);
  g_sensor->set_quality(g_sensor, quality);
  g_fs = fs;
  g_quality = quality;
  Serial.printf("CAM_CFG fs=%s q=%d\n", (fs==FRAMESIZE_QVGA?"QVGA":"QQVGA"), quality);
}

static inline bool is_big_frame(size_t len, uint32_t took_ms) {
  size_t lim = (g_fs==FRAMESIZE_QVGA) ? BIG_QVGA_BYTES : BIG_QQVGA_BYTES;
  return (len > lim) || (took_ms > SLOW_MS);
}

static void adapt_if_needed() {
  if (g_big_hits >= HITS_UP) {
    g_big_hits = 0; g_ok_hits = 0;
    if (g_quality < 22) { g_quality += 2; camera_reconfigure(g_fs, g_quality); }
    else if (g_fs != FRAMESIZE_QQVGA)     camera_reconfigure(FRAMESIZE_QQVGA, g_quality);
  } else if (g_ok_hits >= HITS_DOWN) {
    g_ok_hits = 0;
    if (g_fs == FRAMESIZE_QQVGA)          camera_reconfigure(FRAMESIZE_QVGA, g_quality);
    else if (g_quality > 14)              { g_quality -= 2; if (g_quality<14) g_quality=14; camera_reconfigure(g_fs, g_quality); }
  }
}

// ---------- Wi-Fi ----------
static void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) { delay(200); }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
    Serial.print("RSSI: "); Serial.println(WiFi.RSSI());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Handlers ----------
static void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot-buffer-fixo\","
             "\"hasFrame\":" + String((g_len>0 && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QVGA?"QVGA":"QQVGA") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

static void handle_snapshot(){
  sendCORS();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_buf && g_len>0);
  if(ok){
    server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
    server.sendHeader("Pragma","no-cache");
    server.sendHeader("Expires","0");
    server.setContentLength(g_len);
    server.send(200,"image/jpeg","");
    WiFiClient c = server.client();
    c.write(g_buf, g_len);
  } else {
    server.send(503,"text/plain","no frame\n");
  }
  xSemaphoreGive(g_lock);
}

static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
static void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

static void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

static void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- Captura contínua com buffer fixo ----------
static void cam_task(void*){
  const uint32_t MIN_INTERVAL_MS = 150;   // ~6–7 fps cap
  g_cap_tick = now_ms();
  while(true){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();
    uint32_t took = now_ms() - t0;

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= 6){
        Serial.println("CAM_REINIT");
        esp_camera_deinit();
        delay(120);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(10));
      continue;
    }
    g_fail_streak = 0;

    // Drop duro protege rádio/PSRAM
    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > HARD_DROP_BYTES) {
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      g_big_hits++; g_ok_hits = 0; adapt_if_needed();
      continue;
    }

    // Marca grande/leve p/ adaptação
    if (is_big_frame(fb->len, took)) { g_big_hits++; g_ok_hits = 0; }
    else { g_ok_hits++; if(g_big_hits) g_big_hits--; }
    adapt_if_needed();

    // Copia para buffer fixo (se couber)
    xSemaphoreTake(g_lock, portMAX_DELAY);
    if (fb->len <= g_cap) {
      memcpy(g_buf, fb->buf, fb->len);
      g_len = fb->len;
      g_ts_ms = now_ms();
    } else {
      // não cabe → conta como grande e não atualiza o frame
      g_big_hits++; g_ok_hits = 0;
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // cap de taxa
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(50);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  g_lock = xSemaphoreCreateMutex();

  // Buffer fixo: tenta 160KB, cai para 128KB se necessário
  g_cap = 160*1024;
  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  if(!g_buf){
    g_cap = 128*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }
  if(!g_buf){
    // último recurso: 96KB
    g_cap = 96*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }

  wifi_begin_dhcp();

  if(!camera_begin(FRAMESIZE_QVGA, 16)){
    delay(300);
    camera_begin(FRAMESIZE_QQVGA, 18);
  }

  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}




Como isso resolve o seu sintoma “apontou longe ⇒ trava”




JPEG grande/complexo agora:



é identificado na hora (pelo tamanho e/ou tempo de captura),


dispara queda de quality e até QQVGA rapidamente,


nunca realoca PSRAM por frame (buffer fixo),


descarta frames gigantes em vez de tentar servir/armazenar,


server/app reduzem a pressão (menos fps e sem “requisição dupla”).








Se algo ainda estourar (rede muito ruidosa), a task re-inicializa a câmera automaticamente e segue.


Se quiser, depois podemos expor no /status o last_big_reason (por tamanho/tempo) e um endpoint /config no ESP para travar em QQVGA em ambientes muito texturizados — mas, com os ajustes acima, a tendência é estabilizar sem precisar disso.


// ====== HydroBot – Driver, Modos (APP/AUTO) e Calibração Inteligente (versão limpa) ======
#include <Arduino.h>

// ---- ATIVE 0 PARA TESTAR SEM SERVO (evita conflitos de biblioteca) ----
#define HAVE_SERVO 0

#if HAVE_SERVO
  #include <Servo.h>
  Servo servoMangueira;
  #define SERVO_PIN     12
  #define SERVO_ESQ     45
  #define SERVO_CENTRO 100
  #define SERVO_DIR    135
#endif

// ---------------- PINOS ----------------
#define IN1 8
#define IN2 9
#define IN3 10
#define IN4 11
#define BOMBA_PIN 13
#define LED_VERMELHO 3

#define BOTAO 7
#define SENSOR_FOGO_ESQ_D 4
#define SENSOR_FOGO_MEIO_D 5
#define SENSOR_FOGO_DIR_D 6

#define SENSOR_FOGO_ESQ  A2
#define SENSOR_FOGO_MEIO A1
#define SENSOR_FOGO_DIR  A0
#define NIVEL_AGUA_PIN   A3

// ---------------- TIPOS/ESTADOS ----------------
typedef struct {
  bool digE, digM, digD;   // LOW = fogo nos digitais
  int  aE, aM, aD;         // analógicos crus
  int  dE, dM, dD;         // deltas (base - atual)
  bool fogo;               // há fogo?
  int  side;               // -1 esq, 0 meio, +1 dir (maior delta)
} FireSample;

enum Dir { DIR_STOP=0, DIR_FWD, DIR_BACK, DIR_LEFT, DIR_RIGHT };
enum AutoState { AUTO_IDLE=0, AUTO_ATTACK_FWD, AUTO_ATTACK_BACK, AUTO_PATROL };

// ---------------- PARÂMETROS ----------------
static uint8_t baseSpeed = 70;
static bool pumpOn = false;
static uint8_t modo = 0; // 0=APP, 1=AUTO

// movimento
static Dir currentDir = DIR_STOP;
static bool motionActive = false;
static unsigned long motionEndMs = 0;
static unsigned long lastMoveCmdAt = 0;

// botão
static bool ultimoEstadoBotao = HIGH;
static unsigned long lastDebounce = 0;

// calibração
static int baseEsq=0, baseMeio=0, baseDir=0;
static bool sistemaCalibrado = false;
#define TEMPO_CALIBRACAO_MS 3000
#define DIF_FOGO 150
#define SALTO_LUZ_RECALIB 200
#define PER_RECALIB_MS 30000
#define EMA_ALPHA_NUM 1
#define EMA_ALPHA_DEN 16

// auto
static AutoState autoState = AUTO_IDLE;
static unsigned long autoStateUntil = 0;
static unsigned long ultimaRecalibracao = 0;
static int patrolPhase = 0;

// água
static int nivelAguaPct = 0;

// ---------------- HARDWARE ----------------
void motorsStop(){ digitalWrite(IN1,LOW);digitalWrite(IN2,LOW);digitalWrite(IN3,LOW);digitalWrite(IN4,LOW); currentDir=DIR_STOP; }
void motorsFwd(){  digitalWrite(IN1,HIGH);digitalWrite(IN2,LOW);digitalWrite(IN3,HIGH);digitalWrite(IN4,LOW); currentDir=DIR_FWD; }
void motorsBack(){ digitalWrite(IN1,LOW);digitalWrite(IN2,HIGH);digitalWrite(IN3,LOW);digitalWrite(IN4,HIGH); currentDir=DIR_BACK; }
void motorsLeftTurn(){  digitalWrite(IN1,LOW);digitalWrite(IN2,HIGH);digitalWrite(IN3,HIGH);digitalWrite(IN4,LOW); currentDir=DIR_LEFT; }
void motorsRightTurn(){ digitalWrite(IN1,HIGH);digitalWrite(IN2,LOW);digitalWrite(IN3,LOW);digitalWrite(IN4,HIGH); currentDir=DIR_RIGHT; }

void applyDir(Dir d){
  switch(d){
    case DIR_FWD: motorsFwd(); break;
    case DIR_BACK: motorsBack(); break;
    case DIR_LEFT: motorsLeftTurn(); break;
    case DIR_RIGHT: motorsRightTurn(); break;
    default: motorsStop(); break;
  }
}

void setMotion(Dir d, uint16_t ms){
  if(ms==0 || d==DIR_STOP){ motorsStop(); motionActive=false; return; }
  applyDir(d);
  motionActive = true;
  motionEndMs = millis() + (unsigned long)ms;
  lastMoveCmdAt = millis();
}

void pumpWrite(bool on){ pumpOn=on; digitalWrite(BOMBA_PIN, on?HIGH:LOW); }

uint8_t waterPercent(){
  int raw = analogRead(NIVEL_AGUA_PIN);
  int pct = map(raw,0,1023,0,100);
  pct = constrain(pct,0,100);
  return (uint8_t)pct;
}

void ledLevelByWater(uint8_t pct){
  static unsigned long lastBlink=0; static bool st=false;
  if (pct>=50) { analogWrite(LED_VERMELHO,0); return; }
  if (pct>=25) { analogWrite(LED_VERMELHO,120); return; }
  if (pct>=15) { if (millis()-lastBlink>1000){ st=!st; analogWrite(LED_VERMELHO, st?200:0); lastBlink=millis(); } return; }
  if (millis()-lastBlink>300){ st=!st; analogWrite(LED_VERMELHO, st?255:0); lastBlink=millis(); }
}

void emitStatus(){
  int ax=analogRead(SENSOR_FOGO_ESQ), am=analogRead(SENSOR_FOGO_MEIO), ad=analogRead(SENSOR_FOGO_DIR);
  Serial.print(F("STAT:ax="));Serial.print(ax);
  Serial.print(F(":am="));Serial.print(am);
  Serial.print(F(":ad="));Serial.print(ad);
  Serial.print(F(":water="));Serial.print(nivelAguaPct);
  Serial.print(F(":pump="));Serial.print(pumpOn?1:0);
  Serial.print(F(":mode="));Serial.print(modo);
  Serial.print(F(":auto="));Serial.println((int)autoState);
}

// ---------------- APP (UART/HTTP) ----------------
static inline int _hex(char c){ if(c>='0'&&c<='9')return c-'0'; if(c>='A'&&c<='F')return 10+(c-'A'); if(c>='a'&&c<='f')return 10+(c-'a'); return -1; }
String urlDecode(const String&s){ String o; o.reserve(s.length()); for(size_t i=0;i<s.length();++i){ char c=s[i]; if(c=='+')o+=' '; else if(c=='%'&&i+2<s.length()){int h1=_hex(s[i+1]),h2=_hex(s[i+2]); if(h1>=0&&h2>=0){o+=char((h1<<4)|h2); i+=2;} else o+=c;} else o+=c;} return o; }
bool getQueryFloat(const String&path,const String&key,float&v){ int p=path.indexOf(key+"="); if(p<0)return false; int st=p+key.length()+1; int amp=path.indexOf('&',st); int sp=path.indexOf(' ',st); int en=(amp<0?sp:(sp<0?amp:min(amp,sp))); if(en<0)en=path.length(); String sub=path.substring(st,en); sub.trim(); v=sub.toFloat(); return true; }

void handleMoveCmd(const String&cmd){
  uint16_t ms=200; int pms=cmd.indexOf("ms="); if(pms>=0) ms=(uint16_t)cmd.substring(pms+3).toInt(); ms = constrain(ms,80,700);
  if      (cmd.indexOf("FWD")>=0)   setMotion(DIR_FWD,ms);
  else if (cmd.indexOf("BACK")>=0)  setMotion(DIR_BACK,ms);
  else if (cmd.indexOf("LEFT")>=0)  setMotion(DIR_LEFT,ms);
  else if (cmd.indexOf("RIGHT")>=0) setMotion(DIR_RIGHT,ms);
  else if (cmd.indexOf("STOP")>=0)  setMotion(DIR_STOP,0);
}

void handleCMDLine(const String&line){
  if (line.indexOf("CMD:PUMP:")>=0){ bool on=line.endsWith("1"); if(on && waterPercent()<=15){ pumpWrite(false); Serial.println(F("WARN:NO_WATER")); } else { pumpWrite(on); Serial.println(on?F("OK:PUMP_ON"):F("OK:PUMP_OFF")); } return; }
  if (line.indexOf("CMD:CALIB")>=0){ sistemaCalibrado=false; Serial.println(F("OK:CALIB_START")); return; }
  handleMoveCmd(line);
}

void handleHTTPLine(const String&lineIn){
  int s1=lineIn.indexOf(' '); if(s1<0)return; int s2=lineIn.indexOf(' ',s1+1); if(s2<0)return; String path=lineIn.substring(s1+1,s2);
  if (path.startsWith("/uart")){ int p=path.indexOf("line="); if(p>=0){ String enc=path.substring(p+5); int amp=enc.indexOf('&'); if(amp>=0)enc=enc.substring(0,amp); String dec=urlDecode(enc); dec.trim(); handleCMDLine(dec);} return; }
  if (path.startsWith("/pump")){ int p=path.indexOf("on="); if(p>=0){ char v=path.charAt(p+3); bool on=(v=='1'||v=='t'||v=='T'); if(on&&waterPercent()<=15){pumpWrite(false);Serial.println(F("WARN:NO_WATER"));} else {pumpWrite(on); Serial.println(on?F("OK:PUMP_ON"):F("OK:PUMP_OFF"));} } return; }
  if (path.startsWith("/joystick")){ float x=0,y=0; if(getQueryFloat(path,"x",x)|getQueryFloat(path,"y",y)){ float mag=sqrtf(x*x+y*y); if(mag<0.20f){ setMotion(DIR_STOP,0); return; } float deg=atan2f(y,x)*57.2957795f; Dir d; if(deg>-45&&deg<=45)d=DIR_RIGHT; else if(deg>45&&deg<=135)d=DIR_FWD; else if(deg<=-45&&deg>-135)d=DIR_BACK; else d=DIR_LEFT; uint16_t ms=120+(uint16_t)(min(1.0f,mag)*300.0f); setMotion(d,ms);} return; }
}

// ---------------- CALIBRAÇÃO ----------------
void calibInicial(){
  unsigned long t0=millis(); long sE=0,sM=0,sD=0; int n=0;
  while(millis()-t0<TEMPO_CALIBRACAO_MS){ sE+=analogRead(SENSOR_FOGO_ESQ); sM+=analogRead(SENSOR_FOGO_MEIO); sD+=analogRead(SENSOR_FOGO_DIR); n++; delay(50); }
  if(n==0)n=1; baseEsq=sE/n; baseMeio=sM/n; baseDir=sD/n; sistemaCalibrado=true;
  Serial.print(F("CALIB:E="));Serial.print(baseEsq);Serial.print(F(" M="));Serial.print(baseMeio);Serial.print(F(" D="));Serial.println(baseDir);
}

void emaBasesSemFogo(int aE,int aM,int aD){
  baseEsq  = ((EMA_ALPHA_DEN-EMA_ALPHA_NUM)*baseEsq  + EMA_ALPHA_NUM*aE)/EMA_ALPHA_DEN;
  baseMeio = ((EMA_ALPHA_DEN-EMA_ALPHA_NUM)*baseMeio + EMA_ALPHA_NUM*aM)/EMA_ALPHA_DEN;
  baseDir  = ((EMA_ALPHA_DEN-EMA_ALPHA_NUM)*baseDir  + EMA_ALPHA_NUM*aD)/EMA_ALPHA_DEN;
}

bool precisaRecalibrarPorLuz(int aE,int aM,int aD){
  return (abs(aE-baseEsq)>SALTO_LUZ_RECALIB)||(abs(aM-baseMeio)>SALTO_LUZ_RECALIB)||(abs(aD-baseDir)>SALTO_LUZ_RECALIB);
}

// ---------------- DETECÇÃO ----------------
FireSample lerFogo(){
  FireSample s;
  s.digE=(digitalRead(SENSOR_FOGO_ESQ_D)==LOW);
  s.digM=(digitalRead(SENSOR_FOGO_MEIO_D)==LOW);
  s.digD=(digitalRead(SENSOR_FOGO_DIR_D)==LOW);
  s.aE=analogRead(SENSOR_FOGO_ESQ);
  s.aM=analogRead(SENSOR_FOGO_MEIO);
  s.aD=analogRead(SENSOR_FOGO_DIR);
  s.dE=baseEsq - s.aE; s.dM=baseMeio - s.aM; s.dD=baseDir - s.aD;
  bool fogoAnal=(s.dE>DIF_FOGO)||(s.dM>DIF_FOGO)||(s.dD>DIF_FOGO);
  bool fogoDig =(s.digE||s.digM||s.digD);
  s.fogo = fogoAnal || fogoDig;
  int md=s.dM; s.side=0; if(s.dE>md){md=s.dE; s.side=-1;} if(s.dD>md){md=s.dD; s.side=+1;}
  return s;
}

// ---------------- AUTO ----------------
void autoAimBySide(int side){
#if HAVE_SERVO
  int tgt = (side<0?SERVO_DIR:(side>0?SERVO_ESQ:SERVO_CENTRO));
  servoMangueira.write(tgt);
#else
  (void)side;
#endif
}

void autoPatrolStep(){
  switch(patrolPhase%4){ case 0: setMotion(DIR_FWD,250); break; case 1: setMotion(DIR_LEFT,220); break; case 2: setMotion(DIR_FWD,250); break; case 3: setMotion(DIR_RIGHT,220); break; }
  patrolPhase++;
}

void autoLoop(){
  FireSample s = lerFogo();

  nivelAguaPct = waterPercent(); ledLevelByWater(nivelAguaPct);
  if(nivelAguaPct<10 && pumpOn) pumpWrite(false);

  if ((millis()-ultimaRecalibracao>PER_RECALIB_MS) || precisaRecalibrarPorLuz(s.aE,s.aM,s.aD)){
    Serial.println(F("AUTO:Recalibrando..."));
    calibInicial(); ultimaRecalibracao=millis(); return;
  }

  if (!s.fogo){
    if (pumpOn) pumpWrite(false);
#if HAVE_SERVO
    servoMangueira.write(SERVO_CENTRO);
#endif
    if ((long)(millis()-autoStateUntil)>=0){ autoState=AUTO_PATROL; autoStateUntil=millis()+400; autoPatrolStep(); }
    emaBasesSemFogo(s.aE,s.aM,s.aD);
    return;
  }

  autoAimBySide(s.side);
  if (nivelAguaPct>10) pumpWrite(true); else pumpWrite(false);

  if (autoState==AUTO_IDLE || autoState==AUTO_PATROL || (long)(millis()-autoStateUntil)>=0){
    static uint8_t forwardStrikes=0;
    if (autoState!=AUTO_ATTACK_BACK){
      autoState=AUTO_ATTACK_FWD; autoStateUntil=millis()+500;
      if (s.side<0) setMotion(DIR_LEFT,160);
      else if (s.side>0) setMotion(DIR_RIGHT,160);
      else setMotion(DIR_FWD,220);
      forwardStrikes++;
      if (forwardStrikes>=3){ autoState=AUTO_ATTACK_BACK; autoStateUntil=millis()+600; setMotion(DIR_BACK,280); forwardStrikes=0; }
    } else {
      autoState=AUTO_ATTACK_FWD; autoStateUntil=millis()+500; setMotion(DIR_FWD,220);
    }
  }
}

// ---------------- BOTÃO ----------------
void handleModeButton(){
  bool leitura=digitalRead(BOTAO);
  if (leitura!=ultimoEstadoBotao){ lastDebounce=millis(); ultimoEstadoBotao=leitura; }
  if ((millis()-lastDebounce)>35){
    static bool prev=HIGH;
    if (prev==HIGH && leitura==LOW){
      modo = (modo==0)?1:0;
      motorsStop(); pumpWrite(false);
#if HAVE_SERVO
      servoMangueira.write(SERVO_CENTRO);
#endif
      autoState=AUTO_IDLE;
      Serial.print(F("MODE:")); Serial.println(modo==0?F("APP"):F("AUTO"));
    }
    prev=leitura;
  }
}

// ---------------- MAIN ----------------
String line;

void setup(){
  Serial.begin(115200);
  pinMode(IN1,OUTPUT); pinMode(IN2,OUTPUT); pinMode(IN3,OUTPUT); pinMode(IN4,OUTPUT);
  pinMode(BOMBA_PIN,OUTPUT); pumpWrite(false);
  pinMode(LED_VERMELHO,OUTPUT);
  pinMode(BOTAO,INPUT_PULLUP);
  pinMode(SENSOR_FOGO_ESQ_D,INPUT); pinMode(SENSOR_FOGO_MEIO_D,INPUT); pinMode(SENSOR_FOGO_DIR_D,INPUT);
#if HAVE_SERVO
  servoMangueira.attach(SERVO_PIN);
  servoMangueira.write(SERVO_CENTRO);
#endif
  motorsStop();
  Serial.println(F("ARDUINO_READY"));
  calibInicial(); ultimaRecalibracao=millis();
}

void loop(){
  nivelAguaPct = waterPercent(); ledLevelByWater(nivelAguaPct);

  if (motionActive && (long)(millis()-motionEndMs)>=0){ motorsStop(); motionActive=false; }
  if ((millis()-lastMoveCmdAt)>1000 && currentDir!=DIR_STOP){ motorsStop(); motionActive=false; }

  handleModeButton();

  while(Serial.available()){
    char c=Serial.read();
    if(c=='\n'||c=='\r'){
      if(line.length()>0){
        String s=line; line=""; s.trim();
        if (s.startsWith("REQ:STATUS")){ emitStatus(); continue; }
        if (s.startsWith("SET:SPEED:")){ int v=s.substring(10).toInt(); baseSpeed=(uint8_t)constrain(v,0,100); Serial.println(F("OK:SPEED")); continue; }
        if (s.startsWith("SET:LED:"))  { int v=s.substring(8).toInt(); analogWrite(LED_VERMELHO,constrain(v,0,255)); Serial.println(F("OK:LED")); continue; }
        if (s.startsWith("CMD:CALIB")) { sistemaCalibrado=false; Serial.println(F("OK:CALIB_REQUEST")); continue; }

        if (modo==0){
          if (s.startsWith("CMD:")){ handleCMDLine(s); continue; }
          if (s.startsWith("GET ")){ handleHTTPLine(s); continue; }
          if (s.indexOf("PUMP=1")>=0 || s.indexOf("pump=1")>=0){ pumpWrite(true);  Serial.println(F("OK:PUMP_ON"));  continue; }
          if (s.indexOf("PUMP=0")>=0 || s.indexOf("pump=0")>=0){ pumpWrite(false); Serial.println(F("OK:PUMP_OFF")); continue; }
        } else {
          if (s.startsWith("GET ")) { if (s.indexOf("/pump?")>=0){ handleHTTPLine(s); continue; } }
        }

        Serial.println(F("ERR:UNKNOWN"));
      }
    } else {
      line += c; if(line.length()>240) line.remove(0);
    }
  }

  if (!sistemaCalibrado) { calibInicial(); }

  if (modo==1) { autoLoop(); }
}






































// ====== HydroBot – Driver, Modos (APP/AUTO) e Calibração Inteligente ======
// Modo 0 (APP): controla via UART/HTTP bridge (mesmos comandos anteriores).
// Modo 1 (AUTO): se detectar fogo, mira (servo opcional), anda pra frente e joga água;
//                se não apagar, recua jogando água e reavalia; patrulha quando sem fogo.
//
// ---------------- CONFIG GERAL ----------------
#include <Arduino.h>

// Ative(1)/Desative(0) o uso do SERVO para a mangueira
#define HAVE_SERVO 1
#if HAVE_SERVO
  #include <Servo.h>
  #define SERVO_PIN 12
  Servo servoMangueira;
  #define SERVO_ESQ     45
  #define SERVO_CENTRO 100
  #define SERVO_DIR    135
#endif

// ---------------- PINOS DE POTÊNCIA ----------------
#define IN1 8
#define IN2 9
#define IN3 10
#define IN4 11
#define BOMBA_PIN 13
#define LED_VERMELHO 3      // PWM (nível d’água)

// ---------------- SENSORES (DIGITAIS PERTO DO BOTÃO) ----------------
// Botão de modo (entre pino e GND)
#define BOTAO 7              // mantém o seu D7
// Digitais KY-026 (LOW = fogo)
#define SENSOR_FOGO_ESQ_D 4  // perto do botão
#define SENSOR_FOGO_MEIO_D 5 // perto do botão
#define SENSOR_FOGO_DIR_D 6  // perto do botão
// Analógicos (intensidade)
#define SENSOR_FOGO_ESQ A2
#define SENSOR_FOGO_MEIO A1
#define SENSOR_FOGO_DIR A0
// Nível de água
#define NIVEL_AGUA_PIN A3

// ---------------- ESTADO E PARÂMETROS ----------------
static uint8_t baseSpeed = 70;   // 0..100
static bool pumpOn = false;
static uint8_t modo = 0;         // 0=APP ; 1=AUTO
static bool ultimoEstadoBotao = HIGH;
static unsigned long lastDebounce = 0;

// Movimento não-bloqueante
enum Dir { DIR_STOP=0, DIR_FWD, DIR_BACK, DIR_LEFT, DIR_RIGHT };
static Dir currentDir = DIR_STOP;
static bool motionActive = false;
static unsigned long motionEndMs = 0;
static unsigned long lastMoveCmdAt = 0;

// Calibração & detecção
static int baseEsq=0, baseMeio=0, baseDir=0;
static bool sistemaCalibrado = false;
#define TEMPO_CALIBRACAO_MS 3000
#define DIF_FOGO 150                 // delta analógico acima da base => fogo
#define SALTO_LUZ_RECALIB 200        // mudança grande de luz => recalibração
#define PER_RECALIB_MS 30000         // checagem periódica de recalib
#define EMA_ALPHA_NUM 1              // EMA 1/16 para ajustar base sem fogo
#define EMA_ALPHA_DEN 16

// AUTO – máquina de estados
enum AutoState { AUTO_IDLE=0, AUTO_ATTACK_FWD, AUTO_ATTACK_BACK, AUTO_PATROL };
static AutoState autoState = AUTO_IDLE;
static unsigned long autoStateUntil = 0;
static unsigned long ultimaRecalibracao = 0;

// Patrulha
static int patrolPhase = 0;

// Água
static int nivelAguaPct = 0;

// ---------------- HELPERS HARDWARE ----------------
void motorsStop() {
  digitalWrite(IN1, LOW); digitalWrite(IN2, LOW);
  digitalWrite(IN3, LOW); digitalWrite(IN4, LOW);
  currentDir = DIR_STOP;
}
void motorsFwd() {
  digitalWrite(IN1, HIGH); digitalWrite(IN2, LOW);
  digitalWrite(IN3, HIGH); digitalWrite(IN4, LOW);
  currentDir = DIR_FWD;
}
void motorsBack() {
  digitalWrite(IN1, LOW); digitalWrite(IN2, HIGH);
  digitalWrite(IN3, LOW); digitalWrite(IN4, HIGH);
  currentDir = DIR_BACK;
}
void motorsLeftTurn() {
  digitalWrite(IN1, LOW);  digitalWrite(IN2, HIGH);
  digitalWrite(IN3, HIGH); digitalWrite(IN4, LOW);
  currentDir = DIR_LEFT;
}
void motorsRightTurn() {
  digitalWrite(IN1, HIGH); digitalWrite(IN2, LOW);
  digitalWrite(IN3, LOW);  digitalWrite(IN4, HIGH);
  currentDir = DIR_RIGHT;
}
void applyDir(Dir d) {
  switch (d) {
    case DIR_FWD:   motorsFwd(); break;
    case DIR_BACK:  motorsBack(); break;
    case DIR_LEFT:  motorsLeftTurn(); break;
    case DIR_RIGHT: motorsRightTurn(); break;
    default:        motorsStop(); break;
  }
}
void setMotion(Dir d, uint16_t ms) {
  if (ms == 0 || d == DIR_STOP) {
    motorsStop(); motionActive=false; return;
  }
  applyDir(d);
  motionActive  = true;
  motionEndMs   = millis() + (unsigned long)ms;
  lastMoveCmdAt = millis();
}

void pumpWrite(bool on) {
  pumpOn = on;
  digitalWrite(BOMBA_PIN, on ? HIGH : LOW);
}
uint8_t waterPercent() {
  int raw = analogRead(NIVEL_AGUA_PIN);
  int pct = map(raw, 0, 1023, 0, 100);
  pct = constrain(pct, 0, 100);
  return (uint8_t)pct;
}
void ledLevelByWater(uint8_t pct) {
  static unsigned long lastBlink=0; static bool state=false;
  if (pct >= 50) {
    analogWrite(LED_VERMELHO, 0);
  } else if (pct >= 25) {
    analogWrite(LED_VERMELHO, 120);
  } else if (pct >= 15) {
    if (millis()-lastBlink>1000) { state=!state; analogWrite(LED_VERMELHO, state?200:0); lastBlink=millis(); }
  } else {
    if (millis()-lastBlink>300) { state=!state; analogWrite(LED_VERMELHO, state?255:0); lastBlink=millis(); }
  }
}
void emitStatus() {
  int ax = analogRead(SENSOR_FOGO_ESQ);
  int am = analogRead(SENSOR_FOGO_MEIO);
  int ad = analogRead(SENSOR_FOGO_DIR);
  Serial.print(F("STAT:ax=")); Serial.print(ax);
  Serial.print(F(":am=")); Serial.print(am);
  Serial.print(F(":ad=")); Serial.print(ad);
  Serial.print(F(":water=")); Serial.print(nivelAguaPct);
  Serial.print(F(":pump=")); Serial.print(pumpOn?1:0);
  Serial.print(F(":mode=")); Serial.print(modo);
  Serial.print(F(":auto=")); Serial.println((int)autoState);
}

// ---------------- URL-DECODE / PARSE (para manter compatibilidade) ----------------
static inline int _hex(char c){
  if(c>='0'&&c<='9')return c-'0';
  if(c>='A'&&c<='F')return 10+(c-'A');
  if(c>='a'&&c<='f')return 10+(c-'a');
  return -1;
}
String urlDecode(const String &s){
  String out; out.reserve(s.length());
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') out+=' ';
    else if(c=='%'&&i+2<s.length()){
      int h1=_hex(s[i+1]),h2=_hex(s[i+2]);
      if(h1>=0&&h2>=0){ out+=char((h1<<4)|h2); i+=2; }
      else out+=c;
    } else out+=c;
  }
  return out;
}
bool getQueryFloat(const String &path,const String &key,float &valOut){
  int p=path.indexOf(key+"="); if(p<0) return false;
  int start=p+key.length()+1;
  int amp=path.indexOf('&',start);
  int sp =path.indexOf(' ',start);
  int end=(amp<0?sp:(sp<0?amp:min(amp,sp)));
  if(end<0) end=path.length();
  String sub=path.substring(start,end); sub.trim(); valOut=sub.toFloat(); return true;
}

// ---------------- PARSERS APP ----------------
void handleMoveCmd(const String &cmd) {
  uint16_t ms = 200; // pulso padrão
  int pms = cmd.indexOf("ms=");
  if (pms >= 0) ms = (uint16_t) cmd.substring(pms+3).toInt();
  ms = constrain(ms, 80, 700);

  if      (cmd.indexOf("FWD")   >= 0) setMotion(DIR_FWD,   ms);
  else if (cmd.indexOf("BACK")  >= 0) setMotion(DIR_BACK,  ms);
  else if (cmd.indexOf("LEFT")  >= 0) setMotion(DIR_LEFT,  ms);
  else if (cmd.indexOf("RIGHT") >= 0) setMotion(DIR_RIGHT, ms);
  else if (cmd.indexOf("STOP")  >= 0) setMotion(DIR_STOP,  0);
}
void handleCMDLine(const String &line) {
  if (line.indexOf("CMD:PUMP:") >= 0) {
    bool on = line.endsWith("1");
    if (on && waterPercent() <= 15) { pumpWrite(false); Serial.println(F("WARN:NO_WATER")); }
    else { pumpWrite(on); Serial.println(on?F("OK:PUMP_ON"):F("OK:PUMP_OFF")); }
    return;
  }
  if (line.indexOf("CMD:CALIB") >= 0) {
    sistemaCalibrado = false;
    Serial.println(F("OK:CALIB_START"));
    return;
  }
  handleMoveCmd(line);
}
void handleHTTPLine(const String &lineIn) {
  int sp1=lineIn.indexOf(' '); if(sp1<0) return;
  int sp2=lineIn.indexOf(' ',sp1+1); if(sp2<0) return;
  String path=lineIn.substring(sp1+1,sp2);
  if (path.startsWith("/uart")) {
    int p=path.indexOf("line=");
    if (p>=0) { String enc=path.substring(p+5); int amp=enc.indexOf('&'); if(amp>=0) enc=enc.substring(0,amp);
      String dec=urlDecode(enc); dec.trim(); handleCMDLine(dec); }
    return;
  }
  if (path.startsWith("/pump")) {
    int p=path.indexOf("on=");
    if (p>=0) {
      char v=path.charAt(p+3);
      bool on=(v=='1'||v=='t'||v=='T');
      if (on && waterPercent()<=15) { pumpWrite(false); Serial.println(F("WARN:NO_WATER")); }
      else { pumpWrite(on); Serial.println(on?F("OK:PUMP_ON"):F("OK:PUMP_OFF")); }
    }
    return;
  }
  if (path.startsWith("/joystick")) {
    float x=0,y=0;
    if (getQueryFloat(path,"x",x)|getQueryFloat(path,"y",y)) {
      float mag = sqrtf(x*x+y*y);
      if (mag<0.20f) { setMotion(DIR_STOP,0); return; }
      float deg = atan2f(y,x)*57.2957795f;
      Dir d;
      if (deg > -45 && deg <= 45) d = DIR_RIGHT;
      else if (deg > 45 && deg <=135) d = DIR_FWD;
      else if (deg <= -45 && deg > -135) d = DIR_BACK;
      else d = DIR_LEFT;
      uint16_t ms = 120 + (uint16_t)(min(1.0f, mag)*300.0f);
      setMotion(d, ms);
    }
    return;
  }
}

// ---------------- CALIBRAÇÃO ----------------
void calibInicial() {
  const unsigned long t0 = millis();
  long somaE=0, somaM=0, somaD=0; int n=0;
  while (millis()-t0 < TEMPO_CALIBRACAO_MS) {
    somaE += analogRead(SENSOR_FOGO_ESQ);
    somaM += analogRead(SENSOR_FOGO_MEIO);
    somaD += analogRead(SENSOR_FOGO_DIR);
    n++; delay(50);
  }
  if (n==0) n=1;
  baseEsq  = somaE / n;
  baseMeio = somaM / n;
  baseDir  = somaD / n;
  sistemaCalibrado = true;
  Serial.print(F("CALIB: E="));Serial.print(baseEsq);
  Serial.print(F(" M="));Serial.print(baseMeio);
  Serial.print(F(" D="));Serial.println(baseDir);
}
void emaBasesSemFogo(int aE,int aM,int aD) {
  // ajusta devagar as bases quando NÃO há fogo
  baseEsq  = ( (EMA_ALPHA_DEN-EMA_ALPHA_NUM)*baseEsq  + EMA_ALPHA_NUM*aE )/EMA_ALPHA_DEN;
  baseMeio = ( (EMA_ALPHA_DEN-EMA_ALPHA_NUM)*baseMeio + EMA_ALPHA_NUM*aM )/EMA_ALPHA_DEN;
  baseDir  = ( (EMA_ALPHA_DEN-EMA_ALPHA_NUM)*baseDir  + EMA_ALPHA_NUM*aD )/EMA_ALPHA_DEN;
}
bool precisaRecalibrarPorLuz(int aE,int aM,int aD){
  return (abs(aE-baseEsq) > SALTO_LUZ_RECALIB) ||
         (abs(aM-baseMeio)> SALTO_LUZ_RECALIB) ||
         (abs(aD-baseDir) > SALTO_LUZ_RECALIB);
}

// ---------------- DETECÇÃO DE FOGO ----------------
struct FireSample {
  bool digE, digM, digD; // LOW = fogo
  int aE, aM, aD;        // analógicos crus
  int dE, dM, dD;        // delta = base - atual (maior => mais fogo)
  bool fogo;
  int  side;             // -1 esq, 0 meio, +1 dir (maior delta)
};
FireSample lerFogo() {
  FireSample s;
  s.digE = (digitalRead(SENSOR_FOGO_ESQ_D) == LOW);
  s.digM = (digitalRead(SENSOR_FOGO_MEIO_D)== LOW);
  s.digD = (digitalRead(SENSOR_FOGO_DIR_D) == LOW);
  s.aE = analogRead(SENSOR_FOGO_ESQ);
  s.aM = analogRead(SENSOR_FOGO_MEIO);
  s.aD = analogRead(SENSOR_FOGO_DIR);
  s.dE = baseEsq  - s.aE;
  s.dM = baseMeio - s.aM;
  s.dD = baseDir  - s.aD;
  bool fogoAnal = (s.dE > DIF_FOGO) || (s.dM > DIF_FOGO) || (s.dD > DIF_FOGO);
  bool fogoDig  = (s.digE || s.digM || s.digD);
  s.fogo = fogoAnal || fogoDig; // robusto: aceita qualquer um
  // lado com maior evidência analógica
  int md = s.dM; s.side = 0;
  if (s.dE > md){ md=s.dE; s.side=-1; }
  if (s.dD > md){ md=s.dD; s.side=+1; }
  return s;
}

// ---------------- AUTO: AÇÃO INTELIGENTE ----------------
void autoAimBySide(int side){
#if HAVE_SERVO
  int tgt = (side<0? SERVO_DIR : (side>0? SERVO_ESQ : SERVO_CENTRO));
  servoMangueira.write(tgt);
#else
  (void)side;
#endif
}
void autoPatrolStep(){
  // Pequena patrulha cíclica para procurar fogo
  switch (patrolPhase%4) {
    case 0: setMotion(DIR_FWD, 250); break;
    case 1: setMotion(DIR_LEFT, 220); break;
    case 2: setMotion(DIR_FWD, 250); break;
    case 3: setMotion(DIR_RIGHT, 220); break;
  }
  patrolPhase++;
}
void autoLoop(){
  FireSample s = lerFogo();

  // Água/LED
  nivelAguaPct = waterPercent(); ledLevelByWater(nivelAguaPct);
  if (nivelAguaPct < 10 && pumpOn){ pumpWrite(false); }

  // Recalibração de luz
  if ((millis()-ultimaRecalibracao > PER_RECALIB_MS) || precisaRecalibrarPorLuz(s.aE,s.aM,s.aD)) {
    Serial.println(F("AUTO: Recalibrando por luz..."));
    calibInicial();
    ultimaRecalibracao = millis();
    return;
  }

  // Ajuste de base quando não há fogo
  if (!s.fogo) { emaBasesSemFogo(s.aE,s.aM,s.aD); }

  // Estado
  if (!s.fogo) {
    // Sem fogo
    if (pumpOn) { pumpWrite(false); }
#if HAVE_SERVO
    servoMangueira.write(SERVO_CENTRO);
#endif
    if ((long)(millis()-autoStateUntil) >= 0) {
      autoState = AUTO_PATROL;
      autoStateUntil = millis() + 400; // faz um passo de patrulha
      autoPatrolStep();
    }
    return;
  }

  // Com fogo detectado
  autoAimBySide(s.side);
  if (nivelAguaPct <= 10) {
    // Sem água -> não bombeia, só aproxima
    pumpWrite(false);
  } else {
    pumpWrite(true);
  }

  // Estratégia: primeiro avança curtos pulsos mirando no lado mais forte.
  if (autoState == AUTO_IDLE || autoState == AUTO_PATROL || (long)(millis()-autoStateUntil)>=0) {
    if (autoState != AUTO_ATTACK_BACK) {
      autoState = AUTO_ATTACK_FWD;
      autoStateUntil = millis() + 500; // janela do ciclo
      // Direção preferida: frente; se lado for muito lateral, corrige com giro curto
      if (s.side < 0) setMotion(DIR_LEFT, 160);
      else if (s.side > 0) setMotion(DIR_RIGHT, 160);
      else setMotion(DIR_FWD, 220);
    } else {
      // Voltou do BACK e ainda há fogo? repete frente
      autoState = AUTO_ATTACK_FWD;
      autoStateUntil = millis() + 500;
      setMotion(DIR_FWD, 220);
    }
    return;
  }

  // Se ficamos muito tempo atacando pra frente e ainda tem fogo, recua jogando água
  static uint8_t forwardStrikes=0;
  if (autoState == AUTO_ATTACK_FWD) {
    forwardStrikes++;
    if (forwardStrikes >= 3) {
      autoState = AUTO_ATTACK_BACK;
      autoStateUntil = millis() + 600;
      setMotion(DIR_BACK, 280); // recua para reposicionar/pulverizar
      forwardStrikes = 0;
    } else {
      // novo ataque à frente
      autoStateUntil = millis() + 500;
      setMotion(DIR_FWD, 220);
    }
    return;
  }

  if (autoState == AUTO_ATTACK_BACK && (long)(millis()-autoStateUntil)>=0) {
    // Terminou recuo, reavalia no próximo ciclo (fica em idle e volta para frente se ainda houver fogo)
    autoState = AUTO_IDLE;
  }
}

// ---------------- BOTÃO DE MODO ----------------
void handleModeButton(){
  bool leitura = digitalRead(BOTAO);
  if (leitura != ultimoEstadoBotao) {
    lastDebounce = millis();
    ultimoEstadoBotao = leitura;
  }
  if ((millis()-lastDebounce) > 35) {
    // press (queda de HIGH->LOW)
    static bool prev=HIGH;
    if (prev==HIGH && leitura==LOW) {
      modo = (modo==0)?1:0;
      motorsStop(); pumpWrite(false);
#if HAVE_SERVO
      servoMangueira.write(SERVO_CENTRO);
#endif
      autoState = AUTO_IDLE;
      Serial.print(F("MODE:")); Serial.println(modo==0?F("APP"):F("AUTO"));
    }
    prev = leitura;
  }
}

// ---------------- SETUP / LOOP ----------------
String line;
void setup(){
  Serial.begin(115200);

  pinMode(IN1,OUTPUT); pinMode(IN2,OUTPUT);
  pinMode(IN3,OUTPUT); pinMode(IN4,OUTPUT);
  pinMode(BOMBA_PIN,OUTPUT); pumpWrite(false);
  pinMode(LED_VERMELHO,OUTPUT);

  pinMode(BOTAO, INPUT_PULLUP);

  pinMode(SENSOR_FOGO_ESQ_D, INPUT);
  pinMode(SENSOR_FOGO_MEIO_D, INPUT);
  pinMode(SENSOR_FOGO_DIR_D, INPUT);

#if HAVE_SERVO
  servoMangueira.attach(SERVO_PIN);
  servoMangueira.write(SERVO_CENTRO);
#endif

  motorsStop();
  Serial.println(F("ARDUINO_READY"));

  // Calibração inicial
  calibInicial();
  ultimaRecalibracao = millis();
}

void loop(){
  // LED água e failsafe motores
  nivelAguaPct = waterPercent();
  ledLevelByWater(nivelAguaPct);

  if (motionActive && (long)(millis()-motionEndMs) >= 0) {
    motorsStop(); motionActive=false;
  }
  if ((millis()-lastMoveCmdAt) > 1000 && currentDir != DIR_STOP) {
    motorsStop(); motionActive=false;
  }

  // Botão de modo
  handleModeButton();

  // UART (modo APP sempre ativo; em AUTO a gente ignora comandos de movimento, mas aceita STATUS)
  while (Serial.available()){
    char c=Serial.read();
    if (c=='\n'||c=='\r'){
      if (line.length()>0){
        String s=line; line=""; s.trim();

        if (s.startsWith("REQ:STATUS")) { emitStatus(); continue; }
        if (s.startsWith("SET:SPEED:")) { int v=s.substring(10).toInt(); baseSpeed=(uint8_t)constrain(v,0,100); Serial.println(F("OK:SPEED")); continue; }
        if (s.startsWith("SET:LED:"))   { int v=s.substring(8).toInt(); analogWrite(LED_VERMELHO, constrain(v,0,255)); Serial.println(F("OK:LED")); continue; }
        if (s.startsWith("CMD:CALIB"))  { sistemaCalibrado=false; Serial.println(F("OK:CALIB_REQUEST")); continue; }

        // Em modo APP, aceita comandos de movimento/bomba
        if (modo==0) {
          if (s.startsWith("CMD:")) { handleCMDLine(s); continue; }
          if (s.startsWith("GET ")) { handleHTTPLine(s); continue; }
          if (s.indexOf("PUMP=1")>=0 || s.indexOf("pump=1")>=0) { pumpWrite(true);  Serial.println(F("OK:PUMP_ON"));  continue; }
          if (s.indexOf("PUMP=0")>=0 || s.indexOf("pump=0")>=0) { pumpWrite(false); Serial.println(F("OK:PUMP_OFF")); continue; }
        } else {
          // Em AUTO, ainda aceitamos /REQ:STATUS e /CMD:CALIB, ignorando movimento/bomba
          if (s.startsWith("GET ")) {
            // ainda permitimos /pump?on=... para DESLIGAR (segurança) se quiser
            if (s.indexOf("/pump?")>=0) { handleHTTPLine(s); continue; }
          }
        }

        Serial.println(F("ERR:UNKNOWN"));
      }
    } else {
      line += c;
      if (line.length()>240) line.remove(0);
    }
  }

  // Calibração solicitada via comando
  if (!sistemaCalibrado) { calibInicial(); }

  // Lógica dos modos
  if (modo==0) {
    // APP – nada adicional, já tratado nos handlers
  } else {
    autoLoop();
  }
}






































Vamos atacar o gargalo real: quando a câmera olha “longe” (muita textura/detalhe), os JPEGs ficam grandes, a captura demora mais, a PSRAM fragmenta e o Wi-Fi congestiona — isso faz travar/rebootar. Corrigi isso de 3 lados:






ESP32-CAM:




Buffer único pré-alocado em PSRAM (tamanho fixo) — sem malloc/free por frame.


Queda agressiva de resolução/qualidade quando um frame passa do limite, e recuperação gradual quando aliviar.


Drops “duros” seguros para frames imensos (protege rádio e PSRAM).


fb_count=1, GRAB_LATEST, WiFi sem sleep e reinit da câmera em streak de falhas.








Server (FastAPI):




/snapshot passa a entregar apenas o último frame em cache do grabber (sem refazer requisição direta ao ESP).


Grabber com FPS alvo menor (6–7) e backoff suave para redes mais lentas.








App (CameraScreen):




Poll de imagem ajustado (~5–6 fps) com backoff em falha.


Mantida a lógica de fallback (server → ESP direto) mas com menos pressão.








Abaixo os arquivos completos já ajustados.



1) server_heuristic.py (com cache único e /snapshot leve)


# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot (robusto)
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 10.0
POLL_FPS_TARGET = 6.0                              # ~6 fps para aliviar rede/ESP
MAX_FRAME_AGE_MS = 15000                           # relaxado p/ redes lentas
MAX_RESULT_AGE_MS = 800
REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.1",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}
ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.2")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEURÍSTICA FOGO =========
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.03); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.02); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # Agora SEM requisitar o ESP aqui: apenas entrega o último do grabber (reduz carga)
    b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if not b:
        b = placeholder_jpeg("NO LIVE FRAME")
    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}




2) CameraScreen.tsx (poll mais leve e fallback mantido)


import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando…", waiting:"Aguardando servidor…", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem vídeo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo • score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting…", waiting:"Waiting for server…", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire • score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando…", waiting:"Esperando servidor…", statusFail:"Error de conexión. Revisa Wi-Fi/IP.",
        noVideo:"Sin vídeo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego • score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type SrcBox = { x:number; y:number; w:number; h:number; type:"fire" };
function BoxesOverlay({ frameWH, containerWH, boxes }:{
  frameWH:{w:number;h:number}|null; containerWH:{w:number;h:number}|null; boxes:SrcBox[];
}) {
  const f = frameWH && frameWH.w>0 && frameWH.h>0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w<=0 || containerWH.h<=0) return null;
  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale, dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW)/2, offsetY = (containerWH.h - dispH)/2;
  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position:"absolute", left:offsetX, top:offsetY, width:dispW, height:dispH }}>
        {boxes.map((b,i)=>{
          const left=b.x*scale, top=b.y*scale, width=b.w*scale, height=b.h*scale;
          return (
            <View key={i} style={{ position:"absolute", left, top, width, height, borderWidth:3, borderColor:"#ff3b30", borderRadius:6 }}>
              <View style={{ position:"absolute", left:0, top:-18, paddingHorizontal:6, paddingVertical:2, borderRadius:4, backgroundColor:"#ff3b30" }}>
                <Text style={{ color:"#000", fontWeight:"800", fontSize:10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{w:number;h:number}|null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{w:number;h:number}|null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [useDirectSnapshot, setUseDirectSnapshot] = useState(false);
  const failCountRef = useRef(0);

  const [joy, setJoy] = useState({ x: 0, y: 0 });

  const clean = (s:string)=>s.replace(/\/+$/,"");

  // Server endpoints
  const healthUrl   = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl   = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const configUrl   = useMemo(()=>`${clean(server)}/config`,[server]);

  // ESP endpoints
  const pumpUrl     = useMemo(()=> (on:boolean)=>`http://${ip}/pump?on=${on?"1":"0"}`,[ip]);
  const joystickUrl = useMemo(()=> (x:number,y:number)=>`http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,[ip]);
  const uartUrl     = useMemo(()=> (line:string)=>`http://${ip}/uart?line=${encodeURIComponent(line)}`,[ip]);
  const snapshotEsp = useMemo(()=> `http://${ip}/snapshot`, [ip]);

  // Sincroniza IP no server
  useEffect(()=>{
    let aborted=false;
    (async()=>{
      try{
        const r=await fetch(configUrl,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_ip:ip})});
        const j=await r.json();
        if(!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      }catch{ if(!aborted) setStatusText(T.statusFail); }
    })();
    return()=>{aborted=true};
  },[ip, configUrl, T]);

  // Health
  useEffect(()=>{
    let stop=false, backoff=600;
    const poll=async()=>{
      if(stop) return;
      try{
        const r=await fetch(healthUrl); const j=await r.json();
        if(j?.ok){ setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`); setTimeout(poll, 1500); return; }
      }catch{}
      setStatusText(T.waiting);
      setTimeout(poll, backoff); backoff=Math.min(backoff*1.6, 5000);
    };
    poll(); return()=>{stop=true};
  },[healthUrl, T]);

  // SNAPSHOT loop (menos pressão)
  useEffect(()=>{
    let stop=false;
    let interval=190; // ~5.2 fps
    const pickBase = ()=> useDirectSnapshot ? snapshotEsp : snapshotSrv;

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=190;
      }catch{
        interval=Math.min(interval*1.7, 1400);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotEsp, useDirectSnapshot]);

  const onNextLoadStart = ()=>{ loadingNextRef.current=true; };
  const onNextShown = (ok:boolean)=>{
    if(ok){
      failCountRef.current = 0;
      if(useDirectSnapshot){ setUseDirectSnapshot(false); }
      if(nextFrameUri) setCurrentFrameUri(nextFrameUri);
    }else{
      failCountRef.current += 1;
      if(!useDirectSnapshot && failCountRef.current >= 3){
        setUseDirectSnapshot(true);
        failCountRef.current = 0;
      }
    }
    loadingNextRef.current=false;
  };

  // DETECT loop
  useEffect(()=>{
    let stop=false, interval=300;
    const loop=async()=>{
      if(stop) return;
      try{
        const r=await fetch(detectUrl); const j=await r.json();
        if(j && j.ok!==false){
          setIsFire(!!j.isFire); setFireScore(Number(j.score||0));
          const wh = Array.isArray(j.frame_wh)&&j.frame_wh.length===2
                     ? {w:Number(j.frame_wh[0])||0, h:Number(j.frame_wh[1])||0}:null;
          if(wh && wh.w>0 && wh.h>0) setFrameWH(wh);
          const boxes:SrcBox[]=[];
          if(j.isFire && Array.isArray(j.boxes)){
            for(const b of j.boxes){
              if(Array.isArray(b)&&b.length>=4){
                const [x,y,w,h]=b.map((n:any)=>Number(n)||0);
                boxes.push({x,y,w,h,type:"fire"});
              }
            }
          }
          setOverlayBoxes(boxes); interval=300;
        }
      }catch{
        setIsFire(false); setFireScore(0); setOverlayBoxes([]);
        interval=Math.min(interval*1.5,1500);
      }finally{ setTimeout(loop, interval); }
    };
    loop(); return()=>{stop=true};
  },[detectUrl]);

  // Joystick (mantido)
  const RADIUS=64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder:()=>true,
      onMoveShouldSetPanResponder:()=>true,
      onPanResponderMove:(_e:GestureResponderEvent,g:PanResponderGestureState)=>{
        let nx=g.dx/RADIUS, ny=g.dy/RADIUS;
        const len=Math.hypot(nx,ny); if(len>1){ nx/=len; ny/=len; }
        setJoy({x:nx, y:-ny});
      },
      onPanResponderRelease:()=>{ setJoy({x:0,y:0}); },
      onPanResponderTerminate:()=>{ setJoy({x:0,y:0}); },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef  = useRef<string>("STOP");
  const trySendJoystick = async (x:number,y:number)=>{ try{ await fetch(joystickUrl(x,y)); return true; }catch{ return false; } };
  const sendDiscreteCmd  = async (line:string)=>{ try{ await fetch(uartUrl(line)); return true; }catch{ return false; } };
  const vecToDir=(x:number,y:number):"FWD"|"BACK"|"LEFT"|"RIGHT"|"STOP"=>{
    const mag=Math.hypot(x,y); if(mag<0.2) return "STOP";
    const deg=(Math.atan2(y,x)*180)/Math.PI;
    if(deg>-45&&deg<=45) return "RIGHT";
    if(deg>45&&deg<=135) return "FWD";
    if(deg<=-45&&deg>-135) return "BACK";
    return "LEFT";
  };

  useEffect(()=>{
    let cancelled=false;
    const tick=async()=>{
      if(cancelled) return;
      const now=Date.now();
      if(now-lastSendRef.current<120){ setTimeout(tick,20); return; }
      lastSendRef.current=now;

      const {x,y}=joy; const mag=Math.hypot(x,y);
      const ok = await trySendJoystick(x,y);
      if(ok){
        if(mag<0.2 && lastDirRef.current!=="STOP"){ await sendDiscreteCmd("CMD:STOP"); lastDirRef.current="STOP"; }
        setTimeout(tick,120); return;
      }
      const dir=vecToDir(x,y);
      if(dir!==lastDirRef.current){
        const ms=140+Math.round(260*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd( dir==="STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}` );
        lastDirRef.current=dir;
      }else if(dir!=="STOP"){
        const ms=120+Math.round(200*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick,120);
    };
    tick(); return()=>{cancelled=true};
  },[joy, ip]);

  // Bomba
  async function togglePump(){
    try{ const t=!pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); }
    catch{ setStatusText(T.statusFail); }
  }

  function onVideoLayout(e:LayoutChangeEvent){
    const {width,height}=e.nativeEvent.layout; setVideoContainerWH({w:width,h:height});
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5"
                   autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput value={server} onChangeText={setServer}
                   placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
                   style={[styles.input,{minWidth:220}]} />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn?styles.btnOn:styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn?T.pumpOn:T.pumpOff}</Text>
        </Pressable>
      </View>

      <View style={[styles.statusRow,{paddingTop:4,paddingBottom:8}]}>
        <Text numberOfLines={2} style={styles.status}>{statusText} {useDirectSnapshot ? "• (snapshot direto)" : ""}</Text>
        <View style={[styles.badge,{backgroundColor:"#065f46"}]}>
          <Text style={{ color:"#fff", fontWeight:"800" }}>{isFire ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      <View style={[styles.fireBanner, isFire?styles.fireOn:styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      <View style={{ flex:1 }} onLayout={onVideoLayout}>
        <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri}
                        onNextLoadStart={()=> (loadingNextRef.current=true)}
                        onNextShown={onNextShown}/>
        {overlayBoxes.length>0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap,{width:64*2+24,height:64*2+24}]}
              {...pan.panHandlers}>
          <View style={[styles.joyBase,{width:64*2,height:64*2,borderRadius:64}]} />
          <View style={[styles.joyKnob,{width:22*2,height:22*2,borderRadius:22,
                        transform:[{translateX:joy.x*64},{translateY:-joy.y*64}], opacity: 0.9}]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container:{ flex:1, backgroundColor:PALETTE.bg },
  hero:{ alignItems:"center", paddingTop:12, paddingBottom:6 },
  heroLogo:{ width:80, height:80, marginBottom:6, resizeMode:"contain" },
  heroTitle:{ color:"#fff", fontSize:22, fontWeight:"800" },
  heroSubtitle:{ color:"#d1d5db", marginTop:2 },

  topbar:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:10, gap:8,
           backgroundColor:PALETTE.card, borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  label:{ color:"#cfd3d8", fontSize:12 },
  input:{ backgroundColor:"#0b0d14", color:"white", borderRadius:8, paddingHorizontal:10, paddingVertical:8,
          borderWidth:1, borderColor:PALETTE.border, minWidth:120 },
  btn:{ backgroundColor:PALETTE.accent, paddingHorizontal:10, paddingVertical:10, borderRadius:10 },
  btnOn:{ backgroundColor:"#17a34a" }, btnOff:{ backgroundColor:"#374151" },
  btnText:{ color:"white", fontWeight:"600" },

  statusRow:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:8, gap:8,
              backgroundColor:"#0f1322", borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  badge:{ paddingHorizontal:10, paddingVertical:6, borderRadius:8, borderWidth:1, borderColor:PALETTE.border },
  status:{ color:"#cbd5ff", flex:1, fontSize:12 },

  fireBanner:{ alignItems:"center", justifyContent:"center", paddingVertical:6 },
  fireOn:{ backgroundColor:"#8b0000" }, fireOff:{ backgroundColor:"#223" },
  fireText:{ color:"white", fontWeight:"800" },

  joyWrap:{ position:"absolute", bottom:24, left:24, alignItems:"center", justifyContent:"center" },
  joyBase:{ position:"absolute", backgroundColor:"rgba(255,255,255,0.08)", borderWidth:2, borderColor:"rgba(255,255,255,0.14)" },
  joyKnob:{ position:"absolute", backgroundColor:"rgba(230,64,58,0.9)", borderWidth:2, borderColor:"rgba(255,255,255,0.85)" },
  joyText:{ position:"absolute", bottom:-22, color:"#cbd5ff", fontSize:12 },
});




3) Firmware ESP32-CAM (AI Thinker) — buffer fixo + adaptação agressiva


/*  ESP32-CAM (AI Thinker) — Snapshot buffer fixo + Bridge HTTP<->UART
    Anti-trava ao olhar "longe":
      - Buffer PSRAM fixo (sem malloc/free por frame)
      - Queda agressiva de qualidade/resolução ao detectar frame grande/lento
      - Drop duro de frames > limite
      - fb_count=1, GRAB_LATEST, reinit em streak de falhas
    Endpoints:
      /status, /snapshot, /uart?line=, /pump?on=0|1, /joystick?x=&y=
    Rede: Wi-Fi STA DHCP + mDNS http://hydrobot-esp.local
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer fixo do último frame ----------
static uint8_t* g_buf = nullptr;
static size_t   g_cap = 0;       // capacidade
static size_t   g_len = 0;       // tamanho válido
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;
static uint32_t g_fail_streak = 0;

// ---------- Estado adaptativo ----------
static sensor_t* g_sensor = nullptr;
static framesize_t g_fs   = FRAMESIZE_QVGA;
static int g_quality      = 16;
static uint8_t g_big_hits = 0;
static uint8_t g_ok_hits  = 0;

// thresholds (afinados p/ estabilidade)
static const size_t HARD_DROP_BYTES  = 140*1024; // drop sempre acima disso
static const size_t BIG_QVGA_BYTES   = 60*1024;
static const size_t BIG_QQVGA_BYTES  = 26*1024;
static const uint32_t SLOW_MS        = 500;      // captura >500ms conta como "grande"
static const uint8_t  HITS_UP        = 2;        // reage rápido a cena pesada
static const uint8_t  HITS_DOWN      = 40;       // recupera devagar

// ---------- Utils ----------
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }
static uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 20000000;             // 20 MHz estável
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;
  cfg.jpeg_quality = quality;              // (menor = melhor)
  cfg.fb_count     = 1;                    // evita fragmentação
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);
    g_sensor->set_gain_ctrl(g_sensor, 1);
    g_sensor->set_whitebal(g_sensor, 1);
    g_sensor->set_awb_gain(g_sensor, 1);
    g_sensor->set_gainceiling(g_sensor, GAINCEILING_8X);
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

static void camera_reconfigure(framesize_t fs, int quality) {
  if (!g_sensor) return;
  g_sensor->set_framesize(g_sensor, fs);
  g_sensor->set_quality(g_sensor, quality);
  g_fs = fs;
  g_quality = quality;
  Serial.printf("CAM_CFG fs=%s q=%d\n", (fs==FRAMESIZE_QVGA?"QVGA":"QQVGA"), quality);
}

static inline bool is_big_frame(size_t len, uint32_t took_ms) {
  size_t lim = (g_fs==FRAMESIZE_QVGA) ? BIG_QVGA_BYTES : BIG_QQVGA_BYTES;
  return (len > lim) || (took_ms > SLOW_MS);
}

static void adapt_if_needed() {
  if (g_big_hits >= HITS_UP) {
    g_big_hits = 0; g_ok_hits = 0;
    if (g_quality < 22) { g_quality += 2; camera_reconfigure(g_fs, g_quality); }
    else if (g_fs != FRAMESIZE_QQVGA)     camera_reconfigure(FRAMESIZE_QQVGA, g_quality);
  } else if (g_ok_hits >= HITS_DOWN) {
    g_ok_hits = 0;
    if (g_fs == FRAMESIZE_QQVGA)          camera_reconfigure(FRAMESIZE_QVGA, g_quality);
    else if (g_quality > 14)              { g_quality -= 2; if (g_quality<14) g_quality=14; camera_reconfigure(g_fs, g_quality); }
  }
}

// ---------- Wi-Fi ----------
static void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) { delay(200); }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
    Serial.print("RSSI: "); Serial.println(WiFi.RSSI());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Handlers ----------
static void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot-buffer-fixo\","
             "\"hasFrame\":" + String((g_len>0 && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QVGA?"QVGA":"QQVGA") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

static void handle_snapshot(){
  sendCORS();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_buf && g_len>0);
  if(ok){
    server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
    server.sendHeader("Pragma","no-cache");
    server.sendHeader("Expires","0");
    server.setContentLength(g_len);
    server.send(200,"image/jpeg","");
    WiFiClient c = server.client();
    c.write(g_buf, g_len);
  } else {
    server.send(503,"text/plain","no frame\n");
  }
  xSemaphoreGive(g_lock);
}

static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
static void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

static void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

static void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- Captura contínua com buffer fixo ----------
static void cam_task(void*){
  const uint32_t MIN_INTERVAL_MS = 150;   // ~6–7 fps cap
  g_cap_tick = now_ms();
  while(true){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();
    uint32_t took = now_ms() - t0;

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= 6){
        Serial.println("CAM_REINIT");
        esp_camera_deinit();
        delay(120);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(10));
      continue;
    }
    g_fail_streak = 0;

    // Drop duro protege rádio/PSRAM
    if (fb->format != PIXFORMAT_JPEG || fb->len < 20 || fb->len > HARD_DROP_BYTES) {
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      g_big_hits++; g_ok_hits = 0; adapt_if_needed();
      continue;
    }

    // Marca grande/leve p/ adaptação
    if (is_big_frame(fb->len, took)) { g_big_hits++; g_ok_hits = 0; }
    else { g_ok_hits++; if(g_big_hits) g_big_hits--; }
    adapt_if_needed();

    // Copia para buffer fixo (se couber)
    xSemaphoreTake(g_lock, portMAX_DELAY);
    if (fb->len <= g_cap) {
      memcpy(g_buf, fb->buf, fb->len);
      g_len = fb->len;
      g_ts_ms = now_ms();
    } else {
      // não cabe → conta como grande e não atualiza o frame
      g_big_hits++; g_ok_hits = 0;
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // cap de taxa
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(50);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  g_lock = xSemaphoreCreateMutex();

  // Buffer fixo: tenta 160KB, cai para 128KB se necessário
  g_cap = 160*1024;
  g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  if(!g_buf){
    g_cap = 128*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }
  if(!g_buf){
    // último recurso: 96KB
    g_cap = 96*1024;
    g_buf = (uint8_t*) heap_caps_malloc(g_cap, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  }

  wifi_begin_dhcp();

  if(!camera_begin(FRAMESIZE_QVGA, 16)){
    delay(300);
    camera_begin(FRAMESIZE_QQVGA, 18);
  }

  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}




Como isso resolve o seu sintoma “apontou longe ⇒ trava”




JPEG grande/complexo agora:



é identificado na hora (pelo tamanho e/ou tempo de captura),


dispara queda de quality e até QQVGA rapidamente,


nunca realoca PSRAM por frame (buffer fixo),


descarta frames gigantes em vez de tentar servir/armazenar,


server/app reduzem a pressão (menos fps e sem “requisição dupla”).








Se algo ainda estourar (rede muito ruidosa), a task re-inicializa a câmera automaticamente e segue.


Se quiser, depois podemos expor no /status o last_big_reason (por tamanho/tempo) e um endpoint /config no ESP para travar em QQVGA em ambientes muito texturizados — mas, com os ajustes acima, a tendência é estabilizar sem precisar disso.







































# server_heuristic.py
# FastAPI proxy + heurística de fogo (leve) para ESP32-CAM snapshot
import time
import threading
from typing import Optional, Dict, Any, List, Tuple

import cv2
import numpy as np
import requests
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ========= CONFIG =========
CAMERA_IP = "192.168.3.3"                          # ESP32-CAM IP (roteador)
SNAPSHOT_URL_FMT = "http://{}/snapshot"
CONNECT_TIMEOUT = 4.0
READ_TIMEOUT = 15.0
POLL_FPS_TARGET = 8.0                              # ~8 fps estável
MAX_FRAME_AGE_MS = 15000                            # relaxado p/ redes lentas
MAX_RESULT_AGE_MS = 800
JPEG_QUALITY = 85

# Heurística simples de fogo
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
EMA_ALPHA = 0.25
HYST_HIGH = 0.18
HYST_LOW  = 0.15
MIN_BLOB_AREA = 900
KERNEL_SZ = 5

REQUEST_HEADERS = {
    "Connection": "keep-alive",
    "User-Agent": "HydroBot-Grabber/1.0",
    "Cache-Control": "no-cache",
    "Pragma": "no-cache",
}

ACCEPT_CT_PREFIX = ("image/jpeg", "image/jpg", "image/pjpeg", "application/octet-stream")

def is_jpeg_bytes(b: bytes) -> bool:
    return len(b) > 4 and b[0] == 0xFF and b[1] == 0xD8

# ========= FASTAPI =========
app = FastAPI(title="HydroBot Server (proxy + fire-heuristic)", version="2.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True,
                   allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ========= PLACEHOLDER =========
def placeholder_jpeg(msg: str = "NO LIVE FRAME") -> bytes:
    img = np.zeros((240, 320, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ========= SNAPSHOT GRABBER =========
class SnapshotGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._session = requests.Session()
        self._last_err: Optional[str] = None

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _ok_ct(self, ct: str) -> bool:
        if not ct:
            return True  # às vezes vem vazio; vamos inspecionar magic bytes
        ct = ct.lower()
        return any(ct.startswith(p) for p in ACCEPT_CT_PREFIX)

    def _fetch_once(self) -> Optional[bytes]:
        u = f"{SNAPSHOT_URL_FMT.format(self._ip)}?ts={int(time.time()*1000)}"
        r = self._session.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT),
                              headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = r.headers.get("Content-Type", "")
            b = r.content or b""
            if (self._ok_ct(ct) and b) or is_jpeg_bytes(b):
                return b
        return None

    def _run(self):
        min_interval = 1.0 / POLL_FPS_TARGET
        backoff = 0.0
        while not self._stop.is_set():
            t0 = time.time()
            try:
                jpeg = self._fetch_once()
                if jpeg:
                    with self._lock:
                        self._last_jpeg = jpeg
                        self._last_ts_ms = int(time.time()*1000)
                        self._last_err = None
                    self._frames += 1
                    now = time.time()
                    if now - self._last_fps_tick >= 1.0:
                        self._fps = self._frames / (now - self._last_fps_tick)
                        self._frames = 0
                        self._last_fps_tick = now
                    backoff = 0.0
                else:
                    backoff = min(2.0, max(0.2, (backoff * 1.7) or 0.2))
            except Exception as e:
                with self._lock:
                    self._last_err = f"{type(e).__name__}: {e}"
                backoff = min(3.0, max(0.2, (backoff * 1.7) or 0.2))

            elapsed = time.time() - t0
            sleep = max(0.0, min_interval - elapsed) + backoff
            if self._stop.is_set():
                break
            time.sleep(sleep)

    def get_latest_jpeg(self, max_age_ms=MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None:
                return None
            if int(time.time()*1000) - self._last_ts_ms > max_age_ms:
                return None
            return self._last_jpeg

    def status(self) -> Dict[str, Any]:
        with self._lock:
            age = int(time.time()*1000) - self._last_ts_ms if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age,
                    "fps_in": round(self._fps, 2), "last_err": self._last_err}

grabber = SnapshotGrabber()
grabber.start(CAMERA_IP)

# ========= HEURÍSTICA FOGO =========
def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    out = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area:
            out.append([int(x), int(y), int(w), int(h)])
    return out

class FireDetector:
    def __init__(self, src: SnapshotGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ema = 0.0
        self._score_raw = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._last_ts = 0
        self._fps = 0.0
        self._frames = 0
        self._last_fps_tick = time.time()
        self._frame_wh: Optional[Tuple[int,int]] = None

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / 8.0
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.02); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.01); continue
            H, W = frame.shape[:2]
            self._frame_wh = (W, H)

            mask = hsv_fire_mask(frame)
            v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
            ratio = float(np.count_nonzero(mask))/float(mask.size)
            score_raw = min(1.0, ratio*4.0 + v_mean*0.1)
            ema = score_raw if self._ema==0.0 else EMA_ALPHA*score_raw + (1.0-EMA_ALPHA)*self._ema

            boxes = boxes_from_mask(mask)

            if   ema >= HYST_HIGH: is_fire = True
            elif ema <= HYST_LOW : is_fire = False
            else: is_fire = self._is_fire

            with self._lock:
                self._ema = ema
                self._score_raw = score_raw
                self._is_fire = is_fire
                self._boxes = boxes if is_fire else []
                self._last_ts = int(time.time()*1000)
                self._frames += 1
                now = time.time()
                if now - self._last_fps_tick >= 1.0:
                    self._fps = self._frames / (now - self._last_fps_tick)
                    self._frames = 0
                    self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": bool(self._is_fire),
                "score": round(float(self._ema), 3),
                "score_raw": round(float(self._score_raw), 3),
                "score_ema": round(float(self._ema), 3),
                "boxes": list(self._boxes),
                "ts": int(self._last_ts),
                "fps_det": round(float(self._fps), 2),
                "frame_wh": list(self._frame_wh) if self._frame_wh else None
            }

det = FireDetector(grabber); det.start()

# ========= ENDPOINTS =========
@app.get("/healthz")
def healthz():
    s = grabber.status()
    return {"ok": True, "camera_ip": s.get("ip"), "fps_in": s.get("fps_in"),
            "hasFrame": s.get("hasFrame"), "age_ms": s.get("age_ms"), "last_err": s.get("last_err")}

@app.get("/status")
def status():
    s = grabber.status(); d = det.get()
    return {"ok": True, "camera_ip": s["ip"], **s, **d}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    # 1) tenta direto do ESP (melhor latência e evita placeholder)
    try:
        b = None
        u = f"{SNAPSHOT_URL_FMT.format(CAMERA_IP)}?ts={int(time.time()*1000)}"
        r = requests.get(u, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=REQUEST_HEADERS, stream=False)
        if r.status_code == 200:
            ct = (r.headers.get("Content-Type") or "").lower()
            b = r.content or b""
            if not (ct.startswith(ACCEPT_CT_PREFIX) or is_jpeg_bytes(b)):
                b = None
        if not b:
            b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
        if not b:
            b = placeholder_jpeg("NO LIVE FRAME")
    except Exception:
        b = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS) or placeholder_jpeg("NO LIVE FRAME")

    headers = {
        "Cache-Control": "no-store, no-cache, must-revalidate, max-age=0",
        "Pragma": "no-cache",
        "Expires": "0",
        "Content-Type": "image/jpeg"
    }
    return Response(content=b, headers=headers, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = det.get()
    if res.get("ts", 0) and (int(time.time()*1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg, np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    H, W = frame.shape[:2]
    mask = hsv_fire_mask(frame)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2])) / 255.0
    ratio = float(np.count_nonzero(mask))/float(mask.size)
    score = min(1.0, ratio*4.0 + v_mean*0.1)
    is_fire = bool(score >= HYST_HIGH)
    return {"ok": True, "isFire": is_fire, "score": round(score,3), "score_raw": round(score,3),
            "score_ema": round(score,3), "boxes": [], "ts": int(time.time()*1000), "frame_wh": [W,H], "fallback": True}














import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet,
  PanResponder, GestureResponderEvent, PanResponderGestureState,
  Image, Animated, LayoutChangeEvent,
} from "react-native";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg:"#0b0b0f", card:"#121218", border:"#25273a", accent:"#e6403a", text:"#e5e7eb" };

const textsByLang = {
  pt: { heroSubtitle:"Monitoramento e Controle", espIp:"ESP IP:", pumpOn:"BOMBA ON", pumpOff:"BOMBA OFF",
        server:"Servidor:", detecting:"Detectando…", waiting:"Aguardando servidor…", statusFail:"Falha ao conectar. Confira o Wi-Fi/IP.",
        noVideo:"Sem vídeo (snapshot). Verifique o servidor.", fireOn:(s:number)=>`🔥 FOGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sem fogo • score ${s.toFixed(2)}`, synced:"Server sincronizado",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  en: { heroSubtitle:"Monitoring & Control", espIp:"ESP IP:", pumpOn:"PUMP ON", pumpOff:"PUMP OFF",
        server:"Server:", detecting:"Detecting…", waiting:"Waiting for server…", statusFail:"Failed to connect. Check Wi-Fi/IP.",
        noVideo:"No video (snapshot). Check the server.", fireOn:(s:number)=>`🔥 FIRE • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`No fire • score ${s.toFixed(2)}`, synced:"Server sync OK",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
  es: { heroSubtitle:"Monitoreo y Control", espIp:"ESP IP:", pumpOn:"BOMBA ENC.", pumpOff:"BOMBA APAG.",
        server:"Servidor:", detecting:"Detectando…", waiting:"Esperando servidor…", statusFail:"Error de conexión. Revisa Wi-Fi/IP.",
        noVideo:"Sin vídeo (snapshot). Revisa el servidor.", fireOn:(s:number)=>`🔥 FUEGO • score ${s.toFixed(2)}`,
        fireOff:(s:number)=>`Sin fuego • score ${s.toFixed(2)}`, synced:"Sincronizado con servidor",
        placeholderIp:"192.168.3.3", placeholderServer:"http://192.168.3.4:8000" },
};

const DEFAULT_IP = "192.168.3.3";
const DEFAULT_SERVER = "http://192.168.3.4:8000";
const DEFAULT_FRAME_WH = { w: 320, h: 240 };

const appLogo = require("../../assets/logo.png");

function AppHero({ subtitle }: { subtitle: string }) {
  return (
    <View style={styles.hero}>
      <Image source={appLogo} style={styles.heroLogo} />
      <Text style={styles.heroTitle}>HydroBot</Text>
      <Text style={styles.heroSubtitle}>{subtitle}</Text>
    </View>
  );
}

function CrossfadeImage({
  currentUri, nextUri, onNextLoadStart, onNextShown,
}: { currentUri: string; nextUri: string; onNextLoadStart: () => void; onNextShown: (ok: boolean) => void; }) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image key={currentUri} source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}
      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            key={nextUri}
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(false); fade.setValue(0); setShowNext(false); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown(true); fade.setValue(0); setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

type SrcBox = { x:number; y:number; w:number; h:number; type:"fire" };
function BoxesOverlay({ frameWH, containerWH, boxes }:{
  frameWH:{w:number;h:number}|null; containerWH:{w:number;h:number}|null; boxes:SrcBox[];
}) {
  const f = frameWH && frameWH.w>0 && frameWH.h>0 ? frameWH : DEFAULT_FRAME_WH;
  if (!containerWH || containerWH.w<=0 || containerWH.h<=0) return null;
  const scale = Math.min(containerWH.w / f.w, containerWH.h / f.h);
  const dispW = f.w * scale, dispH = f.h * scale;
  const offsetX = (containerWH.w - dispW)/2, offsetY = (containerWH.h - dispH)/2;
  return (
    <View pointerEvents="none" style={StyleSheet.absoluteFill}>
      <View style={{ position:"absolute", left:offsetX, top:offsetY, width:dispW, height:dispH }}>
        {boxes.map((b,i)=>{
          const left=b.x*scale, top=b.y*scale, width=b.w*scale, height=b.h*scale;
          return (
            <View key={i} style={{ position:"absolute", left, top, width, height, borderWidth:3, borderColor:"#ff3b30", borderRadius:6 }}>
              <View style={{ position:"absolute", left:0, top:-18, paddingHorizontal:6, paddingVertical:2, borderRadius:4, backgroundColor:"#ff3b30" }}>
                <Text style={{ color:"#000", fontWeight:"800", fontSize:10 }}>FOGO</Text>
              </View>
            </View>
          );
        })}
      </View>
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  const [statusText, setStatusText] = useState(T.waiting);
  const [pumpOn, setPumpOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);
  const [overlayBoxes, setOverlayBoxes] = useState<SrcBox[]>([]);
  const [frameWH, setFrameWH] = useState<{w:number;h:number}|null>(null);
  const [videoContainerWH, setVideoContainerWH] = useState<{w:number;h:number}|null>(null);

  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  const [useDirectSnapshot, setUseDirectSnapshot] = useState(false);
  const failCountRef = useRef(0);

  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);
  const [ready, setReady] = useState(false);

  const clean = (s:string)=>s.replace(/\/+$/,"");

  // Server endpoints
  const healthUrl   = useMemo(()=>`${clean(server)}/healthz`,[server]);
  const detectUrl   = useMemo(()=>`${clean(server)}/detect`,[server]);
  const snapshotSrv = useMemo(()=>`${clean(server)}/snapshot`,[server]);
  const configUrl   = useMemo(()=>`${clean(server)}/config`,[server]);

  // ESP endpoints (controle e snapshot direto - fallback)
  const pumpUrl     = useMemo(()=> (on:boolean)=>`http://${ip}/pump?on=${on?"1":"0"}`,[ip]);
  const joystickUrl = useMemo(()=> (x:number,y:number)=>`http://${ip}/joystick?x=${x.toFixed(2)}&y=${y.toFixed(2)}`,[ip]);
  const uartUrl     = useMemo(()=> (line:string)=>`http://${ip}/uart?line=${encodeURIComponent(line)}`,[ip]);
  const snapshotEsp = useMemo(()=> `http://${ip}/snapshot`, [ip]);

  // Sincroniza IP da câmera no server
  useEffect(()=>{
    let aborted=false;
    (async()=>{
      try{
        const r=await fetch(configUrl,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_ip:ip})});
        const j=await r.json();
        if(!aborted && j?.ok) setStatusText(`${T.synced} (${j.camera_ip})`);
      }catch{ if(!aborted) setStatusText(T.statusFail); }
    })();
    return()=>{aborted=true};
  },[ip, configUrl, T]);

  // Health do servidor
  useEffect(()=>{
    let stop=false, backoff=500;
    const poll=async()=>{
      if(stop) return;
      try{
        const r=await fetch(healthUrl); const j=await r.json();
        if(j?.ok){ setReady(true); setStatusText(`Server OK • fps_in:${j.fps_in} • hasFrame:${j.hasFrame}`); return; }
      }catch{}
      setReady(false); setStatusText(T.waiting);
      setTimeout(poll, backoff); backoff=Math.min(backoff*1.6, 5000);
    };
    poll(); return()=>{stop=true};
  },[healthUrl, T]);

  // SNAPSHOT loop com fallback server->ESP
  useEffect(()=>{
    if(!ready) return;
    let stop=false, interval=140;
    const pickBase = ()=> useDirectSnapshot ? snapshotEsp : snapshotSrv;

    setCurrentFrameUri(`${pickBase()}?ts=${Date.now()}`);
    const tick=()=>{
      if(stop) return;
      try{
        if(!loadingNextRef.current){
          const base = pickBase();
          setNextFrameUri(`${base}?ts=${Date.now()}`);
        }
        interval=140;
      }catch{
        interval=Math.min(interval*1.7, 1200);
      }
      setTimeout(tick, interval);
    };
    tick();
    return()=>{stop=true};
  },[snapshotSrv, snapshotEsp, ready, useDirectSnapshot]);

  const onNextLoadStart = ()=>{ loadingNextRef.current=true; };
  const onNextShown = (ok:boolean)=>{
    if(ok){
      failCountRef.current = 0;
      if(useDirectSnapshot){ // tenta voltar ao servidor quando estabilizar
        setUseDirectSnapshot(false);
      }
      if(nextFrameUri) setCurrentFrameUri(nextFrameUri);
    }else{
      failCountRef.current += 1;
      // se falhar 3 vezes seguidas no servidor, troca para ESP direto
      if(!useDirectSnapshot && failCountRef.current >= 3){
        setUseDirectSnapshot(true);
        failCountRef.current = 0;
      }
    }
    loadingNextRef.current=false;
  };

  // DETECT loop
  useEffect(()=>{
    if(!ready) return;
    let stop=false, interval=250;
    const loop=async()=>{
      if(stop) return;
      try{
        const r=await fetch(detectUrl); const j=await r.json();
        if(j && j.ok!==false){
          setIsFire(!!j.isFire); setFireScore(Number(j.score||0));
          const wh = Array.isArray(j.frame_wh)&&j.frame_wh.length===2
                     ? {w:Number(j.frame_wh[0])||0, h:Number(j.frame_wh[1])||0}:null;
          if(wh && wh.w>0 && wh.h>0) setFrameWH(wh);
          const boxes:SrcBox[]=[];
          if(j.isFire && Array.isArray(j.boxes)){
            for(const b of j.boxes){
              if(Array.isArray(b)&&b.length>=4){
                const [x,y,w,h]=b.map((n:any)=>Number(n)||0);
                boxes.push({x,y,w,h,type:"fire"});
              }
            }
          }
          setOverlayBoxes(boxes); interval=250;
        }
      }catch{
        setIsFire(false); setFireScore(0); setOverlayBoxes([]);
        interval=Math.min(interval*1.5,1500);
      }finally{ setTimeout(loop, interval); }
    };
    loop(); return()=>{stop=true};
  },[detectUrl, ready]);

  // Joystick
  const RADIUS=64;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder:()=>true,
      onMoveShouldSetPanResponder:()=>true,
      onPanResponderGrant:()=>{},
      onPanResponderMove:(_e:GestureResponderEvent,g:PanResponderGestureState)=>{
        let nx=g.dx/RADIUS, ny=g.dy/RADIUS;
        const len=Math.hypot(nx,ny); if(len>1){ nx/=len; ny/=len; }
        setJoy({x:nx, y:-ny});
      },
      onPanResponderRelease:()=>{ setJoy({x:0,y:0}); },
      onPanResponderTerminate:()=>{ setJoy({x:0,y:0}); },
    })
  ).current;

  const lastSendRef = useRef(0);
  const lastDirRef  = useRef<string>("STOP");
  const trySendJoystick = async (x:number,y:number)=>{ try{ await fetch(joystickUrl(x,y)); return true; }catch{ return false; } };
  const sendDiscreteCmd  = async (line:string)=>{ try{ await fetch(uartUrl(line)); return true; }catch{ return false; } };
  const vecToDir=(x:number,y:number):"FWD"|"BACK"|"LEFT"|"RIGHT"|"STOP"=>{
    const mag=Math.hypot(x,y); if(mag<0.2) return "STOP";
    const deg=(Math.atan2(y,x)*180)/Math.PI;
    if(deg>-45&&deg<=45) return "RIGHT";
    if(deg>45&&deg<=135) return "FWD";
    if(deg<=-45&&deg>-135) return "BACK";
    return "LEFT";
  };

  useEffect(()=>{
    let cancelled=false;
    const tick=async()=>{
      if(cancelled) return;
      const now=Date.now();
      if(now-lastSendRef.current<120){ setTimeout(tick,20); return; }
      lastSendRef.current=now;

      const {x,y}=joy; const mag=Math.hypot(x,y);
      const ok = await trySendJoystick(x,y);
      if(ok){
        if(mag<0.2 && lastDirRef.current!=="STOP"){ await sendDiscreteCmd("CMD:STOP"); lastDirRef.current="STOP"; }
        setTimeout(tick,120); return;
      }
      const dir=vecToDir(x,y);
      if(dir!==lastDirRef.current){
        const ms=140+Math.round(260*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd( dir==="STOP" ? "CMD:STOP" : `CMD:${dir}:ms=${ms}:spd=${spd}` );
        lastDirRef.current=dir;
      }else if(dir!=="STOP"){
        const ms=120+Math.round(200*Math.min(1,mag));
        const spd=50+Math.round(50*Math.min(1,mag));
        await sendDiscreteCmd(`CMD:${dir}:ms=${ms}:spd=${spd}`);
      }
      setTimeout(tick,120);
    };
    tick(); return()=>{cancelled=true};
  },[joy, ip]);

  // Bomba
  async function togglePump(){
    try{
      const t=!pumpOn; await fetch(pumpUrl(t)); setPumpOn(t);
    }catch{ setStatusText(T.statusFail); }
  }

  function onVideoLayout(e:LayoutChangeEvent){
    const {width,height}=e.nativeEvent.layout; setVideoContainerWH({w:width,h:height});
  }

  return (
    <View style={styles.container}>
      <AppHero subtitle={T.heroSubtitle} />
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput value={ip} onChangeText={setIp} placeholder={T.placeholderIp} placeholderTextColor="#8a93a5"
                   autoCapitalize="none" autoCorrect={false} style={styles.input} keyboardType="numeric" />
        <Text style={styles.label}>{T.server}</Text>
        <TextInput value={server} onChangeText={(s)=>{ setServer(s); setReady(false); setStatusText(T.waiting); }}
                   placeholder={T.placeholderServer} placeholderTextColor="#8a93a5" autoCapitalize="none" autoCorrect={false}
                   style={[styles.input,{minWidth:220}]} />
        <Pressable onPress={togglePump} style={[styles.btn, pumpOn?styles.btnOn:styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn?T.pumpOn:T.pumpOff}</Text>
        </Pressable>
      </View>

      <View style={[styles.statusRow,{paddingTop:4,paddingBottom:8}]}>
        <Text numberOfLines={2} style={styles.status}>{statusText} {useDirectSnapshot ? "• (snapshot direto)" : ""}</Text>
        <View style={[styles.badge,{backgroundColor: ready ? "#065f46" : "#1f2937"}]}>
          <Text style={{ color:"#fff", fontWeight:"800" }}>{ready ? T.detecting : T.waiting}</Text>
        </View>
      </View>

      <View style={[styles.fireBanner, isFire?styles.fireOn:styles.fireOff]}>
        <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
      </View>

      <View style={{ flex:1 }} onLayout={onVideoLayout}>
        <CrossfadeImage currentUri={currentFrameUri} nextUri={nextFrameUri}
                        onNextLoadStart={()=> (loadingNextRef.current=true)}
                        onNextShown={onNextShown}/>
        {overlayBoxes.length>0 && (
          <BoxesOverlay frameWH={frameWH} containerWH={videoContainerWH} boxes={overlayBoxes} />
        )}
      </View>

      {/* Joystick */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap,{width:64*2+24,height:64*2+24}]}
              {...pan.panHandlers}>
          <View style={[styles.joyBase,{width:64*2,height:64*2,borderRadius:64}]} />
          <View style={[styles.joyKnob,{width:22*2,height:22*2,borderRadius:22,
                        transform:[{translateX:joy.x*64},{translateY:-joy.y*64}], opacity: dragging?1:0.9}]} />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container:{ flex:1, backgroundColor:PALETTE.bg },
  hero:{ alignItems:"center", paddingTop:12, paddingBottom:6 },
  heroLogo:{ width:80, height:80, marginBottom:6, resizeMode:"contain" },
  heroTitle:{ color:"#fff", fontSize:22, fontWeight:"800" },
  heroSubtitle:{ color:"#d1d5db", marginTop:2 },

  topbar:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:10, gap:8,
           backgroundColor:PALETTE.card, borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  label:{ color:"#cfd3d8", fontSize:12 },
  input:{ backgroundColor:"#0b0d14", color:"white", borderRadius:8, paddingHorizontal:10, paddingVertical:8,
          borderWidth:1, borderColor:PALETTE.border, minWidth:120 },
  btn:{ backgroundColor:PALETTE.accent, paddingHorizontal:10, paddingVertical:10, borderRadius:10 },
  btnOn:{ backgroundColor:"#17a34a" }, btnOff:{ backgroundColor:"#374151" },
  btnText:{ color:"white", fontWeight:"600" },

  statusRow:{ flexDirection:"row", alignItems:"center", paddingHorizontal:12, paddingVertical:8, gap:8,
              backgroundColor:"#0f1322", borderBottomWidth:StyleSheet.hairlineWidth, borderBottomColor:PALETTE.border },
  badge:{ paddingHorizontal:10, paddingVertical:6, borderRadius:8, borderWidth:1, borderColor:PALETTE.border },
  status:{ color:"#cbd5ff", flex:1, fontSize:12 },

  fireBanner:{ alignItems:"center", justifyContent:"center", paddingVertical:6 },
  fireOn:{ backgroundColor:"#8b0000" }, fireOff:{ backgroundColor:"#223" },
  fireText:{ color:"white", fontWeight:"800" },

  joyWrap:{ position:"absolute", bottom:24, left:24, alignItems:"center", justifyContent:"center" },
  joyBase:{ position:"absolute", backgroundColor:"rgba(255,255,255,0.08)", borderWidth:2, borderColor:"rgba(255,255,255,0.14)" },
  joyKnob:{ position:"absolute", backgroundColor:"rgba(230,64,58,0.9)", borderWidth:2, borderColor:"rgba(255,255,255,0.85)" },
  joyText:{ position:"absolute", bottom:-22, color:"#cbd5ff", fontSize:12 },
});







/*  ESP32-CAM (AI Thinker) — Snapshot buffer + Bridge HTTP<->UART
    Modo estável com ADAPTATIVO:
      - Começa em QVGA, quality=16, fb_count=1
      - Se frames grandes/lerdos se repetirem, sobe quality (18, 20) e pode cair p/ QQVGA
      - Quando aliviar, volta para QVGA/quality menores
      - Dropa frames MUITO grandes para não matar PSRAM
    Endpoints:
      /status, /snapshot, /uart?line=, /pump?on=0|1, /joystick?x=&y=
    Rede: Wi-Fi DHCP + mDNS http://hydrobot-esp.local
*/

#include <WiFi.h>
#include <WebServer.h>
#include <ESPmDNS.h>
#include "esp_camera.h"
#include "soc/rtc_cntl_reg.h"
#include "esp_timer.h"
#include "freertos/FreeRTOS.h"
#include "freertos/semphr.h"

// ---------- Wi-Fi ----------
const char* WIFI_SSID  = "HydroBot";
const char* WIFI_PASS  = "loud2025emibr";
const char* MDNS_NAME  = "hydrobot-esp";

// ---------- Web ----------
WebServer server(80);

// ---------- Pinos câmera (AI Thinker) ----------
#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

// ---------- Buffer do último frame ----------
static uint8_t* g_jpeg = nullptr;
static size_t   g_jlen = 0;
static volatile uint32_t g_ts_ms = 0;
static SemaphoreHandle_t g_lock;

static float g_cap_fps = 0.f;
static uint32_t g_cap_frames = 0;
static uint32_t g_cap_tick = 0;

static uint32_t g_fail_streak = 0;

// ---------- Estado adaptativo ----------
static sensor_t* g_sensor = nullptr;
static framesize_t g_fs   = FRAMESIZE_QVGA; // atual
static int g_quality      = 16;             // atual (10 melhor, 63 pior)
static uint8_t g_big_hits = 0;              // contador de frames "grandes"
static uint8_t g_ok_hits  = 0;              // contador de frames "leves"

// thresholds (ajuste fino)
static const size_t BIG_BYTES_QVGA   = 60*1024;   // QVGA > ~60KB = grande
static const size_t BIG_BYTES_QQVGA  = 26*1024;   // QQVGA > ~26KB = grande
static const size_t HARD_DROP_BYTES  = 120*1024;  // sempre dropar acima disso
static const uint32_t SLOW_MS        = 600;       // captura que passou de 600ms conta como "grande"
static const uint8_t  HITS_UP        = 3;         // 3 grandes seguidos -> subir compressão / reduzir res
static const uint8_t  HITS_DOWN      = 30;        // 30 leves seguidos -> baixar compressão / subir res

// ---------- Utils ----------
static String urlDecode(const String &s) {
  String o; o.reserve(s.length());
  auto hx=[](char c)->int{
    if(c>='0'&&c<='9')return c-'0';
    if(c>='A'&&c<='F')return 10+(c-'A');
    if(c>='a'&&c<='f')return 10+(c-'a');
    return -1;
  };
  for(size_t i=0;i<s.length();++i){
    char c=s[i];
    if(c=='+') o+=' ';
    else if(c=='%' && i+2<s.length()){
      int h1=hx(s[i+1]), h2=hx(s[i+2]);
      if(h1>=0 && h2>=0){ o+=(char)((h1<<4)|h2); i+=2; }
      else o+=c;
    } else o+=c;
  }
  return o;
}
static void sendCORS(){
  server.sendHeader("Access-Control-Allow-Origin","*");
  server.sendHeader("Access-Control-Allow-Methods","GET,POST,OPTIONS");
  server.sendHeader("Access-Control-Allow-Headers","Content-Type");
}
void handle_options(){ sendCORS(); server.send(204); }
static uint32_t now_ms(){ return (uint32_t)(esp_timer_get_time()/1000ULL); }

// ---------- Câmera ----------
static bool camera_begin(framesize_t fs, int quality) {
  camera_config_t cfg{};
  cfg.ledc_channel=LEDC_CHANNEL_0; cfg.ledc_timer=LEDC_TIMER_0;
  cfg.pin_d0=Y2_GPIO_NUM; cfg.pin_d1=Y3_GPIO_NUM; cfg.pin_d2=Y4_GPIO_NUM; cfg.pin_d3=Y5_GPIO_NUM;
  cfg.pin_d4=Y6_GPIO_NUM; cfg.pin_d5=Y7_GPIO_NUM; cfg.pin_d6=Y8_GPIO_NUM; cfg.pin_d7=Y9_GPIO_NUM;
  cfg.pin_xclk=XCLK_GPIO_NUM; cfg.pin_pclk=PCLK_GPIO_NUM; cfg.pin_vsync=VSYNC_GPIO_NUM; cfg.pin_href=HREF_GPIO_NUM;
  cfg.pin_sccb_sda=SIOD_GPIO_NUM; cfg.pin_sccb_scl=SIOC_GPIO_NUM; cfg.pin_pwdn=PWDN_GPIO_NUM; cfg.pin_reset=RESET_GPIO_NUM;

  cfg.xclk_freq_hz = 20000000;
  cfg.pixel_format = PIXFORMAT_JPEG;
  cfg.frame_size   = fs;               // QVGA ou QQVGA
  cfg.jpeg_quality = quality;          // 10..30 (menor = melhor)
  cfg.fb_count     = 1;                // 1 buffer => menos fragmentação PSRAM
  cfg.fb_location  = CAMERA_FB_IN_PSRAM;
  cfg.grab_mode    = CAMERA_GRAB_LATEST;

  esp_err_t err = esp_camera_init(&cfg);
  if (err != ESP_OK) { Serial.printf("CAMERA_INIT_ERR 0x%x\n", err); return false; }

  g_sensor = esp_camera_sensor_get();
  if (g_sensor && g_sensor->id.PID == OV3660_PID) {
    g_sensor->set_vflip(g_sensor, 1);
    g_sensor->set_brightness(g_sensor, 0);
    g_sensor->set_saturation(g_sensor, -1);
  }
  if (g_sensor) {
    g_sensor->set_framesize(g_sensor, fs);
    g_sensor->set_quality(g_sensor, quality);
    g_sensor->set_exposure_ctrl(g_sensor, 1);    // AE
    g_sensor->set_gain_ctrl(g_sensor, 1);        // AGC
    g_sensor->set_whitebal(g_sensor, 1);         // AWB
    g_sensor->set_awb_gain(g_sensor, 1);
    g_sensor->set_gainceiling(g_sensor, GAINCEILING_8X); // um pouco mais de folga
  }
  g_fs = fs;
  g_quality = quality;
  return true;
}

static void camera_reconfigure(framesize_t fs, int quality) {
  // troca leve sem reboot total (seguro)
  if (!g_sensor) return;
  g_sensor->set_framesize(g_sensor, fs);
  g_sensor->set_quality(g_sensor, quality);
  g_fs = fs;
  g_quality = quality;
  Serial.printf("CAM_CFG: fs=%s quality=%d\n",
                (fs==FRAMESIZE_QVGA?"QVGA":"QQVGA"), quality);
}

static void camera_free_buffer(){
  if(g_jpeg){ heap_caps_free(g_jpeg); g_jpeg=nullptr; g_jlen=0; }
}

// Decide se frame é "grande" demais para config atual
static bool is_big_frame(size_t len, uint32_t took_ms) {
  size_t lim = (g_fs==FRAMESIZE_QVGA) ? BIG_BYTES_QVGA : BIG_BYTES_QQVGA;
  return (len > lim) || (took_ms > SLOW_MS);
}

// Adaptação após N hits
static void adapt_if_needed() {
  if (g_big_hits >= HITS_UP) {
    g_big_hits = 0;
    g_ok_hits  = 0;
    if (g_quality < 22) {           // aumenta compressão primeiro
      g_quality += 2;               // 16 -> 18 -> 20 -> 22
      camera_reconfigure(g_fs, g_quality);
    } else if (g_fs != FRAMESIZE_QQVGA) {
      camera_reconfigure(FRAMESIZE_QQVGA, g_quality); // cai para QQVGA
    }
  } else if (g_ok_hits >= HITS_DOWN) {
    g_ok_hits = 0;
    if (g_fs == FRAMESIZE_QQVGA) {
      camera_reconfigure(FRAMESIZE_QVGA, g_quality);  // volta a QVGA
    } else if (g_quality > 14) {     // melhora compressão (imagem melhor)
      g_quality -= 2;                // 22 -> 20 -> 18 -> 16 -> 14
      if (g_quality < 14) g_quality = 14;
      camera_reconfigure(g_fs, g_quality);
    }
  }
}

// Task de captura contínua
void cam_task(void*){
  const uint32_t MIN_INTERVAL_MS = 140;   // ~7 fps cap
  g_cap_tick = now_ms();
  while(true){
    uint32_t t0 = now_ms();
    camera_fb_t* fb = esp_camera_fb_get();

    uint32_t took = now_ms() - t0;
    if (took > SLOW_MS) g_fail_streak++;

    if(!fb){
      g_fail_streak++;
      if(g_fail_streak >= 6){
        Serial.println("CAMERA_REINIT");
        esp_camera_deinit();
        delay(120);
        camera_begin(g_fs, g_quality);
        g_fail_streak = 0;
      }
      vTaskDelay(pdMS_TO_TICKS(10));
      continue;
    }
    g_fail_streak = 0;

    // DROP duro para proteger PSRAM/rádio
    if (fb->len > HARD_DROP_BYTES || fb->format != PIXFORMAT_JPEG || fb->len < 20) {
      esp_camera_fb_return(fb);
      vTaskDelay(pdMS_TO_TICKS(5));
      continue;
    }

    // Marcar grande/leve p/ adaptação
    if (is_big_frame(fb->len, took)) { g_big_hits++; g_ok_hits = 0; }
    else { g_ok_hits++; if(g_big_hits) g_big_hits--; }
    adapt_if_needed();

    // Copia para PSRAM própria (snapshot independente do fb)
    xSemaphoreTake(g_lock, portMAX_DELAY);
    camera_free_buffer();
    g_jlen = fb->len;
    g_jpeg = (uint8_t*) heap_caps_malloc(g_jlen, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
    if(g_jpeg){
      memcpy(g_jpeg, fb->buf, g_jlen);
      g_ts_ms = now_ms();
    } else {
      g_jlen = 0;
    }
    xSemaphoreGive(g_lock);

    esp_camera_fb_return(fb);

    // FPS calculado
    g_cap_frames++;
    uint32_t now = now_ms();
    if(now - g_cap_tick >= 1000){
      g_cap_fps = (float)g_cap_frames / ((now - g_cap_tick)/1000.f);
      g_cap_frames = 0;
      g_cap_tick = now;
    }

    // cap de taxa
    uint32_t elapsed = now_ms() - t0;
    if(elapsed < MIN_INTERVAL_MS) vTaskDelay(pdMS_TO_TICKS(MIN_INTERVAL_MS - elapsed));
  }
}

// ---------- Wi-Fi ----------
void wifi_begin_dhcp() {
  WiFi.mode(WIFI_STA);
  WiFi.setSleep(false);
  WiFi.begin(WIFI_SSID, WIFI_PASS);
  WiFi.setTxPower(WIFI_POWER_19_5dBm);   // potência máxima
  uint32_t t0 = now_ms();
  while (WiFi.status() != WL_CONNECTED && now_ms() - t0 < 20000) {
    delay(200);
  }
  if (WiFi.status() == WL_CONNECTED) {
    MDNS.begin(MDNS_NAME);
    MDNS.addService("http","tcp",80);
    Serial.println("WIFI_OK");
    Serial.print("IP: "); Serial.println(WiFi.localIP());
    Serial.print("RSSI: "); Serial.println(WiFi.RSSI());
  } else {
    Serial.println("WIFI_FAIL");
  }
}

// ---------- Handlers ----------
void handle_status(){
  sendCORS();
  uint32_t age = g_ts_ms ? (now_ms() - g_ts_ms) : (uint32_t) -1;
  String j = "{\"ok\":true,"
             "\"ip\":\""+WiFi.localIP().toString()+"\","
             "\"mode\":\"bridge+snapshot-buffer\","
             "\"hasFrame\":" + String((g_jpeg && age < 15000) ? "true":"false") + ","
             "\"age_ms\":" + String((int)age) + ","
             "\"fps_cap\":" + String(g_cap_fps,1) + ","
             "\"fs\":\"" + String(g_fs==FRAMESIZE_QVGA?"QVGA":"QQVGA") + "\","
             "\"quality\":" + String(g_quality) +
             "}";
  server.send(200,"application/json",j);
}

void handle_snapshot(){
  sendCORS();
  xSemaphoreTake(g_lock, portMAX_DELAY);
  bool ok = (g_jpeg && g_jlen>0);
  if(ok){
    server.sendHeader("Cache-Control","no-store, no-cache, must-revalidate, max-age=0");
    server.sendHeader("Pragma","no-cache");
    server.sendHeader("Expires","0");
    server.setContentLength(g_jlen);
    server.send(200,"image/jpeg","");
    WiFiClient c = server.client();
    c.write(g_jpeg, g_jlen);
  } else {
    server.send(503,"text/plain","no frame\n");
  }
  xSemaphoreGive(g_lock);
}

static String url_uart_arg(){ return server.hasArg("line") ? urlDecode(server.arg("line")) : String(); }
void handle_uart(){
  sendCORS();
  String line = url_uart_arg();
  if(line.length()==0){ server.send(400,"text/plain","missing 'line'\n"); return; }
  Serial.print(line); if(!line.endsWith("\n")) Serial.print("\n");
  server.send(200,"text/plain","OK\n");
}

void handle_pump(){
  sendCORS();
  bool on = server.hasArg("on") && (server.arg("on")=="1" || server.arg("on")=="true" || server.arg("on")=="TRUE");
  Serial.printf("CMD:PUMP:%d\n", on?1:0);
  server.send(200,"text/plain", on?"PUMP_ON\n":"PUMP_OFF\n");
}

void handle_joystick(){
  sendCORS();
  float x = server.hasArg("x") ? server.arg("x").toFloat() : 0.f;
  float y = server.hasArg("y") ? server.arg("y").toFloat() : 0.f;

  // Encaminha nota GET (compat)
  String raw = "GET /joystick?x="+String(x,3)+"&y="+String(y,3)+" HTTP/1.1";
  Serial.println(raw);

  // Comando discreto redundante
  float m = sqrtf(x*x+y*y);
  if(m<0.20f){ Serial.println("CMD:STOP"); }
  else{
    float deg = atan2f(y,x)*57.29578f;
    const char* dir="LEFT";
    if(deg>-45&&deg<=45) dir="RIGHT";
    else if(deg>45&&deg<=135) dir="FWD";
    else if(deg<=-45&&deg>-135) dir="BACK";
    uint16_t ms = 120 + (uint16_t)(min(1.0f,m)*260.0f);
    Serial.printf("CMD:%s:ms=%u:spd=70\n", dir, ms);
  }
  server.send(200,"text/plain","JOY\n");
}

// ---------- setup/loop ----------
void setup() {
  Serial.begin(115200);
  delay(50);
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); // desativa brownout

  g_lock = xSemaphoreCreateMutex();
  wifi_begin_dhcp();

  // Inicializa câmera
  if(!camera_begin(FRAMESIZE_QVGA, 16)){
    delay(300);
    camera_begin(FRAMESIZE_QQVGA, 18); // fallback duro se a primeira falhar
  }

  xTaskCreatePinnedToCore(cam_task, "cam_task", 4096, nullptr, 1, nullptr, 0);

  server.on("/status",    HTTP_GET,     handle_status);
  server.on("/snapshot",  HTTP_GET,     handle_snapshot);
  server.on("/uart",      HTTP_GET,     handle_uart);
  server.on("/pump",      HTTP_GET,     handle_pump);
  server.on("/joystick",  HTTP_GET,     handle_joystick);

  server.on("/",          HTTP_OPTIONS, handle_options);
  server.on("/snapshot",  HTTP_OPTIONS, handle_options);
  server.on("/uart",      HTTP_OPTIONS, handle_options);
  server.on("/pump",      HTTP_OPTIONS, handle_options);
  server.on("/joystick",  HTTP_OPTIONS, handle_options);

  server.onNotFound([](){ sendCORS(); server.send(404,"text/plain","NF\n"); });

  server.begin();
  Serial.println("HTTP_READY");
}

void loop() {
  server.handleClient();
  delay(1);
}
    
