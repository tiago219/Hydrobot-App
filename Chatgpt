
Perfeito ‚Äî o ‚Äúpisca‚Äù acontece porque alguns frames n√£o retornam nada e o app mostra 0 imediatamente. Resolvi isso no servidor, dando um ‚Äúvoto/hold‚Äù temporal nos objetos (como voc√™ j√° faz para o fogo): se aparecer pessoa/animal em alguns frames dentro de uma janela, o servidor mant√©m o estado por um curto per√≠odo (histerese + cooldown). O app praticamente n√£o precisa mudar.


Abaixo vai o server_heuristic.py completo (id√™ntico ao anterior para fogo e stream). A √∫nica diferen√ßa relevante est√° na classe ObjectsDetector, que agora:




mant√©m votos (janela deslizante) para pessoa e animais (VOTE_WIN_OBJ, VOTE_NEED_OBJ);


aplica hold de alguns ms ap√≥s a √∫ltima detec√ß√£o (HOLD_MS_OBJ) para n√£o piscar;


publica no JSON campos prontos para UI:



n_person_stable (0/1), n_animals_stable (0/1) ‚Äî estado suavizado


n_person e n_animals ‚Äî contagem bruta daquele frame


objects ‚Äî lista de caixas como antes









1) Substitua hydrobot-server/server_heuristic.py por este (COMPLETO)


# server_heuristic.py
# FOGO (heur√≠stico, inalterado) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny) com vota√ß√£o/hold anti-pisca
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0
JPEG_QUALITY = 85

# ===================== FOGO (seu, inalterado) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

# anti-pisca (vota√ß√£o/hold) ‚Äî ajuste fino aqui
VOTE_WIN_OBJ   = 10   # √∫ltimos N frames considerados
VOTE_NEED_OBJ  = 3    # precisa de pelo menos 3 "acertos" nessa janela
HOLD_MS_OBJ    = 900  # mant√©m ligado por 0.9s ap√≥s o √∫ltimo acerto

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}
MNET_IN_SIZE = (300,300); MNET_SCALE = 0.007843; MNET_MEAN = 127.5
MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# YOLOv4-tiny (COCO)
YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"
YOLO_IN_SZ = (416,416)

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (AutoBackend, Stable)", version="1.6.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip: self._ip = ip
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200: time.sleep(0.5); continue
                    buf = b""; MAX_BYTES = 4_000_000
                    self._frames = 0; self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VIS√ÉO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area: boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else: self._persist_hits = 1
            else: self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
            elif ema<=HYST_LOW: guess=0
            else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)

            self._det_frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval: time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {"ok":True,"isFire":self._is_fire,"score":round(self._score_ema,3),
                    "score_raw":round(self._score_raw,3),"score_ema":round(self._score_ema,3),
                    "boxes":self._boxes,"ts":self._last_result_ts,"fps_det":round(self._det_fps,2),
                    "vote":{"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                    "persist":{"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                    "hyst":{"hi":HYST_HIGH,"lo":HYST_LOW}}
detector = Detector(grabber); detector.start()

# ===================== OBJETOS (AutoBackend + votos/hold) =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        # estado backend
        self.backend = "mobilenet-ssd"   # ou "yolov4-tiny"
        self.net = None; self.ok = False
        self.proto = None; self.weights = None; self.cfg = None; self.names = None
        self.labels = []
        self.swap_rb = False  # usado s√≥ no MNet
        self._nohit = 0
        self._last_conf_max = 0.0

        # votos/hold
        self.votes_person = deque(maxlen=VOTE_WIN_OBJ)
        self.votes_animal = deque(maxlen=VOTE_WIN_OBJ)
        self.hold_person_until = 0
        self.hold_animal_until = 0

        # FPS/resultado
        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    # ---------- loaders ----------
    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
        self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok = False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok = False; self.net=None

    def _try_load_yolo(self):
        self.backend = "yolov4-tiny"
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    # ---------- thread ----------
    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,MNET_IN_SIZE),
                                     MNET_SCALE, MNET_IN_SIZE, MNET_MEAN, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in MNET_ANIMALS: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, YOLO_IN_SZ, swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            out=[]; cmax=0.0; backend=self.backend
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        # fallback swapRB se n√£o houver sinais por ~1s
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False
                    with self._lock:
                        self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                                    "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            # fallback para YOLO se MNet estiver ‚Äúmudo‚Äù
            if (backend=="mobilenet-ssd" and cmax<0.05 and
                os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
                self._try_load_yolo()
                backend=self.backend
                if self.ok and self.backend=="yolov4-tiny":
                    out,cmax = self._infer_yolo(frame, max(0.2, OBJ_CONF_THRESH))

            # ---- votos/hold (anti-pisca) ----
            n_person  = sum(1 for o in out if o["label"]=="person")
            n_animals = sum(1 for o in out if o["label"]!="person")
            hit_person  = 1 if n_person  > 0 else 0
            hit_animal  = 1 if n_animals > 0 else 0
            self.votes_person.append(hit_person)
            self.votes_animal.append(hit_animal)
            now_ms = int(time.time()*1000)
            if hit_person: self.hold_person_until = now_ms + HOLD_MS_OBJ
            if hit_animal: self.hold_animal_until = now_ms + HOLD_MS_OBJ
            stable_person = (sum(self.votes_person) >= VOTE_NEED_OBJ) or (now_ms < self.hold_person_until)
            stable_animal = (sum(self.votes_animal) >= VOTE_NEED_OBJ) or (now_ms < self.hold_animal_until)

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "proto":self.proto,"weights":self.weights,"cfg":YOLO_CFG if backend=="yolov4-tiny" else None,
                            "names":COCO_NAMES if backend=="yolov4-tiny" else None,
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb,
                            "n_person":n_person,"n_animals":n_animals,
                            "n_person_stable":1 if stable_person else 0,
                            "n_animals_stable":1 if stable_animal else 0}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status(); s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    # fallback r√°pido (fogo somente)
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get(); backend = o.get("backend"); det = objects_det
    try:
        if backend=="yolov4-tiny":
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, conf)))
        else:
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, conf)))
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get(); s = grabber.status()
    return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
            "proto":o.get("proto"), "weights":o.get("weights"),
            "cfg":o.get("cfg"), "names":o.get("names"),
            "swap_rb":o.get("swap_rb"), "conf_max":o.get("conf_max"),
            "conf_thresh":OBJ_CONF_THRESH, "fps_obj":o.get("fps_obj"),
            "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
            "n_person":o.get("n_person"), "n_animals":o.get("n_animals"),
            "n_person_stable":o.get("n_person_stable"), "n_animals_stable":o.get("n_animals_stable"),
            "num_objects":len(o.get("objects",[])), "error":o.get("error")}




2) (Opcional) Pequeno ajuste no app para usar os campos ‚Äúest√°veis‚Äù


Se sua CameraScreen.tsx hoje faz algo como:


const objs = j.objects?.objects || [];
const people = objs.filter(o => o.label === "person").length;
const animals = objs.filter(o => o.label !== "person").length;



troque por:


const objs = j.objects?.objects || [];
const people = j.objects?.n_person_stable ?? j.objects?.n_person ?? objs.filter(o => o.label === "person").length;
const animals = j.objects?.n_animals_stable ?? j.objects?.n_animals ?? objs.filter(o => o.label !== "person").length;



Assim, a UI j√° pega o sinal com histerese do servidor (sem piscar).



3) Como testar




Reinicie o servidor:

uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload





Abra http://SEU_PC:8000/objects e depois http://SEU_PC:8000/debug_models.

Veja n_person_stable / n_animals_stable mudando para 1 e ficando por ~1 segundo ap√≥s sair do quadro.


No app, tocar Detectar e observar que Pessoas / Animais n√£o ‚Äúpiscam‚Äù mais.




Se quiser ainda mais ‚Äúpegajoso‚Äù, aumente:




VOTE_WIN_OBJ para 12,


VOTE_NEED_OBJ para 4,


HOLD_MS_OBJ para 1200‚Äì1500.
































Aqui est√° o HydroBotApp2/src/screens/CameraScreen.tsx completo, j√° lendo os campos est√°veis do servidor (n_person_stable, n_animals_stable) e mostrando um preview opcional com caixas usando /objects_frame. N√£o mexe na detec√ß√£o ‚Äî s√≥ no visual/comunica√ß√£o.


// HydroBotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View,
  Text,
  TextInput,
  Pressable,
  StyleSheet,
  PanResponder,
  GestureResponderEvent,
  PanResponderGestureState,
  Image,
  Animated,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = {
  bg: "#000000",
  card: "#0d0d0d",
  border: "#1a1a1a",
  red: "#E53B2F",
  white: "#ffffff",
};

const textsByLang = {
  pt: {
    espIp: "ESP IP:",
    test: "Testar",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "BOMBA ON",
    pumpOff: "BOMBA OFF",
    server: "Servidor:",
    detect: "Detectar",
    detecting: "Detectando",
    saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi/IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s: number) => `üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento salvo em ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vis√£o:",
    stream: "STREAM (r√°pido)",
    snapshot: "SNAPSHOT (fallback)",
    persons: "Pessoas",
    animals: "Animais",
    boxes: "Caixas",
    backend: "Modelo",
  },
  en: {
    espIp: "ESP IP:",
    test: "Test",
    ledOn: "LED ON",
    ledOff: "LED OFF",
    pumpOn: "PUMP ON",
    pumpOff: "PUMP OFF",
    server: "Server:",
    detect: "Detect",
    detecting: "Detecting",
    saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s: number) => `üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `No fire ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Event saved at ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "View:",
    stream: "STREAM (fast)",
    snapshot: "SNAPSHOT (fallback)",
    persons: "People",
    animals: "Animals",
    boxes: "Boxes",
    backend: "Model",
  },
  es: {
    espIp: "ESP IP:",
    test: "Probar",
    ledOn: "LED ENC.",
    ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.",
    pumpOff: "BOMBA APAG.",
    server: "Servidor:",
    detect: "Detectar",
    detecting: "Detectando",
    saving: "Guardando...",
    statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s: number) => `üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`,
    fireOff: (s: number) => `Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts: string) => `Evento guardado a las ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vista:",
    stream: "STREAM (r√°pido)",
    snapshot: "SNAPSHOT (fallback)",
    persons: "Personas",
    animals: "Animales",
    boxes: "Cajas",
    backend: "Modelo",
  },
};

const DEFAULT_IP = "192.168.4.1";
const DEFAULT_SERVER = "http://192.168.4.2:8000";

/* --------------------------
   STREAM MJPEG (>=20 FPS)
---------------------------*/
function LiveMJPEG({ ip }: { ip: string }) {
  const html = `
    <html><head><meta name="viewport" content="width=device-width, initial-scale=1">
      <style>
        html,body{margin:0;padding:0;background:#000;height:100%;}
        .wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;background:#000;}
        img{max-width:100%;max-height:100%;object-fit:contain;background:#000;}
      </style>
    </head>
    <body>
      <div class="wrap"><img src="http://${ip}:81/stream" /></div>
    </body></html>
  `.trim();

  return (
    <WebView
      originWhitelist={["*"]}
      source={{ html }}
      javaScriptEnabled
      allowsInlineMediaPlayback
      mediaPlaybackRequiresUserAction={false}
      automaticallyAdjustContentInsets={false}
      style={{ flex: 1, backgroundColor: "black" }}
    />
  );
}

/* --------------------------
   SNAPSHOT com crossfade
---------------------------*/
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: () => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {!!currentUri && (
        <Image source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      )}

      {showNext && (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={onNextShown}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown();
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      )}
    </View>
  );
}

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conex√µes
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados do ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState("‚Äî");
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detec√ß√£o
  const [detectOn, setDetectOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);

  // pessoas/animais (usando campos est√°veis do servidor)
  const [people, setPeople] = useState(0);
  const [animals, setAnimals] = useState(0);
  const [backend, setBackend] = useState<string>("‚Äî");
  const [confMax, setConfMax] = useState<number>(0);

  // preview de caixas
  const [showBoxes, setShowBoxes] = useState(false);
  const [boxesUri, setBoxesUri] = useState("");

  // registro autom√°tico (aproveita seu fluxo)
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // vis√£o
  const [useStream, setUseStream] = useState(true);
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // helpers URL
  const cleanServer = (s: string) => s.replace(/\/+$/, "");
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl);
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(`OK ‚Ä¢ ip:${j.ip} ‚Ä¢ mode:${j.mode} ‚Ä¢ led:${j.led ? "on" : "off"} ‚Ä¢ pump:${j.pump ? "on" : "off"}`);
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() {
    try {
      const t = !ledOn;
      await fetch(ledUrl(t));
      setLedOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  async function togglePump() {
    try {
      const t = !pumpOn;
      await fetch(pumpUrl(t));
      setPumpOn(t);
    } catch {
      setStatusText(T.statusFail);
    }
  }
  useEffect(() => {
    pingStatus();
    const id = setInterval(pingStatus, 5000);
    return () => clearInterval(id);
  }, [statusUrl]);

  /* ===== V√≠deo SNAPSHOT fallback (25 fps alvo) ===== */
  useEffect(() => {
    if (useStream) return;
    let stop = false;
    const FPS_INTERVAL = 40; // ~25 fps

    setCurrentFrameUri(`${cleanServer(server)}/snapshot?ts=${Date.now()}`);

    const tick = () => {
      if (stop) return;
      if (!loadingNextRef.current) {
        const url = `${cleanServer(server)}/snapshot?ts=${Date.now()}`;
        setNextFrameUri(url);
      }
      setTimeout(tick, FPS_INTERVAL);
    };
    tick();

    return () => {
      stop = true;
    };
  }, [server, useStream]);

  function onNextLoadStart() {
    loadingNextRef.current = true;
  }
  function onNextShown() {
    if (nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== LOOP DE DETEC√á√ÉO ===== */
  useEffect(() => {
    if (!detectOn) return;
    let stop = false;

    const loop = async () => {
      try {
        const r = await fetch(`${cleanServer(server)}/detect`);
        const j = await r.json();

        if (!stop && j && j.ok !== false) {
          // fogo
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          // objetos (usar valores est√°veis quando existir)
          const o = j.objects || {};
          const objs = o.objects || [];
          const peopleStable =
            typeof o.n_person_stable === "number"
              ? o.n_person_stable
              : typeof o.n_person === "number"
              ? o.n_person
              : objs.filter((x: any) => x.label === "person").length > 0
              ? 1
              : 0;
          const animalsStable =
            typeof o.n_animals_stable === "number"
              ? o.n_animals_stable
              : typeof o.n_animals === "number"
              ? o.n_animals
              : objs.filter((x: any) => x.label !== "person").length > 0
              ? 1
              : 0;

          setPeople(peopleStable);
          setAnimals(animalsStable);
          setBackend(o.backend || "‚Äî");
          setConfMax(Number(o.conf_max || 0));

          // atualiza mini preview de caixas (se ligado)
          if (showBoxes) {
            setBoxesUri(`${cleanServer(server)}/objects_frame?conf=0.25&ts=${Date.now()}`);
          }
        }
      } catch {
        if (!stop) {
          setIsFire(false);
          setFireScore(0);
          setPeople(0);
          setAnimals(0);
        }
      } finally {
        if (!stop) setTimeout(loop, 180); // ~5-6Hz (leve)
      }
    };
    loop();

    return () => {
      stop = true;
    };
  }, [detectOn, server, showBoxes]);

  /* ===== Registro autom√°tico (igual ao seu fluxo) ===== */
  useEffect(() => {
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;

    if (detectOn && rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [detectOn, isFire, server, saving, T]);

  /* ===== Joystick ===== */
  const RADIUS = 64,
    KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS,
          ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny);
        if (len > 1) {
          nx /= len;
          ny /= len;
        }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
      onPanResponderTerminate: () => {
        setDragging(false);
        setJoy({ x: 0, y: 0 });
      },
    })
  ).current;

  const knobLeft = joy.x * RADIUS,
    knobTop = -joy.y * RADIUS;

  return (
    <View style={styles.container}>
      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor + Detectar + Seletor de vis√£o */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={setServer}
          placeholder={T.placeholderServer}
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Pressable onPress={() => setDetectOn((v) => !v)} style={[styles.btn, detectOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{detectOn ? (saving ? T.saving : T.detecting) : T.detect}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>
          {statusText}
        </Text>
      </View>

      {/* Seletor de vis√£o */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.view}</Text>
        <Pressable onPress={() => setUseStream(true)} style={[styles.btn, useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.stream}</Text>
        </Pressable>
        <Pressable onPress={() => setUseStream(false)} style={[styles.btn, !useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.snapshot}</Text>
        </Pressable>

        {/* toggle boxes */}
        <Pressable
          onPress={() => {
            const val = !showBoxes;
            setShowBoxes(val);
            if (val) setBoxesUri(`${cleanServer(server)}/objects_frame?conf=0.25&ts=${Date.now()}`);
          }}
          style={[styles.btn, showBoxes ? styles.btnOn : styles.btnOff]}
        >
          <Text style={styles.btnText}>{T.boxes}</Text>
        </Pressable>
      </View>

      {/* Banner de fogo */}
      {detectOn && (
        <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
          <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
        </View>
      )}

      {/* Banner de pessoas/animais + backend */}
      {detectOn && (
        <View style={[styles.statusRow, { justifyContent: "space-between" }]}>
          <Text style={styles.statChip}>
            {T.persons}: <Text style={styles.statNumber}>{people}</Text>
          </Text>
          <Text style={styles.statChip}>
            {T.animals}: <Text style={styles.statNumber}>{animals}</Text>
          </Text>
          <Text style={styles.modelChip}>
            {T.backend}: {backend} ‚Ä¢ conf_max {confMax.toFixed(2)}
          </Text>
        </View>
      )}

      {/* V√≠deo (stream r√°pido OU snapshot fallback) */}
      <View style={{ flex: 1 }}>
        {useStream ? (
          <LiveMJPEG ip={ip} />
        ) : (
          <CrossfadeImage
            currentUri={currentFrameUri}
            nextUri={nextFrameUri}
            onNextLoadStart={onNextLoadStart}
            onNextShown={onNextShown}
          />
        )}
      </View>

      {/* Mini preview com caixas (opcional) */}
      {detectOn && showBoxes && (
        <View style={{ height: 140, backgroundColor: "#000" }}>
          {!!boxesUri && (
            <Image
              source={{ uri: boxesUri }}
              style={{ flex: 1, width: "100%" }}
              resizeMode="contain"
              onError={() => setBoxesUri(`${cleanServer(server)}/objects_frame?conf=0.25&ts=${Date.now()}`)}
            />
          )}
        </View>
      )}

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: RADIUS * 2 + 24, height: RADIUS * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: RADIUS * 2, height: RADIUS * 2, borderRadius: RADIUS }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: KNOB_R * 2,
                height: KNOB_R * 2,
                borderRadius: KNOB_R,
                transform: [{ translateX: knobLeft }, { translateY: knobTop }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>
            x: {joy.x.toFixed(2)} y: {joy.y.toFixed(2)}
          </Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: PALETTE.bg,
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: "#1e2a4d",
    minWidth: 110,
  },
  btn: {
    backgroundColor: "#2b48ff",
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1730",
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  statChip: { color: "#dbeafe", fontSize: 14, fontWeight: "600" },
  statNumber: { color: "#fff" },
  modelChip: { marginLeft: "auto", color: "#9fb0ff", fontSize: 12 },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: {
    position: "absolute",
    backgroundColor: "rgba(255,255,255,0.08)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.14)",
  },
  joyKnob: {
    position: "absolute",
    backgroundColor: "rgba(43,72,255,0.9)",
    borderWidth: 2,
    borderColor: "rgba(255,255,255,0.85)",
  },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});



Como usar




Coloque este arquivo exatamente em HydroBotApp2/src/screens/CameraScreen.tsx (substituindo o atual).


Abra o app, configure Servidor para http://SEU_PC:8000.


Toque Detectar. O banner de fogo continua igual; a linha ‚ÄúPessoas / Animais‚Äù usa os sinais est√°veis do servidor (n√£o fica piscando).


Se quiser ver as caixas, toque o bot√£o Caixas ‚Äî aparece um mini-preview carregado de /objects_frame.






















































































Valeu pela print. Mesmo com os caminhos dos arquivos corretos, o conf_max continua ~0.0 ‚Äî ent√£o o MobileNet-SSD que usamos n√£o est√° ‚Äúpegando‚Äù na sua cena/dispositivo. Em vez de ficar brigando com isso, vou te dar uma solu√ß√£o mais robusta:




O servidor passa a tentar MobileNet-SSD e, se n√£o vier nada por alguns frames, ele troca automaticamente para YOLOv4-tiny (COCO), que costuma detectar pessoa/c√£o/gato/etc com bem mais confian√ßa.


Voc√™ j√° tem o yolov4-tiny.cfg na pasta; s√≥ faltam os weights e o coco.names.




Abaixo est√£o:




server_heuristic.py completo (substitui o seu).


Passo a passo r√°pido para baixar os arquivos e testar.





1) Substitua o hydrobot-server/server_heuristic.py por este (COMPLETO)




N√£o mexi em nada da sua l√≥gica de fogo. S√≥ troquei a parte de objetos para ‚Äúduplo backend‚Äù: tenta MobileNet-SSD; se o conf_max ficar baixo, ativa YOLOv4-tiny (se os arquivos existirem). Tamb√©m mantive /objects, /objects_frame e /debug_models.




# server_heuristic.py
# FOGO (heur√≠stico, inalterado) + OBJETOS (MobileNet-SSD -> fallback YOLOv4-tiny)
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0
JPEG_QUALITY = 85

# ===================== FOGO (seu) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS =====================
OBJECTS_MAX_FPS = 12.0
OBJ_CONF_THRESH = 0.25
OBJ_NMS_THRESH  = 0.45

COCO_ANIMAL_NAMES = {"person","cat","dog","bird","horse","sheep","cow"}  # classes que nos interessam

# MobileNet-SSD (VOC)
MNET_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
MNET_ANIMALS = {"person","cat","dog","bird","horse","sheep","cow"}
MNET_IN_SIZE = (300,300); MNET_SCALE = 0.007843; MNET_MEAN = 127.5

MNET_PROTOTXT_CANDS = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
MNET_WEIGHTS_CANDS = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# YOLOv4-tiny (COCO)
YOLO_CFG  = "./models/yolov4-tiny.cfg"
YOLO_WTS  = "./models/yolov4-tiny.weights"
COCO_NAMES= "./models/coco.names"
YOLO_IN_SZ = (416,416)

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (AutoBackend)", version="1.5.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip: self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200:
                        time.sleep(0.5); continue
                    buf = b""
                    MAX_BYTES = 4_000_000
                    self._frames = 0
                    self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== VIS√ÉO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    return ((r.astype(np.int16) > (g.astype(np.int16) + delta)) &
            (r.astype(np.int16) > (b.astype(np.int16) + delta))).astype(np.uint8) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    return cv2.inRange(hsv, np.array(HSV_LOW, np.uint8), np.array(HSV_HIGH, np.uint8))

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0,133,77), (255,173,127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    return cv2.bitwise_and(skin, dark)

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax+aw, ay+ah; bx2, by2 = bx+bw, by+bh
    ix1, iy1 = max(ax,bx), max(ay,by); ix2, iy2 = min(ax2,bx2), min(ay2,by2)
    iw, ih = max(0, ix2-ix1), max(0, iy2-iy1)
    inter = iw*ih; union = aw*ah + bw*bh - inter
    return float(inter)/float(union) if union>0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ,KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in cnts:
        x,y,w,h = cv2.boundingRect(c)
        if w*h >= min_area: boxes.append([x,y,w,h])
    return boxes

class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0; self._score_ema = 0.0
        self._is_fire = False; self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW); self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None
        self._det_fps = 0.0; self._det_frames = 0; self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0/DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray,(3,3),0)
            motion_mask = np.zeros_like(gray,np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray,self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS>0:
                    k = np.ones((3,3),np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[...,2]
            bright = cv2.threshold(V,200,255,cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red,bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
            v_mean = float(np.mean(V))/255.0
            score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
            ratio_combined = float(np.count_nonzero(combined))/float(combined.size)
            score_combined = min(1.0, ratio_combined*5.0 + v_mean*0.1)
            ema = score_combined if self._score_ema==0.0 else (EMA_ALPHA*score_combined + (1.0-EMA_ALPHA)*self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)
            main_box = None
            if boxes:
                areas = [w*h for(_,_,w,h) in boxes]; main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    self._persist_hits = self._persist_hits+1 if iou(tuple(main_box),tuple(self._last_main_box))>=IOU_MIN else 1
                else: self._persist_hits = 1
            else: self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema>=HYST_HIGH and self._persist_hits>=PERSIST_CONSEC: guess=1
            elif ema<=HYST_LOW: guess=0
            else: guess=(1 if (len(self._votes)>0 and self._votes[-1]==1 and self._persist_hits>=PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes)>=VOTE_NEED else 0

            with self._lock:
                self._score_raw=float(score_raw); self._score_ema=float(ema)
                self._is_fire=bool(final_fire==1); self._boxes=boxes if self._is_fire else []
                self._last_result_ts=int(time.time()*1000)

            self._det_frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._det_fps=self._det_frames/(now-self._last_fps_tick)
                self._det_frames=0; self._last_fps_tick=now

            elapsed = time.time()-t0
            if elapsed<min_interval: time.sleep(min_interval-elapsed)

    def get_result(self)->Dict[str,Any]:
        with self._lock:
            return {"ok":True,"isFire":self._is_fire,"score":round(self._score_ema,3),
                    "score_raw":round(self._score_raw,3),"score_ema":round(self._score_ema,3),
                    "boxes":self._boxes,"ts":self._last_result_ts,"fps_det":round(self._det_fps,2),
                    "vote":{"win":VOTE_WINDOW,"need":VOTE_NEED,"sum":int(sum(self._votes))},
                    "persist":{"hits":self._persist_hits,"need":PERSIST_CONSEC,"iou_min":IOU_MIN},
                    "hyst":{"hi":HYST_HIGH,"lo":HYST_LOW}}
detector = Detector(grabber); detector.start()

# ===================== OBJETOS (AutoBackend) =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        # estado
        self.backend = "mobilenet-ssd"   # ou "yolov4-tiny"
        self.net = None
        self.ok = False
        self.proto = None; self.weights = None; self.cfg = None; self.names = None
        self.labels = []
        self.swap_rb = False  # s√≥ p/ mnet
        self._nohit = 0
        self._last_conf_max = 0.0

        # FPS/resultado
        self._frames = 0; self._fps = 0.0; self._last_fps_tick = time.time()
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._try_load_mnet()
        if not self.ok:
            self._try_load_yolo()

    # ---------- loaders ----------
    def _try_load_mnet(self):
        self.backend = "mobilenet-ssd"
        self.labels = MNET_CLASSES
        self.proto = next((p for p in MNET_PROTOTXT_CANDS if os.path.exists(p)), None)
        self.weights = next((w for w in MNET_WEIGHTS_CANDS if os.path.exists(w)), None)
        if not self.proto or not self.weights:
            self.ok = False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromCaffe(self.proto, self.weights)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.net = net; self.ok = True; self.swap_rb=False
        except Exception:
            self.ok = False; self.net=None

    def _try_load_yolo(self):
        self.backend = "yolov4-tiny"
        if not (os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
            self.ok=False; self.net=None; return
        try:
            net = cv2.dnn.readNetFromDarknet(YOLO_CFG, YOLO_WTS)
            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(COCO_NAMES, "r", encoding="utf-8") as f:
                self.labels = [ln.strip() for ln in f if ln.strip()]
            self.net = net; self.ok = True
        except Exception:
            self.ok=False; self.net=None

    # ---------- thread ----------
    def start(self):
        self.stop(); self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True); self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive(): self._thread.join(timeout=1.0)
        self._thread=None

    def _infer_mnet(self, frame, conf_th):
        (h,w)=frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame,MNET_IN_SIZE),
                                     MNET_SCALE, MNET_IN_SIZE, MNET_MEAN, swapRB=self.swap_rb, crop=False)
        self.net.setInput(blob); det=self.net.forward()
        boxes=[]; confs=[]; labels=[]
        conf_max=0.0
        for i in range(det.shape[2]):
            conf=float(det[0,0,i,2]); conf_max=max(conf_max, conf)
            if conf<conf_th: continue
            idx=int(det[0,0,i,1])
            if 0<=idx<len(self.labels):
                label=self.labels[idx]
                if label not in MNET_ANIMALS: continue
                x1,y1,x2,y2=(det[0,0,i,3:7]*np.array([w,h,w,h])).astype(int)
                x,y=max(0,x1),max(0,y1); rw,rh=max(0,x2-x),max(0,y2-y)
                if rw*rh<=0: continue
                boxes.append([x,y,rw,rh]); confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":boxes[i]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _infer_yolo(self, frame, conf_th):
        (H,W)=frame.shape[:2]
        ln = self.net.getUnconnectedOutLayersNames()
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, YOLO_IN_SZ, swapRB=True, crop=False)
        self.net.setInput(blob); layerOutputs = self.net.forward(ln)
        boxes=[]; confs=[]; labels=[]
        conf_max = 0.0
        for output in layerOutputs:
            for det in output:
                scores = det[5:]
                classID = int(np.argmax(scores))
                conf = float(scores[classID])
                conf_max = max(conf_max, conf)
                if conf < conf_th: continue
                label = self.labels[classID] if 0<=classID<len(self.labels) else str(classID)
                if label not in COCO_ANIMAL_NAMES: continue
                bx = det[0:4]
                (cx,cy,w,h) = (bx[0]*W, bx[1]*H, bx[2]*W, bx[3]*H)
                x = int(cx - w/2); y = int(cy - h/2)
                boxes.append([max(0,x), max(0,y), int(w), int(h)])
                confs.append(conf); labels.append(label)
        idxs=cv2.dnn.NMSBoxes(boxes,confs,conf_th,OBJ_NMS_THRESH)
        keep = [int(i) for i in (idxs.flatten().tolist() if isinstance(idxs,np.ndarray) else (idxs or []))]
        out=[{"label":labels[i],"conf":float(confs[i]),"box":[int(v) for v in boxes[i]]} for i in keep]
        out.sort(key=lambda o:o["conf"], reverse=True)
        return out[:15], conf_max

    def _run(self):
        min_interval = 1.0/OBJECTS_MAX_FPS
        self.start_time = time.time()
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None: time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
            if frame is None: time.sleep(0.005); continue

            out=[]; cmax=0.0; backend=self.backend
            if self.ok and self.net is not None:
                try:
                    if self.backend=="mobilenet-ssd":
                        out,cmax = self._infer_mnet(frame, OBJ_CONF_THRESH)
                        # fallback rgb swap autom√°tico se nada por 1s
                        self._nohit = self._nohit+1 if cmax<0.05 else 0
                        if self._nohit>=10:
                            self.swap_rb = not self.swap_rb
                            self._nohit = 0
                    else:  # YOLO
                        out,cmax = self._infer_yolo(frame, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok=False; self._last={"ok":False,"backend":backend,"fps_obj":round(self._fps,2),
                                              "objects":[], "ts":int(time.time()*1000), "error":f"forward failed: {e}"}
                    time.sleep(0.05); continue

            # se MobileNet-SSD n√£o funcionar e YOLO existir, trocamos
            if (backend=="mobilenet-ssd" and cmax<0.05 and
                os.path.exists(YOLO_CFG) and os.path.exists(YOLO_WTS) and os.path.exists(COCO_NAMES)):
                self._try_load_yolo()
                backend=self.backend
                if self.ok and self.backend=="yolov4-tiny":
                    out,cmax = self._infer_yolo(frame, max(0.2, OBJ_CONF_THRESH))

            with self._lock:
                self._last_conf_max=cmax
                self._last={"ok":bool(self.ok),"backend":backend,"fps_obj":round(self._fps,2),
                            "objects":out,"ts":int(time.time()*1000),
                            "proto":self.proto,"weights":self.weights,"cfg":YOLO_CFG if backend=="yolov4-tiny" else None,
                            "names":COCO_NAMES if backend=="yolov4-tiny" else None,
                            "conf_max":round(cmax,3),"swap_rb":self.swap_rb}

            self._frames+=1; now=time.time()
            if now-self._last_fps_tick>=1.0:
                self._fps=self._frames/(now-self._last_fps_tick); self._frames=0; self._last_fps_tick=now

            dt = time.time()-t0
            if dt<min_interval: time.sleep(min_interval-dt)

    def get(self)->Dict[str,Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber); objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status()
    s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time()*1000)-res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    # fallback r√°pido
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return {"ok": False, "error": "no recent frame"}
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv))/float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[...,2]))/255.0
    score_raw = min(1.0, ratio_hsv*4.0 + v_mean*0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {"ok":True,"isFire":is_fire,"score":round(score_raw,3),"score_raw":round(score_raw,3),
            "score_ema":round(score_raw,3),"boxes":[],"ts":int(time.time()*1000),"fallback":True,
            "objects": objects_det.get()}

@app.get("/objects")
def objects(conf: float = Query(None)):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.25)):
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None: return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg,np.uint8), cv2.IMREAD_COLOR)
    if frame is None: return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    o = objects_det.get()
    backend = o.get("backend")
    det = objects_det

    try:
        if backend=="yolov4-tiny":
            objs, _ = det._infer_yolo(frame, max(0.05, min(0.95, conf)))
        else:
            objs, _ = det._infer_mnet(frame, max(0.05, min(0.95, conf)))
    except Exception:
        return Response(content=placeholder_jpeg("FORWARD ERR"), media_type="image/jpeg")

    for obj in objs:
        x,y,w,h = obj["box"]
        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
        cv2.putText(frame, f'{obj["label"]} {obj["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get(); s = grabber.status()
    return {"ok":True, "backend":o.get("backend"), "objects_ok":o.get("ok"),
            "proto":o.get("proto"), "weights":o.get("weights"),
            "cfg":o.get("cfg"), "names":o.get("names"),
            "swap_rb":o.get("swap_rb"), "conf_max":o.get("conf_max"),
            "conf_thresh":OBJ_CONF_THRESH, "fps_obj":o.get("fps_obj"),
            "stream_hasFrame":s.get("hasFrame"), "stream_fps_in":s.get("fps_in"),
            "num_objects":len(o.get("objects",[])), "error":o.get("error")}




2) Passo a passo (baixar YOLO e testar)






Baixe os arquivos para hydrobot-server/models/:




yolov4-tiny.weights

URL (oficial AlexeyAB):

https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights


yolov4-tiny.cfg

(voc√™ j√° tem; se precisar:

https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg )


coco.names

https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names




D√™ exatamente esses nomes dentro de hydrobot-server/models/.






Reinicie o servidor:






uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload







Verifique no navegador (no PC do servidor):




http://SEU_PC:8000/debug_models

Deve mostrar backend: "yolov4-tiny" (se o MobileNet n√£o estiver detectando) e objects_ok: true.


http://SEU_PC:8000/objects_frame?conf=0.25

Deve exibir o JPEG com caixas (person/dog/cat‚Ä¶).








No app (tela C√¢mera):




Campo Servidor = http://SEU_PC:8000


Tocar Detectar.

‚ÄúPessoas: N‚Äù e ‚ÄúAnimais: M‚Äù devem sair de 0 quando algu√©m entra no quadro.









Se mesmo com YOLO o /objects_frame ficar sem caixas, me diga o que aparece em /debug_models (backend, conf_max, error, stream_hasFrame) que eu ajusto o que faltar.




























































Vale ‚Äî o app est√° ok; o problema √© o servidor n√£o est√° retornando objetos. Isso costuma ser por par (prototxt/pesos) diferente ou pr√©-processamento (swapRB) que n√£o bate com seu caffemodel. Vou te passar:




server_heuristic.py completo com:



suporte a v√°rios nomes de modelo (os que voc√™ tem na pasta),


ajuste de threshold por query,


fallback autom√°tico de pr√©-processamento (tenta swapRB=False e, se nada sair, troca pra swapRB=True),


endpoints de debug: /objects_raw, /objects_frame e /debug_models (mostram proto, weights, conf_max, etc).






Passo a passo de teste.






N√£o mexe na detec√ß√£o de fogo; s√≥ acrescentei a parte de objetos e debug.





Substitua seu hydrobot-server/server_heuristic.py por este (COMPLETO)


# server_heuristic.py
# FOGO (heur√≠stico, inalterado) + OBJETOS (MobileNet-SSD Caffe) com debug
import os, time, threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ===================== CONFIG STREAM =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0

JPEG_QUALITY = 85

# ===================== FOGO (igual ao seu) =====================
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)
RED_DELTA = 15

DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

PERSIST_CONSEC = 2
IOU_MIN = 0.15

MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS (MobileNet-SSD) =====================
OBJECTS_MAX_FPS = 10.0
OBJ_CONF_THRESH = 0.25       # pode trocar em /objects?conf=0.15
OBJ_NMS_THRESH  = 0.45
OBJ_CLASSES = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
ANIMAL_CLASSES = {"bird","cat","cow","dog","horse","sheep"}

DNN_IN_SIZE = (300, 300)
DNN_SCALE   = 0.007843
DNN_MEAN    = 127.5

# aceita os nomes que voc√™ tem na pasta
DNN_PROTOTXT_CANDIDATES = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",
]
DNN_CAFFE_WEIGHTS_CANDIDATES = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects", version="1.4.0")
app.add_middleware(
    CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER CONT√çNUO =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip: self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200:
                        time.sleep(0.5); continue
                    buf = b""
                    MAX_BYTES = 4_000_000
                    self._frames = 0
                    self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except requests.exceptions.RequestException:
                time.sleep(0.5)
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== FUN√á√ïES VIS√ÉO (fogo) =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    mask = (r.astype(np.int16) > (g.astype(np.int16) + delta)) & (r.astype(np.int16) > (b.astype(np.int16) + delta))
    return (mask.astype(np.uint8)) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    lower = np.array(HSV_LOW, dtype=np.uint8)
    upper = np.array(HSV_HIGH, dtype=np.uint8)
    return cv2.inRange(hsv, lower, upper)

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0, 133, 77), (255, 173, 127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    skin = cv2.bitwise_and(skin, dark)
    return skin

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax + aw, ay + ah; bx2, by2 = bx + bw, by + bh
    ix1, iy1 = max(ax, bx), max(ay, by)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
    inter = iw * ih; union = aw*ah + bw*bh - inter
    return float(inter) / float(union) if union > 0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes: List[List[int]] = []
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if w * h >= min_area:
            boxes.append([x, y, w, h])
    return boxes

# ===================== DETECTOR CONT√çNUO (FOGO) =====================
class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0
        self._score_ema = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW)
        self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None

        self._det_fps = 0.0
        self._det_frames = 0
        self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue

            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (3, 3), 0)
            motion_mask = np.zeros_like(gray, dtype=np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray, self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS > 0:
                    k = np.ones((3, 3), np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[..., 2]
            bright = cv2.threshold(V, 200, 255, cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red, bright)
            combined = cv2.bitwise_or(stable, red_boost)

            ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
            v_mean = float(np.mean(V)) / 255.0
            score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)

            ratio_combined = float(np.count_nonzero(combined)) / float(combined.size)
            score_combined = min(1.0, ratio_combined * 5.0 + v_mean * 0.1)

            ema = score_combined if self._score_ema == 0.0 else (EMA_ALPHA * score_combined + (1.0 - EMA_ALPHA) * self._score_ema)

            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)

            main_box = None
            if boxes:
                areas = [w*h for (_,_,w,h) in boxes]
                main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    if iou(tuple(main_box), tuple(self._last_main_box)) >= IOU_MIN:
                        self._persist_hits += 1
                    else:
                        self._persist_hits = 1
                else:
                    self._persist_hits = 1
            else:
                self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            if ema >= HYST_HIGH and self._persist_hits >= PERSIST_CONSEC:
                guess = 1
            elif ema <= HYST_LOW:
                guess = 0
            else:
                guess = (1 if (len(self._votes) > 0 and self._votes[-1] == 1 and self._persist_hits >= PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes) >= VOTE_NEED else 0

            with self._lock:
                self._score_raw = float(score_raw)
                self._score_ema = float(ema)
                self._is_fire = bool(final_fire == 1)
                self._boxes = boxes if self._is_fire else []
                self._last_result_ts = int(time.time() * 1000)

            self._det_frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._det_fps = self._det_frames / (now - self._last_fps_tick)
                self._det_frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get_result(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema, 3),
                "score_raw": round(self._score_raw, 3),
                "score_ema": round(self._score_ema, 3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps, 2),
                "vote": {"win": VOTE_WINDOW, "need": VOTE_NEED, "sum": int(sum(self._votes))},
                "persist": {"hits": self._persist_hits, "need": PERSIST_CONSEC, "iou_min": IOU_MIN},
                "hyst": {"hi": HYST_HIGH, "lo": HYST_LOW},
            }

detector = Detector(grabber)
detector.start()

# ===================== OBJETOS =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None
        self.ok = False
        self.proto_path = None
        self.weights_path = None

        # debug
        self._last_conf_max = 0.0
        self.swap_rb = False           # fallback autom√°tico
        self._nohit_streak = 0

        # FPS
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._load_net()

    def _load_net(self):
        for p in DNN_PROTOTXT_CANDIDATES:
            if os.path.exists(p): self.proto_path = p; break
        for w in DNN_CAFFE_WEIGHTS_CANDIDATES:
            if os.path.exists(w): self.weights_path = w; break
        if not self.proto_path:
            self.ok = False; self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0, "error": "prototxt not found"}; return
        if not self.weights_path:
            self.ok = False; self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0, "error": "caffemodel not found"}; return
        try:
            self.net = cv2.dnn.readNetFromCaffe(self.proto_path, self.weights_path)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.ok = True
        except Exception as e:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0, "error": f"load failed: {e}"}

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _nms(self, boxes: List[List[int]], confs: List[float]) -> List[int]:
        if not boxes: return []
        idxs = cv2.dnn.NMSBoxes(boxes, confs, OBJ_CONF_THRESH, OBJ_NMS_THRESH)
        if idxs is None or len(idxs) == 0: return []
        if isinstance(idxs, np.ndarray): return [int(i) for i in idxs.flatten().tolist()]
        return [int(i) for i in idxs]

    def _infer_once(self, frame: np.ndarray, swap_rb: bool, conf_th: float) -> Tuple[List[Dict[str, Any]], float]:
        (h, w) = frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame, DNN_IN_SIZE),
                                     DNN_SCALE, DNN_IN_SIZE, DNN_MEAN, swapRB=swap_rb, crop=False)
        self.net.setInput(blob)
        detections = self.net.forward()
        out_objects: List[Dict[str, Any]] = []
        boxes_all: List[List[int]] = []
        confs_all: List[float] = []
        labels_all: List[str] = []
        conf_max = 0.0

        for i in range(detections.shape[2]):
            conf = float(detections[0, 0, i, 2])
            conf_max = max(conf_max, conf)
            if conf < conf_th: continue
            idx = int(detections[0, 0, i, 1])
            if idx < 0 or idx >= len(OBJ_CLASSES): continue
            label = OBJ_CLASSES[idx]
            if label != "person" and label not in ANIMAL_CLASSES: continue
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            x1, y1, x2, y2 = box.astype("int")
            x, y = max(0, x1), max(0, y1)
            rw, rh = max(0, x2 - x), max(0, y2 - y)
            if rw * rh <= 0: continue
            boxes_all.append([int(x), int(y), int(rw), int(rh)])
            confs_all.append(conf)
            labels_all.append(label)

        keep = self._nms(boxes_all, confs_all)
        for k in keep:
            out_objects.append({"label": labels_all[k], "conf": float(confs_all[k]), "box": [int(v) for v in boxes_all[k]]})
        out_objects.sort(key=lambda o: o["conf"], reverse=True)
        out_objects = out_objects[:15]
        return out_objects, conf_max

    def _run(self):
        min_interval = 1.0 / OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue
            frame = cv2.imdecode(np.frombuffer(jpeg, dtype=np.uint8), cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            out_objects: List[Dict[str, Any]] = []
            conf_max = 0.0

            if self.ok and self.net is not None:
                try:
                    out_objects, conf_max = self._infer_once(frame, self.swap_rb, OBJ_CONF_THRESH)
                except Exception as e:
                    self.ok = False
                    self._last = {"ok": False, "backend": self.backend, "fps_obj": round(self._fps,2),
                                  "objects": [], "ts": int(time.time()*1000), "error": f"forward failed: {e}"}
                    time.sleep(0.1)
                    continue

                # Fallback: se n√£o teve nada por um tempo, tente inverter canais e mantenha se melhorar
                if conf_max < 0.05:
                    self._nohit_streak += 1
                else:
                    self._nohit_streak = 0

                if self._nohit_streak >= 10:  # ~1 segundo
                    try_other, conf_other = self._infer_once(frame, not self.swap_rb, max(0.1, OBJ_CONF_THRESH*0.8))
                    if conf_other > conf_max + 0.05:
                        self.swap_rb = not self.swap_rb   # trava no melhor
                        out_objects, conf_max = try_other, conf_other
                    self._nohit_streak = 0

            with self._lock:
                self._last_conf_max = conf_max
                self._last = {
                    "ok": bool(self.ok),
                    "backend": self.backend,
                    "fps_obj": round(self._fps, 2),
                    "objects": out_objects,
                    "ts": int(time.time()*1000),
                    "proto": self.proto_path,
                    "weights": self.weights_path,
                    "conf_max": round(conf_max, 3),
                    "swap_rb": self.swap_rb,
                }

            self._frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._fps = self._frames / (now - self._last_fps_tick)
                self._frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(max(0.0, min_interval - elapsed))

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber)
objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status()
    s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    res["objects"] = objects_det.get()
    if res.get("ts", 0) and (int(time.time() * 1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    arr = np.frombuffer(jpeg, dtype=np.uint8)
    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[..., 2])) / 255.0
    score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    res2 = {
        "ok": True, "isFire": is_fire,
        "score": round(float(score_raw), 3),
        "score_raw": round(float(score_raw), 3),
        "score_ema": round(float(score_raw), 3),
        "boxes": [], "ts": int(time.time() * 1000), "fallback": True,
        "objects": objects_det.get()
    }
    return res2

@app.get("/objects")
def objects(conf: float = Query(None, description="override confidence threshold (0..1)")):
    global OBJ_CONF_THRESH
    if conf is not None:
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/objects_raw")
def objects_raw(conf: float = Query(0.2, description="threshold (0..1)")):
    """Lista TUDO que o modelo v√™ (sem filtrar s√≥ pessoa/animais) para debug."""
    o = objects_det.get()
    return {
        "ok": o.get("ok", False),
        "backend": o.get("backend"),
        "proto": o.get("proto"),
        "weights": o.get("weights"),
        "conf_max": o.get("conf_max"),
        "swap_rb": o.get("swap_rb"),
        "note": "este endpoint s√≥ ecoa status; para ver dete√ß√µes brutas use /objects_frame",
    }

@app.get("/objects_frame")
def objects_frame(conf: float = Query(0.2, description="threshold (0..1)")):
    """Retorna um JPEG com caixas desenhadas (pessoa/animais) ‚Äî debug visual."""
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return Response(content=placeholder_jpeg("NO LIVE FRAME"), media_type="image/jpeg")
    frame = cv2.imdecode(np.frombuffer(jpeg, dtype=np.uint8), cv2.IMREAD_COLOR)
    if frame is None:
        return Response(content=placeholder_jpeg("DECODE ERR"), media_type="image/jpeg")

    # roda uma infer√™ncia direta (mesmo pipeline do detector)
    det = objects_det
    if not det.ok or det.net is None:
        return Response(content=placeholder_jpeg("NET NOT LOADED"), media_type="image/jpeg")

    objs, _ = det._infer_once(frame, det.swap_rb, max(0.05, min(0.95, conf)))
    for o in objs:
        x,y,w,h = o["box"]
        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)
        cv2.putText(frame, f'{o["label"]} {o["conf"]:.2f}', (x, max(15,y-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
    return Response(content=buf.tobytes(), media_type="image/jpeg")

@app.get("/debug_models")
def debug_models():
    o = objects_det.get()
    s = grabber.status()
    return {
        "ok": True,
        "fire_model": "heuristic-balanced",
        "objects_backend": o.get("backend", "mobilenet-ssd"),
        "objects_ok": o.get("ok", False),
        "fps_obj": o.get("fps_obj", 0.0),
        "num_objects": len(o.get("objects", [])),
        "proto": o.get("proto"),
        "weights": o.get("weights"),
        "conf_max": o.get("conf_max"),
        "swap_rb": o.get("swap_rb"),
        "conf_thresh": OBJ_CONF_THRESH,
        "nms_thresh": OBJ_NMS_THRESH,
        "stream_hasFrame": s.get("hasFrame"),
        "stream_fps_in": s.get("fps_in"),
        "error": o.get("error"),
    }




Passo a passo (r√°pido)




Reinicie:




uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload





Abra no navegador do PC do servidor:






http://SEU_PC:8000/debug_models

Verifique:



objects_ok: true


proto e weights apontando para os arquivos dentro de models/


stream_hasFrame: true e stream_fps_in > 0


swap_rb (come√ßa false; o servidor muda sozinho se perceber que n√£o tem hits)






http://SEU_PC:8000/objects

Observe conf_max. Se ficar ~0.0, aguarde 2‚Äì3s (o fallback tenta swapRB=True sozinho).


http://SEU_PC:8000/objects?conf=0.15

Abaixe o limiar temporariamente (se luz ruim).


http://SEU_PC:8000/objects_frame?conf=0.15

Deve aparecer um JPEG com as caixas em pessoas/animais. Se n√£o aparecer nada, ainda √© par de arquivos.






No app (tela C√¢mera):






Servidor = http://SEU_PC:8000


Clique Detectar. Os badges devem sair de 0 quando algu√©m entrar no quadro.





Por que isso resolve?




Se o seu caffemodel exigir RGB (incomum em Caffe, mas acontece em forks), o servidor agora detecta e alterna automaticamente (swap_rb muda para true sozinho ap√≥s ~1s sem hits).


Se o seu par deploy/weights n√£o estiver combinando, o /debug_models mostra quais arquivos e o /objects_frame deixa claro se a sa√≠da est√° vazia por threshold ou por modelo.


Voc√™ ainda pode ajustar o threshold via query sem reiniciar.




Se ainda assim o /objects_frame n√£o desenhar nada, me diga o que aparece em /debug_models (proto, weights, conf_max, swap_rb, stream_hasFrame) que eu ajusto pontualmente.







































































Beleza ‚Äî se o /objects veio vazio mesmo com uma pessoa no quadro, o problema est√° no servidor (n√£o no app). Provavelmente √© par de arquivos n√£o correspondentes (prototxt vs caffemodel) ou limiar de confian√ßa alto para a sua cena/ilumina√ß√£o.


Abaixo te mando um server_heuristic.py atualizado (COMPLETO) que:




aceita v√°rios nomes de prototxt/weights (inclui deploy.prototxt e mobilenet_iter_73000.caffemodel que apareceram no seu clone);


mostra no /debug_models exatamente quais arquivos foram carregados e qual foi a maior confian√ßa da √∫ltima infer√™ncia;


reduz o threshold padr√£o para 0.25 (mais sens√≠vel) ‚Äî voc√™ pode ajustar por query string (/objects?conf=0.35);


mant√©m todo o detector de fogo inalterado.




Depois do c√≥digo, tem um passo-a-passo de teste para voc√™ validar rapidinho.



server_heuristic.py (substitua o arquivo inteiro)


# server_heuristic.py
# FOGO (heur√≠stico, inalterado) + OBJETOS (MobileNet-SSD Caffe)
import time
import threading
from collections import deque
from typing import Optional, List, Tuple, Dict, Any

import numpy as np
import cv2
import requests
from fastapi import FastAPI, Response, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os

# ===================== CONFIG =====================
CAMERA_IP = "192.168.4.1"
STREAM_URL_FMT = "http://{}:81/stream"
BOUNDARY = b"--frame"
CONNECT_TIMEOUT = 3.0
READ_TIMEOUT = 3.0

JPEG_QUALITY = 85

# HSV mais amplo p/ fogo real (amarelo/laranja)
HSV_LOW = (8, 80, 120)
HSV_HIGH = (40, 255, 255)

# Domin√¢ncia de vermelho (refor√ßo, n√£o bloqueio)
RED_DELTA = 15

# Detector fogo
DETECTOR_MAX_FPS = 14.0
HYST_HIGH = 0.18
HYST_LOW  = 0.15
VOTE_WINDOW = 7
VOTE_NEED   = 4
EMA_ALPHA   = 0.25
MIN_BLOB_AREA = 1200
KERNEL_SZ = 5

# Anti-movimento
MOTION_THRESH = 22
MOTION_DILATE_ITERS = 1

# Persist√™ncia espacial
PERSIST_CONSEC = 2
IOU_MIN = 0.15

# Idades m√°ximas
MAX_FRAME_AGE_MS = 3000
MAX_RESULT_AGE_MS = 800

# ===================== OBJETOS (MobileNet-SSD) =====================
OBJECTS_MAX_FPS   = 10.0
OBJ_CONF_THRESH   = 0.25     # <= mais sens√≠vel; pode subir via /objects?conf=0.4
OBJ_NMS_THRESH    = 0.45
OBJ_CLASSES       = [
    "background","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair",
    "cow","diningtable","dog","horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"
]
ANIMAL_CLASSES    = {"bird","cat","cow","dog","horse","sheep"}
DNN_IN_SIZE       = (300, 300)
DNN_SCALE         = 0.007843
DNN_MEAN          = 127.5

# Candidatos de caminhos ‚Äî cobrimos os nomes que voc√™ tem
DNN_PROTOTXT_CANDIDATES = [
    "./models/MobileNetSSD_deploy.prototxt",
    "./models/MobileNetSSD_deploy.prototxt.txt",
    "./models/deploy.prototxt",
    "./models/voc/MobileNetSSD_test.prototxt",     # s√≥ se voc√™ colocou assim
]
DNN_CAFFE_WEIGHTS_CANDIDATES = [
    "./models/MobileNetSSD_deploy.caffemodel",
    "./models/mobilenet_iter_73000.caffemodel",
]

# ===================== FASTAPI =====================
app = FastAPI(title="HydroBot Fire + Objects (MobileNetSSD)", version="1.3.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]
)

class ConfigIn(BaseModel):
    camera_ip: str

# ===================== PLACEHOLDER =====================
def placeholder_jpeg(msg: str = "NO FRAME") -> bytes:
    img = np.zeros((270, 480, 3), dtype=np.uint8)
    img[:, :] = (40, 40, 200)
    cv2.putText(img, msg, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(img, time.strftime("%H:%M:%S"), (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
    return buf.tobytes()

# ===================== GRABBER CONT√çNUO =====================
class MJPEGGrabber:
    def __init__(self):
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._ip = CAMERA_IP
        self._last_jpeg: Optional[bytes] = None
        self._last_ts_ms: int = 0
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

    def start(self, ip: Optional[str] = None):
        if ip:
            self._ip = ip
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        while not self._stop.is_set():
            url = STREAM_URL_FMT.format(self._ip)
            try:
                with requests.get(url, stream=True, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT)) as r:
                    if r.status_code != 200:
                        time.sleep(0.5); continue
                    buf = b""
                    MAX_BYTES = 4_000_000
                    self._frames = 0
                    self._last_fps_tick = time.time()
                    for chunk in r.iter_content(chunk_size=4096):
                        if self._stop.is_set(): break
                        if not chunk: continue
                        buf += chunk
                        if len(buf) > MAX_BYTES: buf = b""
                        i = buf.find(BOUNDARY)
                        if i == -1: continue
                        hdr_start = i + len(BOUNDARY)
                        while hdr_start + 2 <= len(buf) and buf[hdr_start:hdr_start+2] == b"\r\n":
                            hdr_start += 2
                        headers_end = buf.find(b"\r\n\r\n", hdr_start)
                        if headers_end == -1: continue
                        headers_bytes = buf[hdr_start:headers_end]
                        content_length = None
                        for line in headers_bytes.split(b"\r\n"):
                            if line.lower().startswith(b"content-length:"):
                                try: content_length = int(line.split(b":", 1)[1].strip())
                                except: pass
                                break
                        img_start = headers_end + 4
                        jpeg_bytes = None
                        if content_length is not None:
                            if len(buf) < img_start + content_length: continue
                            jpeg_bytes = buf[img_start:img_start + content_length]
                            buf = buf[img_start + content_length:]
                        else:
                            j = buf.find(BOUNDARY, img_start)
                            if j != -1:
                                jpeg_bytes = buf[img_start:j]
                                buf = buf[j:]
                            else:
                                continue
                        if jpeg_bytes:
                            ts_ms = int(time.time() * 1000)
                            with self._lock:
                                self._last_jpeg = jpeg_bytes
                                self._last_ts_ms = ts_ms
                            self._frames += 1
                            now = time.time()
                            if now - self._last_fps_tick >= 1.0:
                                self._fps = self._frames / (now - self._last_fps_tick)
                                self._frames = 0
                                self._last_fps_tick = now
            except requests.exceptions.RequestException:
                time.sleep(0.5)
            except Exception:
                time.sleep(0.5)

    def get_latest_jpeg(self, max_age_ms: int = MAX_FRAME_AGE_MS) -> Optional[bytes]:
        with self._lock:
            if self._last_jpeg is None: return None
            if int(time.time() * 1000) - self._last_ts_ms > max_age_ms: return None
            return self._last_jpeg

    def status(self):
        with self._lock:
            age_ms = (int(time.time() * 1000) - self._last_ts_ms) if self._last_ts_ms else None
            return {"ip": self._ip, "hasFrame": self._last_jpeg is not None, "age_ms": age_ms,
                    "fps_in": round(self._fps, 2), "ts_ms": self._last_ts_ms}

grabber = MJPEGGrabber()
grabber.start(CAMERA_IP)

# ===================== UTILs VIS√ÉO =====================
def rgb_red_dominance_mask(frame_bgr: np.ndarray, delta: int = RED_DELTA) -> np.ndarray:
    b, g, r = cv2.split(frame_bgr)
    mask = (r.astype(np.int16) > (g.astype(np.int16) + delta)) & (r.astype(np.int16) > (b.astype(np.int16) + delta))
    return (mask.astype(np.uint8)) * 255

def hsv_fire_mask(frame_bgr: np.ndarray) -> np.ndarray:
    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)
    lower = np.array(HSV_LOW, dtype=np.uint8)
    upper = np.array(HSV_HIGH, dtype=np.uint8)
    return cv2.inRange(hsv, lower, upper)

def skin_mask_ycrcb(frame_bgr: np.ndarray) -> np.ndarray:
    ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    skin = cv2.inRange(ycrcb, (0, 133, 77), (255, 173, 127))
    dark = cv2.threshold(y, 60, 255, cv2.THRESH_BINARY)[1]
    skin = cv2.bitwise_and(skin, dark)
    return skin

def iou(a: Tuple[int,int,int,int], b: Tuple[int,int,int,int]) -> float:
    ax, ay, aw, ah = a; bx, by, bw, bh = b
    ax2, ay2 = ax + aw, ay + ah; bx2, by2 = bx + bw, by + bh
    ix1, iy1 = max(ax, bx), max(ay, by)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
    inter = iw * ih; union = aw*ah + bw*bh - inter
    return float(inter) / float(union) if union > 0 else 0.0

def boxes_from_mask(mask_bin: np.ndarray, min_area: int = MIN_BLOB_AREA) -> List[List[int]]:
    k = np.ones((KERNEL_SZ, KERNEL_SZ), np.uint8)
    m = cv2.morphologyEx(mask_bin, cv2.MORPH_OPEN, k, 1)
    m = cv2.morphologyEx(m, cv2.MORPH_DILATE, k, 1)
    cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes: List[List[int]] = []
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if w * h >= min_area:
            boxes.append([x, y, w, h])
    return boxes

# ===================== DETECTOR CONT√çNUO (FOGO) =====================
class Detector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self._prev_gray: Optional[np.ndarray] = None
        self._score_raw = 0.0
        self._score_ema = 0.0
        self._is_fire = False
        self._boxes: List[List[int]] = []
        self._votes = deque(maxlen=VOTE_WINDOW)
        self._persist_hits = 0
        self._last_main_box: Optional[Tuple[int,int,int,int]] = None

        self._det_fps = 0.0
        self._det_frames = 0
        self._last_fps_tick = time.time()
        self._last_result_ts = 0

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _run(self):
        min_interval = 1.0 / DETECTOR_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue

            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            # --- m√°scaras base ---
            mask_hsv = hsv_fire_mask(frame)
            mask_skin = skin_mask_ycrcb(frame)
            mask_red  = rgb_red_dominance_mask(frame)

            # anti-movimento
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (3, 3), 0)
            motion_mask = np.zeros_like(gray, dtype=np.uint8)
            if self._prev_gray is not None:
                diff = cv2.absdiff(gray, self._prev_gray)
                _, motion_mask = cv2.threshold(diff, MOTION_THRESH, 255, cv2.THRESH_BINARY)
                if MOTION_DILATE_ITERS > 0:
                    k = np.ones((3, 3), np.uint8)
                    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_DILATE, k, MOTION_DILATE_ITERS)
            self._prev_gray = gray

            # combina√ß√£o principal: HSV ‚àß ¬¨pele ‚àß ¬¨movimento
            stable = cv2.bitwise_and(mask_hsv, cv2.bitwise_not(mask_skin))
            stable = cv2.bitwise_and(stable, cv2.bitwise_not(motion_mask))

            # refor√ßo
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            V = hsv[..., 2]
            bright = cv2.threshold(V, 200, 255, cv2.THRESH_BINARY)[1]
            red_boost = cv2.bitwise_and(mask_red, bright)
            combined = cv2.bitwise_or(stable, red_boost)

            # scores
            ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
            v_mean = float(np.mean(V)) / 255.0
            score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)

            ratio_combined = float(np.count_nonzero(combined)) / float(combined.size)
            score_combined = min(1.0, ratio_combined * 5.0 + v_mean * 0.1)

            ema = score_combined if self._score_ema == 0.0 else (EMA_ALPHA * score_combined + (1.0 - EMA_ALPHA) * self._score_ema)

            # caixas
            boxes = boxes_from_mask(combined, MIN_BLOB_AREA)

            # persist√™ncia espacial leve
            main_box = None
            if boxes:
                areas = [w*h for (_,_,w,h) in boxes]
                main_box = boxes[int(np.argmax(areas))]
                if self._last_main_box is not None:
                    if iou(tuple(main_box), tuple(self._last_main_box)) >= IOU_MIN:
                        self._persist_hits += 1
                    else:
                        self._persist_hits = 1
                else:
                    self._persist_hits = 1
            else:
                self._persist_hits = 0
            self._last_main_box = tuple(main_box) if main_box is not None else None

            # histerese + votos
            if ema >= HYST_HIGH and self._persist_hits >= PERSIST_CONSEC:
                guess = 1
            elif ema <= HYST_LOW:
                guess = 0
            else:
                guess = (1 if (len(self._votes) > 0 and self._votes[-1] == 1 and self._persist_hits >= PERSIST_CONSEC) else 0)

            self._votes.append(guess)
            final_fire = 1 if sum(self._votes) >= VOTE_NEED else 0

            with self._lock:
                self._score_raw = float(score_raw)
                self._score_ema = float(ema)
                self._is_fire = bool(final_fire == 1)
                self._boxes = boxes if self._is_fire else []
                self._last_result_ts = int(time.time() * 1000)

            # FPS detector
            self._det_frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._det_fps = self._det_frames / (now - self._last_fps_tick)
                self._det_frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

    def get_result(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "ok": True,
                "isFire": self._is_fire,
                "score": round(self._score_ema, 3),
                "score_raw": round(self._score_raw, 3),
                "score_ema": round(self._score_ema, 3),
                "boxes": self._boxes,
                "ts": self._last_result_ts,
                "fps_det": round(self._det_fps, 2),
                "vote": {"win": VOTE_WINDOW, "need": VOTE_NEED, "sum": int(sum(self._votes))},
                "persist": {"hits": self._persist_hits, "need": PERSIST_CONSEC, "iou_min": IOU_MIN},
                "hyst": {"hi": HYST_HIGH, "lo": HYST_LOW},
            }

detector = Detector(grabber)
detector.start()

# ===================== DETECTOR DE OBJETOS =====================
class ObjectsDetector:
    def __init__(self, src: MJPEGGrabber):
        self.src = src
        self._lock = threading.Lock()
        self._stop = threading.Event()
        self._thread: Optional[threading.Thread] = None

        self.backend = "mobilenet-ssd"
        self.net = None
        self.ok = False
        self.proto_path = None
        self.weights_path = None

        # m√©tricas p/ debug
        self._last_conf_max = 0.0

        # FPS
        self._frames = 0
        self._fps = 0.0
        self._last_fps_tick = time.time()

        # √∫ltimo resultado
        self._last: Dict[str, Any] = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0}

        self._load_net()

    def _load_net(self):
        # acha prototxt
        for p in DNN_PROTOTXT_CANDIDATES:
            if os.path.exists(p):
                self.proto_path = p
                break
        # acha weights
        for w in DNN_CAFFE_WEIGHTS_CANDIDATES:
            if os.path.exists(w):
                self.weights_path = w
                break

        if not self.proto_path:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": "prototxt not found"}
            return
        if not self.weights_path:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": "caffemodel not found"}
            return
        try:
            self.net = cv2.dnn.readNetFromCaffe(self.proto_path, self.weights_path)
            # for√ßa CPU (compat√≠vel)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            self.ok = True
        except Exception as e:
            self.ok = False
            self._last = {"ok": False, "backend": self.backend, "fps_obj": 0.0, "objects": [], "ts": 0,
                          "error": f"load failed: {e}"}

    def start(self):
        self.stop()
        self._stop.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def stop(self):
        self._stop.set()
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _nms(self, boxes: List[List[int]], confs: List[float]) -> List[int]:
        if not boxes: return []
        idxs = cv2.dnn.NMSBoxes(boxes, confs, OBJ_CONF_THRESH, OBJ_NMS_THRESH)
        if idxs is None or len(idxs) == 0: return []
        if isinstance(idxs, np.ndarray):
            return [int(i) for i in idxs.flatten().tolist()]
        return [int(i) for i in idxs]

    def _run(self):
        min_interval = 1.0 / OBJECTS_MAX_FPS
        while not self._stop.is_set():
            t0 = time.time()
            jpeg = self.src.get_latest_jpeg()
            if jpeg is None:
                time.sleep(0.01); continue
            arr = np.frombuffer(jpeg, dtype=np.uint8)
            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            if frame is None:
                time.sleep(0.005); continue

            out_objects: List[Dict[str, Any]] = []
            conf_max = 0.0

            if self.ok and self.net is not None:
                (h, w) = frame.shape[:2]
                blob = cv2.dnn.blobFromImage(cv2.resize(frame, DNN_IN_SIZE),
                                             DNN_SCALE, DNN_IN_SIZE, DNN_MEAN, swapRB=False, crop=False)
                try:
                    self.net.setInput(blob)
                    detections = self.net.forward()
                except Exception as e:
                    self.ok = False
                    self._last = {"ok": False, "backend": self.backend, "fps_obj": round(self._fps,2),
                                  "objects": [], "ts": int(time.time()*1000), "error": f"forward failed: {e}"}
                    time.sleep(0.1)
                    continue

                boxes_all: List[List[int]] = []
                confs_all: List[float] = []
                labels_all: List[str] = []

                # detections: [1,1,N,7] => [img_id, class_id, conf, x1,y1,x2,y2]
                for i in range(detections.shape[2]):
                    conf = float(detections[0, 0, i, 2])
                    conf_max = max(conf_max, conf)
                    if conf < OBJ_CONF_THRESH:
                        continue
                    idx = int(detections[0, 0, i, 1])
                    if idx < 0 or idx >= len(OBJ_CLASSES):
                        continue
                    label = OBJ_CLASSES[idx]
                    if label != "person" and label not in ANIMAL_CLASSES:
                        continue
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    x1, y1, x2, y2 = box.astype("int")
                    x, y = max(0, x1), max(0, y1)
                    rw, rh = max(0, x2 - x), max(0, y2 - y)
                    if rw * rh <= 0: continue
                    boxes_all.append([int(x), int(y), int(rw), int(rh)])
                    confs_all.append(conf)
                    labels_all.append(label)

                keep = self._nms(boxes_all, confs_all)
                for k in keep:
                    out_objects.append({
                        "label": labels_all[k],
                        "conf": float(confs_all[k]),
                        "box": [int(v) for v in boxes_all[k]]
                    })

                out_objects.sort(key=lambda o: o["conf"], reverse=True)
                out_objects = out_objects[:15]

            with self._lock:
                self._last_conf_max = conf_max
                self._last = {
                    "ok": bool(self.ok),
                    "backend": self.backend,
                    "fps_obj": round(self._fps, 2),
                    "objects": out_objects,
                    "ts": int(time.time()*1000),
                    "proto": self.proto_path,
                    "weights": self.weights_path,
                    "conf_max": round(conf_max, 3),
                }

            self._frames += 1
            now = time.time()
            if now - self._last_fps_tick >= 1.0:
                self._fps = self._frames / (now - self._last_fps_tick)
                self._frames = 0
                self._last_fps_tick = now

            elapsed = time.time() - t0
            if elapsed < min_interval:
                time.sleep(max(0.0, min_interval - elapsed))

    def get(self) -> Dict[str, Any]:
        with self._lock:
            return dict(self._last)

objects_det = ObjectsDetector(grabber)
objects_det.start()

# ===================== ENDPOINTS =====================
@app.get("/status")
def status():
    s1 = grabber.status()
    s2 = detector.get_result()
    return {"ok": True, "camera_ip": s1["ip"], "model": "balanced_detector",
            "fps_in": s1["fps_in"], "hasFrame": s1["hasFrame"], "age_ms": s1["age_ms"], **s2}

@app.post("/config")
def set_config(cfg: ConfigIn):
    global CAMERA_IP
    CAMERA_IP = cfg.camera_ip
    grabber.start(CAMERA_IP)
    return {"ok": True, "camera_ip": CAMERA_IP}

@app.get("/snapshot")
def snapshot():
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        jpeg = placeholder_jpeg("NO LIVE FRAME")
    return Response(content=jpeg, media_type="image/jpeg")

@app.get("/detect")
def detect():
    res = detector.get_result()
    if res.get("ts", 0) and (int(time.time() * 1000) - res["ts"] <= MAX_RESULT_AGE_MS):
        res["objects"] = objects_det.get()
        return res
    jpeg = grabber.get_latest_jpeg(max_age_ms=MAX_FRAME_AGE_MS)
    if jpeg is None:
        return {"ok": False, "error": "no recent frame"}
    arr = np.frombuffer(jpeg, dtype=np.uint8)
    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if frame is None:
        return {"ok": False, "error": "decode failed"}
    mask_hsv = hsv_fire_mask(frame)
    ratio_hsv = float(np.count_nonzero(mask_hsv)) / float(mask_hsv.size)
    v_mean = float(np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)[..., 2])) / 255.0
    score_raw = min(1.0, ratio_hsv * 4.0 + v_mean * 0.2)
    is_fire = bool(score_raw >= HYST_HIGH)
    return {
        "ok": True, "isFire": is_fire,
        "score": round(float(score_raw), 3),
        "score_raw": round(float(score_raw), 3),
        "score_ema": round(float(score_raw), 3),
        "boxes": [], "ts": int(time.time() * 1000), "fallback": True,
        "objects": objects_det.get()
    }

@app.get("/objects")
def objects(conf: float = Query(None, description="override confidence threshold (0..1)")):
    global OBJ_CONF_THRESH
    if conf is not None:
        # permite ajustar on-the-fly sem reiniciar
        OBJ_CONF_THRESH = max(0.05, min(0.95, float(conf)))
    return objects_det.get()

@app.get("/debug_models")
def debug_models():
    o = objects_det.get()
    return {
        "ok": True,
        "fire_model": "heuristic-balanced",
        "objects_backend": o.get("backend", "mobilenet-ssd"),
        "objects_ok": o.get("ok", False),
        "fps_obj": o.get("fps_obj", 0.0),
        "num_objects": len(o.get("objects", [])),
        "proto": o.get("proto"),
        "weights": o.get("weights"),
        "conf_max": o.get("conf_max"),
        "error": o.get("error"),
        "conf_thresh": OBJ_CONF_THRESH,
        "nms_thresh": OBJ_NMS_THRESH,
    }




Teste r√°pido (para achar a causa)




Reinicie:




uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload





Abra no navegador (no PC do servidor):






http://SEU_PC:8000/debug_models

Confira:



objects_ok: true


proto aponta para um dos candidatos (ex.: ./models/deploy.prototxt ou ...MobileNetSSD_deploy.prototxt)


weights aponta para mobilenet_iter_73000.caffemodel ou MobileNetSSD_deploy.caffemodel






http://SEU_PC:8000/objects

Fique na frente da c√¢mera por 2‚Äì3s e veja conf_max subir (ex.: 0.6, 0.8), e aparecer items em objects.






Se ainda vier vazio:






Tente baixar o limiar no voo:

http://SEU_PC:8000/objects?conf=0.15


Recarregue /objects.

Se ent√£o aparecer, ficou claro que era threshold alto para a sua cena.

Depois fixe o valor que funcionar melhor.






Se objects_ok: false ou error: load failed:






√â par de arquivos incompat√≠vel. Use deploy.prototxt do mesmo repo do mobilenet_iter_73000.caffemodel (o que voc√™ clonou).


Atualize OpenCV: pip install --upgrade opencv-python.





No app (C√¢mera)


Com o servidor ok (objects preenchido), a tela que te passei j√° mostra:




üî• fogo (como antes)


üë§ Pessoas: N


üêæ Animais: M




Se /objects mostrar itens mas o app n√£o contar, me manda um pequeno JSON retornado por /detect (s√≥ as primeiras linhas) para eu ajustar o caminho exato ‚Äî mas j√° deixei j.objects.objects (estrutura que sai do servidor acima).


Vamos ver o que aparece no /debug_models (principalmente proto, weights, conf_max) e se baixar conf faz os objetos surgirem.




























































Vamos direto ao ponto: o servidor est√° ok, mas a tela C√¢mera n√£o estava exibindo o feedback de pessoas/animais que o endpoint j√° envia. Abaixo te passo:




como testar o servidor rapidinho (para confirmar que ele est√° detectando),


o arquivo completo CameraScreen.tsx com as mudan√ßas para mostrar contagem est√°vel de pessoas e animais quando voc√™ clica em Detectar (sem depender de novas libs nem desenhar caixas).





1) Teste r√°pido do servidor (confirma se est√° detectando)


No PC do servidor, com a c√¢mera apontando para algu√©m/animal:






Abra http://SEU_PC:8000/debug_models

‚Üí Deve ter: "objects_backend":"mobilenet-ssd", "objects_ok": true.






Abra http://SEU_PC:8000/objects

‚Üí Deve aparecer algo assim quando h√° algu√©m no quadro:


{
  "ok": true,
  "backend": "mobilenet-ssd",
  "objects": [
    {"label":"person","conf":0.82,"box":[...]}
  ]
}







Se /objects trouxer lista vazia mesmo com pessoa no quadro, me diga que ajusto os thresholds; mas normalmente aparece.



2) Substitua sua tela por ESTE CameraScreen.tsx (COMPLETO)


Coloque em:

HydroBotApp2/src/screens/CameraScreen.tsx




O que muda: enquanto Detectar estiver ativo, o app consulta /detect ~5 Hz e mostra dois badges com contagem de üë§ Pessoas e üêæ Animais. N√£o precisa de bibliotecas novas. O v√≠deo continua com STREAM (r√°pido) ‚â•20 fps ou SNAPSHOT (fallback), como voc√™ j√° tinha.




// HydrobotApp2/src/screens/CameraScreen.tsx
import { useEffect, useMemo, useRef, useState } from "react";
import {
  View, Text, TextInput, Pressable, StyleSheet, PanResponder,
  GestureResponderEvent, PanResponderGestureState, Image, Animated,
} from "react-native";
import { WebView } from "react-native-webview";
import { saveEventFromServer } from "../storage/fireLog";
import { useLanguage } from "../context/LanguageContext";

const PALETTE = { bg: "#000000", card: "#0d0d0d", border: "#1a1a1a", red: "#E53B2F", white: "#ffffff" };

/* ============================
   A) VISUAL 1 ‚Äî STREAM (‚â•20fps)
   ============================ */
function LiveMJPEG({ ip }: { ip: string }) {
  const html = `
    <html><head><meta name="viewport" content="width=device-width, initial-scale=1">
      <style>
        html,body{margin:0;padding:0;background:#000;height:100%;}
        .wrap{position:fixed;inset:0;display:flex;align-items:center;justify-content:center;background:#000;}
        img{max-width:100%;max-height:100%;object-fit:contain;background:#000;}
      </style>
    </head>
    <body>
      <div class="wrap">
        <img src="http://${ip}:81/stream" />
      </div>
    </body></html>
  `;
  return (
    <WebView
      originWhitelist={["*"]}
      source={{ html }}
      javaScriptEnabled
      allowsInlineMediaPlayback
      mediaPlaybackRequiresUserAction={false}
      automaticallyAdjustContentInsets={false}
      style={{ flex: 1, backgroundColor: "black" }}
    />
  );
}

/* ==========================================
   B) VISUAL 2 ‚Äî SNAPSHOT com crossfade (fallback)
   ========================================== */
function CrossfadeImage({
  currentUri,
  nextUri,
  onNextLoadStart,
  onNextShown,
}: {
  currentUri: string;
  nextUri: string;
  onNextLoadStart: () => void;
  onNextShown: () => void;
}) {
  const fade = useRef(new Animated.Value(0)).current;
  const [showNext, setShowNext] = useState(false);
  const lastNextRef = useRef<string>("");

  useEffect(() => {
    if (!nextUri || nextUri === lastNextRef.current) return;
    lastNextRef.current = nextUri;
    setShowNext(true);
  }, [nextUri]);

  return (
    <View style={{ flex: 1, backgroundColor: "black" }}>
      {currentUri ? (
        <Image source={{ uri: currentUri }} style={{ flex: 1, width: "100%" }} resizeMode="contain" />
      ) : null}

      {showNext ? (
        <Animated.View style={[StyleSheet.absoluteFill, { opacity: fade }]}>
          <Image
            source={{ uri: nextUri }}
            style={{ flex: 1, width: "100%" }}
            resizeMode="contain"
            onLoadStart={onNextLoadStart}
            onError={() => { onNextShown(); }}
            onLoadEnd={() => {
              Animated.timing(fade, { toValue: 1, duration: 80, useNativeDriver: true }).start(() => {
                onNextShown();
                fade.setValue(0);
                setShowNext(false);
              });
            }}
          />
        </Animated.View>
      ) : null}
    </View>
  );
}

/* ============================
   TEXTOS
   ============================ */
const textsByLang = {
  pt: {
    espIp: "ESP IP:", test: "Testar", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "BOMBA ON", pumpOff: "BOMBA OFF", server: "Servidor:",
    detect: "Detectar", detecting: "Detectando", saving: "Salvando...",
    statusFail: "Falha ao conectar. Confira o Wi-Fi e IP.",
    noVideo: "Sem v√≠deo (snapshot). Verifique o servidor.",
    fireOn: (s:number)=>`üî• FOGO ‚Ä¢ score ${s.toFixed(2)}`, fireOff: (s:number)=>`Sem fogo ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Evento salvo em ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vis√£o:",
    stream: "STREAM (r√°pido)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`üë§ Pessoas: ${n}`,
    animals: (n:number)=>`üêæ Animais: ${n}`,
  },
  en: {
    espIp: "ESP IP:", test: "Test", ledOn: "LED ON", ledOff: "LED OFF",
    pumpOn: "PUMP ON", pumpOff: "PUMP OFF", server: "Server:",
    detect: "Detect", detecting: "Detecting", saving: "Saving...",
    statusFail: "Failed to connect. Check Wi-Fi/IP.",
    noVideo: "No video (snapshot). Check the server.",
    fireOn: (s:number)=>`üî• FIRE ‚Ä¢ score ${s.toFixed(2)}`, fireOff: (s:number)=>`No fire ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Event saved at ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "View:",
    stream: "STREAM (fast)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`üë§ People: ${n}`,
    animals: (n:number)=>`üêæ Animals: ${n}`,
  },
  es: {
    espIp: "ESP IP:", test: "Probar", ledOn: "LED ENC.", ledOff: "LED APAG.",
    pumpOn: "BOMBA ENC.", pumpOff: "BOMBA APAG.", server: "Servidor:",
    detect: "Detectar", detecting: "Detectando", saving: "Guardando...",
    statusFail: "Error de conexi√≥n. Revisa Wi-Fi/IP.",
    noVideo: "Sin v√≠deo (snapshot). Revisa el servidor.",
    fireOn: (s:number)=>`üî• FUEGO ‚Ä¢ score ${s.toFixed(2)}`, fireOff: (s:number)=>`Sin fuego ‚Ä¢ score ${s.toFixed(2)}`,
    eventSavedAt: (ts:string)=>`Evento guardado a las ${ts}`,
    placeholderIp: "192.168.4.1",
    placeholderServer: "http://192.168.4.2:8000",
    view: "Vista:",
    stream: "STREAM (r√°pido)",
    snapshot: "SNAPSHOT (fallback)",
    people: (n:number)=>`üë§ Personas: ${n}`,
    animals: (n:number)=>`üêæ Animales: ${n}`,
  },
};

const DEFAULT_IP = "192.168.4.1";
const DEFAULT_SERVER = "http://192.168.4.2:8000";

type ObjDet = { label: string; conf: number; box: [number, number, number, number] };

export default function CameraScreen() {
  const { lang } = useLanguage();
  const T = textsByLang[lang];

  // conex√µes
  const [ip, setIp] = useState(DEFAULT_IP);
  const [server, setServer] = useState(DEFAULT_SERVER);

  // estados ESP
  const [isChecking, setIsChecking] = useState(false);
  const [statusText, setStatusText] = useState("‚Äî");
  const [ledOn, setLedOn] = useState(false);
  const [pumpOn, setPumpOn] = useState(false);

  // detec√ß√£o
  const [detectOn, setDetectOn] = useState(false);
  const [isFire, setIsFire] = useState(false);
  const [fireScore, setFireScore] = useState(0);

  // pessoas/animais (feedback visual)
  const [peopleCount, setPeopleCount] = useState(0);
  const [animalCount, setAnimalCount] = useState(0);

  // registro autom√°tico
  const [saving, setSaving] = useState(false);
  const lastSaveRef = useRef(0);
  const wasFireRef = useRef(false);
  const SAVE_COOLDOWN_MS = 5000;

  // modo de visualiza√ß√£o
  const [useStream, setUseStream] = useState(true);

  // v√≠deo (snapshot double-buffer)
  const [currentFrameUri, setCurrentFrameUri] = useState("");
  const [nextFrameUri, setNextFrameUri] = useState("");
  const loadingNextRef = useRef(false);

  // joystick (UI)
  const [joy, setJoy] = useState({ x: 0, y: 0 });
  const [dragging, setDragging] = useState(false);

  // URLs do ESP
  const statusUrl = useMemo(() => `http://${ip}/status`, [ip]);
  const ledUrl = useMemo(() => (on: boolean) => `http://${ip}/led?on=${on ? "1" : "0"}`, [ip]);
  const pumpUrl = useMemo(() => (on: boolean) => `http://${ip}/pump?on=${on ? "1" : "0"}`, [ip]);

  /* ===== ESP STATUS ===== */
  async function pingStatus() {
    try {
      setIsChecking(true);
      const r = await fetch(statusUrl, { method: "GET" });
      const j = await r.json();
      setLedOn(!!j.led);
      setPumpOn(!!j.pump);
      setStatusText(`OK ‚Ä¢ ip:${j.ip} ‚Ä¢ mode:${j.mode} ‚Ä¢ led:${j.led ? "on" : "off"} ‚Ä¢ pump:${j.pump ? "on" : "off"}`);
    } catch {
      setStatusText(T.statusFail);
    } finally {
      setIsChecking(false);
    }
  }
  async function toggleLed() { try { const t = !ledOn; await fetch(ledUrl(t)); setLedOn(t); } catch { setStatusText(T.statusFail); } }
  async function togglePump() { try { const t = !pumpOn; await fetch(pumpUrl(t)); setPumpOn(t); } catch { setStatusText(T.statusFail); } }

  useEffect(() => { pingStatus(); const id = setInterval(pingStatus, 5000); return () => clearInterval(id); }, [statusUrl]);

  /* ===== V√≠deo via snapshots ‚Äî ~25fps (fallback) ===== */
  useEffect(() => {
    if (useStream) return;
    let stop = false;
    const FPS_INTERVAL = 40;
    setCurrentFrameUri(`${server.replace(/\/+$/, "")}/snapshot?ts=${Date.now()}`);
    const tick = () => {
      if (stop) return;
      if (!loadingNextRef.current) {
        const url = `${server.replace(/\/+$/, "")}/snapshot?ts=${Date.now()}`;
        setNextFrameUri(url);
      }
      setTimeout(tick, FPS_INTERVAL);
    };
    tick();
    return () => { stop = true; };
  }, [server, useStream]);

  function onNextLoadStart() { loadingNextRef.current = true; }
  function onNextShown() {
    if (nextFrameUri) setCurrentFrameUri(nextFrameUri);
    loadingNextRef.current = false;
  }

  /* ===== DETECT LOOP ===== */
  useEffect(() => {
    if (!detectOn) { setPeopleCount(0); setAnimalCount(0); return; }
    let stop = false;
    const loop = async () => {
      try {
        const r = await fetch(`${server.replace(/\/+$/, "")}/detect`, { method: "GET" });
        const j = await r.json();
        if (!stop && j && j.ok) {
          // fogo
          setIsFire(!!j.isFire);
          setFireScore(Number(j.score || 0));

          // pessoas/animais vindos do servidor
          const objsRoot = (j.objects && j.objects.objects) ? j.objects.objects : [];
          const people = (objsRoot as ObjDet[]).filter(o => o.label === "person").length;
          const animals = (objsRoot as ObjDet[]).filter(o => o.label !== "person").length;

          setPeopleCount(people);
          setAnimalCount(animals);
        }
      } catch {
        if (!stop) {
          setIsFire(false); setFireScore(0);
          setPeopleCount(0); setAnimalCount(0);
        }
      } finally {
        if (!stop) setTimeout(loop, 120); // ~8‚Äì9 Hz de estado (leve)
      }
    };
    loop();
    return () => { stop = true; };
  }, [detectOn, server]);

  /* ===== Registro autom√°tico ===== */
  useEffect(() => {
    const rising = !wasFireRef.current && isFire;
    const now = Date.now();
    const cooldownOk = now - lastSaveRef.current >= SAVE_COOLDOWN_MS;
    if (detectOn && rising && cooldownOk && !saving) {
      (async () => {
        try {
          setSaving(true);
          await saveEventFromServer(server);
          lastSaveRef.current = Date.now();
          setStatusText(T.eventSavedAt(new Date(lastSaveRef.current).toLocaleString()));
        } catch {
          setStatusText(T.noVideo);
        } finally {
          setSaving(false);
        }
      })();
    }
    wasFireRef.current = isFire;
  }, [detectOn, isFire, server, saving, T]);

  /* ===== Joystick ===== */
  const RADIUS = 64, KNOB_R = 22;
  const pan = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,
      onPanResponderGrant: () => setDragging(true),
      onPanResponderMove: (_e: GestureResponderEvent, g: PanResponderGestureState) => {
        let nx = g.dx / RADIUS, ny = g.dy / RADIUS;
        const len = Math.hypot(nx, ny); if (len > 1) { nx /= len; ny /= len; }
        setJoy({ x: nx, y: -ny });
      },
      onPanResponderRelease: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
      onPanResponderTerminate: () => { setDragging(false); setJoy({ x: 0, y: 0 }); },
    })
  ).current;

  const knobLeft = joy.x * RADIUS, knobTop = -joy.y * RADIUS;

  return (
    <View style={styles.container}>
      {/* Linha: ESP + LED + BOMBA */}
      <View style={styles.topbar}>
        <Text style={styles.label}>{T.espIp}</Text>
        <TextInput
          value={ip}
          onChangeText={setIp}
          placeholder={T.placeholderIp}
          autoCapitalize="none"
          autoCorrect={false}
          style={styles.input}
          keyboardType="numeric"
        />
        <Pressable onPress={pingStatus} style={styles.btn}>
          <Text style={styles.btnText}>{isChecking ? "..." : T.test}</Text>
        </Pressable>

        <Pressable onPress={toggleLed} style={[styles.btn, ledOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{ledOn ? T.ledOn : T.ledOff}</Text>
        </Pressable>

        <Pressable onPress={togglePump} style={[styles.btn, pumpOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{pumpOn ? T.pumpOn : T.pumpOff}</Text>
        </Pressable>
      </View>

      {/* Linha: Servidor IA + Detectar + Modo de Vis√£o */}
      <View style={styles.statusRow}>
        <Text style={styles.label}>{T.server}</Text>
        <TextInput
          value={server}
          onChangeText={setServer}
          placeholder={T.placeholderServer}
          autoCapitalize="none"
          autoCorrect={false}
          style={[styles.input, { flex: 1 }]}
        />
        <Pressable onPress={() => setDetectOn((v) => !v)} style={[styles.btn, detectOn ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{detectOn ? (saving ? T.saving : T.detecting) : T.detect}</Text>
        </Pressable>
      </View>

      {/* Status curto */}
      <View style={[styles.statusRow, { paddingTop: 4, paddingBottom: 8 }]}>
        <Text numberOfLines={2} style={styles.status}>{statusText}</Text>
      </View>

      {/* Seletor de vis√£o */}
      <View style={[styles.statusRow, { gap: 6 }]}>
        <Text style={styles.label}>{T.view}</Text>
        <Pressable onPress={() => setUseStream(true)}  style={[styles.btn, useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.stream}</Text>
        </Pressable>
        <Pressable onPress={() => setUseStream(false)} style={[styles.btn, !useStream ? styles.btnOn : styles.btnOff]}>
          <Text style={styles.btnText}>{T.snapshot}</Text>
        </Pressable>
      </View>

      {/* Banners de estado */}
      {detectOn && (
        <>
          <View style={[styles.fireBanner, isFire ? styles.fireOn : styles.fireOff]}>
            <Text style={styles.fireText}>{isFire ? T.fireOn(fireScore) : T.fireOff(fireScore)}</Text>
          </View>

          {/* NOVO: badges de pessoas / animais */}
          <View style={styles.badgesRow}>
            <View style={[styles.badge, { backgroundColor: "#1b2a4b" }]}>
              <Text style={styles.badgeTxt}>{T.people(peopleCount)}</Text>
            </View>
            <View style={[styles.badge, { backgroundColor: "#2b3a1b" }]}>
              <Text style={styles.badgeTxt}>{T.animals(animalCount)}</Text>
            </View>
          </View>
        </>
      )}

      {/* V√≠deo (STREAM r√°pido OU SNAPSHOT fallback) */}
      <View style={{ flex: 1 }}>
        {useStream ? (
          <LiveMJPEG ip={ip} />
        ) : (
          <CrossfadeImage
            currentUri={currentFrameUri}
            nextUri={nextFrameUri}
            onNextLoadStart={onNextLoadStart}
            onNextShown={onNextShown}
          />
        )}
      </View>

      {/* Joystick overlay (UI) */}
      <View pointerEvents="box-none" style={StyleSheet.absoluteFill}>
        <View style={[styles.joyWrap, { width: RADIUS * 2 + 24, height: RADIUS * 2 + 24 }]} {...pan.panHandlers}>
          <View style={[styles.joyBase, { width: RADIUS * 2, height: RADIUS * 2, borderRadius: RADIUS }]} />
          <View
            style={[
              styles.joyKnob,
              {
                width: KNOB_R * 2, height: KNOB_R * 2, borderRadius: KNOB_R,
                transform: [{ translateX: knobLeft }, { translateY: knobTop }],
                opacity: dragging ? 1 : 0.9,
              },
            ]}
          />
          <Text style={styles.joyText}>x: {joy.x.toFixed(2)}   y: {joy.y.toFixed(2)}</Text>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: PALETTE.bg },

  topbar: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 10,
    gap: 8,
    backgroundColor: PALETTE.card,
  },
  label: { color: "#cfd3d8", fontSize: 12 },
  input: {
    backgroundColor: PALETTE.bg,
    color: "white",
    borderRadius: 8,
    paddingHorizontal: 10,
    paddingVertical: 8,
    borderWidth: 1,
    borderColor: "#1e2a4d",
    minWidth: 110,
  },
  btn: {
    backgroundColor: "#2b48ff",
    paddingHorizontal: 10,
    paddingVertical: 10,
    borderRadius: 10,
  },
  btnOn: { backgroundColor: "#17a34a" },
  btnOff: { backgroundColor: "#374151" },
  btnText: { color: "white", fontWeight: "600" },

  statusRow: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 12,
    paddingVertical: 8,
    gap: 8,
    backgroundColor: "#0f1730",
  },
  status: { color: "#cbd5ff", flex: 1, fontSize: 12 },

  fireBanner: { alignItems: "center", justifyContent: "center", paddingVertical: 6 },
  fireOn: { backgroundColor: "#8b0000" },
  fireOff: { backgroundColor: "#223" },
  fireText: { color: "white", fontWeight: "800" },

  // NOVO: badges de pessoas/animais
  badgesRow: {
    flexDirection: "row",
    gap: 8,
    paddingHorizontal: 12,
    paddingVertical: 6,
    backgroundColor: "#0b0f1e",
  },
  badge: {
    paddingHorizontal: 10,
    paddingVertical: 6,
    borderRadius: 8,
  },
  badgeTxt: { color: "white", fontWeight: "700" },

  // Joystick
  joyWrap: { position: "absolute", bottom: 24, left: 24, alignItems: "center", justifyContent: "center" },
  joyBase: { position: "absolute", backgroundColor: "rgba(255,255,255,0.08)", borderWidth: 2, borderColor: "rgba(255,255,255,0.14)" },
  joyKnob: { position: "absolute", backgroundColor: "rgba(43,72,255,0.9)", borderWidth: 2, borderColor: "rgba(255,255,255,0.85)" },
  joyText: { position: "absolute", bottom: -22, color: "#cbd5ff", fontSize: 12 },
});




Checklist r√°pido




Servidor rodando (/debug_models com objects_ok: true).


App: ‚ÄúServidor‚Äù = http://SEU_PC:8000.


C√¢mera ‚Üí bot√£o Detectar.


Veja os badges atualizando: üë§ Pessoas: N e üêæ Animais: M.




Se /objects mostra itens, mas o app ainda n√£o conta, me manda um exemplo de JSON retornado por /detect (primeiras linhas) para eu alinhar o path exato (j.objects.objects).























































(.venv) PS D:\loud2025\hydrobot-server> uvicorn server_heuristic:app --host 0.0.0.0 --port 8000 --reload   
INFO:     Will watch for changes in these directories: ['D:\\loud2025\\hydrobot-server']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [17572] using WatchFiles
Process SpawnProcess-1:
Traceback (most recent call last):
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\process.py", line 313, in _bootstrap
    self.run()
    ~~~~~~~~^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
    ~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 65, in run
    return asyncio.run(self.serve(sockets=sockets))
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run 
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run 
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 725, in 
run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 69, in serve
    await self._serve(sockets)
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\server.py", line 76, in _serve
    config.load()
    ~~~~~~~~~~~^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\config.py", line 434, in load
    self.loaded_app = import_from_string(self.app)
                      ~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "D:\loud2025\hydrobot-server\.venv\Lib\site-packages\uvicorn\importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
  File "C:\Users\yagohmz\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py", line 88, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 1022, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1160, in get_code
  File "<frozen importlib._bootstrap_external>", line 1090, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "D:\loud2025\hydrobot-server\server_heuristic.py", line 259
    self._thread = threading.Thread(target=self._run, daemon=True)
IndentationError: unexpected indent
